[{"title":"博客文章阅读数统计","url":"/Arknight-notes/posts/17688.html","content":"不蒜子 | 给网站、博客文章添加阅读次数统计效果演示：-\n\n\n\n\n本站总访问量次\n\n\n-\n\n\n本站访客数人次\n\n\n-\n一行脚本+一行标签，搞定一切。追求极致的用户可以进行任意DIY。\n不蒜子官网：http://busuanzi.ibruce.info/\n一、安装脚本（必选）要使用不蒜子必须在页面中引入busuanzi.js，目前最新版如下。\n&lt;script async src=\"//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js\"&gt;&lt;/script&gt;\n不蒜子可以给任何类型的个人站点使用，如果你是用的hexo，打开themes/你的主题/layout/_partial/footer.ejs添加上述脚本即可，当然你也可以添加到 header 中。\n二、安装标签（可选）\n只需要复制相应的html标签到你的网站要显示访问量的位置即可。您可以随意更改不蒜子标签为自己喜欢的显示效果，内容参考第三部分扩展开发。根据你要显示内容的不同，这分几种情况。\n1、显示站点总访问量要显示站点总访问量，复制以下代码添加到你需要显示的位置。有两种算法可选：\n算法a：pv的方式，单个用户连续点击n篇文章，记录n次访问量。\n本站总访问量&lt;span id=\"busuanzi_value_site_pv\"&gt;&lt;/span&gt;次\n算法b：uv的方式，单个用户连续点击n篇文章，只记录1次访客数。\n本站访客数&lt;span id=\"busuanzi_value_site_uv\"&gt;&lt;/span&gt;人次\n如果你是用的hexo，打开themes/你的主题/layout/_partial/footer.ejs添加即可。\n实例效果参考：\nhttps://blog.ccswust.org/busuanzi/\n2、显示单页面访问量要显示每篇文章的访问量，复制以下代码添加到你需要显示的位置。\n算法：pv的方式，单个用户点击1篇文章，本篇文章记录1次阅读量。\n本站总访问量&lt;span id=\"busuanzi_value_site_pv\"&gt;&lt;/span&gt;次\n代码中文字是可以修改的，只要保留id正确即可。\n注意：不蒜子为保持极简，暂不支持在站点文章摘要列表中（如首页）逐个显示每篇文章的阅读次数，如果您非常需要这一功能，可以留言。根据需要程度再考虑开发相应的功能。\n实例效果参考：\nhttps://blog.ccswust.org/busuanzi/pv.html\n注意：不蒜子为保持极简，暂不支持在站点文章摘要列表中（如首页）逐个显示每篇文章的阅读次数，如果您非常需要这一功能，可以留言。根据需要程度再考虑开发相应的功能。\n3、显示站点总访问量和单页面访问量本站访客数&lt;span id=\"busuanzi_value_site_uv\"&gt;&lt;/span&gt;人次\n实例效果参考：\nhttps://blog.ccswust.org/busuanzi/ip.html\n4、只计数不显示只安装脚本代码，不安装标签代码。\n至此，不蒜子已经可以正常运行\n附录：扩展开发（自定义）不蒜子之所以称为极客的算子，正是因为不蒜子自身只提供标签+数字，至于显示的style和css动画效果，任你发挥。\n\n**busuanzi_value_site_pv** 的作用是异步回填访问数，这个id一定要正确。\n**busuanzi_container_site_pv**的作用是为防止计数服务访问出错或超时（3秒）的情况下，使整个标签自动隐藏显示，带来更好的体验。这个id可以省略。\n\n因此，你也可以使用极简模式：\n本站总访问量&lt;span id=\"busuanzi_value_site_pv\"&gt;&lt;/span&gt;次本站访客数  &lt;span id=\"busuanzi_value_site_uv\"&gt;&lt;/span&gt;  人次本文总阅读量&lt;span id=\"busuanzi_value_page_pv\"&gt;&lt;/span&gt;次\n或者个性化一下：\nTotal &lt;span id=\"busuanzi_value_site_pv\"&gt;&lt;/span&gt; views.您是xxx的第&lt;/span&gt;个小伙伴 Hits\n1、我只要统计不显示？ 只引入busuanzi.js，不引入显示标签即可。\n2、你的标签太丑了，我想美化一下可以么？ 可以的，您可以用自己站点的css进行控制，只要内层span的id正确以便回填访问次数即可，甚至标签都可以不是span。\n3、中文字体太丑了，我的主题不适合？ 您可以将本站总访问量xxx次改成view xxx times等英文以获得更和谐的显示效果。\n4、在访问量数据未取回来之前，我不想让页面显示为诸如“本站总访问量 次”，显得太low，怎么办？ 只需要如下css，不蒜子执行完毕会自动将标签显示出来，其他以此类推：\n `本站总访问量次`&lt;/span&gt;\n上面的做法还是很low？！看下这个https://blog.ccswust.org/busuanzi/diy.html 右键看下源码，没加载出来前就显示个菊花转转转: 首先，你要引入font-awesome字体：\n&lt;link rel=\"stylesheet\" href=\"//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css\"&gt;或&lt;link rel=\"stylesheet\" href=\"//cdn.bootcss.com/font-awesome/4.3.0/css/font-awesome.min.css\"&gt;\n其次，修改不蒜子标签：\n&lt;span id=\"busuanzi_value_page_pv\"&gt;&lt;i class=\"fa fa-spinner\"&gt;&lt;/i&gt;&lt;/span&gt; Hits或（旋转效果）&lt;span id=\"busuanzi_value_page_pv\"&gt;&lt;i class=\"fa fa-spinner fa-spin\"&gt;&lt;/i&gt;&lt;/span&gt; Hits\n Hits或（旋转效果） Hits\ns\n","categories":["博客美化"],"tags":["美化"]},{"title":"何加盐｜中文互联网正在加速崩塌","url":"/Arknight-notes/posts/14940.html","content":"何加盐｜中文互联网正在加速崩塌05/23/2024\n1先问你一个小问题：\n如果我们在百度上搜索“马云”这两个字，把时间设定在1998年到2005年，能搜出来的信息，大概有多少条呢？是1亿条，还是1000万条，还是100万条？\n我在几个群问过，大家普遍的猜想是，应该是百万或者千万的级别。毕竟，互联网信息如此浩如烟海。马云作为那个时代的风云企业家，在网上留下的痕迹肯定是非常多的。\n但实际上用百度搜索，选定日期范围为“1998年5月22日到2005年5月22日”，含有马云的信息，总共是1条（2024年5月22日数据）。\n而仅有的这一条信息，也是虚假的。点进去会发现，文章的发布时间其实是2021年，不属于上面限定的时间段，只是不知怎么回事，它被莫名其妙地搜索出来。\n也就是说，如果我们想要了解那一段时间关于马云的经历、报道、人们对他的讨论、他的讲话、公司的发展史等等，我们能得到的有效的原始信息量，是零。\n你可能会觉得，这是不是百度的问题啊？如果换必应或谷歌，会不会能搜出来？\n我测试过，这两个网站搜出来的有效信息，和百度没有太大区别，比百度略多一些，但也只是个位数。更多的也都是时间紊乱的无效信息，只不过不知道是什么技术原因，被错误地抓取出来。\n你可能还会觉得，是不是因为马云属于比较有争议的人，由于某种不可描述的原因，所以他的信息才无法搜到？\n但实际上，不仅仅是马云的情况如此，我们去搜马化腾、雷军、任正非等，甚至是罗永浩和芙蓉姐姐这样在那个时候红极一时的网红，或周杰伦、李宇春那样曾经火遍全网的明星，结果也都一样的。\n在测试过不同网站、不同人名、不同时间段之后，我发现一个令人震惊的现象：\n几乎所有在那个年代曾经红火过的中文网站，如网易、搜狐、校园BBS、西祠胡同、凯迪猫眼、天涯论坛、校内网（人人网）、新浪博客、百度贴吧、以及大量的个人网站等，在一定年份之前的信息都已经完全消失不见了，甚至大部分网站是所有年份的信息都消失了。唯一例外的是新浪网，还能找到一些十几年前的信息，但也是极少数的寥寥几条，其他99.9999%以上的内容，全都消失了。\n大家都没有意识到一个严重的问题：中文互联网正在迅速崩塌，移动互联网出现之前的中文互联网内容，已经几乎消失殆尽。\n我们原以为，互联网是有记忆的，但没有想到，这种记忆，原来是像金鱼一样的记忆。\n2我之所以注意到这个问题，是因为何加盐公众号的主题是研究牛人，所以我需要经常查找他们的资料。\n这两年来，我有一个非常明显的感觉：网上能找到的原始资料，每年都以断崖式的速度在锐减。之前还能看到一些原始的报道，后来慢慢没有了；之前还能找到主人公的演讲或者他们写的文章，后来慢慢找不到了；之前还能看到很多采访或对谈的视频，后来慢慢消失了。\n似乎有一个吞噬网页的怪兽，它沿着历史的时间线，从过去向着现在吞噬，先是小口小口，然后大口大口，把中文互联网的一切内容，以五年、十年为单位，一口吞掉。\n等我们回过神来，会发现，在移动互联网之前曾经存在过的中文互联网的一切，不管是门户网站、机构官方网站、个人网页，还是校园BBS、公众论坛，还是新浪博客、百度贴吧，还是文件、照片、音乐、视频等，都已消失不见。\n记得十几年前，我曾经因为换电脑，把一些照片和文章打成一个压缩包，存在某BBS上，几年之后发现，那整个BBS都没有了。我曾经用过hotmail的邮箱，里面有很多很珍贵的邮件，后来全都没有了。我还写过人人网、MySpace，后来全都没有了。\n我们曾经以为互联网可以保留一切，但结果是一切都没能保留。\n这让我想起刘慈欣《三体》里面提到过的“二向箔”。歌者文明发现了太阳系有智慧生物的存在，出于宇宙先进文明的清除本能，他们向太阳系扔出一张二向箔，于是，整个太阳系以光的速度从三维坍塌成二维，变化成一张酷似梵高“星空”的画片。一切生命、一切文明的痕迹，从此都不复存在。\n在互联网上，我们已经处于二向箔的吞噬之中。这种二向箔可以称之为“时间的二向箔”，它吞噬的是时间那一维。\n太阳系被歌者文明的二向箔拍扁之后，好歹还留下了一幅《星空》图，而互联网被时间的二向箔吞噬后，只留下一片虚空。\n3为什么会出现这种情况呢？我猜想，主要原因可能是两个：\n一是经济原因。\n网站的存在，需要服务器、需要带宽、需要机房、需要人员运维，还有很多杂七杂八的监管和维护费用，这些都是成本。如果是有战略价值（例如需要向外展示公司想要展示的信息），或者有短期流量价值（例如还时不时有较多的人上来看），同时公司账上也不差钱，那么还会有动力去维持。\n但是如果公司在商业上走了弯路，没钱了，整个网站就会直接死掉。例如人人网就是典型代表。\n即便公司还有钱，从运营的角度来看，如果一个网页一年到头都没有几个人来点击，对公司来说，就成了一笔负担，从经济上最理性的方法，就是直接关掉。搜狐、网易早年的内容大量丢失，以及以天涯论坛为代表的BBS集体消亡，都是这个原因。\n二是监管原因。\n总体而言，互联网信息的监管，是从无到有，从宽到严，从严到更严的过程。以前可以合法存在的内容，后来不符合监管要求了；或者是以前可以灰色存在的内容，后来被定义为黑色了。这些内容都会直接被咔嚓掉。\n还有一些是随着时代的变化，舆论的两极分化越来越极端，以前“只道是平常”的内容，在后来的舆论环境中显得非常尖锐、敏感，尽管不违法，但是可能激化矛盾，形成混乱，监管方也有可能会要求处理掉。\n除了官方部门之外，愤怒的网友，也时时充当着舆论监管员的角色。他们会翻出十几年前某人无意中说的某句话，揪着不放，把人网暴至“社会性死亡”。\n但监管上最重要的影响，还不是监管部门的处理或愤怒网友的攻击，而是它们会造成公司与个人的“自我审查”。\n因为谁也不知道，网站上存在的哪一条内容，某人曾说过的哪一句话，会不会在若干年后，给当事人带来灭顶之灾。最好的办法，就是直接把这些潜在的“定时炸弹”全部清除，也就是把网站关掉或者把内容全部删除。\n当然，除了上述两个原因之外，还会有其他很多原因。\n例如，在南斯拉夫解体之后不久，所有“yu”（南斯拉夫国名Yugoslavia的缩写）这个国际域名之下的网页内容全部消失了。又如，随着版权保护的加强，曾经随处可下载的音乐和电影网站，就都消失了。还有一些机构和个人，纯粹是由于自己的原因，不想在对外展示信息了，就把官网或个人主页关掉等等。\n但这些原因都是次要的、局部的。整个互联网内容系统性的、大规模的消失，主要就是由于经济规律和自我审查。\n本质上，互联网内容和生命一样，也受进化论的支配。其存在的标准只有一条：以尽可能低的成本争取尽可能多的注意力。\n当一个内容能够在互联网上的海量内容中争取到足够多的注意力，而维持这个内容的成本（包括经济成本、监管成本和对抗监管的成本）比其他方式更低时，这个内容就有可能存活在互联网上。只不过它有可能会换一种呈现方式，例如从文字变为图片，从静图变为动图，从动图变为视频，未来可能从二维视频变为三维全息视频等等。承载这个内容的平台也会变迁，从门户网站到BBS，到个人博客，到微博微信，到抖音视频号，到未来可能一个我们不知道什么平台。\n当一个内容不能再吸引到足够多的注意力，或者维持这个内容的成本比其他方式更高时，这个内容就会从互联网上消失。以电脑为浏览端、以网页为载体的传统互联网的集体消亡，只不过是这种“信息进化竞争”的必然结果而已。\n生物的进化秘诀是“物竞天择，适者生存”，而互联网内容的进化秘诀是“信息竞，注意力择，适者生存”。由于网络效应，这种竞争比自然界还要猛烈万倍，残酷万倍。传统互联网不是单个物种式的灭绝，而是几乎所有内容的整体性灭绝。\n每一代新的互联网崛起，旧的互联网必将崩塌，时间二向箔是所有网站、所有内容无可逃避的宿命。\n4如果未来的文明是互联网的文明。我们这一代人，将是没有历史的。因为互联网没有留下我们的痕迹。\n“没有历史”，这件事情重要吗？\n当然很重要。\n我曾经为了写邵亦波的文章，想尽了一切办法，试图找到邵亦波2007年参加《波士堂》节目的原始视频，以及他妻子鲍佳欣以“文爱妈咪”网名在宝宝树社区发了好几年的帖子。最终还是没有找到，只能深深遗憾。\n虽然《红尘已忘邵亦波》那篇文章，依然很受大家欢迎，短短一周就有70多万人阅读，2万多人转发，但我十分肯定，我一定还是错过了某些非常重要的信息。如果它们能呈现在那篇文章里，文章质量会更好。\n但是我找不到，就只能让文章以不完美的方式呈现。\n你可能会觉得：这只是对何加盐这样的研究者和写作者有用，我又不写这样的文章，互联网信息没有就没了，对我又没什么影响。\n真的吗？\n如果我们已经看不到马云的所有演讲，看不到任正非的以《我的父亲母亲》和《一江春水向东流》为代表的所有文章，看不到段永平在雪球的所有发帖，你会不会觉得有点可惜？\n好吧，你说你并不觉得可惜。\n那如果我们已经搜不到黄峥的公众号，看不到张一鸣的微博，上不了王兴的饭否，你会不会觉得有点遗憾？\n好吧，你说你也并不觉得遗憾。\n那如果某一天，知乎如同天涯论坛一样没了，豆瓣就像人人网一样消失，B站好比新浪博客一样已无人问津，你会不会有点心痛？\n如果某一天，你喜欢的微博博主所有的微博只显示“作者已设置只展示半年内微博，此微博已不可见”，你常看的公众号只显示“此账号已被屏蔽，内容无法查看”，你在抖音或小红书搜索某些信息，结果显示“作者已清空全部内容”……\n甚至，微博、公众号、抖音、小红书，就像曾经存在过的bbs、贴吧、空间、博客一样，全部消亡……\n你会不会为此难过哪怕是短短的一分钟？\n作为传统互联网的一代人，七零后、八零后已经找不回我们的历史。因为它们已经全部消失了。\n新生代也许还能看看朋友圈，但是朋友圈也越来越多“三天可见”，越来越沉默不语。\n唯一还在热情发圈的，只剩下一水的营销信息。\n未来就连这些营销信息，也终将消亡。\n5如果一件事对我们很重要，而它正在消亡，我们有什么办法挽救它吗？\n有人曾作出这样的尝试。美国有一个网站叫做“Internet Archive”，中文译作“互联网档案馆”，保存了很多原始网页。但是我试过，中文的原始网页，保存的很少，而且使用非常麻烦，搜索功能十分原始低效，和没保存差不多。\n从技术层面来讲，保存从中国有互联网以来，到移动互联网兴起的十来年时间的所有网页，应该并不难，成本也不高，毕竟比起现在的视频时代，原始互联网的那些图文网页，占的空间几乎可以忽略不计。\n问题是，谁来做这件事，有什么动机？\n商业机构不会做。因为没有任何商业利益。\n政府或许可以像建图书馆、博物馆一样，搞一个能保存所有网页的档案馆。但是政府为什么要花钱费力干这件事？除了保存历史之外，似乎也没有其他理由。再说了，就算是政府做了这件事，对普通网民也没有任何意义，因为这个档案馆肯定也会需要一定的登陆权限，以免信息被滥用。\n况且，就算是有机构愿意做这件事，现在也晚了。移动互联网兴起之后，传统互联网的中文内容，几乎已经消失殆尽了。粗略估算，99%以上应该都已经没有了。\n从某种意义上，何加盐写的牛人系列文章，也为保存这些牛人们存在过的历史，做出了一点贡献。如果我没有写他们，很多历史就已经在网上找不到了。但毕竟这也不是原始信息，只是经我整合过的二手信息。\n现在的中文互联网上，这个世纪前十年发生过的所有重大事件，所有留下过深深痕迹的名人，目前还能找到的信息，几乎已经全是经自媒体编辑过的二手信息，甚至是传过多手，早已面目全非的信息。\n关于它们的原始报道没有了，原始视频没有了，原始讲话没有了，原始的网友目击没有了，原始的评论没有了……\n再过一些年，这些二手信息和N手信息，也都会消失。就像那些事件从未发生过、那些人从未存在过一样。\n我们已经无能为力，只能接受现实。\n在未来的互联网时代里，回首看21世纪的前二十年，将是没有历史记录的二十年。\n我们是互联网时代消失的一代人。\n如果你现在还能看到一些中文互联网的古早信息，那只是夕阳的最后一抹余晖。\n如果你明白了它们的转瞬即逝，可能会像临死前的浮士德一样感叹：\n你真美啊，请停留一下吧。\n但那抹余晖，很快将和你这句感叹一起，被时间的二向箔吞没，陷入虚空。\n《三体》中，程心和艾AA还能有幸乘坐唯一的一艘曲率飞船，逃离正在二维化的太阳系。\n而我们，连曲率飞船都没有。\n逃无可逃。\n现在你所看到的、你所创造的几乎所有内容，连同这篇文章，这个平台，终究也会淹没在虚空中。\n—end—\n�**\n"},{"title":"广州大学选课脚本","url":"/Arknight-notes/posts/20869.html","content":"-\n项目地址：\nhttps://github.com/Acring/gzhu-course-seizer\n广大选课脚本\n 本脚本只做学习使用, 禁止用作商业用途\n\n\nversion: 1.0.1\nauthor: acring\n\n简介:\n\n\n广大选课脚本, 可多线程自动选全校性选课和体育选课的课程\n\nusage:\n\n\n安装python3\n安装第三方库\npip install requests\npip install beautifulsoup4\n\n\n点开run.py, 按提示修改上面的学号,密码,目标老师等信息\n\ndata = {    \"tag\": \"xxx\",  # 标志    \"username\": \"xxx\",  # 学号    \"password\": \"xxx\",  # 密码    \"cour_type\": \"whole\",  # 选课类型 sport/whole    \"teacher\": \"方碧真\",  # 目标老师    \"index\": 1  # 相同老师,选第几个}\n\npython run.py 运行脚本\n\n\npackage:\nrequests\nbs4\n\n\n运行截图\n\n\n\nbp)\n","categories":["Github项目"]},{"title":"GitHub贡献图表📊","url":"/Arknight-notes/posts/14584.html","content":"在博客网站等地方引用 Github 贡献图表Github 的提交记录，总的来说能够回顾这一年，看看你的工作效率是一种很棒的感觉，而这个小绿色日历实际上是我最喜欢的数据可视化之一。但是没有理由让它只限于出现在 Github 网站上\n来看一下 Github “提交狂魔” @ruanyf 的提交记录\n\n\n以上是如何做到的呢？这可不是截图，而是现成的 API，官网地址：https://ghchart.rshah.org/\n源码在 Github 上开源，仓库地址：https://github.com/2016rshah/githubchart-api\n感谢作者2016rshah提供此 API\n使用怎么使用这个 API 呢？很简单，使用img标签引用即可\n&lt;img src=\"https://ghchart.rshah.org/Zhongye1\" /&gt;\n将src中的Zhongye1使用自己的 Github 用户名替换即可\n也支持修改配色，只需在用户名前加上所需的十六进制颜色代码即可。例如，如果想要一个基于十六进制颜色的蓝色主题图表#409ba5\n自定义颜色例如，如果你想要一个基于十六进制颜色的蓝色主题图表 #409ba5，只需在用户名前加上所需的十六进制颜色代码即可。例如，如果想要一个基于十六进制颜色的蓝色主题图表#409ba5\n&lt;img src=\"https://ghchart.rshah.org/409ba5/Zhongye1\" /&gt;\n效果是这样的\n\nZhongye1's Github Chart \n\n附上HTML拾色器\n link HTML 取色器/拾色器, https://www.runoob.com/tags/html-colorpicker.html, https://picx.zhimg.com/80/v2-7c046fc439e9fab342cda2e9291febdb_720w.webp?source=d16d100b \n如果有任何可以改进的内容，\n可以给作者在 Github 上提交 issue/PR（\n=15% &gt;\n"},{"title":"数学分析笔记其二","url":"/Arknight-notes/posts/27543.html","content":"数分思维导图（分块对比版）\n\n\n\n\n\n\n\n\n\n\n\n\n\n一些公式和解题方法\n\n\n\n\n\n编辑于 2024-07-2707-27 \n","categories":["笔记"]},{"title":"数据结构复习其二","url":"/Arknight-notes/posts/42108.html","content":"-\n——算法、线性表——概念明晰：随机存取、顺序存取、随机存储和顺序存储\n随机存取、顺序存取、随机存储和顺序存储这四个概念是完全不一样的，切不可将之混淆\n很多人包括我可能认为随机存取就是随机存储，顺序存取就是顺序存取，其实不是这样。\n\n下面完整的介绍一下这4个概念\n1、存取结构分为随机存取和非随机存取（又称顺序存取）\n1、随机存取就是直接存取，可以通过下标直接访问的那种数据结构，与存储位置无关。例如数组。\n 非随机存取就是顺序存取，不能通过下标访问了，只能按照存储顺序存取，与存储位置有关，例如链表。\n2、顺序存取就是存取第N个数据时，必须先访问前（N-1）个数据 （list）;\n 随机存取就是存取第N个数据时，不需要访问前（N-1）个数据，直接就可以对第N个数据操作 （array）。\n\n2、存储结构分为顺序存储和随机存储3、顺序存储结构\n\n在计算机中用一组地址连续的存储单元依次存储线性表的各个数据元素，称作线性表的顺序存储结构。\n- 顺序存储结构是存储结构类型中的一种，该结构是把**逻辑上相邻的节点**存储在**物理位置上相邻的存储单元**中，结点之间的逻辑关系由存储单元的邻接关系来体现。 - 由此得到的储结构为顺序存储结构，通常顺序存储结构是借助于计算机程序设计语言（例如c/c++）的数组来描述的。12\n– 主要优点：节省存储空间。\n因为分配给数据的存储单元全用存放结点的数据（不考虑c/c++语言中数组需指定大小的情况），结点之间的逻辑关系没有占用额外的存储空间。采用这种方法时，可实现对结点的随机存取，即每一个结点对应一个序号，由该序号可以直接计算出来结点的存储地址。\n– 主要缺点：不便于修改，对结点的插入、删除运算时可能要移动一系列的结点。\n\n\n\n4、随机存储结构\n在计算机中用一组任意的存储单元存储线性表的数据元素（这组存储单元可以是连续的，也可以是不连续的）。它不要求逻辑上相邻的元素在物理位置上也相邻。因此它没有顺序存储结构所具有的弱点，但也同时失去了顺序表可随机存取的优点。\n\n —随机存储最典型的代表为链式存储：\n链式存储结构特点\n1、比顺序存储结构的存储密度小 （每个节点都由数据域和指针域组成，所以相同空间内假设全存满的话顺序比链式存储更多）。\n2、逻辑上相邻的节点物理上不必相邻。\n3、插入、删除灵活 （不必移动节点，只要改变节点中的指针）。\n4、查找结点时链式存储要比顺序存储慢。\n5、每个结点是由数据域和指针域组成\n一、数据结构的概念1、基本概念:\n\n数据：描述客观事实的符号，是计算机中可以操作的对象，能被计算机识别，并输给计算机处理的符号集合。\n数据元素：是组成数据的、有一定意义的基本单位，在计算机中通常作为整体处理，也被成为记录。\n数据对象：是性质相同数据元素的集合，是数据的一个子集。\n数据项：一个数据元素可以由若干个数据项组成，数据项是数据不可分割的最小单位。\n数据结构：相互之间存在一种或者多种特定关系的数据元素的集合。可分为逻辑结构和物理结构。\n\n\n\n2、算法(1)概念\n解决特定问题的求解步骤的一种描述，它是指令的有限序列，其中的每条指令表示一个或多个操作。\n\n(2)重要特性：\n①输入：有零个输入或者多个输\n②输出：只有一个或者多个输出\n③有穷性：算法在执行有限个步骤时，会自动结束而不会陷入无限循环里面\n④确定性：算法的每一步都有确定的含义而不会出现二义性\n⑤可行性：算法的每一步都可以通过有限次数完成。\n\n3、算法的评价标准(“好”的算法应该考虑达到以下目标)\n①正确性。算法能够正确地求解问题。\n②可读性。算法能具有良好的可读性，以帮助人们理解。\n③健壮性。输入非法数据时，算法能适当地做出反应或进行处理。而不会产生莫名其妙的输出结果。\n④效率与低存储量需求。效率指算法执行的时间，存储量需求是指算法执行过程中所需的最大存储空间。\n\n4、算法的时空效率(1)时间复杂度根据算法写成的程序在执行时耗费时间的长度，记为T(n) = O(n)(2)空间复杂度根据算法写成的程序在执行时占用存储单元的长度记为S(n)(3)语句频度一个算法中的语句执行次数称为语句频度或时间频度，记为T(n)\n时间复杂度：时间复杂度实际上是一个函数，代表基本操作重复执行的次数，进而分析函数虽变量的变化来确定数量级，数量级用O表示，所以算法的时间复杂度为： T（n）=O（f（n））\n在一个算法存在最好、平均、最坏三种情况，我们一般关注的是最坏情况，原因是，最坏情况是任何输入实例在运行时间的上界，对于某些算法来说，最坏情况出现的比较频繁，从大体上来看，平均情况和最坏情况一样差。\n\n(4)一般O（n）的计算方法：\n①用 1代替所有运行时间中出现的加法常数；\n②在修改后的运行函数中**保留最高阶的项；\n③如果最高阶的项系数不是1，则去除这个项系数。\n④ 递归算法的时间复杂度为：递归总次数每次递归中基本操作执行的次数。\n\n(5)常见的时间复杂度有以下七种：\n① O（1）常数型；② O（log2N）对数型；③ O（N）线性型；④ O（Nlog2N）二维型；⑤ O（N^2)平方型；⑥ O（N^3)立方型；⑦ O（2^N）指数型。\n例如：\ni=1;①while (i&lt;=n){\ti=i*2; ②}解：语句1的频度是1, 设语句2的频度是f(n),则：2^f(n)&lt;=n;f(n)&lt;=log2n  取最大值f(n)= log2n, T(n)=O(log2n )12345678\n二、线性表1、顺序存储(1)结构体的定义typedef int Position;typedef struct LNode * PtrToLNode;struct LNode{    ElmenetType Data[ MAXSIZE ];    Position Last;};typedef PtrToLNode List;12345678\n(2)顺序表的初始化\n1、构造一个空表\n2、动态分配表结构所需的存储空间，然后将表中Last指针置为-1 表示表中没有数据。\n\nList MakeEmpty(){    List L;\t    L = (List)malloc(sizeof(struct LNode));    L-&gt;Last = -1;\t//Last 置为-1 表示表中没有数据元素    Return L;}1234567\n\n通过L我们可以访问相应线性表的内容。比如：下标为i 的元素：L-&gt;Data[i]\n查询线性表的长度：L-&gt;Last+1;\n\n(3)顺序表的查找(时间复杂度为O(n))\n在线性表中查找与给定值 X 相等的数据元素。\n由于线性表的元素都存储在数组Data中，所以这个查找的过程实际上就是在数组里顺序查找：\n\n从第 1 个元素 a1 起依次和 X 比较， 直到找到一个与 X 相等的数据元素，返回它在顺序表中的存储下标；\n或者查遍整个表都没有找到与 X 相等的元素，则返回错误信息 ERROR。\n\n\n#define ERROR -1  /* 将错误信息 ERROR 的值定义为任一负数都可以 */Position Find( List L, ElementType X ){    Position i = 0;    While( i &lt;= L-&gt;Last &amp;&amp; L-&gt;Data[i] != X)    \ti++;    if( i &gt; L-&gt;Last)    \treturn ERROR;\t/* 如果没有找到，则返回错误信息 */    else    \treturn i;\t/* 找到后返回的是存储位置 */}1234567891011\n(4）顺序表的插入 (时间复杂度为O(n))\n在表的插入是指在表的第 i（1≤ i ≤ n + 1）个位序上插入一个值为 X 的新元素（也可以理解为在第 i 个元素之前插入新的元素）\n插入后使得原来长度为 n 的序列，变为长度为 n+1的序列（i = 1时插入序列的最前端，i = n+1 时插入序列的最后）\n\n将ai~an顺序向后移动（移动次序是从 an 到ai)，为新元素让出位置；\n将 X 放入空出的第 i 个位序；\n修改 Last 指针（相当于修改表长）,使之指向最后一个元素。\n\n\nbool Insert( List L, ElementType X, int i){ /* 在 L 的指定位序 i 前插入一个新元素 X； 位序 i 元素数组位置下标为 i-1 */    Postion j;    if(L-&gt;Last == MAXSIZE-1)    {/* 表空间已满，不能插入 */        printf(\"表满！\\n\");        return false;    }        if( i&lt;1 || i &gt; L-&gt;Last+2)    {/* 检查插入位序的合法性：是否在 1~n+1； n为当前元素个数，即Last+1 */        printf（\"位序不合法！\\n\");        return false;    }        for( j = L-&gt;Last; j &gt;= i-1; j--) /*Last 指向序列最后元素an */        L-&gt;Data[j+1] = L-&gt;Data[j]; /* 将位序为 i 及以后的元素顺序向后移动 */   \tL-&gt;Data[i-1] = X;\t/* Last 仍指向最后一个元素 */    L-&gt;Last++;    return true;}123456789101112131415161718192021\n(5)顺序表的删除（时间复杂度为O(n)）\n将表中的位序为 i（1≤ i ≤ n + 1）的元素从线性表中去掉，删除后使原长度为 n 的数组元素序列,变为长度为 n-1 的序列\n\n将a[i+1]~a[n] 顺序向前移动 ，a[i] 元素被a[i+1]覆盖；\n修改 Last 指针（相当于修改表长）使之仍指向最后一个元素。\n\n\nbool Delete(List L, int i){  /*从 L 中删除指定位序 i 的元素，该元素数组下标为 i-1*/\tPosition j;\t\tif(i &lt; 1 || i &gt; L-&gt;Last + 1)/* 检查空表及删除位序的合法性*/ \t{\t\tprintf(\"位序%d不存在元素\",i);\t\treturn false;\t}     \tfor( j = i; i &lt;= L-&gt;Last; j++)\t\tL-&gt;Data[j-1] = L-&gt;Data[j];/*将位序 i+1 及以后的元素顺序向前移动*/ \tL-&gt;Last--;/*Last 仍指向最后元素*/ \treturn true; }123456789101112131415\n2、链表存储(1）结构体的定义（时间复杂度为O(n)）typedef struct LNode * PtrToLNode;struct LNode{    ElementType Data;    PtrToLNode Next;};typedef PtrToLNode Position; /*这里的位置是结点的地址 */typedef PreToLNode List;12345678\n(2)求表长（时间复杂度为O(n)）\n在顺序存储中求表长是很容易的，直接返回 Last+1 就可以了。但在链式存储中，需要将链表从头到尾遍历一遍\n\n设一个移动指针p和计数器cnt，初始化后，p从表的第 1 个结点开始逐步往后移，同时计数器 cnt+1.\n当后面不再有结点时，cnt 的值就是结点个数，即 表长。\n\n\n\nint Length(List L){//默认该链表是有头结点的   \tPosition p;\tint i=0;  /* 初始化计数器 */        //单向链表的遍历(三部曲)\tp = L-&gt;next; /* p指向表的第 1 个结点 */\twhile(p)\t{ /* 遍历单链表，统计结点数 */ \t\tp=p-&gt;next;  \t\ti++; \t} \treturn i;}1234567891011121314\n(3)判空int ListEmpty(LinkList L){\t//若 L 为空，则返回1，否侧返回 0\tif(L-&gt;Next) //非空        return 0;    else        return 1;}1234567\n(4)查找（时间复杂度为O(n)）\n有两种 按序号查找（FindKth）和 按值查找（Find）\n\n①按序号查找 FindKth（时间复杂度为O(n)）\n对于顺序存储，按序号查找是很直接的事情，要得到第 K 个元素的值，直接取L-&gt;Data[K-1]即可。\n但是对于链式存储则需要采用跟求表长类似的思路：\n\n从链表的第 1 个元素结点起，判断当前结点是否是第 K 个；\n若是，则返回该结点的值，否则继续对比后一个，直到表结束为止。\n如果没有第 K 个结点则返回错误信息。\n\n\n#define ERROR -1 /* 一般定义为表中元素不可能取到的值 */ElementType FindKth(List L, int K) {\t/* 根据指定的位序 K， 返回 L 中相应的元素 */\tPosition P;    int cnt = 1; /* 位序从 1 开始 */\tp = L; /* p 指向 L的第 1 个结点 */\twhile(p &amp;&amp; cnt &lt; K)\t{\t\tp = p-&gt;next;\t\tcnt++\t} \t\tif((cnt == K) &amp;&amp; p)\t\treturn p-&gt;Data;\t/* 返回第 K 个 */\telse\t\treturn ERROR;\t/* 否则返回错误信息 */} 123456789101112131415161718\n②按值查找，即定位 Find（时间复杂度为O(n)）\n基本方法：也是从头到尾遍历，直到找到为止：\n\n从链表的第 1 个元素结点起，判断当前结点的值是否等于 X；\n若是，返回该结点的位置，否则继续对比后一个，直到表结束位置为止；\n找不到时返回错误信息。\n\n\n#define ERROR NULL /*空地址表示错误 */Position Find( List L, ElementType X){    Position p = L;/* p指向 L 的第 1 个元素 */    while(p &amp;&amp; p-&gt;Data != x)    {        p = p-&gt;Next;    }        if(p)     \t return p;    else        return ERROR;}123456789101112131415\n(5)链表的插入（时间复杂度为O(n)）\n\nint  ListInsert_L(LinkList &amp;L, int i,ElementType e){    p = L;    j = 0;    while(p&amp;&amp; j&lt;i-1)    {//寻找第 i-1 个结点        p = p-&gt;next;        ++=j;    }    if(!p || j &gt; i-1)        return ERROR;//    s = (LinkList)malloc(sizeof(LNode));//生成新结点s    s-&gt;data = e;\t\t//将结点s 的数据域的值 更新为 e    s-&gt;next = p-&gt;next;  //将结点s 插入 L 中    p-&gt;next = s;    return OK;}1234567891011121314151617\n(6)创建链表（时间复杂度为O(n)）1、带头结点的【头插法】（时间复杂度为O(n)）\n/* 带头结点的插入创建 */void createListHead( Linklist L, int n ){  \t\t//建立头结点    \tL = (LNode*)malloc(sizeof(struct LNode));    \tL-&gt;Next = NULL;    \t//建立单链表（头插法）    \tLNode *temp = NULL;    \t//申请空间，写入数据    \tfor(int i = 0; i &lt; n; i++)        {            tmp = (LNode*)malloc(sizeof(struct LNode)); /* 申请、填装结点 */            scanf(\"%d\",&amp;tmp-&gt;Data);//输入元素值            //插入到头结点的后面       \t \ttmp-&gt;Next = L-&gt;Next;         \tL-&gt;Next = tmp;\t           }}123456789101112131415161718\n2、带尾结点的插入【尾插法】（时间复杂度为O(n)）/*带尾结点的插入*/void CreateList_L( Listlist &amp;L, int n ){ //正位序数输入 n 个元素的值，建立带表头结点的单链表L    \t//建立头结点   \t    L = (LNode*)malloc(sizeof(struct LNode));   \t\tL-&gt;Next = NULL;    \t//建立单链表（尾插法）   \t \tLNode r = L; //尾指针指向头结点    \t//申请空间，写入数据    \tfor(int i = 0;i &lt; n; i++)        {           \tLNode *tmp = (LNode*)malloc(sizeof(struct LNode)); /* 申请新结点 */            scanf(\"%d\",&amp;tmp-&gt;Data); //输入元素            tmp-&gt;Next = NULL;            //插入到尾结点后面        \tr-&gt;next = temp;         \tr = tmp;\t   //r指向新的尾结点        }}12345678910111213141516171819\n(7)删除（时间复杂度为O(n)）\n\n//将线性表L 中第 i 个数据元素删除int ListDelete_L(LinkList &amp;L, int i, ElementType &amp;e){    p=L;    int j=0;    while(p-&gt;next &amp;&amp; j &lt; i-1)    {//寻找第 i 个结点，并令p指向其前驱        p = p&gt;next;        ++j;    }    if(!(p-&gt;next)||j &lt; i-1)        return ERROR;//删除位置不合理        q = p-&gt;next;\t//临时保存被删除结点的地址以备释放    p-&gt;next = q-&gt;next; //改变被除结点的驱结点的指针域    e = q-&gt;data;\t//保存被删除结点的数据域    free(q);\t\t//释放被删除结点的空间    return OK;}12345678910111213141516171819\n3、二者时间复杂度和优缺点的比较1、两者复杂度比较\n\n\n\n\n查找\n插入\n删除\n\n\n\n\n顺序表\nO(1)\nO(1)\nO(n)通过下标直接找到待操作元素，主要时间花在移动元素上。\n\n\n链表\nO(n)\nO(n)主要时间用于找到插入元素的位置\nO(n)主要时间用于找到待删除元素的位置\n\n\n\n\n2、两者优缺点比较\n\n\n\n数组\n优点\n缺点\n\n\n\n\n\n随机访问性强；查找速度快\n插入和删除效率低；可能浪费内存；内存空间要求高，必须有足够的连续内存空间；数组大小固定，不能动态拓展\n\n\n\n\n\n\n\n\n链表\n优点\n缺点\n\n\n\n\n\n插入删除速度快；内存利用率高，不会浪费内存；大小没有固定，拓展很灵活。\n不能随机查找，必须从第一个开始遍历，查找效率低\n\n\n\n\n\n两者的区别在于顺序结构的要求一片连续的存储空间，而链式结构的不要求存储空间连续。\n\n三、栈1、栈的顺序存储实现\n通常由一个一维数组和一个记录栈顶元素位置的变量组成。\n\n(1)顺序栈结构体的定义\n当 Top = -1时，表示栈空；当Top = MaxSize -1 时，栈满！\n\ntypedef int Position;typedef int ElementType;typedef struct SNode *PtrToNode;struct SNode{\tElementType * Data;  /*存储元素的数组*/\tPosition Top;\t\t /*栈顶指针*/\tint MaxSize;\t\t /*堆栈最大容量*/ };typedef PtrToNode Stack;12345678910\n(2)顺序栈的创建Stack CreateStack(int MaxSize) /*顺序栈的创建*/ {\tStack S = (Stack)malloc(sizeof(struct SNode));\tS-&gt;Data = (ElementType *)malloc(MaxSize * sizeof(ElementType));\tS-&gt;Top = -1;\t\t       /*\"-1\"表示空栈  \"MaxSize-1\"表示满栈*/ \tS-&gt;MaxSize = MaxSize;      /*指定栈的最大容量*/ \treturn S;}12345678\n(3)判满bool IsFull(Stack S)\t\t/*判断栈是否满了*/ {\treturn(S-&gt;Top == S-&gt;MaxSize-1);}1234\n(4)判空bool IsEmpty(Stack S)\t/*判断堆栈是否为空*/ {\treturn(S-&gt;Top == -1);}1234\n(5)入栈\n在执行堆栈 Push 操作时，先判断栈是否满；\n\n若不满，Top 加1，并将新元素放入 Data数组的Top位置上\n若满，则返回错误标志\n\n\nbool Push(Stack S, ElementType X)\t/*顺序栈的 入栈 操作*/ { \tif(IsFull(S)) \t{\t\tprintf(\"堆栈满！\");\t\treturn false;\t}\telse\t{\t\tS-&gt;Data[++(S-&gt;Top)] = X;\t/*若是栈不满，则Top加 1,并将新元素放入Data数组的Top位置中*/ \t\treturn true;\t}}12345678910111213\n(6)出栈\n执行Pop操作时，首先判别栈是否为空；\n\n若不为空，返回Data[Top]，同时将Top-1;\n否则要返回错误标志\n\n\nElementType Pop(Stack S) /*顺序栈 的 出栈 操作*/ {\tif(IsEmpty(S))\t\t\t{\t\tprintf(\"堆栈空！\");\t\treturn ERROR;\t\t\t\t\t/*ERROR 是 ElementType 类型的特殊值，标志错误。必须是正常栈元素数据不可能取到的值 */ \t}\telse\t\treturn(S-&gt;Data[(S-&gt;Top)--]);\t/*若不空，返回Data[Top]，同时将Top减 1*/  }12345678910\n2、栈的顺序存储实现\n链栈与单链表类似，但其操作受限制，插入和删除操作只能在链栈的栈顶进行。\n\n(1)顺序栈结构体的定义typedef struct SNode *PtrToSNode;typedef int ElementType;struct SNode{\tElementType Data;\tPtrToSNode Next;};typedef PtrToSNode Stack;12345678\n(2)顺序栈的创建Stack CreateStack(){\t/*构建一个堆栈的头结点，返回该结点指针*/ \tStack S;\tS = (Stack)malloc(sizeof(struct SNode));\tS-&gt;Next = NULL;\treturn S;}1234567\n(3)判空bool IsEmpty(Stack S){\t/*判断堆栈 S 是否为空，若是返回 true，否则返回 false*/ \treturn(S-&gt;Next == NULL);}1234\n(4)判满 注意：链栈，不必判断堆栈是否满(5)入栈\n链栈，不必判断堆栈是否满\n\nbool Push(Stack S, ElementType X){\t/*将元素 X 压入堆栈 S */ \tPtrToSNode TmpCell;\tTmpCell = (PtrToSNode)malloc(sizeof(struct SNode));\tTmpCell-&gt;Data = X;        //头插法\tTmpCell-&gt;Next = S-&gt;Next;\tS-&gt;Next =TmpCell;\treturn true;}1234567891011\n(6)出栈ElementType Pop(Stack S) ElementType Pop(Stack S){\t/*删除并返回堆栈 S 的栈顶元素*/  \tPtrToSNode FirstCell;\tElementType TopElem;\t\tif(IsEmpty(S))\t{\t\tprintf(\"堆栈空！\");\t\treturn ERROR;\t}\telse\t{\t\tFirstCell = S-&gt;Next;\t\tTopElem = FirstCell-&gt;Data;\t\tS-&gt;Next = FirstCell-&gt;Next;\t\tfree(FirstCell);\t\treturn TopElem;\t\t\t\t\t\t\t\t}}/*顺序栈 的 出栈 操作*/ {\tif(IsEmpty(S))\t\t\t{\t\tprintf(\"堆栈空！\");\t\treturn ERROR;\t\t\t\t\t/*ERROR 是 ElementType 类型的特殊值，标志错误。必须是正常栈元素数据不可能取到的值 */ \t}\telse\t\treturn(S-&gt;Data[(S-&gt;Top)--]);\t/*若不空，返回Data[Top]，同时将Top减 1*/  }12345678910111213141516171819202122232425262728\n3、栈的应用四、队列1、队列的顺序存储实现(1) 循环队列的结构体定义typedef int Status; typedef int QElemType; /* QElemType类型根据实际情况而定，这里假设为int *//* 循环队列的顺序存储结构 */typedef struct QNode{\tQElemType data[MAXSIZE];\tint front;    \t/* 头指针 */\tint rear;\t\t/* 尾指针，若队列不空，指向队列尾元素的下一个位置 */}SqQueue;123456789\n(2)生成空队列/* 初始化一个空队列Q */Status CreateQueue(SqQueue *Q){    SqQueue *Q = (SqQueue)malloc(sizeof(struct QNode));    Q-&gt;data = (ElementType*)malloc(MaxSize * sizeof(ElementType));\tQ-&gt;front = Q-&gt;rear = 0;\treturn  OK;}12345678\n(3)判空\n队空的条件是：rear=front\n\nbool IsEmpty(SqQueue *Q){    return(Q-&gt;front == Q-&gt;rear);}1234\n(4)判满\n队满的条件是：(rear+1)%数组的长度等于 front\n\nbool IsFull(SqQueue *Q){    return((Q-&gt;rear+1)% MaxSize == Q-&gt;front);}1234\n(5)入队/* 若队列未满，则插入元素e为Q新的队尾元素 */Status EnQueue(SqQueue *Q,QElemType e){\tif ((Q-&gt;rear+1)%MAXSIZE == Q-&gt;front)\t/* 队列满的判断 */\t\treturn ERROR;\tQ-&gt;data[Q-&gt;rear]=e;\t\t\t/* 将元素e赋值给队尾 */\tQ-&gt;rear=(Q-&gt;rear+1)%MAXSIZE;/* rear指针向后移一位置， */\t\t\t\t\t\t\t\t/* 若到最后则转到数组头部 */\treturn  OK;}12345678910\n(6)出队/* 若队列不空，则删除Q中队头元素，用e返回其值 */Status DeQueue(SqQueue *Q,QElemType *e){\tif (Q-&gt;front == Q-&gt;rear)\t\t\t/* 队列空的判断 */\t\treturn ERROR;\t*e=Q-&gt;data[Q-&gt;front];\t\t\t\t/* 将队头元素赋值给e */\tQ-&gt;front=(Q-&gt;front+1)%MAXSIZE;\t/* front指针向后移一位置， */\t\t\t\t\t\t\t\t\t/* 若到最后则转到数组头部 */\treturn  OK;}12345678910\n2、队列的链式存储实现\n队列与堆栈一样，也可以采用链式存储结构，但队列的头（front）必须指向链表的头结点，队列的尾（rear）指向链表的尾结点。\n\n(1)队列的链式存储结构体定义typedef int Status; typedef int QElemType; /* QElemType类型根据实际情况而定，这里假设为int */typedef struct QNode\t/* 结点结构 */{   QElemType data;   struct QNode *next;}QNode,*QueuePtr;typedef struct\t\t\t/* 队列的链表结构 */{   QueuePtr front,rear; /* 队头、队尾指针 */}LinkQueue;123456789101112\n(2)生成空队列/* 构造一个空队列Q */Status InitQueue(LinkQueue *Q){ \tQ-&gt;front=Q-&gt;rear=(QueuePtr)malloc(sizeof(QNode));\tif(!Q-&gt;front)\t\texit(OVERFLOW);\tQ-&gt;front-&gt;next=NULL;\treturn OK;}123456789\n(3)判空\n队空的条件是：rear=front\n\nStatus QueueEmpty(LinkQueue Q){ \tif(Q.front==Q.rear)\t\treturn TRUE;\telse\t\treturn FALSE;}1234567\n(4)判满 链式队列，不必判断堆栈是否满(5)入队/* 插入元素e为Q的新的队尾元素 */Status EnQueue(LinkQueue *Q,QElemType e){ \tQueuePtr s=(QueuePtr)malloc(sizeof(QNode));\tif(!s) /* 存储分配失败 */\t\texit(OVERFLOW);\ts-&gt;data=e;\ts-&gt;next=NULL;\tQ-&gt;rear-&gt;next=s;\t/* 把拥有元素e的新结点s赋值给原队尾结点的后继，见图中① */\tQ-&gt;rear=s;\t\t/* 把当前的s设置为队尾结点，rear指向s，见图中② */\treturn OK;}123456789101112\n(6)出队/* 若队列不空,删除Q的队头元素,用e返回其值,并返回OK,否则返回ERROR */Status DeQueue(LinkQueue *Q,QElemType *e){\tQueuePtr p;\tif(Q-&gt;front==Q-&gt;rear)\t\treturn ERROR;\tp=Q-&gt;front-&gt;next;\t\t/* 将欲删除的队头结点暂存给p，见图中① */\t*e=p-&gt;data;\t\t\t\t/* 将欲删除的队头结点的值赋值给e */\tQ-&gt;front-&gt;next=p-&gt;next;/* 将原队头结点的后继p-&gt;next赋值给头结点后继，见图中② */\tif(Q-&gt;rear==p)\t\t/* 若队头就是队尾，则删除后将rear指向头结点，见图中③ */\t\tQ-&gt;rear=Q-&gt;front;\tfree(p);\treturn OK;}1234567891011121314\n五、栈和队列操作的特点\n\n\n\n\n相同点\n不同点\n\n\n\n\n堆栈(FILO)\n只允许在端点处插入和删除元素；\n栈是先进后出或者后进先出；栈是只能在表的一端进行插入和删除操作的线性表\n\n\n队列(FIFO)\n只允许在端点处插入和删除元素；\n队列是先进先出；队列是只能在表的一端进行插入，然后在另外一端进行删除操作的线性表\n\n\n\n\n六、数组存储地址的计算\n\n\n\n数组类型\n存储地址的计算（a是数组首地址，len是每个数组元素所占长度）\n\n\n\n\n一维数组\na[i]的存储地址：a+i*len\n\n\n二维数组:a[m] [n]\n按行存储：a+(i  n+j)  len；按列存储：a+(j  m+i)  len\n\n\n\n\n\n例子：数组存储地址的计算示例：1）已知一维数组a中每个元素占用2个字节，求a[10]的存储地址？答：a[10]的存储地址为：a+102=a+202）已知二维数组a[4][5]中, 每个元素占用2个字节，求元素a[3][2]按行为主序存储的存储地址和按列为主序存储的存储地址？答： 按行存储：a+(35+2) 2 = a+34按列存储：a+(24+3) *2 = a+22\n\n———————树———————一、二叉树1、定义\n二叉树是每个节点最多有两个子树的树结构。\n它有五种基本形态:\n\n二叉树可以是空集;\n根可以有空的左子树或右子树；\n或者左、右子树皆为空。\n\n\n\n2、结点的度、孩子、双亲、深度、有序树、无序树、树的高度a.结点、叶子、树的度\n\n结点的度：结点拥有的子树的数目。\n叶子：度为零的结点。\n树的度：树中结点的最大的度\n\n\nb.孩子、双亲、兄弟、子孙、祖先\n\n双亲：若一个结点有子树，该结点称为子树根的”双亲”。\n孩子：子树的根是该结点的”孩子”。\n兄弟：有相同双亲的结点互为”兄弟”。\n子孙：一个结点的所有子树上的任何结点都是该结点的子孙。\n祖先：从根结点到某个结点的路径上的所有结点都是该结点的祖先。\n\n\nc.无序树、有序树、森林\n\n无序树：如果树中结点的各子树之间的次序是无次序的，可以交换位置。\n有序树：如果树中结点的各子树之间的次序是有次序的, 不可以交换位置。\n森林：0个或多个不相交的树组成。对森林加上一个根，森林即成为树；删去根，树即成为森林。\n\n\nd.层次、高度\n层次：根结点的层次为1，其余结点的层次等于该结点的双亲结点的层次加1。树的深度和高度：二叉树中节点的最大层次称为二叉树的深度或高度。\n\n2、性质\n性质1：二叉树第 i 层上最多为 2^(i-1) (i≥1)个结点。\n性质2：深度为k的二叉树至多有2^k - 1个结点(k≥1)。\n性质3：具有n个结点的【完全二叉树】的高度k为(log&lt;2&gt;n) +1）（[log2n]表示不大于与其的整数）\n性质4：在任意一棵二叉树中，若终端结点的个数为n0，度为2的结点数为n2，则n0=n2+1。\n性质5：如果对一棵有 n个结点的完全二叉树（其深度为(log&lt;2&gt;n) +1）的结点按 【层序】编号（从第1层到第(log&lt;2&gt;n) +1） 层，每层从左到右），对任一结点 i （1≤ i ≤ n）有：\n\n如果 i = 1，则结点 i是二叉树的根，无双亲；如果 i ＞ 1，则其双亲是结点 [i/2];\n如果2i ＞n，则结点 i 无左孩子（即结点 i 为叶子结点）；否则其左孩子是结点 2i；\n如果 2i+1 ＞n，则结点 i 无右孩子；否则其右孩子是结点 2i+1。\n\n\n3、满二叉树、完全二叉树和二叉排序树a.满二叉树\n定义：高度为h，并且由2{h} –1个结点的二叉树，被称为满二叉树。\n\n\nb.完全二叉树\n定义：一棵二叉树中，只有最下面两层结点的度可以小于2，并且最下一层的叶结点集中在靠左的若干位置上。这样的二叉树称为完全二叉树。\n特点：叶子结点只能出现在最下层和次下层，且最下层的叶子结点集中在树的左部。显然，一棵满二叉树必定是一棵完全二叉树，而完全二叉树未必是满二叉树。\n\n\nc.二叉查找树\n定义：二叉查找树(Binary Search Tree)，又被称为二叉搜索树。左小右大，任意结点的左、右子树也是二叉查找树\n\n\n\n在二叉查找树中：(01) 若任意节点的左子树不空，则左子树上所有结点的值均小于它的根结点的值；(02) 任意节点的右子树不空，则右子树上所有结点的值均大于它的根结点的值；(03) 任意节点的左、右子树也分别为二叉查找树。(04) 没有键值相等的节点（no duplicate nodes）。\n\n二、静态查找1、顺序存储结构\n指用一组地址连续的存储单元依次自上而下、自左至右存储完全二叉树的结点元素，即将完全二叉树上编号为i的结点元素存储在一维数组下标i－1的分量中。\n\n2、顺序查找\n从表的一端开始，逐个将记录的关键字和给定值比较，若找到一个记录的关键字与给定值相等，则查找成功；若整个表中记录均比较过，仍未找到关键字等于给定值的记录，则查找失败。\n\n缺点：查找表的长度越长，查找效率越低。\n优点：简单、适应面广，对查找表结构没有要求，对顺序存储和链式存储都适用。\n3、二分查找（也称“折半查找”，是一棵“二叉排序树”）\n设查找表元素存储在一维数组r[1,…,n]中，在表中的元素已经按关键字递增方式排序的情况下，\n进行[折半查找]的方法是：首先将待查元素的关键字（key）值与表r中间位置上（下标为mid）记录的关键字关键字进行比较，\n\n若相等，则查找成功；\n若key&gt;r[mid].key,则说明待查记录只可能在后半个子表r[mid+1,…,n]中；\n若key&lt;r[mid].key，则说明待查记录只可能在前半个子表r[1,…,mid-1]中；\n\n这样逐步缩小范围，直到查找成功或子表为空时失败为止。\n\n注意：每次缩小范围后，改变的下标是哪个\n//递增的方式排序，则折半查找的算法为//在数组r[low...high],在数组r中找值为key的元素int Bsearch(int r[],int low,int high,int key){    int mid;    while(low &lt;= high)    {        mid = (low + high)/2;        if(key == r[mid])            return mid;        else if(key &lt; r[mid])            high = mid-1;        else            low = mid+1;    }    return -1;} //折半查找，递归算法int Bsearch_rec(int r[],int low,int high,int key){    int mid;    if(low &lt;= high)    {        mid = (low + high)/2;        if(key == r[mid])            return mid;        else if(key &lt; r[mid])            return Bsearch_rec(r,low,mid-1,key);        else            return Bsearch_rec(r,mid+1,high,key);    }    return -1;}12345678910111213141516171819202122232425262728293031323334\n\n折半查找的过程可以用一颗二叉树来描述，以当前查找区域间的中间位置序号作为根，左半个子表和右半个子表中的记录序号分别分别作为根的左子树和右子树上的结点，这样构造的二叉树称为折半查找判定树，从树上可以看出：\n 查找成功时，折半查找的过程恰好走了一条从根结点到被查找结点的路径，与关键字进行比较的次数即为被查找结点在树中的层数。因此，折半查找判定树在查找成功时进行比较的关键字个数最多不超过树的深度，而具有n个结点的判定树的深度为；所以折半查找在查找成功时和给定值进行比较的关键字个数最多为。\n优点：查找效率更高，但它要求查找表进行顺序存储并按关键字进行排序。缺点：对表进行插入或删除时，需要移动大量元素。适用：表不易变动，且又经常进行查找的情况\n4、二分查找判定树ASL计算\n折半查找的过程看，可用二叉树来描述，二叉树中的每个结点对应有序表中的一个记录，结点中的值为该记录在表中的位置。通常称这个描述折半查找二叉树的过程称为折半查找判定树。\n\n例如：顺序存储的序列{1,2,3,4,5,6,7,8,9,10} 来构建二叉判定树，计算其ASL\n\n例如：长度为10的折半查找判定树的具体生成过程：\t都遵循这个规律，左孩子结点&lt;根结点&lt;右孩子结点 【左小右大】    （1）在长度为10的有序表中进行折半查找，不论查找哪个记录，都必须和中间记录进行比较，而中间记录为（1+10）/2 =5  (注意要取整)   即判定数的的根结点为5，如图7-2（a）所示。     （2）考虑判定树的左子树，即将查找区域调整到左半区，此时的查找区间为[1,4],那么中间值为（1+4）/2 =2 (注意要取整) ，所以做孩子根结点为2,如图7-2（b）所示。     （3）考虑判定树的右子树，即将查找区域调整到右半区，此时的查找区间为[6,10],那么中间值为（6+10）/2 =8 (注意要取整) ，所以做孩子根结点为8,如图7-2（c）所示。       (4)重复以上步骤，依次去确定左右孩子、123456789101112\n特点：\n\n1.折半查找是一棵二叉排序树，每个根结点的值都大于左子树的所有结点的值，小于右子树所有结点的值。\n2.折半查找判定数中的结点都是查找成功的情况，将每个结点的空指针指向一个实际上不存在的结点————外结点，所有外界点都是查找不成功的情况，如图7-2（e）所示。如果有序表的长度为n,则外结点一定有n+1个。\n\n（1）查找成功的ASL\n折半查找判定数中，某结点所在的层数就是即将要比较的次数，整个判定树代表的有序表的平均查找长度即为查找每个结点的比较次数之和除以有序表的 长度。\n\nASL成功 = 每层结点所在高度×每层结点数 之和 除以 总结点数\n 例如：长度为10的有序表的平均查找长度为\tASL=(1×1+2×2+3×4+4×3)/10=29/10;123\n（2）查找不成功的ASL\n折半查找判定数中，查找不成功的次数即为查找相应外结点(定义在上方）与内结点的比较次数。整个判定树代表的有序表的平均查找长度。查找失败时的有序表的平均查找长度即为查找每个外结点的比较次数之和除以外结点的个数。\n\nASL失败 = （每层【补上的】结点所在高度-1）×每层【补上的】结点数 之和 除以 【补上的】总结点数\n例如：查找失败时，长度为10的有序表的平均查找长度为：\tASL=(3×5+4×6)/11=39/11;123\n三、动态查找1、二叉树链表结构描述如下：typedef struct TNode *Position;typedef Position BinTree; /* 二叉树类型 */struct TNode{/*树结点定义 */    ElementType Data; /* 结点数据*/    BinTree Left; /*指向左子树*/    BinTree Right;/*指向右子树*/};12345678\n二叉链表至少包含3个域：数据域 data、左指针域 lchild和右指针域 rchild\n指针域： n个结点有2n个指针域。\n空指针域：n 个结点的二叉链表中含有 n+1 个空指针域。\n\n2、二叉搜索（排序、查找）树的构造过程(1)构造过程\n构造二叉排序树的过程，就是从空二叉树开始，逐个向树中插入节点的过程。\n设记录的关键码序列为：63,90,70,55,67,42,98,83,10,45,58\n\n\n(2)插入过程算法及其代码\n设待插入节点关键码值为 X ：\n（1）先在树中查找值为 X 的节点，若查找成功，说明节点已存在，无需插入；\n（2）若查找失败，说明节点不存在，则将其插入到树中\n因此，新插入节点一定是作为叶子节点插入的。\n\nBinTree Insert(Bintree BST, ElmentType X){    if(!BST)    {/*若原来树为空，生成并返回一个结点的二叉搜索树*/        BST = (BinTree)malloc(sizeof(struct TNode));        BST-&gt;Data = X;        BST-&gt;Left = BST-&gt;Right = NULL;    }    else    {/*开始查找插入元素的位置*/        if(X &lt; BST-&gt;Data)            BST-&gt;Left = Insert(BST-&gt;Left, X);/*递归插入左子树*/        else if(X &gt; BST-&gt;Data)            BST-&gt;Right = Insert(BST-&gt;Right, X);/*递归插入右子树*/    }    return BST;}1234567891011121314151617\n(2)删除过程算法及其代码\n二叉搜索树的删除操作比其它操作更为复杂，要删除结点在树中的位置决定了操作所采用的策略。\n\na.若要删除的结点是叶子结点\n 可以直接删除，然后再修改其父结点的指针。\n\nb.若要删除的结点只有一个孩子结点（该结点不一定是叶结点，可以是子树的根）\n 删除之前需要改变父结点的指针，指向要删除结点的孩子结点。\nc.若要删除的结点有左、右两棵子树，有两种选择：\n 基本原则：保持二叉搜索树的有序性\n 1、取其右子树中的最小元素；\n 2、取其左子树中的最大元素。\n\n(3)查找过程算法及其代码\nBST树的查找思想:\n首先将给定的K值与二叉排序树的根节点的关键字进行比较：\n\n若相等，则查找成功；\n若给定的K值小于BST树的根节点的关键字：继续在该节点的左子树上进行查找；\n若给定的K值大于BST树的根节点的关键字：继续在该节点的右子树上进行查找。\n\n\na.二叉搜索树的递归查找函数\n在二叉排序树上进行查找，则是从根结点出发走了一条从根到待查结点的路径；\n若查找不成功，则是从根结点出发走了一条从跟到某一叶结点的路径。\n\nPosition Find(BinTree BST,ElementType X){    if(!BST-&gt;Data)        return NULL;/* 查找失败 */    if(X &gt; BST-&gt;Data)        return Find(BST-&gt;Right, X);/* 在 右子树 中递归查找 */    else if(X &lt; BST-&gt;Data)        return Find(BST-&gt;Left, X);/* 在 左子树 中递归查找 */    else        return BST;/* 在当前结点查找成功，返回当前结点的地址*/}1234567891011\nb.迭代查找算法\n由于非递归函数的执行效率高，一般采用非递归的迭代来实现查找。很容易将递归函数改为迭代函数\nwhile循环 代替 Find递归调用即可\n\nPosition Find(BinTree BST,ElementType X){    while(BST)    {        if(X &gt; BST-&gt;Data)            BST = BST-&gt;Right;/* 向 右子树 中移动，继续查找 */        else if(X &lt; BST-&gt;Data)            BST = BST-&gt;Left; /* 向 右子树 中移动，继续查找 */        else /* X == BST-&gt;Data;*/            break;/* 在当前结点查找成功，跳出循环 */    }     return BST;/* 返回找到的结点地址，或是NULL */}12345678910111213\n(4)查找最大值和最小值\n根据二叉搜索树的性质，最小元素一定是在树的最左分支的端点上。最左分支的端点：最左分支上无左孩子的结点。\n最大元素一定在最右分支的端结点上。\n\n从根结点开始，当其不为空时，沿左分支或者右分支逐个判断各结点的指针，直到遇到空指针为止。\n当左分支逐层推下来查找到的是最小元素。\n反之，当右分支逐层推下来查找到的是最大元素。\n\n\n\na.最小元素的递归函数Position FindMin(BinTree BST){ /* 最小元素在最左端点 */    if(!BST)        return NULL;/* 空的二叉搜素树，返回NULL */    else if(!BST-&gt;Left)        return BST;\t/* 找到最左端点并返回 */    else        return FindMin(BST-&gt;Left); /*沿左分支递归查找 */}123456789\nb.查找最大元素的迭代函数Position FindMax(BinTree BST){    if(BST)        while(BST-&gt;Right);    \t\tBST = BST-&gt;Right; /*沿右分支一直向下，直到最右端点 */    return BST;}1234567\n四、二叉树的遍历\n指按照某种次序访问二叉树的所有结点，并且每个结点仅访问一次，得到一个线性序列。\n\n1、先序遍历\n（1）访问根结点（2）先序遍历左子树（3）先序遍历右子树\n-中序、后序遍历相似\n\n\n\n先序遍历：A → B → D → C中序遍历：B → D → A → C后续遍历：D → B → C → A层序遍历：A → B → C → D\n\nvoid PreOrderTraverse(BiTree T)    //链式二叉树先序遍历递归算法{\tif (T != NULL)\t{\t\tprintf_s(\"%d \", T-&gt;data);    //访问根结点\t\tPreOrderTraverse(T-&gt;lchild);    //先序遍历左子树\t\tPreOrderTraverse(T-&gt;rchild);    //先序遍历右子树\t}}//链式二叉树中序遍历递归算法void InOrderTraverse(BiTree T) {\tif (T != NULL) {\t\tInOrderTraverse(T-&gt;lchild);\t\tprintf_s(\"%d \", T-&gt;data);\t\tInOrderTraverse(T-&gt;rchild);\t}}//链式二叉树后序遍历递归算法void PostOrderTraverse(BiTree T) {\tif (T != NULL) {\t\tPostOrderTraverse(T-&gt;lchild);\t\tPostOrderTraverse(T-&gt;rchild);\t\tprintf_s(\"%d \", T-&gt;data);\t}}123456789101112131415161718192021222324252627282930\n2、层序遍历(队列实现）\n仔细看看层序遍历过程，其实就是从上到下，从左到右依次将每个数放入到队列中，然后按顺序依次打印就是想要的结果。\n实现过程\n\n从队列中取出一个元素；\n访问该元素所指结点；\n若该元素所指结点的左、右孩子结点非空，则将其左、右孩子的指针顺序入队。\n\n不断执行这三步操作，直到队列为空，再无元素可取，二叉树的程序遍历就完成了。\n\nvoid LevelorDerTraversal(BinTree BT){    Queue Q;    BinTree T;        if(!BT)        return;/* 若是空树则直接返回 */        Q = CreatQueue();\t/* 创建空队列 */    AddQ(Q, BT);    while(!IsEmpty(Q))    {        T = DeteleQ(Q);        printf(\"%d\",T-&gt;Data); /* 访问取出队列的结点 */        if(T-&gt;Left)            AddQ(Q, T-&gt;Left);        if(T-&gt;Right)            AddQ(Q, T-&gt;Right);    }}1234567891011121314151617181920\n3、由遍历序列还原二叉树\n已知先序遍历和中序遍历，可以还原二叉树；已知中序遍历和后序遍历，可以还原二叉树；已知先序遍历和后序遍历，不可以还原二叉树.\n\na.已知先序遍历和中序遍历还原二叉树\n\n算法思路：1、根据先序遍历结果确定根节点。先序遍历的第一个节点为根节点。2、 在中序遍历结果中找到根节点，根节点左侧的部分为左子树节点，根节点右侧的部分为右子树节点。3、 将中序遍历的结果按根节点分为两部分，迭代的执行第一步和第二步，直到还原整个二叉树。\n\n例如：已知先序遍历的结果为：ABDHIEJKCFLMGNO,中序遍历的结果为：HDIBJEKALFMCNGO\n则二叉树为以下结构：\n\n其后序遍历结果为：HIDJKEBLMFNOGCA\nb.已知后序遍历和中序遍历还原二叉树\n算法思路：1、根据后序遍历结果确定根节点。后序遍历的最后一个节点为根节点。2、在中序遍历结果中找到根节点，根节点左侧的部分为左子树节点，根节点右侧的部分为右子树节点。3、将中序遍历的结果按根节点分为两部分，迭代的执行第一步和第二步，直到还原整个二叉树。\n\n例如：已知后序遍历的结果为：HIDJKEBLMFNOGCA,中序遍历的结果为：HDIBJEKALFMCNGO\n则二叉树为以下结构：\n\n其先序遍历结果为：ABDHIEJKCFLMGNO\n五、递归遍历算法的应用1、求二叉树的深度//求树的深度int TreeDeep(BiTree T) {    int deep = 0;    if (T != NULL)     {        int leftDeep = TreeDeep(T-&gt;lchild);        int rightDeep = TreeDeep(T-&gt;rchild);        deep = leftDeep &gt;= rightDeep ? leftDeep + 1 : rightDeep + 1;    }    return deep;}123456789101112\n2、求二叉树的叶子树//求叶子树int LeafCount(BinTree T,int num){    if(T)    {        if(!T-&gt;Left &amp;&amp; !T-&gt;Right)        {            nm++;        }        TreeDeep(T-&gt;lchild, num);        TreeDeep(T-&gt;rchild, num);    }    return num; }1234567891011121314\n3、交互（换）左、右子树void Swap(BiTree *&amp;right,BiTree *&amp;left){\tBiTree *temp=right;\tright=left;\tleft=temp;}void SwapSubtrees(BiTree *T){\tif(!T)\t\treturn ;\tSwapSubtrees(T-&gt;rchild);\tSwapSubtrees(T-&gt;lchild);\tSwap(T-&gt;rchild,T-&gt;lchild);}123456789101112131415\n六、静态查找和动态查找的根本区别\n上述基于二叉排序树的动态查找，它的基本原理和基于线性表的静态二分查找很相似，都是利用有序性不断缩小查找空间。\n而之所以有静态和动态之分，主要是为了适应不同的应用需求。\n\n\n\n\n\n\n适合用于\n\n\n\n\n静态查找\n数据一旦建立好，不需要或者很少进行 删除 和 插入 操作\n\n\n动态查找\n频繁的数据变化，插入 和 删除 是基本操作\n\n\n\n\n七、树/森林与二叉树的转换1、树、森林与二叉树的转换由于二叉树是有序的，为了避免混淆，对于无序树，我们约定树中的每个结点的孩子结点按从左到右的顺序进行编号。\n\n将树转换成二叉树的步骤是：（1）加线。就是在所有兄弟结点之间加一条连线；（2）抹线。就是对树中的每个结点，只保留他与第一个孩子结点之间的连线，删除它与其它孩子结点之间的连线；（3）旋转。就是以树的根结点为轴心，将整棵树顺时针旋转一定角度，使之结构层次分明。\n\n2、森林转换为二叉树森林是由若干棵树组成，可以将森林中的每棵树的根结点看作是兄弟，由于每棵树都可以转换为二叉树，所以森林也可以转换为二叉树。\n\n将森林转换为二叉树的步骤是：（1）先把每棵树转换为二叉树；（2）第一棵二叉树不动，从第二棵二叉树开始，依次把后一棵二叉树的根结点作为前一棵二叉树的根结点的右孩子结点，用线连接起来。当所有的二叉树连接起来后得到的二叉树就是由森林转换得到的二叉树。\n\n\n3、二叉树转换为树\n二叉树转换为树是树转换为二叉树的逆过程，其步骤是：（1）若某结点的左孩子结点存在，将左孩子结点的右孩子结点、右孩子结点的右孩子结点……都作为该结点的孩子结点，将该结点与这些右孩子结点用线连接起来；（2）删除原二叉树中所有结点与其右孩子结点的连线；（3）整理（1）和（2）两步得到的树，使之结构层次分明。\n\n4、二叉树转换为森林\n二叉树转换为森林比较简单，其步骤如下：（1）先把每个结点与右孩子结点的连线删除，得到分离的二叉树；（2）把分离后的每棵二叉树转换为树；（3）整理第（2）步得到的树，使之规范，这样得到森林。\n\n5、转换以后的特点： (1、 根据树与二叉树的转换关系以及二叉树的遍历定义可以推知：\n\n树的先序遍历与其转换的相应的二叉树的先序遍历的结果序列相同；\n树的后序遍历与其转换的二叉树的中序遍历的结果序列相同；\n树的层序遍历与其转换的二叉树的后序遍历的结果序列相同。\n\n（2、 由森林与二叉树的转换关系以及森林与二叉树的遍历定义可知：\n 森林的先序遍历和中序遍历与所转换得到的二叉树的先序遍历和中序遍历的结果序列相同。\n八、线索二叉树\n传统的二叉链表仅能体现出一种父子关系，不能直接得到结点在遍历中的前驱或后继。引入【线索二叉树】正是为了加快查找结点前驱和后继的速度。（1、定义：\n\n前驱与后继：在二叉树的先序、中序或后序遍历序列中的两个相邻的结点；\n线索：指向前驱或后继的结点的指针；\n线索二叉树：加上线索的二叉链表的二叉树；\n线索化：对二叉树按某个遍历次序使其变为线索二叉树的过程。\n\n（2、规定：【口诀：左前右后，0孩1前后】\n\n若无左子树，令lchild指向其前驱结点；\n若无右子树，令rchild执行指向其后继结点\n增加两个标志域标识是指左/右孩子还是指向前驱/后继。\n\n\n1、存储结构//线索二叉树存储结构typedef struct ThreadNode{\tchar data;\tstruct ThreadNode *lchild, *rchild;\t// 左右孩子指针\tint ltag, rtag;\t// 左右线索标志}ThreadNode, *ThreadTree;123456\n\n2、如何判断是孩子还是线索其标志位含义如下： 【口诀：左前右后，0孩1前后】\n\n\n这种加上线索的二叉链表称为线索链表，相应的二叉树称为线索二叉树。\n根据线索性质的不同， 线索二叉树可分为前序线索二叉树、 中序线索二叉树和后序线索二叉树三种。\n\n3、三种遍历\n因为线索化后， 各个结点指向有变化， 因此原来的遍历方式不能使用， 需要使用新的方式遍历线索化二叉树。\n中序线索二叉树的结点中隐含了线索二叉树的前驱和后继信息。\n在对其遍历时，需要找到第一个具有前驱结点的左结点，然后依次找结点的后继。\n在中序线索二叉树中找结点后继的规律是:\n\n若其右标志为1，则右链为线索，指示其后继;\n否则遍历右子树中第一个访问的结点（右子树中最左下的结点）为其后继。\n\n\nvoid InOrderTraverse(BiThrTree T){ // 中序输出    if(T)    {        InOrderTraverse(T-&gt;lchild); //中序遍历左子树        cout&lt;&lt; T-&gt;data;        InOrderTraverse(T-&gt;rchild); //中序遍历右子树    }}12345678\n九、哈夫曼树1、带权路径长度WPL\n2、哈夫曼树的构造（算法）\n构造 Huffman 树的基本思想：权值大的结点用短路径，权值小的结点用长路径。\n\n\n\n构造过程\n\n\n\n3、哈夫曼树的性质\n4、哈夫曼编码\n\n———散列查找———一、散列查找1、基本概念\n散列函数\n在进行查找时，在记录的存储位置与它的关键字之间建立一个确定的对应关系h,以线性表中每个元素的关键字K为自变量，通过函数h(K)计算出该元素的存储位置，我们将h函数称为散列函数或哈希函数。h(K)的值称为散列地址或哈希地址。\n\n冲突\n在实际应用中，通常可能出现一个待插入元素的散列地址单元已被占用情况，使得该元素无法直接存入此单元，这种情况称为冲突。\n\n同义词\n 具有不同关键字而具有相同散列地址的元素称为同义词，即key1≠key2，但h(key1)=h(key2)。由同义词引起的冲突称作同义词冲突。\n\n装填因子(α)\n指散列表中已存入的元素数n与散列表空间大小m的比值,即：α=n/m。当α越小时，冲突可能性就越小，但同时，存储空间利用率就越低。\n\n\n散列表：根据设定的哈希函数及处理冲突的方法将一组关键字映象到一个有限的连续的地址集上，即把记录存放在表中映象的位置上，这种表便称为散列表(哈希表)。\n\n一个散列表的好坏与三个因素有关：1.装填因子 2、所采用的散列函数 3、解决冲突的方法\n\n\n假定一个线性表为A=(18,75,60,43,54,90,46)，选取散列函数为：h(K)=K%m 取m=13则得每个元素散列地址：h(18)=18 % 13=5h(75)=75 % 13=10h(60)=60 % 13=8h(43)=43 % 13=4h(54)=54 % 13=2h(90)=90 % 13=12h(46)=46 % 13=7根据散列地址，实现元素的存储映象H[m]：\n\n\n\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\n\n\nH\n\n\n54\n\n43\n18\n\n46\n60\n\n75\n\n90\n\n\n\n\n例：如向下表中再插入元素70时，70%13=5，则出现了冲突\n\n\n\n\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\n\nH\n\n\n54\n\n43\n18\n\n46\n60\n\n75\n\n90\n\n\n\n\n\n2、散列函数[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-OtlYI1uv-1641217649135)(myReviewPicture/散列函数.png)]\n 构造散列函数的目标是使散列地址尽可能均匀分布在散列空间上，同时使计算尽可能简单，以节省计算时间。1\n（1、关键词为数字时：a.直接定址法\nb.除留余数法(常用)\nc.数字分析法分析数字关键字在各位上的变化情况，取比较随机的位作为散列地址，如电话号码、身份证号码某几位会比较随机；1\n\n例：有一组关键字如下：\n 92326875\n 92739628\n 92343634\n 92706816\n 92774638\n 92381262\n 92394220\n通过分析：每个关键字从左到右第1、2、3位和第6位取值较集中，不宜作散列地址，其余的第4、5、7、8位取值分散，可以选择，若取最后两位作散列地址，得：(2,75,28,34,16,38,62,20)\n\nd.平方取中法key取平方再取中间几位1\n（2、关键词为字符时：a、ASCII码加和法h(key)=(求和key[i])mod TableSize1\nb、前3个字符移位法h(key)=(key[0]*27*27+key[1]*27+key[2])mod TableSize1\n二、处理冲突的方法1、开放定址法\na.线性探测法\n\n\n注意：查找某个值时，用散列函数计算完后，如果那个结果位置上的数字与关键词不一样时，并不能断定关键词不存在，还应该按照冲突解决策略继续找，直到找到空位置了还没找到，才能断定该关键词不存在。\nb、平方探测（二次探测）\n\n举例：h(key)=key mod 11;\n\n\n\n注意：取素数是为了减少公因子（减少冲突）\n\nc.在散列法\n2、分离链接法\n\n———————————————图————————————————一、图的基本概念\n集合只有同属于一个集合；线性结构存在一对一的关系；树形结构存在一对多的关系；图状结构存在多对多的关系。\n\n\n\n1、简单图\n简单图满足以下两条内容：\n1）不存在重复边\n2）不存在顶点到自身的边\n\n2、完全图\n任意两顶点之间都存在边\n\n3、连通分量\n在无向图中，两顶点有路径存在，就称为连通的。若图中任意两顶点都连通，同此图为连通图。无向图中的极大连通子图称为连通分量。\n\n4、强连通分量\n在有向图中，两顶点两个方向都有路径，两顶点称为强连通。\n若任一顶点都是强连通的，称为强连通图。有向图中极大强连通子图为有向图的强连通分量。\n\n5.顶点的度、入度和出度\n顶点的度为以该顶点为一个端点的边的数目。\n对于无向图，顶点的边数为度，度数之和是顶点边数的 2 倍。\n对于有向图，入度是以顶点为终点，出度相反。有向图的全部顶点入度之和等于出度之和且等于边数。顶点的度等于入度与出度之和\n\n注意：入度与出度是针对有向图来说的\n二、图的存储1、数组（邻接矩阵）表示法\n建立一个顶点表（记录各个顶点信息）和一个邻接矩阵（表示各个顶点之间关系）。\n\n设图A=（V，E）有n个顶点，则\n\n\n图的邻接矩阵是一个二位数组A.arcs[n] [n]，定义为：\n\n\nåœ¨è¿™é‡Œæ’å¥å›¾ç‰‡æè¿°\na.无向图的邻接矩阵表示法\n分析1：无向图的邻接矩阵是对称的；分析2：顶点i的度=第i行（列）中1的个数；特别：完全图的邻接矩阵中，对角元素为0，其余1。\n\n\nb.有向图的邻接矩阵表示法\n注：在有向图的邻接矩阵中，第 i 行含义：以结点vi为尾的弧（即出度边）第 i 列含义：以结点vi为头的弧（即入度边）分析1：有向图的邻接矩阵可能是不对称的；分析2：顶点的出度 = 第 i 行元素之和顶点的入度 = 第 i 列元素之和顶点的度 = 第 i 行元素之和 + 第 i 列元素之和\n\n\nc.有权图（网）的邻接矩阵表示法\n\n2.邻接表（顺序存储与链式存储结合）![\na.无向图的邻接表\nb.有向图的邻接表与逆邻接表\nc.带权值的网图\n三、图的遍历1、深度优先遍历算法\n深度优先搜索类似于树的先序遍历。\n其基本思想是：\n\n首先访问起始顶点v，然后由v出发，访问与v 邻接且未被访问的任一顶点w1，再访问与w1 邻接且未被访问的任一顶点W2……重复上述操作。\n当不能再继续向下访问时，依次退回到最近被访问的顶点，若它还有邻接顶点未被访问过，则从该点开始继续上述搜索过程，直至图中所有顶点均被访问过为止。\n\n\n\n\n从顶点a 出发，进行深度优先遍历，可以得到的一种顶点序列为：a e d f c b\n\n2、广度优先遍历算法\n广度优先搜索类似于二叉树的层序遍历算法。\n其基本思想是：\n\n首先访问起始顶点v，接着由ν出发，依次访问v 的各个未访问过的邻接顶点W1，W2，…，Wi，然后依次访问W1，W2，…，Wi的所有未被访问过的邻接顶点；\n再从这些访问过的顶点出发，访问它们所有未被访问过的邻接顶点，直至图中的所有顶点都被访问过为止。\n若此时图中尚有顶点未被访问，则另选图中的一个未被访问的顶点作为始点，重复上述过程，直至图中所有顶点都被访问到为止。\n\n\n\n\n从顶点1 出发，按照广度优先规则遍历，可以得到的一种顶点序列是： 1234576\n\n二、最小生成树1、性质\n2、Prim算法\n\n\n3、Kruskal算法\n三、拓扑排序\n\n四、最短路径迪杰斯特拉算法\n通过迪杰斯特拉算法计算图G中的最短路径时，需要指定起点s。\n 此外，需要引进两个集合S和U。\n\nS的作用：记录已求出最短路径的顶点（以及相应的最短路径长度），\nU的作用：记录还未求出最短路径的顶点（以及该顶点到起点s的距离）。\n初始时，S中只有起点s；\nU中是除s之外的顶点，并且U中顶点的路径是“起点s到该顶点的路径”。\n然后，从U中找到路径最短的顶点，并将其加入到S中；\n接着，更新U中的顶点和顶点对应的路径。\n然后，再从U中找到路径最短的顶点，并将其加入到S中；接着，更新U中的顶点和顶点对应的路径。\n重复上述操作，直到遍历完所有顶点。\n\n\n\n\n具体过程1、初始化，所有顶点的距离初始化为无穷大（INFINITY)\n\n2、选定点A，更新（A-A距离设为0)\n\n3、S集合为{A,B}，考察B的所有邻接点\n\n为什么选定B加入集合S？因为不可能还有其他路径比2还短，我不管经过C到B还是D到B都不可能是路径小于2，所以我们得到了A-&gt;B的最短路径\n\n\n\n做完这一步，下一步加入集合S的是D因为目前A-&gt;D的路径长度最短，为3（我已经知道了A直接到D和A经过B到D的路径长度）如果A-&gt;B-&gt;X-&gt;D小于min{A-&gt;D,A-&gt;B-&gt;D},那么A-&gt;B-&gt;X小于min{A-&gt;D,A-&gt;B-&gt;D}，那么加入集合的应该是X，这是矛盾的（接下来的操作都是一样的道理\n\n4、S集合为{A,B,D}，在U中没有D的邻接点，不操作\n5、S集合为{A,B,D,C}，在U中没有C的邻接点，不操作\n6、S集合为{A,B,D,C,F}，更新\n\n7、S集合为{A,B,D,C,F,E}，在U中没有E的邻接点，不操作\n8、S集合为{A,B,D,C,F,E,G}，在U中没有G的邻接点，不操作\n9、最终结果如上图。\n———排序———一、排序的类别\n1、插入排序基本思想：\n【1】直接插入排序（1、基本思想：\n1）、将待排序的一组序列（有N个数）分为已排好的和未排好的 2个部分；\n2）、初始状态时，已排序序列仅包含第1 个元素，未排序序列中的元素为除去第1 个元素意外的N-1 个元素；\n3）、此后，将未排序序列中的元素逐一插入到已排序的序列中；\n4）、如此往复，经过N-1 次插入后，未排序序列中元素个数为0 ，则排序完成。\n\n（2、执行过程\n\n（3、时空效率及稳定性\n【2】希尔排序（1、基本思想：\n1）、将带排序序列的一组元素按一定间隔分为若干序列分别进行插入排序；\n2）、开始时设置的“间隔”较大，在每轮排序中，将”间隔“逐步缩小\n3）、直到“间隔”为 1，也就到了最后一步，做简单插入排序。\n\n（2、执行过程\n（3、时空效率及稳定性\n2、交换排序基本思想：\n【1】冒泡排序（1、基本思想：\n（2、执行过程\n（3、时空效率及稳定性\n【2】快速排序（1、基本思想：\n1)、将未排序元素根据一个作为基准的“主元（pivot）分为两个子序列；\n2）、其中一个子序列的记录均大于“主元”，另一个序列则均小于“主元；\n3）、递归地对两个子序列用类似的方法进行排序。\n\n（2、执行过程\n\n\n（3、时空效率及稳定性\n3、选择排序基本思想：\n【1】简单选择排序（1、基本思想：\n1）、在未排序的序列中选出最小元素和序列的首位元素交换，\n2）、再在剩下的排序序列中再选出最小元素与序列的第2 个位置元素交换\n3）、以此类推，最后形参从小到大的已排序序列。\n\n（2、执行过程\n（3、时空效率及稳定性\n【2】堆排序（1、基本思想：\n1）、利用最大堆（或最小堆）\\输出*堆顶元素*，即最大值（或最小值）；\n2）、将剩余元素重新生成最大堆（或最小堆），继续输出堆顶元素；\n3）、重复此过程，知道全部元素都已输出，得到的输出元素序列即为有序序列\n\n（2、执行过程要点&lt;1&gt;初始化堆的过程\n\n\n下面是构建初始堆的过程\n\n\n\n下面是堆排序的过程\n\n\n\n（3、时空效率及稳定性\n4、归并排序\n二、各种排序的比较口诀：快选堆希不稳，选堆归基不变\n不稳：说的是 算法不稳定\n不变：说的是 关于移动次数和关键字顺序无关的排序\n\n\nend\nend\n","categories":["笔记"]},{"title":"LiteLoaderQQNT","url":"/Arknight-notes/posts/12035.html","content":"LiteLoaderQQNTLiteLoaderQQNT 是 QQNT 的插件加载器，一般在 QQNT 的环境内简称为 LiteLoader。它可以让你自由地为 QQNT 添加各种插件，并实现例如美化主题、增加功能等各种功能。\n（比如防撤回，设置动态背景啥的\n\n（波奇可爱捏\n安装此文档为 LiteLoaderQQNT 1.1.x 编写\n\n（法一）（推荐）第三方工具一些社区开发的安装工具来帮助你快速安装，或跳过此条目来阅读官方安装教程\n link LiteLoaderQQNT 快速安装, https://github.com/Mzdyl/LiteLoaderQQNT_Install/, https://avatars.githubusercontent.com/u/95263282?v=4 \n\n（法二）你需要先下载 LiteLoaderQQNT 到任意位置，以下有两种方式\n\n通过 Release\n前往 LiteLoaderQQNT 仓库，在 Release 中 Latest 内，下载 LiteLoaderQQNT.zip 文件，将压缩包内 LiteLoaderQQNT 目录解压到任意位置\nLiteLoaderQQNT：https://github.com/LiteLoaderQQNT/LiteLoaderQQNT\n\n通过 Clone\n使用 Git 工具将 LiteLoaderQQNT 仓库 Clone 到本地任意位置\nshell\ngit clone --depth 1 https://github.com/LiteLoaderQQNT/LiteLoaderQQNT.git\n\n\n找到 QQNT 安装目录，编辑 resources\\app\\app_launcher\\index.js 文件，在最前端插入一行require(String.raw此处为你 LiteLoaderQQNT 目录路径);\njavascript\nrequire(String.raw`C:\\LiteloaderQQNT`); // 此处换成你 LiteLoaderQQNT 目录位置require('./launcher.node').load('external_index', module);\n请确保拥有 QQNT 安装目录的读写权限！如果不想给予 QQNT 安装目录读写权限\n\n按照下文 存储位置 一节进行设置\n将 LiteLoaderQQNT/src/preload.js 复制到 QQNT/resources/app/versions/此处为版本号/application/preload.js\n\nLiteLoaderQQNT 会在第二步骤的文件不一致或没有文件时自动复制，也就是说在更新本体后需再进行一次这步骤\n\n插件此文档为 LiteLoaderQQNT 1.1.x 编写\n安装方式一：手动安装如果你有现成的插件，请先确保是与 LiteLoaderQQNT 兼容的，并且拥有对应依赖插件\n将插件目录移动到 LiteLoaderQQNT/plugins 文件夹内，如果插件是压缩包请先解压\n方式二（推荐）：LiteLoaderQQNT Plugin 插件安装助手可以先手动安装第三方插件市场类插件，在其中安装插件\nhttps://github.com/ltxhhz/LL-plugin-list-viewer/功能\n插件列表查看\n插件检查更新\n插件安装（支持镜像）\n插件卸载\n插件查找\n\n\n\n依赖查找\n\n\n使用方法法一：下载发行版https://github.com/ltxhhz/LL-plugin-list-viewer/releases/tag/v1.3.1\n\n下载发行版并解压\n将文件夹移动至 LiteLoaderQQNT数据目录/plugins/ 下面\n重启 QQNT\n\n法二：使用 git clone\nclone 本仓库 git clone https://github.com/ltxhhz/LL-plugin-list-viewer.git\n运行以下命令\n\nnpm inpm run build\n\n如果clone到了 plugins 目录下，修改 manifest.json 中 inject 为\n\n\"injects\": {    \"main\": \"./dist/main/index.js\",    \"preload\": \"./dist/preload/index.js\",    \"renderer\": \"./dist/renderer/index.js\"}\n\n否则可以将 dist 目录移动到 LiteLoaderQQNT数据目录/plugins/ 目录下\n\n使用安装完后打开QQ打开设置页面选择插件列表即可\n\n附录寻找插件插件列表官方维护着一份插件列表，收录了已知的大部分插件，可在官网首页中查看详情\n通过搜索LiteLoaderQQNT 的插件基本发布在 GitHub，善用搜索可以快速的找到所需插件\n比如在搜索框键入关键词LiteLoader和插件，即可找到大量LiteLoaderQQNT生态的插件\n官网首页LiteLoaderQQNt 官网下面已列出全部已收录插件，点击卡片即可跳转至对应仓库\n插件市场有一些第三方插件市场，手动安装后可列出大量插件\n修补此条目仅需 Windows 用户查看，其他系统无需继续阅读此条目\n由于 Windows 系统平台 QQNT 被添加文件完整性验证，你需要额外步骤来解除限制,有下列四种方式：\n\nDLLHijackMethod\n在 Release 下载 dll 文件，重命名为 dbghelp.dll 放入 QQ.exe 同级目录下即可https://github.com/LiteLoaderQQNT/QQNTFileVerifyPatch/tree/DLLHijackMethod\n\nQQNTFileVerifyPatch\n在 Release 下载 exe 文件，运行将弹出文件选择框，进入 QQNT 安装目录选择 QQ.exe 开始修补，每次更新都需要重新修补https://github.com/LiteLoaderQQNT/QQNTFileVerifyPatch\n\nPatcherNFixer\n在 Release 下载 zip 文件，解压后运行 exe 将弹出图形化界面，根据软件界面提示选择相应选项与修补方式，每次更新都需要重新修补https://github.com/xh321/LiteLoaderQQNT-PatcherNFixer\n\nV8Killer\n此方式目前过于麻烦，且需要自行寻找对应的 RVA 偏移量，只说明此方式的可行性，需自行探索使用方式https://github.com/ShellWen/v8_killer\n\n\n检查按照上述教程完成安装后，有两种方法检查 LiteLoaderQQNT 是否成功安装\n\n运行 QQNT 并打开设置，查看左侧列表是否出现 LiteLoaderQQNT 选项\n使用终端运行 QQNT 查看是否有 LiteLoaderQQNT 相关内容输出显示\n\n如果有显示，即安装成功，玩的开心！\n存储目录支持设置 LITELOADERQQNT_PROFILE 环境变量指定 data plugins config.json 存储位置，即可不在本体目录进行读写操作，比如 MacOS 与 Linux 平台 QQNT，以及类似于 flatpak 打包的 QQNT，让其实现成为可能\n如果你想将本体与存储目录合并在一起（便携软件）需将 LITELOADERQQNT_PROFILE 环境变量删除，将 data plugins config.json 移动回本体根目录下\n更新QQNT每次更新 QQNT 都需要重新根据上述教程重新修补\n版本支持支持 QQNT 桌面端 全架构 最低 20667 版本到官网最新版更老的版本也支持，只是设置界面样式会崩坏，不介意也可以用\n外部链接Telegram群聊：https://t.me/LiteLoaderQQNT频道：https://t.me/LiteLoaderQQNT_Channel\nLiteLoaderQQNT框架本体：https://github.com/LiteLoaderQQNT/LiteLoaderQQNT插件模板：https://github.com/LiteLoaderQQNT/Plugin-Template插件列表：https://github.com/LiteLoaderQQNT/Plugin-List\nist\n","categories":["Github项目"]},{"title":"近期CDN状况分析","url":"/Arknight-notes/posts/19085.html","content":"原博主在 V2EX 发声, 表示其被威胁删帖: https://www.v2ex.com/t/1057993原博主首次在 V2EX 发帖: 《供应链投毒后，我们的选择还剩下哪些？》 https://v2ex.com/t/1056428\n原博文: https://www.54yt.net/435.html\n原博客文章备份: https://web.archive.org/web/https://www.54yt.net/435.html\n为了防止丢失并出于公共利益, 以下是全图文转载, 如有不妥可删除\n-\n-\n-\nBootCDN/Staticfile投毒分析供应链投毒后，我们的选择还剩下哪些？病毒分析分区附件样本、网址谨慎下载点击，可能对计算机产生破坏，仅供安全人员在法律允许范围内研究，禁止非法用途！\n禁止求非法渗透测试、非法网络攻击、获取隐私等违法内容，即使对方是非法内容，也应向警方求助！\n\n前言从早前的LNMP、OneinStack到XZ Utils，再到现在的Staticfile、BootCDN；供应链攻击总是让人猝不及防。纵观这些被攻击的项目，往往都是无处不在，经常被大家所使用，但是却并没有给提供者带来什么收入。 在突然有一天，提供者感到疲惫不堪，却又迫于用户们的压力无法关停服务的情况下，突然有新的组织/个人来帮助一起进行开发或提供服务，甚至是直接的现金收购/服务赞助；在这种情况下，接受帮助自然是首选的方案。 我认为建立有效的捐助途径不失为缓解这一问题的良方，正如AlmaLinux、RockyLinux或是cdnjs、jsdelivr一样，这些服务背后都有着可靠的企业长期提供捐助承诺，也帮助项目不断成长和有效地提供服务。序幕和WDCP、LNMP、OneinStack一样，这次的Staticfile、BootCDN、Polyfill事件也是背后指向同一个组织[[1]]。更进一步的研究表明这些组织似乎会恶意攻击其他提供类似服务的供应商，同时采取接触洽谈来并入攻击目标。 在这种做法下，曾经由七牛云提供服务的Staticfile.org被易手，而原先由个人提供服务、由又拍云提供接入服务的BootCSS也同样被易手。 但是这些背后的交易在事件发生前却没有人进行公开，也许是原来的提供者厌倦了日复一日付出却看不到回报的生活，也许是这些组织瞒天过海许下了虚假的承诺，让原本积累了大量用户的基础服务成为了这些组织用来攻击用户们的利刃。\n探究大多数关于这次攻击的报道集中于一个星期之前，然而事件的开始却远早于这个时间。一年以前，V2EX社区就有用户发文表示BootCSS的静态资源被投毒[2]。通过查阅记录可以发现，BootCSS.com由王赛于2012年底批量注册，建站初期主要提供的是BootStrap介绍和交流[3,4,5]。于此同时进行批量注册的还有golaravel.com等一系列技术栈的中文网，猜测是想使用站群方式来进行项目文档的本地化，同时积累受众用户。在2013年十一月初，BootStrap中文网上线了OpenCDN加速服务，由又拍云赞助，提供cdnjs的国内镜像[6]。也许是由于用户的增长又拍云难以承担高额的成本，又或者是又拍觉得收益无法Cover成本，这段关系一直持续到了2017年年底[7]。自此之后的一段时间，提供服务的CDN便开始快速变更，从白山云到京东云，最终到了10月份由于账单压力或是其他原因出现了大面积的服务中断[8]。在恢复后，原先的服务开始由猫云提供，自此开始BootCDN的服务出现了一些不连续的中断事件[9]。2019年3月、10月、2020年1月陆续出现小规模的中断，尽管如此，但是在接下来的几年时间中，猫云一直为BootCDN提供加速服务，只是加速域名从cdn.bootcss.com更换为了cdn.bootcdn.net；而于此同时百度静态资源公共库则彻底停止了服务。时间来到2022年，在1月份经历了中断后，2月份猫云或许是基于和又拍云同样的原因停止了赞助，服务商也从此开始变更为了极兔云[10]。或许是由于极兔云本身是融合CDN服务，与上一家同样类型的赞助商服务相冲突的原因，BootCDN发布公告表示将下线cdn.bootcss.com域名。在此期间，jsDelivr的备案被关停、解析被污染，从此基本断绝了在中国大陆的使用。\n梦醒2023年4月份，BootCDN的三个关联域名[bootcdn.net,bootcdn.cn,bootcss.com]ICP备案变更为郑州紫田网络科技有限公司，同时域名注册商也从阿里云转入腾讯云，由此揭幕了噩梦的来临[11]。2023年6月份，开始有用户陆续发现部分静态资源内存在投毒行为[12]。即便到现在，投毒行为仍在继续，大量用户反馈存在资源被投毒[13]。自此BootCDN这个拥有十多年历史的国内静态资源加速服务彻底沦为了攻击者的工具，恶意代码随意被嵌入无数正在使用的网站中。而由于BootCDN历史久远，以至于许多生产环境甚至都不知道他们曾经引入了该服务。而这样的攻击相信还会继续持续下去，直到大家渐渐意识到…又或是仍旧…\n巧合无独有偶，原本由七牛云提供服务的Staticfile CDN于2023年10月进行了备案信息变更和注册局转移[14]。两个关联域名staticfile.org和staticfile.net被转入河南泉磐网络科技有限公司。而先前BootCDN所转入的公司名称为郑州紫田网络科技有限公司，两者同为河南省郑州市的相同类型公司。而先前Ze-Zheng Wu所发现的几个域名由统一组织控制高度符合[15]。通过天眼查查询可知紫田科技旗下知名的一个产品为51.La站点统计平台。通过Bing搜索不难发现在2023年集中出现大量使用该统计平台遇到劫持的案例。通过天眼查对紫田科技股东徐征进行查询，发现其曾担任郑州帝恩爱斯网络科技有限公司法定代表人及高管，也曾担任河南云打包网络科技有限公司高管和股东。而Staticfile域名持有公司河南图网信息技术有限公司的法人申石磊同时任职郑州帝恩爱斯网络科技有限公司法定代表人。而Staticfile的域名注册商商中在线也与紫田科技关联的公司存在着说不清道不明的关系。自此可以确定这两个原本由不同云厂商所赞助的静态资源加速服务已经被同一组织所控制，与上述Ze-Zheng Wu的调查一致。看似似乎这只是一个名不见经传的小公司所为，然而这只不过是挡在云层前的迷雾。通过查阅可以发现郑州紫田网络科技有限公司总经理李跃磊同时担任河南亿恩科技股份有限公司股东。\n通过天眼查透视链可以查看到企业彼此之间的关联信息。故事到这里似乎就结束了，然而还有收购polyfill服务的那家公司Funnull需要进行调查。通过查询域名注册和备案信息可以发现背后的公司为南京妙彩文化传播有限公司。这家公司的主营业务则是为博彩网站提供国内优化CDN服务，与上述的劫持行为不谋而合。不过更为危险的是这家公司同时还提供诈骗、钓鱼、色站等令人发指的服务，将供应链攻击提升到了新的高度。\n答案这就像一张巨大的关系网，串联起了利益链中的彼此。每一家公司都看似运营者合规可靠的服务，背后进行的确实见不得人的勾当。\n郑州紫田网络科技有限公司商中在线科技股份有限公司河南亿恩科技股份有限公司南京妙彩文化传播有限公司河南图网信息技术有限公司河南云打包网络科技有限公司北京新网互联软件服务有限公司郑州帝恩爱斯网络科技有限公司\n镇痛从来没有什么疼痛能够有效缓解，更何况是这种绝症。目前最为可靠的同类服务为字节跳动静态资源公共库你可以将以下地址进行修改\ncdn.bootcss.comcdn.bootcdn.net/ajax/libscdn.staticfile.netcdn.staticfile.org\n替换为\n//zstatic.net 又拍云赞助s4.zstatic.net/ajax/libs//本站提供，回源南科大，使用火山云CDNcdnjs.snrat.com/ajax/libs\n或者你可以尝试其他的提供商\n//7EDuse.sevencdn.com/ajax/libs//Web缓存网cdnjs.webstatic.cn/ajax/libs///字节跳动 最后更新于2022年lf3-cdn-tos.bytecdntp.com/cdn/expire-1-Mlf6-cdn-tos.bytecdntp.com/cdn/expire-1-Mlf9-cdn-tos.bytecdntp.com/cdn/expire-1-Mlf26-cdn-tos.bytecdntp.com/cdn/expire-1-M//360奇舞团，长期未更新https://lib.baomitu.com///晓白云sf.akass.cn//泽瑶网络 jsDelivr镜像cdn.jsdmirror.com\n目前已经收到相关企业的威胁邮件*\n[1]https://www.bleepingcomputer.com/news/security/polyfillio-bootcdn-bootcss-staticfile-attack-traced-to-1-operator/[2]https://www.v2ex.com/t/950163[3]https://web.archive.org/web/20121206014141/http://www.bootcss.com/[4]https://ip.sb/whois/bootcss.com[5]https://www.icpapi.com/%E4%BA%ACICP%E5%A4%8711008151%E5%8F%B7/[6]https://web.archive.org/web/20131103022433/http://open.bootcss.com/[7]https://web.archive.org/web/20171230183848/http://www.bootcdn.cn/[8]https://global.v2ex.com/t/494375[9]https://web.archive.org/web/20190119210705/https://www.bootcdn.cn/[10]https://web.archive.org/web/20220208201547/https://www.bootcdn.cn/[11]https://whoisfreaks.com/tools/whois/history/lookup/bootcss.com[12]https://www.v2ex.com/t/950163[13]https://github.com/Tencent/vConsole/issues/683[14]https://www.icpapi.com/staticfile.net/[15]https://x.com/mdmck10/status/1806349965733544160\n\n附：\n\n\n\n\n\n发表于 2024-7-17 19:03**本帖最后由 你好，再见 于 2024-7-18 14:32 编辑\n\n\n\n\n\n这样说来到让我想起平时手机上搜索一些资料会访问到一些个人博客，也都是加载完成后过一会跳转到垃圾网站 以前我以为是运营商在搞鬼，现在看来还真有可能是这个公共库的问题 看了一下，我自己的博客也引用了bootcdn的资源，bootcdn用的人太多太多了 个人博客真的是重灾区，很多主题作者在开发的时候就已经把这些公共库资源写死了   ————————————————————————————————\n\n\n\n\n\n\n\n\n\n\n\n\n) |\n","categories":["随记"],"tags":["CDN"]},{"title":"将博客CDN从jsDelivr切换至自建反向代理源","url":"/Arknight-notes/posts/4746.html","content":"快速将Butterfly主题的CDN从jsDelivr切换至自建反向代理源最新版的Butterfly取消了原来设置在_config.yml里的默认CDN，导致不能快速替换掉现在极不稳定的jsDelivr CDN。本文的默认Butterfly版本为4.1.0。\n配置现在的默认CDN地址被放在了主题的/scripts/events/config.js中：\n/** * Butterfly * 1. Merge CDN * 2. Capitalize the first letter of comment name */'use strict'hexo.extend.filter.register('before_generate', () =&gt; {  const themeConfig = hexo.theme.config  /**   * Merge CDN   */  const defaultCDN = {    main_css: '/css/index.css',    main: '/js/main.js',    utils: '/js/utils.js',    // pjax    pjax: 'https://cdn.jsdelivr.net/npm/pjax/pjax.min.js',    // comments    gitalk: 'https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js',    gitalk_css: 'https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css',    blueimp_md5: 'https://cdn.jsdelivr.net/npm/blueimp-md5/js/md5.min.js',    valine: 'https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js',    disqusjs: 'https://cdn.jsdelivr.net/npm/disqusjs@1/dist/disqus.js',    disqusjs_css: 'https://cdn.jsdelivr.net/npm/disqusjs@1/dist/disqusjs.css',    utterances: 'https://utteranc.es/client.js',    twikoo: 'https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js',    waline: 'https://cdn.jsdelivr.net/npm/@waline/client/dist/Waline.min.js',    giscus: 'https://giscus.app/client.js',    // share    addtoany: 'https://static.addtoany.com/menu/page.js',    sharejs: 'https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js',    sharejs_css: 'https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css',    // search    local_search: '/js/search/local-search.js',    algolia_js: '/js/search/algolia.js',    algolia_search_v4: 'https://cdn.jsdelivr.net/npm/algoliasearch@4/dist/algoliasearch-lite.umd.js',    instantsearch_v4: 'https://cdn.jsdelivr.net/npm/instantsearch.js@4/dist/instantsearch.production.min.js',    // math    mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js',    katex: 'https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css',    katex_copytex: 'https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.min.js',    katex_copytex_css: 'https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.css',    mermaid: 'https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js',    // count    busuanzi: '//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js',    // background effect    canvas_ribbon: 'https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-ribbon.min.js',    canvas_fluttering_ribbon: 'https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-fluttering-ribbon.min.js',    canvas_nest: 'https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-nest.min.js',    lazyload: 'https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js',    instantpage: 'https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js',    typed: 'https://cdn.jsdelivr.net/npm/typed.js/lib/typed.min.js',    pangu: 'https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js',    // photo    fancybox_css_v4: 'https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.css',    fancybox_v4: 'https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.js',    medium_zoom: 'https://cdn.jsdelivr.net/npm/medium-zoom/dist/medium-zoom.min.js',    // snackbar    snackbar_css: 'https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css',    snackbar: 'https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js',    // effect    activate_power_mode: 'https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/activate-power-mode.min.js',    fireworks: 'https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/fireworks.min.js',    click_heart: 'https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/click-heart.min.js',    ClickShowText: 'https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/click-show-text.min.js',    // fontawesome    fontawesomeV6: 'https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6/css/all.min.css',    // Conversion between Traditional and Simplified Chinese    translate: '/js/tw_cn.js',    // flickr-justified-gallery    flickr_justified_gallery_js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',    flickr_justified_gallery_css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css',    // aplayer    aplayer_css: 'https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css',    aplayer_js: 'https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js',    meting_js: 'https://cdn.jsdelivr.net/gh/metowolf/MetingJS@1.2/dist/Meting.min.js',    // Prism.js    prismjs_js: 'https://cdn.jsdelivr.net/npm/prismjs/prism.min.js',    prismjs_lineNumber_js: 'https://cdn.jsdelivr.net/npm/prismjs/plugins/line-numbers/prism-line-numbers.min.js',    prismjs_autoloader: 'https://cdn.jsdelivr.net/npm/prismjs/plugins/autoloader/prism-autoloader.min.js'  }  // delete null value  const deleteNullValue = obj =&gt; {    for (const i in obj) {      obj[i] === null &amp;&amp; delete obj[i]    }    return obj  }  themeConfig.CDN = Object.assign(defaultCDN, deleteNullValue(themeConfig.CDN))  /**   * Capitalize the first letter of comment name   */  let { use } = themeConfig.comments  if (!use) return  if (typeof use === 'string') {    use = use.split(',')  }  const newArray = use.map(item =&gt; item.toLowerCase().replace(/\\b[a-z]/g, s =&gt; s.toUpperCase()))  themeConfig.comments.use = newArray})\n所以只要快速替换掉这里的CDN，就可以切换到我们自建的CDN上。\n成果将cdn.jsdelivr.net全部替换为自己的反代源后，成果就诞生了：\n/** * Butterfly * 1. Merge CDN * 2. Capitalize the first letter of comment name */'use strict'hexo.extend.filter.register('before_generate', () =&gt; {  const themeConfig = hexo.theme.config  /**   * Merge CDN   */  const defaultCDN = {    main_css: '/css/index.css',    main: '/js/main.js',    utils: '/js/utils.js',    // pjax    pjax: 'https://jsdelivr.pai233.top/npm/pjax/pjax.min.js',    // comments    gitalk: 'https://jsdelivr.pai233.top/npm/gitalk@latest/dist/gitalk.min.js',    gitalk_css: 'https://jsdelivr.pai233.top/npm/gitalk/dist/gitalk.min.css',    blueimp_md5: 'https://jsdelivr.pai233.top/npm/blueimp-md5/js/md5.min.js',    valine: 'https://jsdelivr.pai233.top/npm/valine/dist/Valine.min.js',    disqusjs: 'https://jsdelivr.pai233.top/npm/disqusjs@1/dist/disqus.js',    disqusjs_css: 'https://jsdelivr.pai233.top/npm/disqusjs@1/dist/disqusjs.css',    utterances: 'https://utteranc.es/client.js',    twikoo: 'https://jsdelivr.pai233.top/npm/twikoo/dist/twikoo.all.min.js',    waline: 'https://jsdelivr.pai233.top/npm/@waline/client/dist/Waline.min.js',    giscus: 'https://giscus.app/client.js',    // share    addtoany: 'https://static.addtoany.com/menu/page.js',    sharejs: 'https://jsdelivr.pai233.top/npm/social-share.js/dist/js/social-share.min.js',    sharejs_css: 'https://jsdelivr.pai233.top/npm/social-share.js/dist/css/share.min.css',    // search    local_search: '/js/search/local-search.js',    algolia_js: '/js/search/algolia.js',    algolia_search_v4: 'https://jsdelivr.pai233.top/npm/algoliasearch@4/dist/algoliasearch-lite.umd.js',    instantsearch_v4: 'https://jsdelivr.pai233.top/npm/instantsearch.js@4/dist/instantsearch.production.min.js',    // math    mathjax: 'https://jsdelivr.pai233.top/npm/mathjax@3/es5/tex-mml-chtml.js',    katex: 'https://jsdelivr.pai233.top/npm/katex@latest/dist/katex.min.css',    katex_copytex: 'https://jsdelivr.pai233.top/npm/katex@latest/dist/contrib/copy-tex.min.js',    katex_copytex_css: 'https://jsdelivr.pai233.top/npm/katex@latest/dist/contrib/copy-tex.css',    mermaid: 'https://jsdelivr.pai233.top/npm/mermaid/dist/mermaid.min.js',    // count    busuanzi: '//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js',    // background effect    canvas_ribbon: 'https://jsdelivr.pai233.top/npm/butterfly-extsrc@1/dist/canvas-ribbon.min.js',    canvas_fluttering_ribbon: 'https://jsdelivr.pai233.top/npm/butterfly-extsrc@1/dist/canvas-fluttering-ribbon.min.js',    canvas_nest: 'https://jsdelivr.pai233.top/npm/butterfly-extsrc@1/dist/canvas-nest.min.js',    lazyload: 'https://jsdelivr.pai233.top/npm/vanilla-lazyload/dist/lazyload.iife.min.js',    instantpage: 'https://jsdelivr.pai233.top/npm/instant.page/instantpage.min.js',    typed: 'https://jsdelivr.pai233.top/npm/typed.js/lib/typed.min.js',    pangu: 'https://jsdelivr.pai233.top/npm/pangu/dist/browser/pangu.min.js',    // photo    fancybox_css_v4: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css',    fancybox_v4: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js',    medium_zoom: 'https://jsdelivr.pai233.top/npm/medium-zoom/dist/medium-zoom.min.js',    // snackbar    snackbar_css: 'https://jsdelivr.pai233.top/npm/node-snackbar/dist/snackbar.min.css',    snackbar: 'https://jsdelivr.pai233.top/npm/node-snackbar/dist/snackbar.min.js',    // effect    activate_power_mode: 'https://jsdelivr.pai233.top/npm/butterfly-extsrc@1/dist/activate-power-mode.min.js',    fireworks: 'https://jsdelivr.pai233.top/npm/butterfly-extsrc@1/dist/fireworks.min.js',    click_heart: 'https://jsdelivr.pai233.top/npm/butterfly-extsrc@1/dist/click-heart.min.js',    ClickShowText: 'https://jsdelivr.pai233.top/npm/butterfly-extsrc@1/dist/click-show-text.min.js',    // fontawesome    fontawesomeV6: 'https://jsdelivr.pai233.top/npm/@fortawesome/fontawesome-free@6/css/all.min.css',    // Conversion between Traditional and Simplified Chinese    translate: '/js/tw_cn.js',    // flickr-justified-gallery    flickr_justified_gallery_js: 'https://jsdelivr.pai233.top/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',    flickr_justified_gallery_css: 'https://jsdelivr.pai233.top/npm/flickr-justified-gallery@2/dist/fjGallery.min.css',    // aplayer    aplayer_css: 'https://jsdelivr.pai233.top/npm/aplayer/dist/APlayer.min.css',    aplayer_js: 'https://jsdelivr.pai233.top/npm/aplayer/dist/APlayer.min.js',    meting_js: 'https://jsdelivr.pai233.top/gh/metowolf/MetingJS@1.2/dist/Meting.min.js',    // Prism.js    prismjs_js: 'https://jsdelivr.pai233.top/npm/prismjs/prism.min.js',    prismjs_lineNumber_js: 'https://jsdelivr.pai233.top/npm/prismjs/plugins/line-numbers/prism-line-numbers.min.js',    prismjs_autoloader: 'https://jsdelivr.pai233.top/npm/prismjs/plugins/autoloader/prism-autoloader.min.js'  }  // delete null value  const deleteNullValue = obj =&gt; {    for (const i in obj) {      obj[i] === null &amp;&amp; delete obj[i]    }    return obj  }  themeConfig.CDN = Object.assign(defaultCDN, deleteNullValue(themeConfig.CDN))  /**   * Capitalize the first letter of comment name   */  let { use } = themeConfig.comments  if (!use) return  if (typeof use === 'string') {    use = use.split(',')  }  const newArray = use.map(item =&gt; item.toLowerCase().replace(/\\b[a-z]/g, s =&gt; s.toUpperCase()))  themeConfig.comments.use = newArray})\n替换完后，运行hexo cl &amp;&amp; hexo g -d部署后，就成功切换到了你的反代源上。你也可以直接复制博主的成果进行使用\n\n原帖： https://cloud.tencent.com/developer/article/1987454 \n发表于2022-02-277**\n","categories":["博客美化"],"tags":["CDN"]},{"title":"IP签名","url":"/Arknight-notes/posts/60087.html","content":"\n\n\n\n\nd/)\n","categories":["博客美化"],"tags":["美化"]},{"title":"数据结构复习其一","url":"/Arknight-notes/posts/49533.html","content":"大一下数据结构泡图书馆战斗几个星期从日到夜好不容易勉强过了\n艹\n\n\n第一章：数据结构绪论一、数据1.数据是信息的载体，是描述客观事物的数、字符、以及所有能输入到计算机中，被计算机程序识别和处理的符号的集合。\n2.数据分为：数值性数据和非数值性数据。\n二、数据元素1.数据元素是数据的基本单位，是数据集合的个体。\n2.一个数据元素可以由若干数据项组成（此时数据元素被称为记录）。\n3.数据元素又称为元素、结点、记录。\n三、数据项1.数据项是具有独立含义的最小标识单位。\n2.数据项是数据的最小单位。\n四、数据对象1.数据对象是具有相同性质的数据元素的集合，是数据的一个子集。\n（整数数据对象，字母字符数据对象）\n五、结构1.结构是元素之间的。\n2.结构包含空间位置关系，相互作用和依赖关系。\n3.四种基本结构：集合结构、线性结构、树形结构、图形结构。\n(1)集合结构：结构中的数据元素之间除“同属一个集合”外，别无其他关系。\n(2)线性结构：数据元素一对一关系。\n(3)树形结构：一对多。\n(4)图形结构：多对多。\n六、数据结构1.形式定义：某一数据对象的所有数据成员之间的关系。记为：\nData_Structure={D,S}\n其中,D是某一数据对象，即数据元素的有限集合，S是该对象中所有数据成员之间的关系的有限集合。\n2.数据结构是相互之间存在一种或多种特点关系的数据元素的集合。\n3.数据结构包含三方面的内容：逻辑结构，存储结构和数据的运算。\n2.线性数据结构：L={K,R}（其中K为点集，R为关系&lt;&gt;）\n3.树形数据结构：T={K,R}（其中K为点集，R为关系&lt;&gt;）\n4.图形数据结构：G={K,R}（其中K为点集，R为关系() ）\n七、数据结构要解决的问题1.从广义上讲，数据结构描述现实世界实体的数学模型及其上的操作在计算机中的表示和实现。\n八、逻辑结构1.逻辑结构描述数据元素之间的关系。\n2.逻辑结构包括线性结构和非线性结构。\n（1）线性结构包括线性表（表、栈、队列、串）。栈、队列、串是受限线性表。\n（2）非线性结构包括树（二叉树、赫夫曼树、二叉排序树）和图（有向图、无向图）。\n九、物理结构（存储结构）1.物理结构是数据结构在计算机中的表示（或映像）。（存储结构是逻辑结构在计算机中的存储映像，包括数据元素映像和关系映像，但是逻辑结构是独立于存储结构的。）\n2.物理结构包括：顺序存储表示、非顺序存储（链式存储表示、索引存储表示、散列存储表示）。\n注意：有序表属于逻辑结构；顺序表、哈希表、单链表属于存储结构\n(1)顺序存储：逻辑上相邻的元素，存储的物理位置也相邻。优点：随机存取，每个元素占用最少的存储空间；缺点：只能使用相邻的一整块存储单元，可能产生较多的外部碎片。\n(2)链式存储：不要求逻辑上相邻的元素，存储的物理位置也相邻。借助指针表示元素之间的逻辑关系。优点：不会出现碎片现象，充分利用所有存储单元；缺点：每个元素因存储指针占用额外的存储空间，且只能实现顺序存取。\n(3)索引存储：建立附加索引表。优点：检索速度快；缺点：附加的索引表占内存，增加和删除数据也会修改索引表，花费较多时间。\n(4)散列存储：根据关键字直接计算存储地址。优点：检索、删除、增加都很快；缺点：会发生冲突，花费时间。\n十、数据类型1.数据类型是一个值的集合和定义在这个值集上的一组操作的总称。\n（如int整型变量，其值集为某个区间上的整数，定义在其上的操作为+、-、x、/等)\n2.原子数据类型是不可分解的数据类型（如int、float、char、*等等）。\n3.结构数据类型\n（1）由若干成分（原子类型或结构类型）按照某种结构组成的数据类型）\n（2）结构数据类型可以看做是一种数据结构和定义在其上的一组操作组成的整体。\n（3）如数组，由若干个分量组成，每个分量可以是整数，也可以是数组（int A[10]）。\n4.抽象数据类型\n（1）由用户定义，用以表示应用问题的数据模型。\n（2）由基本的数据类型组成，并包括一组相关的操作。\n（3）信息隐蔽和数据封装，使用与现实相分离。\n（4）抽象数据类型ADT是一个数学模型以及定义在该模型上的一组操作。\n（5）抽象数据类型=数据结构+定义在此数据结构上的一组操作。\n（6）（D，S，P）三元组表示。（D是数据对象，S是D上的关系集，P是对D的基本操作集）\n（7）ADT定义：\nADT 抽象数据类型名{\n数据对象：&lt;数据对象的定义&gt;\n数据关系：&lt;数据关系的定义&gt;\n基本操作：&lt;基本操作（函数）的定义&gt;\n}ADT 抽象数据类型名\n例子：\nADT Triplet {\n数据对象：D = {e1,e2,e3 | e1,e2,e3∈ElemSet}\n数据关系：R = {&lt;e1,e2&gt;, &lt;e2,e3&gt;}基本操作：Max(T, &amp;e)                           \n初始条件：三元组T已存在。\n操作结果：用e返回T的3个元素中的最大值。　　\n　　　　 Min(T, &amp;e)\n初始条件：三元组T已存在。\n操作结果：用e返回T的3个元素中的最小值。　\n} ADT Triplet\n（7）抽象数据类型可以通过固有的数据类型来实现：\n抽象数据类型：类class\n数据对象：数据成员\n基本操作：成员函数（方法）\n十一、算法1.算法是对特定问题求解步骤的一种描述。\n2.算法是一有限长的操作序列。\n3.算法特性：\n（1）有穷性：算法在执行有穷步后能结束。\n（2）确定性：每步定义都是确切、无歧义，相同输入相同输出。\n（3）可行性：每一条运算应足够基本（已验算正确）。\n（4）输入：有0个或多个输入。\n（5）输出：有1个或多个输出。\n4.算法设计要求（目标）：\n（1）正确性：满足具体题目的需求。\n（2）可读性：便于理解和修改。\n（3）健壮性：当输入数据非法时，也能适当反应。\n（4）效率高：执行时间少。\n（5）空间省:执行中需要的最大存储空间少。\n十二、时间复杂度1.算法效率的度量是通过时间复杂度和空间复杂度来描述的。\n衡量算法的效率，主要依据算法执行所需要的时间，即时间复杂度。\n注意：算法分析的目的：分析算法的效率以求改进。\n2.事后统计法：计算算法开始时间与完成时间差值。\n缺点：（必须执行程序；其它因素遮盖算法本质）\n3.事前统计法：依据算法选用何种策略及问题的规模n，是常用的方法。\n4.（事前统计法）和算法执行时间相关的因素：\n（1）算法选用的策略（主要）\n（2）问题的规模（主要）\n（3）编写的语言\n（4）编译程序产生的机器代码的质量\n（5）计算机执行指令的速度\n5.一般情况下，算法中基本操作重复执行的次数是问题规模n的某个函数，算法的时间量度记作 T(n)=O(f(n))，称作算法的渐近时间复杂度,简称时间复杂度。它表示随问题规模n的增大，算法执行时间的增长率和f(n)的增长率相同。\n（1）加法规则：T(n)=T1(n)+T2(n)=O(f(n))+O(g(n))=O(max(f(n),g(n)))\n（2）乘法规则：T(n)=T1(n)T2(n)=O(f(n))  O(g(n))=O(f(n)*g(n))\n6.时间复杂度除常量阶[O(1)], 线性阶[O(n)], 平方阶[O(n^2)]外，还有对数阶[O(logn)]，排列阶[O(n!)]，指数阶[O(2^n)]等，是相对于问题规模n的增长率的表示方法。\n（1）多项式：O(1)&lt;O(log2(n))&lt;O(n)&lt;O(nlog2(n))&lt;O(n^2)&lt;O(n^3)\n（2）指数时间：O(2^n)&lt;O(n!)&lt;O(n^n)\ni=1;while(i&lt;=n)i=i*2;//令执行x次，2^x=n，x=log2(n)，即时间复杂度为O(log2(n))//递归算法，时间复杂度是O(n) int rec(int n)   {      if (n==1) return 1;                       else return (n*rec(n-1));   }\n7.如果算法的执行有多种可能的操作顺序，则求其平均时间复杂度。\n如果无法求取平均时间复杂度，则采用最坏情况下的时间复杂度。\n时间复杂度是衡量算法好坏的一个最重要的标准。\nvoid bubble-sort(int a[]，int n){    for(i=n-1,change=TURE;i&gt;1 &amp;&amp; change;--i)      {           change=false;           for(j=0;j&lt;i;++j)               if (a[j]&gt;a[j+1]) {                     a[j] ←→a[j+1];                    change=TURE}       }     }//最好情况：0次（全部升序排列）//最坏情况：n*(n-1)/2次（全部降序排列）//5 4 3 2 1（5要比较（n-1）次，1被移到最前面了，比较0次，共有n个元素，使用求和公式0+1+...+(n-1)=n*(n-1+0)/2//平均时间复杂度：O(n^2)\n十三、空间复杂度1.空间复杂度指算法执行时，所需要存储空间的量度，它也是问题规模的函数，即：S(n) = O(f(n))。\n2.算法的存储量包括：\n（1）程序本身所占空间（与算法无关）\n（2）输入数据所占空间（与算法无关）\n（3）辅助变量所占空间（若所需额外空间相对于输入数据量来说是常数，则称此算法为原地工作。否则,按最坏情况分析）\n注意：只有辅助变量所占空间与算法有关\n第二章：线性表一、线性数据结构的特点在数据元素的非空有限集中 ：\n1.存在惟一的一个被称作“第一个”的数据元素。\n2.存在惟一的一个被称作“最后一个”的数据元素。\n3.除第一个元素外，每个数据元素均只有一个前驱 。\n4.除最后一个元素外，每个数据元素均只有一个后继 。\n二、线性表1.线性表是最简单的一类线性数据结构。\n2.线性表是由n个数据元素组成的有限序列，相邻数据元素之间存在着序偶关系，可以写为：(a1, a2,…ai-1, ai, ai+1,…an-1, an)其中,ai是表中元素,i表示元素ai的位置,n是表的长度。\n3.线性表中的元素具有相同的特性，属于同一数据对象，如：1.26个字母的字母表: (A,B,C,D,…,Z)2.近期每天的平均温度:(30℃, 28℃, 29℃,…)。\n三、顺序表1.顺序表是线性表的顺序表示。（线性表的顺序存储称为顺序表）\n2.用一组地址连续的存储单元依次存储线性表的数据元素。逻辑相邻，物理也相邻。\n3.顺序表数据元素的位置：\nloc(a[i])=loc(a[i-1])+length\nloc(a[i])=loc(a[1])+(i-1)*length\n其中length表示元素占用的内存单元数。\n4.顺序表的插入操作：\n（1）顺序表的插入操作是指在顺序表的第i-1个数据元素和第i个数据元素之间插入一个新的数据元素，即将长度为n的顺序表：(a1,…ai-1, ai, …, an) 变成长度为n+1的顺序表：(a1,…ai-1, e, ai, …, an)\n（2）在顺序表中的第i个位置插入一个元素，需要向后移动的元素个数为：n-i+1\n（3）平均移动元素数为（假设在第i个元素之间插入的概率为pi）：Eis = ∑ pi x (n-i+1) 其中i从1到n+1。\n（4）当插入位置等概率时pi=1/(n+1)，因为可以插在最后面。因此：\nEis = ∑ [1/(n+1)] x (n-i+1) = n/2其中i从1到n+1。\n\n注意：顺序表插入平均移动元素数为n/2\n（5） 顺序表插入操作的时间复杂度为O(n)。\n5.顺序表的删除操作：\n（1）顺序表的删除操作是指将顺序表的第i个数据元素删除，即将长度为n的顺序表：(a1,…ai-1, ai, ai+1,…, an) 变成长度为n-1的顺序表：(a1,…ai-1, ai+1, …, an)\n（2）在顺序表中删除一个元素，需要向前移动元素个数为：n-i（不用加一）\n（3）平均移动元素数为：Edl = ∑ qi x (n-i) 其中i从1到n。\n\n（4）当删除位置等概率时qi=1/n，因为只有n个元素可以删除。因此：\nEdl = ∑ [1/n] x (n-i) = (n-1)/2其中i从1到n。\n\n注意：顺序表删除平均移动元素数为(n-1)/2\n（5）顺序表删除操作的时间复杂度为O(n)。\n6.顺序表的其它操作:\n（1）查找第i个位置的元素值。\n（2）查找元素所在位置。\n（3）得到表长。\n（4）置空表。\n（5）销毁表(析构函数~SqList())。\n7.顺序表的优缺点：\n（1）优点：元素可以随机存取；元素位置可用一个简单、直观的公式表示并求取。通过首地址和元素序号,O(1)内找到指定元素。存储密度高，每个结点只存储数据元素。\n（2）缺点：在作插入或删除操作时，需要移动大量元素 。\n注意：一个顺序表的第一个元素存储地址为2001,每个元素占用4个地址单元，第6个元素的存储地址为：2001+（6-1）5=2021；对于顺序存储的线性表，删除、增加结点的时间复杂度为O(n)\n四、链表1.链表是线性表的链式存储表示。\n2.链表中逻辑关系相邻的元素不一定在存储位置上相连，用指针表示元素之间的邻接关系。\n3.线性表的链式存储表示主要有三种形式：线性链表、循环链表、双向链表。\n4.线性链表：\n（1）线性链表的元素称为结点。\n（2）结点除包含数据元素信息的数据域外，还包含指示直接后继的指针域。\n（3）每个结点，在需要时动态生成，在删除时释放。\n（4）N个结点(ai(1≤i ≤ n)的存储映像)链结成一个链表,即为线性表的链式存储结构。\n（5）链表的每个结点中只包含一个指针域,故又称线性链表或单链表。\n（6）线性链表可由头指针惟一确定。\n（7）以线性表中的第一个数据元素a1的存储地址作为线性表的地址，称作线性表的头指针。\n（8）有时为了操作方变，在第一个节点之前虚加一个”头结点“，以指向头结点的指针为链表的头指针。\nLNode *head;//头指针head = new LNode;//生成头结点  head-&gt;[ |^]//head-&gt;[ |-]-&gt;[a|-]-&gt;[b|-]-&gt;....\n注意：头结点和头指针区分：不管带不带头结点，头指针始终指向链表的第一个结点，而头结点是带头结点的链表中第一个结点，结点内通常不存储信息。增加头结点的目的是为了方便运算。\n头结点的优点:(1)由于第一个数据结点的位置被存放在头结点的指针域中，所以在链表的第一个位置上的操作和在表的其他位置上的操作一致，无需进行特殊处理；(2)无论链表是否为空，其头指针都指是向头结点的非空指针（空表中头结点的指针域为空）\n单链表的头指针为head，不带头结点的判空条件：head==NULL\n带头结点的判空条件：head-&gt;next==NULL (L -&gt;[ |^] (head-&gt;next==NULL))\n（9）找第i个元素getelement：在线性链表中找到第i个元素，并返回指针；从头结点开始，顺链一步步查找；查找第i个数据元素的基本操作为：移动指针，比较k和i（k为当前指针所指向的结点序号）。时间复杂度为O(n)。\n（10）线性链表的插入：在线性链表的第i-1个元素与第i和元素之间插入一个新元素。s-&gt;next=p-&gt;next;p-&gt;next=s。（其中s为新元素）时间复杂度主要取决于getelement的时间复杂度，getelement的时间复杂度为O(n)，因此线性链表插入的时间复杂度为O(n)。\n注意：在单链表中第i个结点之前进行插入的基本操作：找到线性表中的第i-1个结点p，创建新结点s，然后修改第i-1个结点和s结点的后继指针。s-&gt;next=p-&gt;next;p-&gt;next=s\n（11）线性链表的删除：将线性链表的第i个元素删除。\n找到线性表中第i-1个结点p，修改其指向后继的指针。\nq=p-&gt;next;p-&gt;next=q-&gt;next;(e=q-&gt;data)delete q;（删除p-&gt;next这个结点）时间复杂度主要取决于getelement的时间复杂度，getelement的时间复杂度为O(n)，因此线性链表删除的时间复杂度为O(n)。\n（12）线性链表的创建：链表是一个动态的结构，不需要预分配空间，生成链表的过程是一个结点”逐个插入“的过程。依次调用insert即可，时间复杂度O(n^2)。n个结点，每个结点每次插入Insert函数，头指针指向最后，表尾插入故为n*n。\n（13）线性链表的创建-头插法：即表头不断插入新结点。逆序输入数据值。头插法时间复杂度O(n)。\n（14）线性链表的创建-尾插法：即表尾不断插入新结点。按链表序输入数据值。为记录尾结点，增加一个尾指针tail，指向最后一个结点。尾插法时间复杂度O(n)\n（15）单链表的合并：将两个有序链表合并成一个有序链表。\n（16）拷贝构造函数被调用的三种情况：一个对象以值传递的方式传入函数体；一个对象以值传递的方式从函数返回；一个对象需要通过另一个对象进行初始化。\n（17）赋值函数被调用的时机：当一个类的对象向该类的另一个对象赋值时，就会用到该类的赋值函数。\n（18）拷贝构造函数与赋值函数比较：\n调用拷贝构造函数来初始化一个对象：\nA a;A b(a); A b=a;\n都是拷贝构造函数来创建对象b（b还不存在）\n调用赋值函数对对象复制：\nA a;A b;b=a;\n强调：这里a,b对象是已经存在的，是用a 对象来赋值给b的！！\n5.静态链表：线性链表也可以采用静态数组实现。\n与顺序表有两点不同：\n（1）每个元素包括数据域和指针域。\n（2）元素的逻辑关系由指针确定。\n与单链表的区别：\n（1）静态链表暂时不用结点，链成一个备用链表。\n（2）插入时，从备用链表中申请结点。\n（3）删除结点时，将结点放入备用链表。\n6.循环链表：\n（1）循环链表是一种特别的线性链表。\n（2）循环链表中最后一个结点的指针域指向头结点，整个链表形成一个环。\n（3）在只有尾指针的单循环链表中：\n表头插入结点：在只有尾指针的情况下，要在表头插入结点，首先需要找到尾结点，然后将新结点插入到尾结点之后。因此，表头插入结点的时间复杂度为 O(1)（常数时间），因为无论链表有多长，插入操作所需的时间都是相对固定的。\n虽然在只有尾指针的情况下，插入结点时需要找到尾结点，但这并不会导致时间复杂度变为 O(n)。在单循环链表中，尾结点指向头结点，因此我们可以直接通过尾指针找到头结点，然后在头结点之后插入新结点。\n因此，表头插入结点的时间复杂度仍然是 O(1)，因为无论链表有多长，插入操作所需的时间都是相对固定的。\n表尾插入结点：由于只有尾指针，直接在尾结点之后插入新结点即可。因此，表尾插入结点的时间复杂度同样为 O(1)。\n（4）查找、插入和删除：与线性链表基本一致，差别仅在于算法中的循环条件不是p-&gt;next或p是否为空（^)，而是它们是否等于头指针(L)。\n注意循环链表带头结点判空：head-&gt;next==head\n7.双向链表\n（1）双向链表是一种特殊的线性链表：每个结点有两个指针，一个指针指向直接后继(next)，另一个指针指向直接前驱(prior)。\n（2）对于任何一个中间节点有：p=p-&gt;next-&gt;prior/p=p-&gt;prior-&gt;next。\n（3）插入操作需要改变两个方向的指针：s-&gt;next=p;s-&gt;prior=p-&gt;prior;p-&gt;prior-&gt;next=s;p-&gt;prior=s;\n（4）删除操作需要改变两个方向的指针：p-&gt;prior-&gt;next=p-&gt;next;p-&gt;next-&gt;prior=p-&gt;prior;\n8.双向循环链表\n（1）存在两个环：一个是直接后继环，另一个是直接前驱环。\n五、一元多项式1.pn (x) = p0 + p1x + p2 x^ 2 + … + pn x^ n\n在计算机中，可以用一个线性表来表示：P = (p0 , p1 , …，pn)\n2.pn(x)=p1x^e1+p2x^e2+…+pmx^em\n线性表示((p1,e1),(p2,e2),…,(pm,em))\n六、顺序表与链表的比较1.基于空间的比较\n（1）存储分配的方式：顺序表的存储空间是静态分配的，链表的存储空间是动态分配的。\n（2）存储密度=结点数据本身所占的存储量/结点结构所占的存储总量\n顺序表的存储密度=1，链表的存储密度&lt;1\n2.基于时间的比较\n（1）存取方式：顺序表可以随机存取也可以顺序存取，链表必须顺序存取。\n（2）插入、删除时移动元素个数：顺序表平均需要移动近一半元素，链表不需要移动元素只需要修改指针。\n3.基于应用的比较 （1）线性表主要是存储大量数据，并用于查找时，采用顺序表比较好。\n（2）若线性表存储的数据元素要经常插入和删除，采用链表比较好。\n注意：某线性表中最常用的操作是在最后一个元素之后插入一个元素和删除第一个元素，则采用带尾指针的单循环链表最节省时间。\n仅有尾指针的单循环链表，可以非常方便地找到尾结点，尾结点后面的第一个结点往往是头结点，头结点的下一个结点就是线性表的第一个结点。对最后一个元素和第一个元素操作对带尾指针的单循环链表是非常方便的\n循环链表是线性表，它是线性表的链表存储结构之一。\n在一个以h为头的单循环链表中，p指针指向链尾的条件是p-&gt;next=h。\n第三章：栈和队列一、栈1.栈是限定仅在表尾(top)进行插入或删除操作的线性表。\n2.允许插入和删除的一端称为栈顶(top，表尾)，另一端称为栈底(bottom，表头）\n3.特点：后进先出 (LIFO)\n4.栈的存储结构：顺序栈和链式栈。\n5.顺序栈：\n（1）顺序栈是栈的顺序存储结构。\n（2）利用一组地址连续的存储单元依次存放自栈底到栈顶的数据元素。\n（3）指针top指向栈顶元素在顺序栈中的下一个位置，base为栈底指针，指向栈底的位置。\n（4）top=0 或top=base 表示空栈。\n（5）base=NULL表示栈不存在。\n（6）当插入新的栈顶元素时,指针top+1。\n（7）删除栈顶元素时，指针top-1。\n（8）当top&gt;stacksize时，栈满，溢出。\n注意：向顺序表中压入新元素，应当先移动栈顶指针，再入栈，出栈时先取栈顶元素再移动指针\n6.链栈：\n（1）栈的链式存储结构称为链栈，它是运算受限的单链表，可插入和删除操作仅限制在表头位置上进行。\n（2）由于只能在链表头部进行操作，故链表没有必要像单链表那样附加头结点。栈顶指针就是链表的头指针。\n（3）链栈中为何不设头指针？因为链栈只在链表头插入和删除结点,不可能在链表中间插入或删除结点,算法实现很简单,所以一般不设置头结点。\n（4）链栈对比顺序栈主要优点在于，通常不会栈满的情况\n7.C++中栈容器：\n（1）stack 模板类的定义在头文件中。\n（2）定义stack 对象的示例代码如下：stack s1;stack s2;\n（3）stack 的基本操作有：\n入栈，如例：s.push(x);\n出栈，如例：s.pop();注意，出栈操作只是删除栈顶元素，并不返回该元素。\n访问栈顶，如例：s.top()\n判断栈空，如例：s.empty()，当栈空时，返回true。\n访问栈中的元素个数，如例：s.size()。\n8.栈的应用举例\n（1）数值转换：\n将十进制转换为其他进制（d）：N=(Nd)d+N mod d\n（计算顺序与输出顺序相反）\n（2）行编辑程序\n（3）迷宫求解（用一个栈来记录已走过的路径）\n设定当前位置为入口位置　\ndo {若当前位置可通，则 {\n　将该位置插入栈顶(Push)；若该位置是出口，则结束\n　否则切换当前位置的东邻方块为当前位置；\n} 否则 {      　\n若栈不空则｛\n    　  如果栈顶位置的四周均不可通,则删除栈顶位置(Pop)      　并重新测试新的栈顶位置\n　　如果找到栈顶位置的下一方向未经探索，则将该方向\n　　方块设为当前位置}}}while(栈不空)；找不到路径；\n（4）表达式求值：表达式由操作数、运算符和界限符组成，它们皆称为单词。\n操作数：常数或变量。运算符：+, -, *, / 等。界限符：(, ), #(表达式开始及结束符)。\n计算步骤：假设操作数栈NS和运算符栈OS，\n—（1）依次读取表达式，若为操作数，则直接进栈；\n若为运算符(记为op2)，转（2）\n—（2）将op2与运算符栈顶元素(记为op1)按P53的表3.13 比较优先权，并按如下规则进行操作：\n若prec(op1) &lt; prec(op2), 则op2入OS;\n若prec(op1) = prec(op2), 则op1出栈，回到（1）；\n若prec(op1) &gt; prec(op2), 则NS出2个操作数 num2,num1,op1出栈，\n计算num2 op1 num2，结果入NS；回到(2) 。\n—（3）重复（1）、（2）直至整个表达式求值完毕。\n\n例如: Exp = a x b + (c - d / e) x f\n前缀式: + x a b x - c / d e f\n中缀式: a x b + c - d / e x f\n后缀式: a b x c d e / - f x +\n前缀式的运算规则为:连续出现的两个操作数和在它们之前且紧靠它们的运算符构成一个最小表达式;\n中缀式丢失了括弧信息,致使运算的次序不确定;（编译系统中：中缀转后缀进行计算）\n后缀式的运算规则为: 运算符在式中出现的顺序恰为表达式的运算顺序; 每个运算符和在它之前出现 且 紧靠它的两个操作数构成一个最小表达式。\n结论：操作数之间的相对次序不变；运算符的相对次序不同。\n得到后缀表达式后，我们在计算表达式时，可以设置一个栈，从左到右扫描后缀表达式，每读到一个操作数就将其压入栈中；每到一个运算符时，则从栈顶取出两个操作数进行运算，并将结果压入栈中，一直到后缀表达式读完。最后栈顶就是计算结果。\n\n9.栈与递归的实现\n（1）当在一个函数的运行期间调用另一个函数时，在运行该被调用函数之前，需先完成三项任务：将所有的实在参数、返回地址等信息传递给被调用函数保存；为被调用函数的局部变量分配存储区；将控制转移到被调用函数的入口。\n（2）从被调用函数返回调用函数之前，应该完成下列三项任务：保存被调函数的计算结果；释放被调函数的数据区；依照被调函数保存的返回地址将控制转移到调用函数\n（3）多个函数嵌套调用：后调用先返回！此时的内存管理实行“栈式管理”。\n（4）递归函数执行的过程可视为同一函数进行嵌套调用。\n注意：n个不同元素进栈，出栈元素不同排列个数为：(1/(n+1))C(2n,n)其中C为组合数，从2n个选n个\n二、队列1.队列是只允许在表的一端进行插入，而在另一端删除元素的线性表。\n2.在队列中，允许插入的一端叫队尾（rear），允许删除的一端称为对头(front)。特点：先进先出 (FIFO)\n3.顺序队列：采用一组地址连续的存储单元依次存储从队列头到队列尾的元素。顺序队列有两个指针：队头指针front和队尾指针rear\n4.顺序队列的进队和出队原则：进队时，新元素按rear指针位置插入，然后队尾指针增一，即 rear = rear + 1；出队时，将队头指针位置的元素取出，然后队头指针增一，即 front = front + 1；队头指针始终指向队列头元素；队尾指针始终指向队列尾元素的下一个位置。\n5.顺序队列存在的问题：\n（1）当队尾指针指向队列存储结构中的最后单元时，如果再继续插入新的元素，则会产生溢出当队列发生溢出时。\n（2）不能用rear==maxsize判断队满。\n（3）队列存储结构中可能还存在一些空白位置（已被取走数据的元素），假上溢。(前面还有空位)\n\n（3）解决办法之一：将队列存储结构首尾相接，形成循环(环形)队列。\n6.循环队列：\n（1）循环队列采用一组地址连续的存储单元。\n（2）将整个队列的存储单元首尾相连。\n（3）判断对空和队满：\n对循环队列而言，无法通过front==rear来判断队列“空”还是“满”。 解决此问题的方法至少有三种：\n其一是另设一个布尔变量以匹别队列的空和满；\n其二是少用一个元素的空间，约定入队前，测试尾指针在循环意义下加1后是否等于头指针，若相等则认为队满（注意：rear所指的单元始终为空！！）；\nfront = rear，（都指向空）循环队列空；(rear+1) % MAXQSIZE = front，循环队列满。\n\n其三是使用一个计数器记录队列中元素的总数（实际上是队列长度）。\n（4）循环队列：\n初始时：front=rear=0\n出队，队首指针加一：front=(front+1)%maxsize\n进队，队尾指针加一：rear=(rear+1)%maxsize\n队列长度：(rear-front+maxsize)%maxsize\n若牺牲一个单元来区分队列空和队列满，队列少用一个队列单元：\n队满：(rear+1)%maxsize==front\n队空：front==rear\n题目：假设Q[ 11] (下标为从0到10)是一个循环队列,初始状态为front=rear=0;画出分别做完下列操作后队列的头尾指针的装填变化情况,若不能入队,请指出其元素,说明理由..(采用少用一个元素空间的方式)\nd,e,b,g,h入队\nd,e出队\ni,j,k,l,m入队\nb 出队\nn,o,p,q,r 入队\n\n(上述答案采用front指向空，应改为rear时刻指向空！)\n7.链队列\n（1）链队列采用链表存储单元链队列中，有两个分别指示队头和队尾的指针。\n（2）链式队列在进队时无队满问题，但有队空问题。\n（3）链队列是链表操作的子集。\n设长度为n的链队列用单循环链表表示，若只设头指针，则入度时间复杂度为O(n)，出队时间复杂度为O(1);若只设尾指针，则入队时间复杂度和出队时间复杂度都为O(1)，出队队头之间是tail-&gt;next即可。\n删除一个结点，即出队时的指针操作为：front=front-&gt;next\n8.C++中的队列容器\n（1）queue 模板类的定义在头文件中。\n（2）定义queue 对象的示例代码如下：queue q1;queue q2;\n（3）queue 的基本操作有：\n入队，如例：q.push(x); 将x 接到队列的末端。\n出队，如例：q.pop(); 弹出队列的第一个元素，注意，并不会返回被弹出元素的值。\n访问队首元素，如例：q.front()，即最早被压入队列的元素。\n访问队尾元素，如例：q.back()，即最后被压入队列的元素。\n判断队列空，如例：q.empty()，当队列空时，返回true。\n访问队列中的元素个数，如例：q.size()\n9.C++中的map容器\n（1）map是c++的一个标准容器，提供了key和value的映射。map 模板类定义在头文件中。\n（2）map对象定义：map&lt;string , int &gt; mapstring;\n（3）map添加数据：map&lt;int ,string&gt; maplive; -1.maplive.insert(pair(102,“aclive”));\n-2.maplive.insert(map::value_type(321,“hai”));\n-3.maplive[112]=”April”;//map中最简单最常用的插入添加！\n（4）map中查找数据：\n-1.使用map的下标运算符重载\nmap&lt; std::string,int&gt; mapTest;\ncout&lt;&lt;mapTest[“index”]&lt;&lt;endl;\n-2.使用map的find接口。\nmap&lt; std::string,int&gt; mapTest;\nmap&lt; std::string,int&gt;::iterator it = mapTest.find(“index”);\nif(it!=mapTest.end()) cout&lt;&lt; it-&gt;second&lt;&lt;endl;\n大题重点：表达式求值\n\n(同种符号比较，先出现的优先级高)\n第四章：串一、字符串1.字符串是n个字符的有限序列。\n2.字符串术语：\n（1）空串：不含任何字符的串，串长度=0。\n（2）空格串：仅由一个或多个空格组成的串。\n（3）子串：由串中任意个连续的字符组成的子序列。\n（4）主串：包含子串的串。\n（5）位置：字符在主串中的序号。子串在主串中的位置以子串第一个字符在主串中的位置来表示。\n（6）串相等的条件：当两个串的长度相等且各个对应位置的字符都相等时才相等。\n（7）模式匹配：确定子串在主串中首次出现的位置的运算\n3.字符串与线性表的关系\n—-串的逻辑结构和线性表极为相似：\n（1）它们都是线性结构。\n（2）串中的每个字符都仅有一个前驱和一个后继。\n—-串与线性表又有区别，主要表现为：\n（1）串的数据对象约定是字符集。\n（2）在线性表的基本操作中，以“单个元素”作为操作对象。\n（3）在串的基本操作中，通常以“串的整体”作为操作对象，如：在串中查找某个子串、在串的某个位置上插入一个子串等。\n4.字符串的操作\n13种操作中的最小操作子集(五种)：串赋值StrAssign;串比较StrCompare;求串长StrLength;串联接Concat;求子串SubString。\n最小操作集：\n这些操作不可能利用其他串操作来实现，反之，其他串操作（除串清除ClearString和串销毁DestroyString外）可在这个最小操作子集上实现。\n5.字符串的操作(index)\n（1）串匹配(查找)的定义: INDEX (S, T, pos)\n（2）初始条件：串S和T存在，T是非空串，1≤pos≤StrLength(S)。\n（3）操作结果：若主串S中存在和串T值相同的子串返回它在主串S中第pos个字符之后第一次出现的位置；否则函数值为0。\n二、串的表示和实现1.定长顺序存储表示（静态存储分配）\n（1）用一组地址连续的存储单元存储字符序列。\n（2）如C语言中的字符串定义(以“\\0”为串结束标志) char Str[MAXSTRLEN+1];\n（3）定义了长度为MAXSTRLEN字符存储空间字符串长度可以是小于MAXSTRLEN的任何值（最长串长度有限制，多余部分将被截断）\n（4）隐含：一般可使用一个不会出现在串中的特殊字符在串值的尾部来表示串的结束。\n优点:便于系统自动实现。\n缺点:不利于某些操作(如合并).\n例如，C语言中以字符‵\\0′表示串值的终结，这就是为什么在上述定义中，串空间最大值maxstrlen为256，但最多只能存放255个字符的原因。\n（5）显式：若不设终结符，可用一个整数来表示串的长度，那么该长度减1的位置就是串值的最后一个字符的位置（下标）。\n优点:便于在算法中用长度参数控制循环过程。\n2.堆分配存储表示\n（1）在程序执行过程中，动态分配（malloc）一组地址连续的存储单元存储字符序列。\n（2）在C++语言中，由new和delete动态分配与回收的存储空间称为堆。\n（3）堆分配存储结构的串既有顺序存储结构的特点，处理方便,操作中对串长又没有限制,更显灵活。\n3.链存储表示\n（1）采用链表方式存储串值。\n（2）每个结点中，可以存放一个字符，也可以存放多个字符。\n（3）存储密度=数据元素所占存储位/实际分配的存储位。\n三、串的匹配算法1.求子串位置函数Index()\n（1）子串的定位操作通常称做串的模式匹配。\n（2）算法（穷举法，朴素算法，BF(Brute-Force)算法）：\n从主串的指定位置开始，将主串与模式（要查找的子串）的第一个字符比较：\n若相等，则继续逐个比较后续字符；若不等，从主串的下一个字符起再重新和模式的字符比较。\n（3）在最好的情况下，除比较成功的位置外，其余位置仅需比较一次（模式第一个字符），其时间复杂度为：O(n+m)(n，m分别为主串和模式的长度)\n（4）但在最坏的情况下，如模式为‘00000001’，主串为‘0000000000000000000000000000000001’,则每次模式的前7个0都要与主串逐一比较，因此，其时间复杂度为：O(n*m)\n2.KMP算法（时间复杂度O(n+m))\n（1）当一趟匹配过程中出现字符比较不等(失配)时\n—1.不需回溯i指针\n—2.利用已经得到的“部分匹配”的结果\n—3.将模式向右“滑动”尽可能远的一段距离(next[j])后，继续进行比较\n（2）在模式串中第j个字符“失配”时,模式串第k个字符再同主串中对应的失配位置(i)的字符继续进行比较 ：‘p1p2…pk-1’ = ‘pj-k+1pj-k+2…pj-1’\nk值可以在做串的匹配之前，求出一般用next函数求取k值。\n（3）next函数定义为（下标从1开始）：\n—当j=1时next[j] = 0；\n—next[j] = max{k | 0&lt;k&lt;j且‘p1…pk-1’=‘pj-k+1…pj-1’}；(直接等于0~j-1的字符串的最长公共前后缀的长度+1)\n—当其它情况时next[j]=1。\n\n（4）next函数定义为（下标从0开始）：\n—当j=0时next[j] = -1；\n—next[j] = max{k | 0&lt;k&lt;j且‘p0…pk-1’=‘pj-k…pj-1’}；(直接等于0~j-1的字符串的最长公共前后缀的长度)\n—当其它情况时next[j]=0。\n\n即寻找当前j前可相互重叠（不完全重叠）的最长真子串的长度。从第一个字符开始的子串的下一个元素的下标，指示出，如果j所指示的模式串的字符与目标串中的当前字符不相等时，j应回退的位置。\n\n（5）求next[j]值的算法：\n—1. j的初值为0, next[0]=-1, k=-1\n—2. While(j&lt;模式串长度-1) {\n—(1).若k=-1或者Tj=Tk,则j++,k++,next[j]=k\n—(2).否则,k=next[k]\n}\n这实际上也是一个匹配的过程，不同在于：主串和模式串是同一个串。\n（6）KMP算法：\n—1.令i的初值为pos,j的初值为0\n—2. While((i&lt;主串长度)且(j&lt;模式串长度)) {\n—(1).若j=－1或者si=pj,则i++, j++\n—(2).否则,j=next[j]\n}//j=－1表示第一个字符失配\n（7）时间复杂度：\nKMP()函数的时间复杂度为O(n)，为了求模式串的next值,其算法与KMP很相似,其时间复杂度为O(m)，因此,KMP算法的时间复杂度为O(n+m)。\n（8）nextval：\n—1.首先计算next\n—2.比较当前字符t.ch[j]与其next值k所指字符 t.ch[k]\n—（1）不等： nextval[j]=next[j]（即维持不变）\n—（2）相等： nextval[j]=nextval[k]\n\nvoid getnext(string p){    int j,k;    j=0,k=-1;    next[0]=-1;//!    while(j&lt;p.size()-1)    {        if(k==-1||T[j]==T[k])            next[++j]=++k;        else            k=next[k];    }}\n大题题目重点：字符串匹配\n题目：求串eefegeef的next值。写出计算过程。假设主串为eefeefegeebeefegeeb，写出KMP算法查找串eefegeef的过程。\n\n第五章：数组和广义表一、数组的定义1.数组\n数组是相同类型的数据元素的集合\n数组是一种定长的线性表\n数组一般不作插入和删除操作\n一旦建立了数组，则结构中的数据元素个数和数据元素之间的关系就不再发生变动\n判断：“数组的处理比其它复杂的结构要简单”，对吗？\n答：对的。因为——① 数组中各元素具有统一的类型；② 数组元素的下标一般具有固定的上界和下界，即数组一旦被定义，它的维数和维界就不再改变。③数组的基本操作比较简单，除了结构的初始化和销毁之外，只有存取元素和修改元素值的操作。\n2.一维数组\n一维数组是一种简单的定长线性表\n一维数组中的每个数据元素是一个(数)值\n(原子)如：int A[8]={8,7,5,4,6,1,3,2} b=8，有8个数据元素，每个元素都是一个数值\n3.二维数组\n二维数组是这样一个定长线性表，其每个数据元素也是一个定长线性表(一维数组)\n\nAmxn= ((a00 a01…a0,n-1), (a10 a11…a1,n-1),…,(am-1,0 …am-1,n-1))\n4.多维数组\n多维数组是这样一个定长线性表，其每个数据元素也是一个定长线性表(降一维)\n如果其数据元素不是一维数组，则其数据元素的每个数据元素也是一个定长线性表\n一直到最后一个定长线性表是一维数组，其每个数据元素为一个(数)值\n二、数组的表示1.数组的顺序表示\n顺序存储：数组由相同类型的数据组成，且一般不作插入和删除操作，一般采用顺序存储结构表示数组\n次序约定：计算机中，存储单元是一维结构，而数组为多维结构，则用一组连续的存储单元存放数组的数据元素时，有一个次序约定问题\n\nAmxn= ((a00 a01…a0,n-1), (a10 a11…a1,n-1),…,(am-1,0 …am-1,n-1))\nAmxn= ((a00 a10…am-1,0), (a01 a11…am-1,1),…,(a0,n-1 …am-1,n-1))\n（1）行序（m行n列）\nLOC(aij) = LOC(a00) + (i x n + j) x L\nLOC(a00)是二维数组的起始存储地址\nL为每个数据元素占用存储单元的长度(数目)\nLoc(aij)=Loc(a11)+[(j-1) +(i-1)  n ]K\n（2）列序（m行n列）\nLOC(aij) = LOC(a00) + (i + j x m) x L\nLOC(a00)是二维数组的起始存储地址\nL为每个数据元素占用存储单元的长度(数目)\nLoc(aij)=Loc(a11)+[(j-1)  m+(i-1)]K\n注意：已知二维数组Am,m按行存储的元素地址公式是： Loc(aij)= Loc(a11)+[(i-1) * m+(j-1)]K , 请问按列存储的公式相同吗？\n答：尽管是方阵，但公式仍不同。应为： Loc(aij)=Loc(a11)+[(j-1) * m+(i-1)]K\n2.多维数组的顺序表示\n（1）以行序为主序存储,多(K)维数组元素存储位置\nLOC(aj1,j2,..,jk) = LOC(a00 0) + ((b2xb3x…xbkxj1)+(b3x…xbkxj2)+…+jk) x L\n（2）以列序为主序存储,多(K)维数组元素存储位置\nLOC(aj1,j2,..,jk) = LOC(a00 0) + ((b1xb2x…xbk-1xjk)+(b1x…xbk-2xjk-1)+…+j1)xLp\n三、矩阵的压缩存储1.矩阵的压缩存储\n（1）如果矩阵中有许多值相同的元素或者零元素(特殊矩阵、稀疏矩阵)，为了节省存储空间，可以对这类矩阵进行压缩存储\n（2）压缩存储：为多个值相同的元素只分配一个存储空间；对零元素不分配空间\n2.特殊矩阵\n（1）特殊矩阵：矩阵中，值相同的元素或者零元素的分布有一定规律\n（2）对称矩阵：矩阵中，对角线两边对应位置上元素的值相同(aij=aji)\n（3）三角矩阵：矩阵中，对角线上(下)边元素值为常数(或者0)，称下(上)三角矩阵\n（4）如果只存储对称矩阵对角线上的值和对角线以上部分的值，则与上三角矩阵存储方法相同；如果只存储对称矩阵对角线上的值和对角线以下部分的值，则与下三角矩阵存储方法相同。\n\nLOC(aij) = LOC(a00) + ((i+1)i/2+j) L\n若i&gt;=j，数组元素a[i] [j]在数组B中的存放位置为：1+2+..+i+j=(i+1)*i/2+j\n(i+1)*i/2为前i行元素总数，j为第i行第j个元素前元素个数（因为下标都从0开始）\n若 i &lt; j，数组元素 a[i] [j] 在矩阵的上三角部分, 在数组 B 中没有存放，可以找它的对称元素a[j] [i]：= j *(j +1) / 2 + i (在上则找对称到下)\n\n若i &lt;= j，数组元素A[i] [j]在数组B中的存放位置为 n + (n-1) + (n-2) + … + (n-i+1) + j-i=(2n-i-1)  i/2+j-i\n其中(2n-i-1) i/2为前i行元素总数，j-i为第i行第j个元素前元素个数\n若i &gt; j，数组元素A[i] [j]在矩阵的下三角部分，在数组 B 中没有存放。因此，找它的对称元素A[j] [i]。 A[j] [i]在数组 B 的第 (2n-j-1)  j / 2 + i 的位置中找到。\n3.稀疏矩阵\n（1）稀疏矩阵：矩阵中有许多值相同的元素或者零元素，而且分布没有任何规律\n假设在mxn的矩阵中，有t个非零元素，令：\nδ= t /(m x n)\n如果稀疏因子δ≤0.05，则称该矩阵为稀疏矩阵\n（2）用三元组存储稀疏矩阵中的非零元素\n三元组(i,j,aij)表示矩阵中i行、j列位置的值为aij\n\n（3）转置\n设矩阵列数为m，对矩阵三元组表扫描m次\n第k次扫描，找寻所有列号为k的项\n将其行号变列号、列号变行号，顺次存于转置矩阵三元组表中\n\n四、广义表1.广义表的定义\n（1）广义表：由n(≥0)个表元素组成的有限序列：\nLS = (a0, a1, a2, …, an-1)\n（2）LS是广义表的名称\n（3）ai是广义表的元素，既可以是表(称为子表)，也可以是数据元素(称为原子)\n（4）n为广义表的长度(n=0的广义表为空表)\n2.广义表的举例\nA=( ); //表A是一个空表\nB=(e); //表B有一个原子\nC=(a,(b,c,d)); //两个元素，分别为原子a和子表(b,c,d)\nD=(A,B,C); //有三个元素均为列表\nE=(a,E); //递归的列表\n其中，“表”以及“列表”，均指广义表\n3.广义表的存储\n广义表一般采用链式存储结构\n表结点[Tag=1|hp|tp]；原子结点[Tag=0|atom]；hp表示表头，tp表示表尾\n\n4.广义表的表头\n表头(head)：广义表的第一个元素\n表头既可以是原子，也可以是列表(广义表)\nGetHead(B) = e；GetHead(D) = A；GetHead((B,C)) = B\n5.广义表的表尾\n表尾(tail)：广义表中，除表头外的部分\n注意：表尾一定是列表，要加括号！\nGetTail(B) = ()；GetTail(D) = (B,C)；GetTail((B,C)) = (C)\n\nGetTail【(b, k, p, h)】＝ （k,p,h） ;\nGetHead【( (a,b), (c,d) )】＝ （a,b） ;\nGetTail【( (a,b), (c,d) )】＝（(c,d)） ;\nGetTail【 GetHead【((a,b),(c,d))】】＝（b）;\nGetTail【（e）】＝（）;\nGetHead 【 ( ( ) )】＝（）；\nGetTail【 ( ( ) ) 】＝ （）；\n\n第六章：树与二叉树一、树的概念与基本术语1.树的定义(Tree)\n（1）树是有n(n≥0)个结点的有限集合。\n（2）如果 n=0，称为空树；\n（3）如果 n&gt;0,称为非空树,对于非空树,有且仅有一个特定的称为根(Root)的节点(无直接前驱)\n（4）如果 n&gt;1，则除根以外的其它结点划分为 m (m&gt;0)个互不相交的有限集 T1, T2 ,…, Tm，其中每个集合本身又是一棵树，并且称为根的子树(SubTree)。(此为递归定义)\n（5）每个结点都有唯一的直接前驱，但可能有多个后继。\n2.树的基本术语\n（1）结点：包含一个数据元素及若干指向其子树的分支；（包括分支！）\n（2）结点的度：结点拥有的子树数；结点的深度是从根结点开始自顶向下逐层累加；结点的高度是从叶节点开始自底向上逐层累加。\n（3）叶结点：度为0的结点[没有子树的结点] (终端结点 )\n（4）分支结点：度不为0的结点[包括根结点]，也称为非终端结点。除根外称为内部结点。\n注意：除根之外都是内部结点！\n（5）孩子：结点的子树的根[直接后继，可能有多个]\n（6）双亲：孩子的直接前驱[最多只能有一个]\n（7）兄弟：同一双亲的孩子\n（8）子孙：以某结点为根的树中的所有结点\n（9）祖先：从根到该结点所经分支上的所有结点\n（10）层次：根结点为第一层，其孩子为第二层，依此类推\n（11）深度：树中结点的最大层次（从根算第一层），也为树的高度。\n（12）有序树：子树之间存在确定的次序关系。\n（13）无序树：子树之间不存在确定的次序关系。\n（14）森林：互不相交的树的集合。对树中每个结点而言，其子树的集合即为森林。任何一棵非空树是一个二元组 Tree = （root，F）其中：root 被称为根结点 ，F 被称为子树森林。\n3.树型结构与线性结构的区别在于：一个元素可以有多个后继。\n4.树的相关性质：\n（1）树中的结点数等于所有结点的度数加一\n（2）度为m的树中第i层上至多有m^(i-1)个结点\n（3）高度为h的m叉树至多有(m^h-1)/(m-1)个结点\n（4）具有n个结点的m叉树的最小高度为logm(n(m-1)+1)\n二、二叉树1.二叉树是一种特殊的树，每个结点最多有2棵子树，子树有左右之分。\n2.在二叉树的第i层上最多有2^(i-1)个结点。\n3.深度为k的二叉树最多有2^k-1个结点。\n4.如果二叉树终端结点数为n0(也为叶子结点数),度为2的结点数为n2,则n0=n2+1\n三、满二叉树1.一个深度为k且有2^k-1个结点的二叉树。\n2.每层上的结点数都是最大数。\n3.可以自上而下、自左至右连续编号。\n四、完全二叉树1.当且仅当每一个结点都与深度相同的满二叉树中编号从1到n的结点一一对应的二叉树。\n2.叶子结点只在最大两层上出现。\n3.左子树深度与右子树深度相等或大１。\n4.具有n个结点的完全二叉树,其深度为floor(log2(n)) +1\n5.在完全二叉树中，结点i的双亲为 i/2;\n结点i的左孩子LCHILD(i)=2i;\n结点i的右孩子RCHILD(i)=2i+1.\n五、二叉树的顺序存储结构1.用一组连续的存储单元依次自上而下,自左至右存储结点。\n\n六、二叉树的链式存储结构1.二叉链表：二叉链表结点由一个数据域和两个指针域组成，采用数据域加上左、右孩子指针。\n\n2.三叉链表：采用数据域加上左、右孩子指针及双亲指针。\n\n七、遍历二叉树1.遍历二叉树：树的遍历就是按某种次序访问树中的结点，要求每个结点访问一次且仅访问一次（非线性结构线性化）。\n2.一个二叉树由根节点与左子树和右子树组成，设访问根结点用D表示，遍历左、右子树用L、R表示，如果规定先左子树后右子树，则共有三种组合\n（1）DLR [先序遍历]\n（2）LDR [中序遍历]\n（3）LRD [后序遍历]\n\n八、线索二叉树1.利用空指针\n（1）在有n个结点的二叉树中，必定存在n+1个空链域；\n（2）因为每个结点有两个链域（左、右孩子指针），因此共有2n个链域；\n（3）除根结点外，每个结点都有且仅有一个分支相连，即n-1个链域被使用。\n\n十、树与森林1.树的存储结构\n（1）双亲表示法：采用一组连续的存储空间；由于每个结点只有一个双亲，只需要一个指针。\n\n（2）孩子表示法：可以采用多重链表，即每个结点有多个指针，最大缺点是空链域太多[(d-1)n+1个]。将每个结点的孩子排列起来，用单链表表示；将每个结点排列成一个线性表。\n\n（3）孩子兄弟表示法（常用）：采用二叉链表左边指针指向第一个孩子，右边指针指向兄弟。\n\n2.树与二叉树的对于关系\n（1）树与二叉树都可以采用二叉链表作存储结构。\n（2）任意给定一棵树，可以找到一个唯一的二叉树(没有右子树)。\n\n3.森林与二叉树的对应关系\n\n4.树的遍历：\n（1）先根（次序）遍历（树的先根——-二叉树的先序）\n\n（2）后根（次序）遍历（树的后根——-二叉树的中序）\n\n5.森林的遍历：\n（1）先序遍历：依次从左至右对森林中的每一棵树进行先根遍历。\n（2）中序遍历：依次从左至右对森林中的每一棵树进行后根遍历。\n\n十一、赫夫曼树及其应用1.最优二叉树\n（1）路径：从树中一个结点到另一个结点之间的分支构成这两个结点之间的路径\n（2）路径长度：路径上的分支数目\n（3）树的路径长度：从树根到每个结点的路径长度之和\n（4）结点的带权路径长度：从结点到树根之间的路径长度与结点上权的乘积\n（5）树的带权路径长度(WPL)：树中所有叶子结点的带权路径长度之和（是叶子结点！）\n（6）最优二叉树：假设二叉树有n个叶子，其每个叶子结点带权wi，则带权路径长度WPL最小的二叉树称为最优二叉树\n（7）赫夫曼(Huffman)树就是一棵最优二叉树\n2.赫夫曼树\n（1）在Huffman树中，权值最大的结点离根最近；权值最小的结点离根最远。\n（2）构建算法：\n—-1.根据给定的n个权值(w1, w2, …, wn)构成n棵二叉树的集合F={T1, T2, …, Tn}，其中每棵二叉树Ti中只有一个带权为wi的根结点，左右子树为空。\n—-2.在F中选取两棵根结点的权值最小的树作为左右子树构造一棵新的二叉树，且置其根结点的权值为其左右子树根结点的权值之和。\n—-3.在F中删除这两棵树，同时将新得到的二叉树加入F中。\n—-4.重复2, 3，直到F只含一棵树为止。\n\n注意：画图时每一次要把所有点都画出来！\n（3）编码算法：（从叶子开始！）\n—-1.从Huffman树的每一个叶子结点开始\n—-2、依次沿结点到根的路径，判断该结点是父亲结点的左孩子还是右孩子，如果是左孩子则得到编码‘0’，否则得到编码‘1’，先得到的编码放在后面\n——3、直到到达根结点，编码序列即为该叶子结点对应的Huffman编码\n（4）译码算法：\n—-1.指针指向Huffman树的根结点，取第一个Huffman码\n—-2、如果Huffman码为‘0’，将指针指向当前结点的左子树的根结点；如果Huffman码为‘1’，将指针指向当前结点的右子树的根结点\n—-3、如果指针指向的当前结点为叶子结点，则输出叶子结点对应的字符；否则，取下一个Huffman码，并返回2\n—-4、如果Huffman码序列未结束，则返回1继续译码\n题目：（4）设给出一段报文：GOODGOOD_GOOD_GOOOOOOOO_OFF字符集合是 { O, G, , D, F}，各个字符出现的频度(次数)是 W＝{ 15, 4, 4, 3, 2}。\n若给每个字符以等长编码 O: 000 G: 001 _: 010 D: 011 F: 100\n则总编码长度为 (15+4+4+3+2) * 3 = 84.\n若按各个字符出现的概率不同而给予不等长编码，可望减少总编码长度。\n各字符{ O, G, _, D, F }出现概率为\n{ 15/28, 4/28, 4/28, 3/28, 2/28 },化整为 { 15, 4, 4, 3, 2 }\n令左孩子分支为编码‘0’，右孩子分支为编码‘1’将根结点到叶子结点路径上的分支编码，组合起来，作为该字符的Huffman码，则可得到：　\n\nO:1 _:011 G:010 D:001 F:000\n则总编码长度为 151+(2+3+4+4) 3 = 54 &lt; 84\nHuffman是一种前缀编码，解码时不会混淆\n如GOOD编码为：01011001\n如Huffman编码序列01011001，译码后的字符串为GOOD\n（5）前缀编码：指的是，任何一个字符的编码都不是同一字符集中另一个字符的编码的前缀。利用赫夫曼树可以构造一种不等长的二进制编码，并且构造所得的赫夫曼编码是一种最优前缀编码，即使所传电文的总长度最短。\n题目：（1）设有字符集{A, B, C, D}，各字符在电文中出现的次数集为{1, 3, 5, 7}，则哈夫曼树构造过程如下图所示：\n\n\n（最终哈夫曼树的构造结果如上，一定要记得写结果！）\n\n（2）已知一颗完全二叉树第7层有20个结点，则整棵树的结点数？\n83\n（3）在二叉树中，指针p指向的结点是叶子，则p满足条件？\np-&gt;leftChild==NULL&amp;&amp;p-&gt;rightChild==NULL\n（4）由3个结点组成的二叉树最多有多少种形态？\n5\n（5）已知一棵完全二叉树有100个结点，根节点编号为1，按层次遍历编号，则结点45的父亲编号为？结点50的孩子编号情况如何？\n22;100,101\n第七章：图一、图的定义与术语1.图是由顶点集合(vertex)及顶点间的关系集合组成的一种数据结构： Graph＝( V, E )\n其中V = {x | x属于数据对象}是顶点的有穷非空集合\nE是顶点之间关系的有穷集合，包括E1 = {(x, y) | x, y 属于 V } 边的集合或E2 = { | x, y 属于 V } 弧的集合\n注意：在一个图中，所有顶点的度数之和等于边数的2倍！\n2.无向图（无向图的邻接矩阵是对称矩阵）\n用(x,y)表示两个顶点x,y之间的一条边(edge)N={V,E}，V={0,1,2,3,4,5}，E={(0,1), (0,4), (0,5), (1,2), (1,3), (1,5), (2,3), (3,4), (3,5), (4,5)}\n（1）邻接点：如果(x,y)属于E,称x,y互为邻接点，即x,y相邻接\n（2）依附：边(x,y)依附于顶点x,y\n（3）相关联：边(x,y)与x,y相关联\n（4）顶点的度：和顶点相关联的边的数目，记为TD(x)\n3.无向图（完全图）：如果无向图有n(n-1)/2条边，则称为无向完全图。\n4.有向图\n用表示从x到y的一条弧(Arc)，且称x为弧尾，y为弧头，N={V,E}，V={0,1,2,3,4}，E={&lt;0,1&gt;，&lt;0,3&gt;，&lt;0,4&gt;，&lt;1,2&gt;，&lt;2,4&gt;，&lt;3,2&gt; }\n（1）邻接：如果属于E,称x邻接到y,或y邻接\n（2）自x相关联：弧与x,y相关联\n（3）入度：以顶点为头的弧的 数目，记为ID(x)\n（4）出度：以顶点为尾的弧的 数目，记为OD(x)\n（5）度：TD(x)=ID(x)+OD(x)\n4.有向图（完全图）：如果有向图有n(n-1)条边，则称为有向完全图。\n5.路径：是一个从顶点x到y的顶点序列(x, vi1, vi2,…, vin, y)其中，(x,vi1),(vij-1,vij),(vin,y)皆属于E。\n6.回路：\n（1）回路或环：路径的开始顶点与最后一个顶点相同，即路径中(x, vi1, vi2,…, vin, y)，x=y\n（2）简单路径：路径的顶点序列中，顶点不重复出现\n7.连通：\n（1）连通：如果顶点x到y有路径，称x和y是连通的\n（2）连通图：图中所有顶点都连通\n8.子图：\n设有两个图 G＝(V, E) 和 G’＝(V’, E’)。\n若 V’包含于 V 且 E’包含于E, 称图G’是图G的子图\n9.生成树\n一个连通图的生成树是一个极小连通子图，它含图中全部n个顶点，但只有足以构成一棵树的n-1条边。\n二、图的存储结构图的存储结构有4种：邻接矩阵，邻接表，十字链表（有向），邻接多重表（无向）\n1.邻接矩阵\n（1）邻接矩阵：记录图中各顶点之间关系的二维数组。\n（2）对于不带权的图，以1表示两顶点存在边(或弧)(相邻接)，以0表示两顶点不邻接，即 如果(i,j)属于E 或 属于E，A[ i ] [ j ] =1 否则等于0。\n（3）无向图的邻接矩阵为对称矩。\n（4）其第i行1的个数等于顶点i的出度OD(i)，第j列1的个数等于顶点j的入度ID(j)。\n2.邻接矩阵（网络）\n在网络中，两个顶点如果不邻接，则被视为距离为无穷大；如果邻接，则两个顶点之间存在一个距离值(即权值)，即如果(i,j)属于E 或 属于E，A[ i ] [ j ] =wi,j 否则等于∞。\n\n3.邻接表\n（1）邻接表是图的一种链式存储结构。\n（2）在邻接表中，每个顶点设置一个单链表，其每个结点都是依附于该顶点的边（或以该顶点为尾的弧）。\n\n无向图中，注意左侧的表格数组！\n\n（邻接表（有向网络））\n（3）在一个无向图的邻接表表示中，每个顶点对应一个链表，链表中包含该顶点相邻的其他顶点。每条边在邻接表中对应两个链表结点，因为无向图的边是双向的。给定图包含 10 个顶点和 20 条边，那么每个顶点的平均度数是 2×边数/顶点数=4。\n由于每个链表结点对应一条边，总的链表结点数是 2×边数。所以，邻接表包含 2×20=40 个链表结点。\n注意：n个结点，e条边的无向图邻接表中，有n个头结点和2e个表结点\n（4）在有向图的邻接表中不易找到指向该顶点的弧。\n（5）对于有向图的邻接表，其第i个链表中结点的个数只是该顶点的出度；如果要计算入度，必须遍历整个邻接表[也可以建立一个逆邻接表]要判定两个顶点i和j是否有边（或弧），必须搜索整个第i个和第j个链表，不及邻接矩阵方便。\n在有向图的逆邻接表找每个结点入度：\n\n（5）无向邻接表所需存储空间O(|V|+2|E|)，有向邻接表所需存储空间O(|V|+|E|)\n（6）对于稀疏图，采用邻接表能极大节省空间。\n4.十字链表（有向图！）\n（1）十字链表是有向图的另一种存储结构\n（2）十字链表是将有向图的邻接表和逆邻接表结合起来的一种存储结构\n\n\n绿色代表：相同弧尾（邻接表）\n红色代表：相同弧头（逆邻接表）\n5.邻接多重表（无向图！）\n（1）邻接多重表是无向图的另一种存储结构\n（2）在无向图中，一条边要用2个结点表示(分别从2个顶点的角度看)\n（3）在邻接多重表中，一条边只用一个结点表示\n（4）将所有具有某顶点的结点，全部用链连结起来，链所在的域为该顶点对应的指针域\n\n三、图的遍历1.从图的某一顶点开始，访遍图中其余顶点，且使每一个顶点仅被访问一次\n2.图的遍历主要应用于无向图\n3.深度优先搜索DFS\n（1）图的深度优先搜索是树的先根遍历的推广\n（2）图中可能存在回路，且图的任一顶点都可能与其它顶点相通，在访问完某个顶点之后可能会沿着某些边又回到了曾经访问过的顶点。\n（3）为了避免重复访问，可设置一个标志顶点是否被访问过的辅助数组 visited [ ]\n（4）算法：\n所有顶点访问标志visited[]设置为FALSE\n从某顶点v0开始，设v=v0\n—1.如果visited[v]=FALSE，则访问该顶点，且设visited[v]=TRUE\n—2.如果找到当前顶点的一个新的相邻顶点w,设v=w,重复1\n—3.否则(说明当前顶点的所有相邻顶点都已被访问过，或者当前顶点没有相邻顶点)，如果当前顶点是v0，退出；否则返回上一级顶点，重复2\n（5）存储结构未定，则遍历顺序不确定。\n\n4.广度优先搜索（BFS）\n（1）广度优先搜索(BFS)是一种分层搜索方法\n（2）BFS每向前走一步可能访问一批顶点, 不存在往回退的情况\n（3）BFS不是一个递归的过程。\n（4）算法：\n所有顶点访问标志visited[]设置为FALSE\n从某顶点v0开始，访问v0，visited[v0]=TRUE，将v0插入队列Q\n—1.如果队列Q不空，则从队列Q头上取出一个顶点v,否则结束\n—2.依次找到顶点v的所有相邻顶点v’，如果visited[v’]=FALSE，访问该顶点v’，visited[v’]=TRUE，将v’插入队列Q\n—3.重复1,2\n5.结论\n（1）如果图为连通图，则从该图的任意一个顶点开始执行一次深度优先遍历或广度优先遍历，即可访问该连通图的所有顶点。\n（2）如果图为非连通图，则依次从未访问过的顶点开始执行深度优先遍历或广度优先遍历，直至所有的顶点均被访问。\n（3）事实上执行一次深度优先可以遍历一个连通分支。图有多少个连通分支，就调用多少次深度优先遍历。\n6.时间复杂度\n（1）可以看出无论是深度优先遍历还是广度优先遍历,其实质都是透过边或弧找邻接点的过程,只是访问的顺序不同。\n（2）两者的时间复杂度相同，取决于采取的存储结构，若用邻接矩阵为O(N^2),若 用邻接表则为O(N+E) 即O(n)。\n注意：深度优先搜索遍历类似于树的先根遍历，广度优先搜索遍历类似于树的层次遍历。\n题目：假设用邻接表存储，下图中边上序号表示边输入顺序(链表头插入)，画出该图邻接表，写出用该邻接表存储时其深度优先顺序和广度优先顺序。\n\n四、图的连通性问题1.无向图的连通性\n如果无向图中，存在不连通的顶点，则该图称为非连通图。\n2.无向图的连通分量\n（1）非连通图的极大连通子图叫做连通分量。\n（2）若从无向图的每一个连通分量中的一个顶点出发进行DFS或BFS遍历，可求得无向图的所有连通分量的生成树(DFS或BFS生成树)。\n（3）所有连通分量的生成树组成了非连通图的生成森林。\n（4）连通分量是无向图的极大连通子图，其中极大的含义是将依附于连通分量中顶点的所有边都加上，所以连通分量中可能存在回路。\n（5）生成树是一个连通图的极小连通子图，包含连通图的所有顶点，且使其连通的边数最少。\n（6）极大连通子图是无向图（不一定连通）的连通分量。极小连通子图是连通无向图的生成树。\n（7）任何连通图的连通分量只有一个，即使其自身。\n3.无向图的生成树\n（1）由DFS遍历，求得连通分量称为DFS生成树\n（2）由BFS遍历，求得连通分量称为BFS生成树\n4.有向图的强连通分量\n强连通图是指在有向图中，对于每一对不同的顶点u和v，都存在从u到v及v到u的路径，n个顶点用弧向同一方向连接形成一个环时，就是强连通图，需要弧最少。\n（1）深度优先搜索算法是求有向图的强连通分量的有效方法。\n（2）在有向图G上，从某个顶点出发沿该顶点为尾的弧进行深度优先搜索，并按其所有邻接点的搜索都完成（即退出dfs函数）的顺序将顶点排列起来。\n（3） 在有向图G上，从最后搜索的顶点出发，沿着以该顶点为头的弧作逆向的深度优先搜索遍历。若此次遍历不能访问到有向图中的所有顶点，则从余下顶点中最后完成搜索的顶点出发继续进行逆向的深度优先搜索遍历。\n（4）每次调用dfs作逆向深度优先遍历所访问到的顶点集便是有向图G中的一个强连通分量的顶点集。\n（5）为了实现以上遍历，需要对深度优先遍历算法作以下修改\n—1.在进入DFStraverse函数时，对计数变量count进行初始化，count=0\n—2.在退出DFS函数之前，将完成搜索的顶点号记录在另一个辅助数组finish【vernum】中，在DFS函数结束之前加上finished【++count】=v\n5.最小生成树\n（1）如果无向图中，边上有权值，则称该无向图为无向网\n（2）如果无向网中的每个顶点都相通，称为连通网\n（3）最小生成树(Minimum Cost Spanning Tree)是代价最小的连通网的生成树，即该生成树上的边的权值和最小\n（4）准则：必须使用且仅使用连通网中的n-1条边来联结网络中的n个顶点；不能使用产生回路的边；各边上的权值的总和达到最小。常用于道路建设、线路铺设等应用中计算成本。\n6.Prim普里姆算法生成最小生成树\n（1）假设N=(V,E)是连通网\n（2）TE是N上最小生成树中边的集合\n—1.U={u0}，(u0属于V), TE={}\n—2.在所有u属于U,v属于V-U的边(u,v)属于E中找一条代价最小的边(u,v0)并入集合TE，同时v0并入U\n—3.重复2，直到U=V。T=(V，TE)即为所求最小生成树。\n\n（记得每一次画上所有点！）\n\n（Prim V1-Vn mindis flag U)\n（3）在生成树的构造过程中，图中 n 个顶点分属两个集合：已落在生成树上的顶点集 U 和尚未落在生成树上的顶点集V-U，应在所有连通U中顶点和V-U中顶点的边中选取权值最小的边逐渐加入TE,相应顶点加入U中。\n7.Kruscal克鲁斯卡尔算法生成最小生成树\n（1）假设N=(V,E)是连通网\n—1.非连通图T={V,{}}，图中每个顶点自成一个连通分量\n—2.在E中找一条代价最小，且其两个顶点分别依附不同的连通分量的边，将其加入T中\n—3.重复2，直到T中所有顶点都在同一连通分量上\n\n（2）把边按照从小到大的顺序排序；\n判断边的顶点不在同一个联通分支-》并查集。\n8.生成最小生成树：\n当为稠密图（邻接矩阵）prim算法 O(n^2)\n当为稀疏图（邻接表）Kruscal算法O(eloge)\n\n五、最短路径1.最短路径\n（1）最短路径是求从图（或网）中某一顶点，到其余各顶点的最短路径\n（2）最短路径与最小生成树主要有三点不同：\n—1.最短路径的操作对象主要是有向图(网)，而最小生成树的操作对象是无向图\n—2.最短路径有一个始点，最小生成树没有（Prim算法有起点）\n—3.最短路径关心的是始点到每个顶点的路径最短，而最小生成树关心的是整个树的代价最小\n2.基本概念\n（1）路径长度:一条路径上所经过的边的数目\n（2）带权路径长度:路径上所经过边的权值之和\n（跟树的带权路径长度区分好！）\n（3）最短路径:(带权)路径长度(值)最小的那条路径\n（4）最短路径长度或最短距离:最短路径长度\n3.Dijkstra算法(O(n^3))\n（1）Dijkstra算法思想：采用按路径长度递增的次序产生最短路径\n—1.设置两个顶点的集合U和T，集合U中存放已找到最短路径的顶点，集合T中存放当前还未找到最短路径的顶点。\n—2.初始状态时，集合U中只包含源点，设为v0；\n—3.然后从集合T中选择到源点v0路径长度最短的顶点u加入到集合U中；\n—4.集合U中每加入一个新的顶点u都要修改源点v0到集合T中剩余顶点的当前最短路径长度值，集合T中各顶点的新的当前最短路径长度值，为原来的当前最短路径长度值与从源点过顶点u到达该顶点的路径长度中的较小者。\n—5.转到3，此过程不断重复，直到集合T中的顶点全部加入到集合U中为止。\n（2）在Dijkstra算法中，引进了一个辅助向量D\n每个分量D[i]表示当前所找到的从始点到每个终点vi的最短路径长度。\nD[i]初值为始点v0到各终点vi的直接距离，即若从始点到某终点有(出)弧，则为弧上的权值，否则为∞。\n（3）得到路径：\n—1.设置另一个辅助向量path[]，用来存放得到的从源点v0到其余各顶点的最短路径上到达目标顶点的前一顶点下标。\n—2.为每一个顶点i设置辅助向量pathi，用来存放得到的从源点v0到该顶点的最短路径中依次访问过的顶点。第一个值是路径上的顶点数。\n题目：对下图求从V0出发到各顶点的最短路径。\n\n\n（最后的过程5“无”一定要加，且要补充最后最短路径的结果!)\n4.求n个顶点之间的最短路径\n（1）用Dijkstra算法也可以求得有向图G=(V，E)中每一对顶点间的最短路径。\n方法是： 设置二维数组D [i] [j]，数组每一行D[i]表示从顶点vi出发到其它顶点的最短路径，即每次以一个不同的顶点vi为源点重复Dijkstra算法便可求得每一对顶点间的最短路径，时间复杂度是O(n^3) 。\n（2）弗罗伊德(Floyd)算法，其时间复杂度仍是O(n^3) ， 但算法形式更为简明，步骤更为简单，数据结构是基于图的邻接矩阵。\n\n将图中一个顶点Vk 加入到S中，修改A[i] [j]的值，修改方法是：\nA[i] [j] = Min{ A[i] [j] , (A[i] [k]+A[k] [j]) }\n找路径：定义二维数组Path[n] [n] (n为图的顶点数) ，元素Pathi保存从Vi到Vj的最短路径所经过的顶点。若Path[i] [j]=k：从Vi到Vj 经过Vk ，最短路径序列是(Vi , …, Vk , …, Vj) ，则路径序列：(Vi , …, Vk)和(Vk , …, Vj)一定是从Vi到Vk和从Vk到Vj 的最短路径。从而可以根据Path[i] [k]和Path[k] [j]的值再找到该路径上所经过的其它顶点，…依此类推。\n初始时令Path[i] [j]=-1，表示从Vi到Vj 不经过任何(S中的中间)顶点。当某个顶点Vk加入到S中后使A[i] [j]变小时，令Path[i] [j]=k。\n六、有向无环图及其应用1.AOV网（有向图！）\n（1）如果用有向图的顶点表示活动，用弧表示活动间的优先关系，则称该有向图为顶点表示活动的网AOV(Activity On Vertex Network)\n（2）AOV的应用包括流程图、工程安排等。对AOV网，应判定图中不存在环，因为存在环意味着某项活动应以自己为先决条件。\n2.有向无环图(DAG)Directed Acycline Graph\n3.检查有向图中是否有回路：\n（1）深度优先搜索 ：从某个顶点v出发，进行DFS，如果存在一条从顶点u到v的回边，则有向图中存在环。\n（2）拓扑排序：由严格偏序定义得到的拓扑有序的操作称拓扑排序。\n若集合X上的关系R是：⑴.自反的：x R x⑵.反对称的：x R y =&gt; y R x⑶.传递的：xRy &amp; yRz =&gt; xRz 则称R是集合X上的偏序关系。\n全序：设关系R是集合X上的偏序，如果对每个x,y属于X，必有xRy或者yRx，则称R是X上的全序关系。\n偏序：指集合中仅有部分成员之间可比较。\n全序：指集合中全体成员之间均可比较\n算法：⑴.在有向图中选一个没有前驱的顶点(无入度)且输出之⑵.从图中删除该顶点和所有以它为尾的弧；重复⑴⑵两步，直到所有顶点输出为止或跳出循环。\n（3）拓扑排序与AOV网：\n拓扑排序可检测AOV网是否存在环。如果通过拓扑排序能将AOV网络的所有顶点都排入一个拓扑有序的序列中, 则该网络中必定不会出现有向环。反之其中存在环。\n4.拓扑排序实现\n（1）没有前驱的顶点 == 入度为零的顶点\n（2）删除顶点及以它为尾的弧 == 弧头顶点的入度减1\n题目:写出某AOV网的邻接表存储结构如下，写出分别用队列和栈存储入读为零的顶点时的拓扑排序序列。\n\n栈的拓扑：C4,C0,C2,C1,C3,C5\n队列的拓扑：C2,C4,C0,C1,C5,C3\n5.AOV-网\n（1）如果用有向图的顶点表示事件，用弧表示活动，则称该有向图为边表示活动的网AOE(Activity On Edge)\n（2）AOE应该同样是DAG，AOE包括估算工程的完成时间。\n注意：AOE网和AOV网都是有向无环图，不同在于AOE网中的边有权值；而AOV网中的边无权值，仅表示顶点之间的前后关系。\n6.关键路径\n（1）工程问题的AOE网中，从工程开始(顶点)到工程结束(顶点)之间路径长度最长的路径叫关键路径（最长路径！）\n（2）提前完成关键路径上的活动，工程进度会加快\n（3）提前完成非关键路径上的活动，对工程无帮助\n7.关键活动\n（1）关键路径上的所有活动称为关键活动\n（2）找到工程AOE中的所有关键活动，即找到了关键路径\n8.关键活动有关的量\n（1）e(i)：活动ai最早开始时间\n（2）l(i)：活动ai最迟开始时间\n（3）l(i)-e(i)：活动ai开始时间余量\n（4）如果l(i)=e(i)，则称活动ai为关键活动\n（5）ve(j)：事件vj最早开始时间\n（6）vl(j)：事件vj最迟开始时间\n（7)e(i)=ve(j)\n（8）l(i)=vl(k)-dut() 　\ndut()为活动ai的持续时间\n（9）活动的最早开始时间是活动的弧尾事件的最早发生时间，\n活动的最晚发生时间是活动的弧头事件的最晚发生时间减去活动的持续时间。\nj———&gt;k(此边即活动的编号为i)\n（10）从ve(0)=0开始向前递推（事件的最早发生时刻）\n事件的最早发生时间是以其为弧头事件的所有弧尾事件的最早发生时间与对应弧活动的持续时间之和的最大值\n（11）从vl(n-1)=ve(n-1)起向后递推（事件的最晚发生时刻）\n事件的最晚发生时间是以其为弧尾事件的所有弧头事件的最晚发生时间与对应弧活动的持续时间之差的最小值。\n9.求关键活动算法（先计算事件，再计算活动）\n（1）从始点v0出发，令ve[0]=0（源点），按拓扑有序求ve[j]\n即vk为vj的任意后续\nve[k]=max{ve[j]+Weight(vj,vk)}\n（2）从终点vn-1出发，令vl[n-1]=ve[n-1]（汇点），按逆拓扑有序求vl[i]\n即vk为vj的任意前驱\nvl[k]=min{ vl[j]-Weight(vk,vj)}\n（简单记忆：我们都想晚点开学早点放假，晚点开学即最早开始取max，早点放假即最晚开始取min)\n（3）根据各顶点的ve和vl值，求每条弧(活动)ai的最早开始时间e[ai]和最迟开始时间l[ai]\n若边表示活动ai,则e(i)=ve[k]\nl[i]=vl[j]-Weight(vk,vj)\n（4）如果e[ai]=l[ai]，则ai为关键活动(e[i]-l[i]==0)\n（5）如果ve[i]=vl[i]，则vi为关键路径上的事件\n题目：下表给出了某工程各工序之间的优先关系和各工序所需的时间。\n\n\n\n\n工序代号\nA\nB\nC\nD\nE\nF\nG\nH\n\n\n\n\n所需时间\n3\n2\n2\n3\n4\n3\n2\n1\n\n\n先驱工序\n-\n-\nA\nA\nB\nB\nC,E\nD\n\n\n\n\n问: 该工程是否能够顺利进行? 如果能，请问要花多长时间？ 缩短那些工序可以缩短整个工程的完工时间？\n\n第九章：查找一、查找的概念1.查找表\n（1）查找表是由同一类型的数据元素(或记录)构成的集合\n（2）对查找表的操作:\n—1.查询某个“特定的”数据元素是否在查找表中；\n—2.检索某个“特定的”数据元素的各种属性；\n—3.在查找表中插入一个数据元素；\n—4.从查找表中删去某个数据元素\n（3）静态查找表：仅作查询和检索操作的查找表。\n（4）动态查找表：在查找过程中同时插入查找表中不存在的数据元素，或者从查找表中删除已存在的某个数据元素。\n2.关键字\n（1）关键字是数据元素（或记录）中某个数据项的值，用以标识（识别）一个数据元素（或记录\n注意：关键字是某个数据项的值！不是数据元素\n（2）主关键字：可以识别唯一的一个记录的关键字\n（3）次关键字：能识别若干记录的关键字\n3.查找\n（1）查找是根据给定的某个值，在查找表中确定一个其关键字等于给定值的数据元素（或记录）。\n（2）查找成功：在查找表中查找到指定的记录。\n（3）查找不成功：在查找表中没有找到指定记录。\n4.衡量查找算法的标准\n（1）时间复杂度\n（2）空间复杂度\n（3）平均查找长度ASL\n5.平均查找长度ASL\n（1）平均查找长度定义为确定记录在表中的位置所进行的和关键字比较的次数的平均值。\n（2）ASL = ∑ PiCi （i为1到n）\n\nn为查找表的长度，即表中所含元素的个数；Pi为查找第i个元素的概率(∑Pi=1)；Ci是查找第i个元素时同给定值K比较的次数。\n二、静态查找表（顺序、折半、分块）1.顺序查找\n（1）顺序查找算法是顺序表的查找方法。\n（2）在顺序查找算法中，以顺序表或线性链表表示静态查找表。\n（3）顺序查找算法：\n—1.从表中最后一个记录开始\n—2.逐个进行记录的关键字和给定值的比较\n—3.若某个记录比较相等，则查找成功\n—4.若直到第1个记录都比较不等，则查找不成功\n（4）算法性能分析\n对顺序表而言，Ci=n-i+1\n在等概率查找的情况下，Pi=1/n\nASL（成功）=n*P1 +(n-1)P2 +…+ 2Pn-1+ Pn = (n+1)/2\n（5）顺序查找(不等概率)\n如果被查找的记录概率不等时，取 Pn≥Pn-1≥···≥P2≥P1；\n若查找概率无法事先测定，则查找过程采取的改进办法是，在每次查找之后，将刚刚查找到的记录直接移至表尾的位置上。\n（6）特点：\n优点：1.简单2.适应面广(对表的结构无任何要求)\n缺点：1.平均查找长度较大2.特别是当n很大时，查找效率很低。\n2.折半查找（有序表！）\n（1）折半查找算法是有序表的查找方法。\n（2）在折半查找算法中，静态查找表按关键字大小的次序，有序地存放在顺序表中。\n（3）折半查找的原理是：1.先确定待查记录所在的范围(前部分或后部分)2.逐步缩小(一半)范围直到找(不)到该记录为止。\n（4）算法：\n—1.n个对象从小到大存放在有序顺序表ST中，k为给定值\n—2.设low、high指向待查元素所在区间的下界、上界，即low=1, high=n\n—3.设mid指向待区间的中点，即mid=(low+high)/2\n—4.让k与mid指向的记录比较若k=ST[mid].key，查找成功\n若k&lt;ST[mid].key，则high=mid-1 [上半区间]\n若k&gt;ST[mid].key，则low=mid+1 [下半区间]\n—5.重复3,4操作，直至low&gt;high时，查找失败。（严格大于）\n（5）折半查找（判定树）\n判定树：描述查找过程的二叉树。\n有n个结点的判定树的深度为floor(log2(n)) +1（与含有 n 个结点的完全二叉树的深度相同）\n折半查找法在查找过程中进行的比较次数最多不超过floor(log2(n)) +1\n题目：假设某有序表查找中有12个元素，请问该查找表查找成功时的平均查找长度为多少？（查找失败的ASL：为白块到根结点的路径长度之和/白块个数；ASL=1/2  成功+1/2 失败）\n\n（6）性能分析\n设有序表的长度n=2^h-1（即h=log2(n+1)）,则描述折半查找的判定树是深度为h的满二叉树。\n树中层次为1的结点有1个，层次为2的结点有2个，层次为h的结点有2^(h-1)个。\n假设表中每个记录的查找概率相等，则查找成功时折半查找的平均查找长度：ASL（成功）=[(n+1)/n]*log2(n+1)-1\n（7）特点\n折半查找的效率比顺序查找高(特别是在静态查找表的长度很长时)。\n折半查找只能适用于有序表，并且以顺序存储结构存储。\n3.分块查找\n（1）分块查找是一种索引顺序表(分块有序表)查找方法，是折半查找和顺序查找的简单结合。\n（2）索引顺序表(分块有序表)将整个表分成几块，块内无序，块间有序。\n（3）所谓块间有序是指后一块表中所有记录的关键字均大于前一块表中的最大关键字。\n（4）分块查找(分块有序表)\n主表：用数组存放待查记录,每个数据元素至少含有关键字域。\n索引表：每个结点含有最大关键字域和指向本块第一个结点的指针。\n（5）采用折半查找方法在索引表中找到块[第2块]，用顺序查找方法在主表对 应块中找到记录[第3记录]。\n（6）性能分析：\n若将长度为n的表分成b块，每块含s个记录，并设表中每个记录查找概率相等。\n用折半查找方法在索引表中查找索引块，ASL块间≈log2(n/s+1)\n用顺序查找方法在主表对应块中查找记录，ASL块内=s/2\nASL(成功)≈log2(n/s+1) + s/2\n三、动态查找表1.动态查找表\n（1）表结构本身是在查找过程中动态生成的\n（2）若表中存在其关键字等于给定值key的记录,表明查找成功；\n（3）否则插入关键字等于key的记录。\n2.二叉排序树（将判定树的结点信息从下标改为数据即为二叉排序树）\n（1）空树或者是具有如下特性的二叉树：\n—⑴.若它的左子树不空，则左子树上所有结点的值均小于根结点的值；\n—⑵.若它的右子树不空，则右子树上所有结点的值均大于根结点的值；\n—⑶.它的左、右子树也都分别是二叉排序树。\n（2）二叉排序树又称二叉查找树\n查找算法： 给定值与根结点比较：—1.若相等，查找成功—2.若小于，查找左子树—3.若大于，查找右子树\n生成举例：\n题目：画出在初始为空的二叉排序树中依次插入56,64,92,80,88,75时该树的生长全过程\n\n（3）二叉排序树(插入)\n二叉排序树是一种动态树表；\n当树中不存在查找的结点时，作插入操作；\n新插入的结点一定是叶子结点（只需改动一个结点的指针）；\n该叶子结点是查找不成功时路径上访问的最后一个结点左孩子或右孩子(新结点值小于或大于该结点值)。（最后一个！）\n（4）中序遍历二叉排序树，可得到一个关键字的有序序列。\n（5）二叉排序树(删除)\n删除二叉排序树中的一个结点后，必须保持二叉排序树的特性（左子树的所有结点值小于根结点，右子树的所有结点值大于根结点）也即保持中序遍历后，输出为有序序列。\n被删除结点具有以下三种情况：1.是叶子结点（直接删除结点，并让其父结点指向该结点的指针变为空）；2.只有左子树或右子树（删除结点,让其父结点指向该结点的指针指向其左子树(或右子树),即用孩子结点替代被删除结点即可）；3.同时有左、右子树。（以中序遍历时的直接前驱s替代被删除结点p，然后再删除该直接前驱（只可能有左孩子））\n\n（6）性能分析\n\n（注意根算1！）\n对于每一棵特定的二叉排序树，均可按照平均查找长度的定义来求它的 ASL 值。\n显然，由值相同的 n 个关键字，构造所得的不同形态的各棵二叉排序树的平均查找长度的值不同，甚至可能差别很大。\n在最坏的情况下，二叉排序树为近似线性表时(如以升序或降序输入结点时)，其查找深度为n量级，即其时间复杂性为O(n)\n（7）特性\n一个无序序列可以通过构造一棵二叉排序树而变成一个有序序列（通过中序遍历）。\n插入新记录时，只需改变一个结点的指针，相当于在有序序列中插入一个记录而不需要移动其它记录。\n二叉排序树既拥有类似于折半查找的特性，又采用了链表作存储结构。\n但当插入记录的次序不当时(如升序或降序)，则二叉排序树深度很深，增加了查找的时间。\n3.平衡二叉树\n（1）平衡二叉树是二叉排序(查找)树的另一种形式\n（2）平衡二叉树又称AVL树(Adelsen-Velskii and Landis)\n（3）其特点为：树中每个结点的左、右子树深度之差的绝对值不大于1，即|hL-hR|≤1\n（4）平衡因子：每个结点附加一个数字, 给出该结点左子树的高度减去右子树的高度所得的高度差,这个数字即为结点的平衡因子balance （左减右！）\n（5）AVL树任一结点平衡因子只能取 -1, 0, 1\n（6）平衡二叉树(删除)与二叉排序树相同\n如果被删结点A最多只有一个孩子，那么将结点A从树中删去，并将其双亲指向它的指针指向它的唯一的孩子，并作平衡化处理。\n如果被删结点A没有孩子，则直接删除之，并作平衡化处理。\n如果被删结点A有两个子女，则用该结点的直接前驱S替代被删结点，然后对直接前驱S作删除处理(S只有一个孩子或没有孩子)。\n4.AVL平衡化旋转\n（1）如果在一棵平衡的二叉查找树中插入一个新结点，造成了不平衡。此时必须调整树的结构，使之平衡化。\n（2）平衡化旋转(处理)有两类：\n—1.单向旋转 (单向右旋和单向左旋)\n\n—2.双向旋转 (先左后右旋转和先右后左旋转)\n\n（3）每插入一个新结点时, AVL树中相关结点的平衡状态会发生改变。\n—1.在插入一个新结点后，需要从插入位置沿通向根的路径回溯，检查各结点的平衡因子。\n—2.如果在某一结点发现高度不平衡，停止回溯。(出现2或者-2)\n—3.从发生不平衡的结点起，沿刚才回溯的路径取直接下两层的结点。（做旋转操作）\n题目：画出在初始为空的AVL树中依次插入64,5,13,21,19,80,75,37,56时该树的生长过程，并在有旋转时说出旋转的类型。\n\n四、哈希表1.哈希表（散列表）\n（1）哈希(Hash)表又称散列表散列表，是一种直接计算记录存放地址的方法，它在关键码与存储位置之间直接建立了映象。\n（2）哈希函数是从关键字空间到存储地址空间的一种映象。\n（3）哈希函数在记录的关键字与记录的存储地址之间建立起一种对应关系。可写成：addr(ai)= H(keyi)，H(·)为哈希函数k，eyi是表中元素ai关键字,addr(ai)是存储地址。\n2.哈希表(查找)\n（1）哈希查找也叫散列查找，是利用哈希函数进行查找的过程。\n—1.首先利用哈希函数及记录的关键字计算出记录的存储地址.。\n—2.然后直接到指定地址进行查找\n—3.不需要经过比较，一次存取就能得到所查元素\n3.哈希表(冲突)\n（1）不同的记录，其关键字通过哈希函数的计算，可能得到相同的地址。把不同的记录映射到同一个散列地址上，这种现象称为冲突。\n4.哈希表(定义)\n（1）根据设定的哈希函数 H(key) 和所选中的处理冲突的方法\n（2）将一组关键字映象到一个有限的、地址连续的地址集 (区间) 上\n（3）并以关键字在地址集中的“象”作为相应记录在表中的存储位置\n（4）如此构造所得的查找表称之为“哈希表”\n5.哈希函数(均匀性)\n（1）哈希函数实现的一般是从一个大的集合（部分元素，空间位置上一般不连续）到一个小的集合（空间连续）的映射\n（2）一个好的哈希函数，对于记录中的任何关键字，将其映射到地址集合中任何一个地址的概率应该是相等的\n（3）即关键字经过哈希函数得到一个“随机的地址“\n6.哈希函数(要求)\n（1）哈希函数应是简单的，能在较短的时间内计算出结果。\n（2）哈希函数的定义域尽可能包括需要存储的全部关键字，如果散列表允许有 m 个地址时，其值域必须在 0 到 m-1 之间。\n（3）散列函数计算出来的地址应能均匀分布在整个地址空间中。\n7.哈希函数(直接定址法)\n（1）直接定址法中，哈希函数取关键字的线性函数： H(key) = a x key + b（其中a和b为常数）\n（2）直接定址法仅适合于地址集合的大小与关键字集合的大小相等的情况\n（3）当a=1时，H(key)=key，即用关键字作地址\n（4）在实际应用中能使用这种哈希函数的情况很少\n8.哈希函数(数字分析法)\n（1）假设关键字集合中的每个关键字都是由 s 位数字组成 (u1, u2, …, us)。\n（2）分析关键字集中的全体\n（3）从中提取分布均匀的若干位或它们的组合作为地址\n\n（4）数字分析法仅适用于事先明确知道表中所有关键码每一位数值的分布情况\n（5）数字分析法完全依赖于关键码集合\n（6）如果换一个关键码集合，选择哪几位要重新决定\n9.哈希函数(平方取中法)\n（1）以关键字的平方值的中间几位作为存储地址。\n（2）求“关键字的平方值” 的目的是“扩大差别”\n（3）同时平方值的中间各位又能受到整个关键字中各位的影响。\n（4）此方法在词典处理中使用十分广泛。它先计算构成关键码的标识符的内码的平方, 然后按照散列表的大小取中间的若干位作为散列地址。\n\n（5）平方取中法是较常用的构造哈希函数的方法\n（6）适合于关键字中的每一位都有某些数字重复出现且频度很高的情况\n（7）中间所取的位数，由哈希表长决定\n10.哈希函数(折叠法)\n（1）将关键字分割成位数相同的若干部分(最后部分的倍数可以不同)，然后取它们的叠加和(舍去进位)为哈希地址。\n（2）移位叠加:将分割后的几部分低位对齐相加。\n（3）间界叠加:从一端沿分割界来回折送，然后对齐相加。\n\n（4）折叠法适合于关键字的数字位数特别多，而且每一位上数字分布大致均匀的情况。\n11.哈希函数(除留余数法)\n（1）取关键字被某个不大于哈希表长m的数p除后所得余数为哈希地址： H(key) = key MOD p ( p≤m )\nm为表长 p为不大于m的素数或是不含20以下的质因子\n（2）除留余数法是一种最简单、最常用的构造哈希函数的方法\n（3）不仅可以对关键字直接取模(MOD)，也可在折叠、平方取中等运算之后取模\n12.处理冲突的方法\n“处理冲突” 的实际含义是：为产生冲突的地址寻找下一个哈希地址。\n处理冲突的方法主要有三种：1.开放定址法2.再哈希法3.链地址法\n13.处理冲突的方法(开放定址法)\n（1）为产生冲突的地址 H(key) 求得一个地址序列： H0, H1, H2, …, Hs，1≤s≤m-1\n（2）Hi = [H(key)+di] MOD m\ni=1,2,…,s\nH(key)为哈希函数\nm为哈希表长\n（3）开放定址法－线性探测：\n当di取1,2,3,…,m-1时，称这种开放定址法为线性探测再散列\n\n（4）开放定址法－二次探测：\n当di取= 1^2, -1^2，2^2, -2^2，3^2,…时，称这种开放定址法为二次探测再散列\n（5）特性\n当di取= 1^2, -1^2，2^2, -2^2，3^2,…时，称这种开放定址法为二次探测再散列；\n二次探测再散列：m=4j+3的素数时总能找到。\n缺点：易产生“二次聚集”，即在处理同义词的冲突过程中，又添加了非同义词的冲突，对查找不利\n14.处理冲突的方法(再哈希法)\n（1）构造若干个哈希函数，当发生冲突时，计算下一个哈希地址，直到冲突不再发生，即：Hi = Rhi(key) i=1,2,……k\nRhi—不同的哈希函数\n（2）特点：不易产生聚集，但增加计算时间\n15.处理冲突的方法(链地址法)\n（1）将所有哈希地址相同的记录都链接在同一链表中\n（2）表头插入和表后插入\n题目：已知一组关键字(19,14,23,1,68,20,84,27,55,11,10,79)哈希函数为： H(key)=key MOD 13,用链地址法处理冲突[表头插入]\n（注意左侧数组表示和空符号^)\n\n16.哈希表的实现\n17.哈希表的性能分析\n（1）虽然哈希表在关键字与记录的存储位置之间建立了直接映象，但由于“冲突”的产生，使得哈希表的查找过程仍然是一个给定值和关键字进行比较的过程\n（2）因此，仍需以平均查找长度(ASL)作为衡量哈希表的查找效率的量度\n（3）决定哈希表查找的ASL的因素：\n—1.选用的哈希函数\n—2.选用的处理冲突的方法\n—3.哈希表的装填因子：哈希表的装填因子是哈希表中填入的记录数与哈希表的长度的比值，即：α = 哈希表中填入的记录数 / 哈希表的长度。装填因子α标志哈希表的装满程序。\n注意：散列表的平均查找长度依赖于装填因子，不直接依赖于n或m\n（4）装填因子α越小，发生冲突的可能性就越小；装填因子α越大，发生冲突的可能性就越大。\n（5）平均查找长度ASL:\n线性探测再散列的哈希表查找成功时：ASL ≈ (½)(1 + 1/(1-α))\nASL(成功)=(1/2)*(1+1/(1-记录数/哈希表长度))\n二次探测再散列的哈希表查找成功时：ASL ≈ -(1/α)ln(1-α)\nASL(成功)=-(1/(记录数/哈希表长度))ln(1-记录数/哈希表长度)\n链地址法处理冲突的哈希表查找成功时：ASL ≈ (1 + α/2)\nASL(成功)=(1+(记录数/哈希表长度)/2)\n五、B-树[结点结构]1.B-树是一种特殊的多路平衡查找树\n2.R.Bayer和E.Maccreight于1970年提出\n3.B-树是一种在外存文件系统中常用的动态索引\n4.技术磁盘中文件的读写以“盘块”为单位进行\n5.将关键字索引信息，放在盘块中，可以加快数据的查找速度\n6.结点结构：\n（1）Ki是关键字，且Ki&lt;Ki+1\n（2）Ai是指向子树根结点的指针\n（3）Ai-1所指子树中所有结点的关键字均小于Ki\n（4）Ai 所指子树中所有结点的关键字均大于Ki\n（5）对于m阶B-树，ceil(m/2) -1≤n≤m-1 (分支数比关键字数目多一)\n\n7.m阶B-树定义:\n（1）树中每个结点至多有m棵子树（m-1个关键字）\n（2）若根结点不是叶子结点，则至少有两棵子树\n（3）除根之外的所有非终端结点至少有 ceil(m/2) 棵子树\n（4）所有叶子结点，都出现在同一层次上，且不带信息（可以看作是查找失败的结点，指向这些结点的指针为空指针）\n题目:3阶B-树（11个结点）\n\n(1)关键字比分支数少一（B-）,m=3(3阶)\n(2)关键字数目为n,ceil(3/2)-1&lt;=n&lt;=3-1即1&lt;=n&lt;=2\nceil(m/2)-1&lt;=n&lt;=m-1\n(3)如图深度为3，结点数最少(所有都是关键字n=1,分支为2)：2^3-1=7;结点数最多(所有都是关键字n=2,分支为3)：1+3+3^2=13\n结点数最少：2^h-1;结点数最多：1+m+m^2+..+m^(h-1)\n第十章：内部排序一、排序1.排序\n（1）排序：将一个数据元素（或记录）的任意序列，重新排列成一个按关键字有序的序列\n（2）内部排序：在排序期间数据对象全部存放在内存的排序；\n（3）外部排序：在排序期间全部对象个数太多，不能同时存放在内存，必须根据排序过程的要求，不断在内、外存之间移动的排序。\n2.排序基本操作：\n（1）比较：比较两个关键字的大小\n（2）移动：将记录从一个位置移动至另一个位置\n3.排序时间复杂度\n排序的时间复杂度可用算法执行中的记录关键字比较次数与记录移动次数来衡量。\n4.排序方法的稳定性\n（1）如果在记录序列中有两个记录r[i]和r[j], 它们的关键字 key[i] == key[j] , 且在排序之前, 记录r[i]排在r[j]前面。\n（2）如果在排序之后, 记录r[i]仍在记录r[j]的前面, 则称这个排序方法是稳定的, 否则称这个排序方法是不稳定的。\n二、插入排序1.直接插入排序\n（1）当插入第i(i≥1)个对象时, 前面的r[0], r[1], …, r[i-1]已经排好序。\n（2）用r[i]的关键字与r[i-1], r[i-2], …的关键字顺序进行比较(和顺序查找类似)，如果小于，则将r[x]向后移动(插入位置后的记录向后顺移)\n（3）找到插入位置即将r[i]插入\n（4）每步将一个待排序的对象, 按其关键字大小, 插入到前面已经排好序的有序表的适当位置上, 直到对象全部插入为止。\n\n（5）关键字比较次数和记录移动次数与记录关键字的初始排列有关。\n（6）最好情况下, 排序前记录已按关键字从小到大有序, 每趟只需与前面有序记录序列的最后一个记录比较1次, 移动2次记录, 总的关键字比较次数为 n-1, 记录移动次数为 2(n-1)。\n（7）最坏情况下, (i从1开始，下标从0开始)第i趟时第i个记录必须与前面i个记录都做关键字比较, 并且每做1次比较就要做1次数据移动。则总关键字比较次数KCN和记录移动次数RMN分别为\n\n（8）在平均情况下的关键字比较次数和记录移动次数约为 n^2/4。\n（9）直接插入排序的时间复杂度为O(n^2)。\n（10）直接插入排序是一种稳定的排序方法。\n（11）直接插入排序最大的优点是简单，在记录数较少时，是比较好的办法。\n2.折半插入排序\n（1）折半插入排序在查找记录插入位置时，采用折半查找算法\n（2）折半查找比顺序查找快, 所以折半插入排序在查找上性能比直接插入排序好\n（3）但需要移动的记录数目与直接插入排序相同(为O(n2))\n（4）折半插入排序的时间复杂度为O(n^2)。\n（5）折半插入排序是一种稳定的排序方法\n3.希尔排序\n（1）从直接插入排序可以看出，当待排序列为正序时，时间复杂度为O(n)\n（2）若待排序列基本有序时，插入排序效率会提高希尔排序方法是先将待排序列分成若干子序列分别进行插入排序，待整个序列基本有序时，再对全体记录进行一次直接插入排序\n（3）希尔排序又称为缩小增量排序。\n\n（4）算法：\n首先取一个整数 gap &lt; n(待排序记录数) 作为间隔, 将全部记录分为 gap 个子序列, 所有距离为 gap 的记录放在同一个子序列中。（gap为组数！）\n在每一个子序列中分别施行直接插入排序。然后缩小间隔 gap, 例如取 gap = gap/2。\n重复上述的子序列划分和排序工作，直到最后取gap = 1, 将所有记录放在同一个序列中排序为止。\n（5）算法分析：\n开始时 gap 的值较大, 子序列中的记录较少, 排序速度较快。\n随着排序进展, gap 值逐渐变小, 子序列中记录个数逐渐变多,由于前面大多数记录已基本有序, 所以排序速度仍然很快。\nGap的取法有多种。 shell 提出取 gap = n/2，gap = gap/2，直到gap = 1。\n对特定的待排序记录序列，可以准确地估算关键字的比较次数和记录移动次数。\n希尔排序所需的比较次数和移动次数约为n^1.3\n当n趋于无穷时可减少到n x(log2 n)^2\n希尔排序的时间复杂度约为O(n x(log2 n)^2)\n希尔排序是一种不稳定的排序方法\n三、快速排序1.冒泡排序\n（1）设待排序记录序列中的记录个数为n(下标从1到n)。\n（2）一般地，第i趟起泡排序从1到n-i+1依次比较相邻两个记录的关键字，如果发生逆序，则交换之\ni=1时，为第一趟排序，关键字最大的记录将被交换到最后一个位置\ni=2时，为第二趟排序，关键字次大的记录将被交换到最后第二个位置\n关键字小的记录不断上浮(起泡)，关键字大的记录不断下沉(每趟排序最大的一直沉到底)\n（3）其结果是这n-i+1个记录中，关键字最大的记录被交换到第n-i+1的位置上，最多作n-1趟。\n（4）最好情况：在记录的初始排列已经按关键字从小到大排好序时,此算法只执行一趟起泡,做n-1次关键字比较,不移动记录。\n（5）最好情况：在记录的初始排列已经按关键字从小到大排好序时,此算法只执行一趟起泡,做n-1次关键字比较,不移动记录\n\n（6）起泡排序的时间复杂度为O(n^2)\n（7）起泡排序是一种稳定的排序方法\n（8）每一趟可以确定一个数的位置（从后往前）\n2.快速排序\n（1）任取待排序记录序列中的某个记录(例如取第一个记录)作为基准(枢),按照该记录的关键字大小,将整个记录序列划分为左右两个子序列\n（2） 左侧子序列中所有记录的关键字都小于或等于基准记录的关键字\n（3）右侧子序列中所有记录的关键字都大于基准记录的关键字\n（4）基准记录则排在这两个子序列中间(这也是该记录最终应安放的位置)。\n（5）然后分别对这两个子序列重复施行上述方法，直到所有的记录都排在相应位置上为止。\n（6）基准记录也称为枢轴（或支点）记录。\n（7）算法：\n取序列第一个记录为枢轴记录，其关键字为Pivotkey。\n指针low指向序列第一个记录位置。\n指针high指向序列最后一个记录位置。\n一趟排序(某个子序列)过程：\n—1.从high指向的记录开始,向前找到第一个关键字的值小于Pivotkey的记录,将其放到low指向的位置,low+1\n—2.从low指向的记录开始,向后找到第一个关键字的值大于Pivotkey的记录,将其放到high指向的位置,high-1\n—3.重复1,2，直到low=high，将枢轴记录放在low(high)指向的位置\n对枢轴记录前后两个子序列执行相同的操作，直到每个子序列都只有一个记录为止。\n\n（8）性能分析：\n快速排序是一个递归过程。\n利用序列第一个记录作为基准，将整个序列划分为左右两个子序列。只要是关键字小于基准记录关键字的记录都移到序列左侧。\n如果每次划分对一个记录定位后, 该记录的左侧子序列与右侧子序列的长度相同, 则下一步将是对两个长度减半的子序列进行排序, 这是最理想的情况。\n可以证明, 快速排序的平均计算时间也是O(nlog2 n)。\n实验结果表明: 就平均计算时间而言, 快速排序是所有内排序方法中最好的一个。\n但快速排序是一种不稳定的排序方法。\n（9）在最坏情况下, 即待排序记录序列已经按其关键字从小到大排好序, 其递归树成为单支树, 时间复杂度达O(n2)\n每次划分只得到一个比上一次少一个记录的子序列。\n必须经过n-1 趟才能把所有记录定位,\n而且第 i 趟需要经过 n-i 次关键字比较才能找到第 i 个记录的安放位置，总的关键字比较次数将达到：\n\n（10）改进：枢轴记录取low、high、(low+high)/2三者指向记录关键字居中的记录。\n四、选择排序1.简单选择排序\n（1）每一趟(例如第i趟,i=0,1,…,n-2)在后面n-i个待排序记录中选出关键字最小的记录,与第i个记录交换。\n\n（2）每趟可确定一个数（从前往后）\n算法中的几个表示关系的缩写EQ 就是 EQUAL等于\nNE 就是 NOT EQUAL不等于\nGT 就是 GREATER THAN大于　\nLT 就是 LESS THAN小于\nGE 就是 GREATER THAN OR EQUAL 大于等于\nLE 就是 LESS THAN OR EQUAL 小于等于\n（2）性能分析：\n直接选择排序的关键字比较次数 KCN 与记录的初始排列无关。\n设整个待排序记录序列有n个记录,则第i趟选择具有最小关键字记录所需的比较次数总是 n-i-1次。总的关键字比较次数为：\n\n记录的移动次数与记录序列的初始排列有关。\n当这组记录的初始状态是按其关键字从小到大有序的时候,记录的移动次数RMN=0,达到最少。\n最坏情况是每一趟都要进行交换，总的记录移动次数为 RMN = 3(n-1)。\n直接选择排序是一种不稳定的排序方法。\n2.堆排序\n（1）设有一个关键字集合，按完全二叉树的顺序存储方式存放在一个一维数组中。对它们从根开始，自顶向下，同一层自左向右从 1 开始连续编号。若满足 Ki &gt;=K2i &amp;&amp; Ki &gt;=K2i+1则称该关键字集合构成一个堆(最大堆)\n注意：只对根有要求，对左右节点大小关系顺序无要求\n（2）最大堆（筛选）：\n输出根结点\n用最后结点代替根结点值（最后的！）\n比较根结点与两个子结点的值，如果小于其中一个子结点，则选择大的子结点与根结点交换\n继续将交换的结点与其子结点比较\n直到叶子结点或者根节点值大于两个子结点\n（2）创建初始堆：\n根据给定的序列，从1至n按顺序创建一个完全二叉树\n由最后一个非终端结点(第n/2个结点)开始至第1个结点，逐步做筛选（第n/2个！）\n（3）性能排序\n对于长度为n的序列，其对应的完全二叉树的深度为k(2^(k-1) &lt;= n &lt;= 2^k)\n对深度为k的堆，筛选算法中进行的关键字比较次数至多为2(k-1)次\n堆排序时间主要耗费在建初始堆和调整建新堆(筛选)上\n建初始堆最多做n/2次筛选\n对长度为n的序列，排序最多需要做n-1次调整建新堆(筛选)\n因此共需要O(nxk)量级的时间k = log2n\n堆排序时间复杂度为O(nlog2n)\n堆排序是一个不稳定的排序方法\n记录数较多时，推荐堆排序\n\n五、归并排序1.归并（有序！）\n（1）归并是将两个或两个以上的有序表合并成一个新的有序表。\n（2）两路归并\n假设待归并两个有序表长度分别为m和n，则两路归并后，新的有序表长度为m+n\n两路归并操作至多只需要m+n次移位和m+n次比较\n因此两路归并的时间复杂度为O(m+n)\n2.2路－归并排序\n（1）将n个记录看成是n个有序序列\n（2）将前后相邻的两个有序序列归并为一个有序序列(两路归并)（前后相邻！）\n（3）重复做两路归并操作，直到只有一个有序序列为止\n\n（4）性能分析：\n如果待排序的记录为n个，则需要做log2n趟两路归并排序\n每趟两路归并排序的时间复杂度为O(n)\n因此2路－归并排序的时间复杂度为O(nlog2n)\n归并排序是一种稳定的排序方法\n\n六、基数排序1.多关键字的排序(最低位优先法LSD)\n（1）从最低位关键字kd起进行排序，\n（2）然后再对高一位的关键字排序，……\n（3）依次重复，直至对最高位关键字k1排序后，便成为一个有序序列\n\n2.链式基数排序\n（1）基数排序：借助“分配”和“收集”对单逻辑关键字进行排序的一种方法\n（2）链式基数排序方法：用链表作存储结构的基数排序\n（3）设置10个队列，f[i]和e[i]分别为第i个队列的头指针和尾指针\n（4）第i趟分配：根据第i位关键字的值，改变记录的指针，将链表中记录分配至10个链队列中，每个队列中记录关键字的第i位关键字相同\n（5）第i趟收集：改变所有非空队列的队尾记录的指针域，令其指向下一个非空队列的队头记录，重新将10个队列链成一个链表\n（6）从最低位至最高位，逐位执行上述两步操作，最后得到一个有序序列\n\n\n（7）性能分析\n若每个关键字有 d 位,关键字的基数为radix 。\n需要重复执行d 趟“分配”与“收集”。\n每趟对 n 个对象进行“分配”，对radix个队列进行“收集”。\n总时间复杂度为O(d(n+radix))。\n若基数radix相同, 对于对象个数较多而关键字位数较少的情况, 使用链式基数排序较好。\n基数排序需要增加n+2radix个附加链接指针。\n基数排序是稳定的排序方法。\n七、各种排序方法比较\n注意：在插入和选择排序中，若初始数据基本正序，则选用插入排序。\n1.时间性能\n（1）\n时间复杂度为 O(nlogn)：快速排序、堆排序和归并排序\n时间复杂度为 O(n^2)：直接插入排序、冒泡排序、简单选择排序\n时间复杂度为 O(n): 基数排序\n（2）当待排记录序列按关键字顺序有序时\n直接插入排序和起泡排序能达到O(n)的时间复杂度；\n快速排序的时间性能蜕化为O(n^2) 。\n（3）简单选择排序、堆排序和归并排序的时间性能不随记录序列中关键字的分布而改变。\n2.空间性能\n（1）指的是排序过程中所需的辅助空间大小\n（2）所有的简单排序方法(包括：直接插入、起泡和简单选择) 和堆排序的空间复杂度为O(1)\n（3）快速排序为O(logn)，为递归程序执行过程中，栈所需的辅助空间；\n（4）归并排序所需辅助空间最多，其空间复杂度为 O(n);\n（5）链式基数排序需附设队列首尾指针，则空间复杂度为 O(rd)。\n3.排序方法的稳定性能\n口诀：考试情绪不稳定，就快些选堆朋友吧！\n（不稳定：快-&gt;快速排序，些-&gt;希尔排序，选-&gt;直接选择排序，堆-&gt;堆排序）\n（1）稳定的排序方法指的是，对于两个关键字相等的记录，它们在序列中的相对位置，在排序之前和经过排序之后，没有改变。\n\n（2） 当对多关键字的记录序列进行LSD方法排序时，必须采用稳定的排序方法。\n（3）对于不稳定的排序方法，只要能举出一个实例说明即可。\n（4）快速排序、堆排序和希尔排序是不稳定的排序方法。\n（5）所有时间复杂度为O(n^2) 的简单排序算法都是稳定的（直接选择排序算法除外）。\n（6）归并排序和基数排序是稳定的。\n所有排序整理：\n\neg)\n","categories":["笔记"]},{"title":"高代知识点全汇总","url":"/Arknight-notes/posts/16207.html","content":" folding cyan open, CSDN上的一些知识点合集（点击折叠） \n第一章——矩阵及初等变换§1.1. 矩阵及其运算\n线性代数学习笔记——第一讲——线性代数课程绪论\n线性代数学习笔记——第二讲——矩阵的定义及示例\n线性代数学习笔记——第三讲——矩阵加法及数乘\n线性代数学习笔记——第四讲——矩阵乘法的定义\n线性代数学习笔记——第五讲——矩阵乘法的性质\n线性代数学习笔记——第六讲——矩阵的转置§1.2. 高斯消元法与矩阵的初等变换\n线性代数学习笔记——第八讲——矩阵的初等变换\n线性代数学习笔记——第九讲——初等矩阵\n§1.3. 逆矩阵\n线性代数学习笔记——第十讲——逆矩阵的定义\n线性代数学习笔记——第十一讲——逆矩阵的计算（利用初等变换求逆矩阵）\n线性代数学习笔记——第十二讲——求解矩阵方程§1.4. 分块矩阵\n线性代数学习笔记——第七讲——分块矩阵\n第二章——行列式§2.1. n阶行列式的定义\n线性代数学习笔记——第十三讲——行列式的定义\n§2.2. n阶行列式的性质\n线性代数学习笔记——第十四讲——行列式的性质§2.3. Laplace定理\n线性代数学习笔记——第十五讲——行列式按行（列）展开\n线性代数学习笔记——第十六讲——行列式的计算\n线性代数学习笔记——第十七讲——伴随矩阵与逆矩阵\n线性代数学习笔记——第十八讲——抽象矩阵的可逆性§2.4. Cramer法则\n线性代数学习笔记——第十九讲——克拉默法则§2.5. 矩阵的秩\n线性代数学习笔记——第二十讲——矩阵秩的定义、\n线性代数学习笔记——第二十一讲——矩阵秩的等式\n 线性代数学习笔记——第二十二讲——矩阵秩的不等式\n第三章——几何空间§3.1. 空间直角坐标系与向量\n线性代数学习笔记——第二十三讲——空间直角坐标系\n线性代数学习笔记——第二十四讲——向量及其线性运算\n线性代数学习笔记——第二十五讲——向量在轴上的投影\n 线性代数学习笔记——第二十六讲——向量线性运算的几何意义\n线性代数学习笔记——第二十七讲——向量的方向余弦§3.2. 向量的乘法\n线性代数学习笔记——第二十八讲——向量内积的概念与性质\n线性代数学习笔记——第二十九讲——向量内积的坐标形式\n线性代数学习笔记——第三十讲——向量外积的概念与性质\n线性代数学习笔记——第三十一讲——向量外积的坐标形式\n线性代数学习笔记——第三十二讲——向量混合积的概念与性质\n线性代数学习笔记——第三十三讲——向量混合积的几何意义\n第四章——n维向量空间§4.1. n维向量空间的概念\n线性代数学习笔记——第四十讲——n维向量空间的概念\n线性代数学习笔记——第四十一讲——n维向量空间的子空间§4.2. 向量组的线性相关性\n线性代数学习笔记——第四十二讲——向量组的线性组合\n线性代数学习笔记——第四十三讲——向量组之间的线性表出\n线性代数学习笔记——第四十四讲——线性相关性的概念\n线性代数学习笔记——第四十五讲——线性相关性的判定\n线性代数学习笔记——第四十六讲——线性相关基本定理§4.3. 向量组的秩与最大无关组\n线性代数学习笔记——第四十七讲——向量组的秩与最大无关组的概念\n线性代数学习笔记——第四十八讲——矩阵的列秩和行秩\n线性代数学习笔记——第四十九讲——向量组之间的线性表出和秩\n线性代数学习笔记——第五十讲——最大无关组的性质和等价叙述§4.4. 线性方程组解的结构\n线性代数学习笔记——第五十一讲——n维向量空间的基、维数与坐标\n线性代数学习笔记——第五十二讲——齐次方程组解的性质和基础解系\n线性代数学习笔记——第五十三讲——齐次方程组求解实例\n线性代数学习笔记——第五十四讲——非齐次方程组解的性质\n线性代数学习笔记——第五十五讲——非齐次方程组求解实例\n第五章——特征值与特征向量5.1 特征值与特征向量的概念与计算\n线性代数学习笔记——第五十六讲——特征值及特征向量的定义\n线性代数学习笔记——第五十七讲——特征子空间\n线性代数学习笔记——第五十八讲——特征值与特征向量的判定\n线性代数学习笔记——第五十九讲——特征值与特征向量的计算\n 线性代数学习笔记——第六十讲——特征多项式\n线性代数学习笔记——第六十一讲——矩阵函数、逆矩阵、伴随矩阵的特征值与特征向量§5.2 矩阵的相似对角化\n线性代数学习笔记——第六十二讲——矩阵的相似对角化引例\n线性代数学习笔记——第六十三讲——相似的定义与性质\n线性代数学习笔记——第六十四讲——相似对角化的判定（1）\n线性代数学习笔记——第六十五讲——相似对角化的判定（2）\n线性代数学习笔记——第六十六讲——矩阵方幂的计算\n§5.3 n维向量空间的正交性\n线性代数学习笔记——第六十七讲——向量的内积\n线性代数学习笔记——第六十八讲——柯西—施瓦兹（Cauchy-Schwarz）不等式\n线性代数学习笔记——第六十九讲——正交向量组与标准正交基\n线性代数学习笔记——第七十讲——格拉姆—施密特（Gram-Schmidt）正交化方法\n线性代数学习笔记——第七十一讲——正交矩阵\n线性代数学习笔记——第七十二讲——共轭矩阵\n§5.4实对称矩阵的相似对角化\n线性代数学习笔记——第七十三讲——实对称矩阵的特征值与特征向量\n线性代数学习笔记——第七十四讲——实对称矩阵的相似对角化\n第六章——二次型与二次曲面§6.1.实二次型\n线性代数学习笔记——第七十五讲——二次型及其矩阵表示\n线性代数学习笔记——第七十六讲——矩阵的合同\n线性代数学习笔记——第七十七讲——用配方法化二次型为标准型\n线性代数学习笔记——第七十八讲——用正交变换化二次型为标准型§6.2. 正定二次型\n线性代数学习笔记——第七十九讲——正定二次型的概念\n线性代数学习笔记——第八十讲——正定二次型的性质（1）\n线性代数学习笔记——第八十一讲——正定二次型的性质（2）\n线性代数学习笔记——第八十二讲——二次型的其它类型\n endfolding \n一些总结，可能较零碎。\n\n本节是线代某些知识点总结，可能较零碎。\n对于简单的知识点，例如“两行对应成比例，行列式为0”就不讲了。暂时不举例题，有时间会继续补充！\n一.初等行/列变换1.计算行列式时，行列变换都可因为，所以不论动行/列都是等价的。\n\n变换规则：\n1.“倍乘”：行列式的某行(列)乘某个元素k。相应的，若行列式中某行(列)元素有公因子k(k≠0)，则k可提到行列式外面，即:\n\n2.”互换”：行列式中两行(列)互换，行列式变号。\n3.“倍加”：某行(列)的k倍加到另一行(列)，行列式不变。\n\n2.求矩阵的秩时，行列变换都可因为初等变换不改变某个矩阵非零子式的最高阶数，秩指的就是非零子式的最高阶数。\n\n初等变换的规则：\n1.”倍乘”：一个非零常数乘矩阵矩阵的某一行(列)。\n2.”互换”：互换矩阵中某两行(列)的位置。\n3.”倍加”：将矩阵的某一行(列)的k倍加到令一行(列)。\n注意：\n某矩阵乘元素k，是矩阵中的每个元素都成k，要与行列式区分。\n也就是。\n\n3.解线性方程组时，仅能使用初等行变换因为矩阵的每一种初等行变换都对应着线性方程组的同解变换，而作列变换会改变原来的方程。\n\n4.判定解的情况，单纯求r(A),r(A,b)的过程行列变换都可注：将r(A,b)化行阶梯求秩时，往往我们需要同时得到r(A)，如果想用列变换的话，只能对A单独列变换，千万不要将b列和A的列混合运算，这样r(A)就不准了。(但r(A,b)是准的)。\n但是，如果涉及到求通解或唯一解，那么就只能做行变换化行阶梯了，所以建议一开始就只做行变换。\n\n总结：求解的过程，就只进行初等行变换化行阶梯求秩，并且顺势化为行最简型求解。\n\n5.求向量组极大无关组、线性表出关系，则仅行变换因为初等行变换不改变列向量组的线性表出关系。例如下图，矩阵中，，矩阵同样有这样的关系。\n\n6.求向量组的秩时，行列变换都可求向量组的秩，其实最后会转化为求矩阵的秩，原理就是“矩阵的秩=行向量组的秩=列向量组的秩”，所以求向量组的秩也是行列变换都可。\n\n但是一般求向量组的秩后面会继续求解极大无关组/线性表出关系，这时只能做行变换，所以还是建议从开头就只使用行变换。\n7.求特征值时，行列变换都可因为特征多项式本质上是行列式，求行列式时，行列都可以换。\n\n8.求特征向量时，仅做行变换因为求特征向量时，本质是在解线性方程组，只能进行初等行变换。\n\n9.求逆矩阵时，对(A,E)仅做初等行变换因为以A−1𝐴−1左乘A得到E，以A−1𝐴−1左乘E得到A−1𝐴−1，以A−1𝐴−1左乘的过程就是做初等行变换的过程。\n\n所以怎么体现A和E做了完全一样的A−1𝐴−1所带来的初等行变换，就是将A，E横着拼在一起，此时做的初等行变换就是同步的了。\n\n 总结：\n除了① 求行列式的值（求特征值本质上就是求行列式的值）和 ② 单纯求秩，行列变换都可，其余情况通通只做行变换。\n\n二.要牢记先写那么多，后面有再补充：\n\n一些推导：\n\n对于AB ≠ BA的补充：\n\n\n1.矩阵的逆\n\n推导如下：\n\n初等矩阵的逆：\n2.矩阵的伴随\n\n三.某某子式1.余子式在n阶行列式中，去掉元素a所在的第i行、第j列元素，由剩下的元素按原来的位置与顺序组成的n-1阶行列式称为元素a的余子式，记作Mij𝑀𝑖𝑗。\n2.代数余子式余子式Mij𝑀𝑖𝑗乘(−1)i+j(−1)𝑖+𝑗后称为a的代数余子式，记作AAij𝐴𝑖𝑗\n\n3.k阶子式给定一个矩阵，任取k行，任取k 列，共k2𝑘2个数构成的行列式，出现在矩阵的秩中，定义如下：\n设A是mxn矩阵，则若存在k阶子式不为零，而任意k+1阶子式(如果有的话)全为零，则r(A)=k，且若A为nxn矩阵，则：\n\n 4.k阶主子式指在行列式中选k行k列，但要求行和列的下标相同。如：行为r1、r2、r3，列必须为c1、c2、c3；行为r2、r3、r5，列必须为c2、c3、c5。因此，k阶主子式不唯一。\n这在矩阵相似会用到，下面会讲。\n5.顺序主子式顺序主子式是在主子式上再加限定，顺序主子式是由 1~k 行和 1~k 列所确定的子式。\n\n例如：\n1阶时：取第1行，第1列\n2阶时：取第1、2行，第1、2列\n3阶时：取第1、2、3行，第1、2、3列\n4阶时：取第1、2、3、4行，第1、2、3、4列\n实际上，主子式的主对角线元素是原 n 阶行列式的主对角线元素的一部分，且顺序相同。\n所以k 阶主子式是不唯一的，而 k 阶顺序主子式是唯一的。\n\n用在判断二次型正定上，下面会讲。\n四.矩阵的秩 ① 0 &lt;= r(A) &lt;= min{m,n}\n② r(kA)=r(A)(k ≠ 0)\n③ r(AB) &lt;= min{r(A),r(B)}\n④ r(A+B) &lt;=r(A)+r(B)\n⑤ \n\nr(A)=n-1,r(A*)=1的证明：\n\n进而可得出一个重要结论：\n\n*\\*****************A************m****∗****n********************B************n****∗****s**************=****0************𝐴𝑚∗𝑛𝐵𝑛∗𝑠=0******，则r(A)+r(B)&lt;=n**\n\n所以，看到A*B就要想到两个结论：\n\n⑥ 设A是m*n矩阵，P,Q分别是m阶，n阶可逆矩阵，则\n\nr(A)=r(PA)=r(AQ)=r(PAQ)\n\n⑦ r(A)=r(AT)𝑟(𝐴𝑇)=r(AAT𝐴𝐴𝑇)=r(ATA𝐴𝑇𝐴)\n关于⑤的例题：\n\n为什么Ax=b有n-r+1个线性无关的解：\n\n 五.常用特征值与特征向量\n注意这样一道例题：\n\n\n\n\n关于特征值的一些提示：\n\n六.矩阵，向量组，方程组矩阵，向量组\n\n① 向量组是由有限个相同维数的行向量或者列向量组成，其中向量是由n个实数组成的有序数组,是一个n1的矩阵(n维列向量)或是一个1n的矩阵(n维行向量)。\n ② 矩阵是由m*n个数排列成m行n列的数表。\n一个向量组可以看作是一个矩阵的列（或行）向量集合。如果一个矩阵有n列，那么这n列就可以看作是一个由n个向量组成的向量组。反过来，一个矩阵也可以看作是由其列（或行）向量组成的向量组。\n\n1.怎么判断两个矩阵等价\n矩阵等价的前提：A与B是\\同型**矩阵，即A,B行数，列数相同\n矩阵等价的充要条件：\n① r(A)=r(B)\n② PAQ=B，P,Q可逆\n\n2.怎么判断两个向量组是等价向量组\n向量组等价的前提：A，B矩阵\\同维**\n若r( Ⅰ )=r(α1,α2,α3,α4𝛼1,𝛼2,𝛼3,𝛼4….) r(Ⅱ)=r(β1,β2,β3,β4𝛽1,𝛽2,𝛽3,𝛽4….)    \n向量组等价的充要条件：① r(Ⅰ)=r(Ⅱ)，且(Ⅰ)可由(Ⅱ)线性表出（单向表出即可）\n② r(Ⅱ)=r(Ⅰ)，且(Ⅱ)可由(Ⅰ)线性表出（单向表出即可）\n③ r(α1,α2,α3,α4𝛼1,𝛼2,𝛼3,𝛼4….) =r(β1,β2,β3,β4𝛽1,𝛽2,𝛽3,𝛽4….) =r(α1,α2,α3,α4𝛼1,𝛼2,𝛼3,𝛼4…,β1,β2,β3,β4𝛽1,𝛽2,𝛽3,𝛽4…)，即\nr(Ⅰ)=r(Ⅱ)=r(Ⅰ，Ⅱ)\n④ Ⅰ和Ⅱ能够相互线性表示。\n总结：① 两个矩阵A与B等价指的是A可以通过有限次初等变换变成B。两个不同型矩阵是不可能等价乡② 两个向量组等价只指的是它们能够互相线性表示，它们各自所含向量的个数可能是不一样的。\n\n例题：\n\n\nD.即使Ⅰ 和 Ⅱ 同为n维向量组，但是s与t的关系未知，也就是行数相等，列数未知，所以A，B两个矩阵可能不同型，不能等价。\nB.(Ⅰ)可由（Ⅱ）表示，缺少其他条件，如果① 加上(Ⅱ)可由(Ⅰ)线性表出 或者② r(Ⅰ)=r(Ⅱ)就对了\nC正确\nD r(A)=r(B)，只能推出两个向量组秩相同，缺少其他条件，如果加上① 加上(Ⅱ)可由(Ⅰ)线性表出 或者②加上(Ⅰ )可由(Ⅱ)线性表出或者③ r(Ⅰ)=r(Ⅱ)=r(Ⅰ，Ⅱ)，就对了。\n\n3.矩阵和向量等价的比较\n例题：\n\nA.(α1,α2,α3,0𝛼1,𝛼2,𝛼3,0)能与(α1,α2,α3𝛼1,𝛼2,𝛼3)相互线性表示，但是(α1,α2,α3,0𝛼1,𝛼2,𝛼3,0)不是Ax=0的基础解系\nB.基础解系一定是线性无关的，但是B选项3个向量是线性相关的（3个向量相加=0）\nC.像上面举的例子一样，α1α2𝛼1𝛼2，β1β2𝛽1𝛽2等秩，但是α1α2𝛼1𝛼2与β1β2𝛽1𝛽2不能相互线性表示。\nD.\n在(α1,α2,α3𝛼1,𝛼2,𝛼3)的右边乘可逆矩阵，不改变原来矩阵的秩，且(β1,β2,β3𝛽1,𝛽2,𝛽3)与(α1,α2,α3𝛼1,𝛼2,𝛼3)能相互线性表示\n所以，求Ax=0的另一个基础解析，需要满足与(\\******************α********1**********,**********α********2**********,**********α********3******************𝛼1,𝛼2,𝛼3*****)等价且等秩。*\n\n 4.同解方程组若两个方程组Am∗nx=0𝐴𝑚∗𝑛𝑥=0与Bs∗nx=0𝐵𝑠∗𝑛𝑥=0有完全相同的解，则称它们为同解方程组\n\n充要条件：\n① Ax=0的解满足Bx=0，且Bx=0的解满足Ax=0(互相把解代入求出结果即可)\n② r(A)=r(B)，且Ax=0的解满足Bx=0(或Bx=0的解满足Ax=0)\n③ r(A)=r(B)=r([AB][𝐴𝐵])(三秩相同)\n\n例1：\n\n例2：\n\n例3：\n\n 七.齐次线性方程组和非齐次线性方程组\n齐次线性方程组有解的条件：\n① r(A)=n时，方程组有唯一零解。\n② r(A)=r&lt;n时，方程组有非零解（无穷多解），且有n-r个线性无关解\n齐次方程组其实就是解和系数的正交，例如，给你一个条件：\nα1=2α2+α3𝛼1=2𝛼2+𝛼3——&gt;α1−2α2−α3+0α4=0𝛼1−2𝛼2−𝛼3+0𝛼4=0\n\n则(1 -2 -1 0)就是齐次方程组的基础解系\n非齐次线性无关组有解的条件：\n① 若r(4)≠r([A,b])，则方程组无解；② 若r(A)=r([A,b])=n，则方程组有唯一解；③ r(A)=r([A,b])=r&lt;n，则方程组有无穷多解。\n非齐次方程组的通解的求法：\n①求Ax=0的解\n② 求Ax=b的一个特解\n③ 非齐次方程组的通解=齐次方程组的解+一个非齐次的特解\n\n\n\n如果A行满秩，则r(A)=r(A|b)，那么方程组一定有解。\n如果A列满秩，则r(A)与r(A|b)的关系不确定：\n① r(A)&lt;r(A|b)，则无解\n② r(A)=r(A|b)&lt;n，有无穷多解\n③ r(A)=r(A|b)=n，有唯一解\n\n非齐次方程组解的性质：\n\n若η1η2η3𝜂1𝜂2𝜂3是非齐次线性方程组Ax=b的解，ξ𝜉是对应齐次方程组Ax=0的解，则：(1) η1−η2𝜂1−𝜂2是Ax=0的解；（2）kξ+η𝑘𝜉+𝜂是Ax=b的解\n\n扩展：\n\n\n解释：\n1.p个解的任意组合，都是齐次线性方程组的解\n2.非齐次的解线性组合也能得到齐次线性方程组的解，但是需要满足k1+k2+…+kp=0，例如，α1−α2𝛼1−𝛼2=0(1-1=0),α1−α2𝛼1−𝛼2就是齐次线性方程组的解。\n3.非齐次的解线性组合也能得到非齐次线性方程组的解，但是需要满足k1+k2+…+kp=1，例如，(α1+α2)/2(𝛼1+𝛼2)/2，就是非齐次线性方程组的一个解。\n4.齐次线性方程组的解与非齐次线性方程组的解相加，得到的是非齐次线性方程组的解。\n5.r(A)=r，A就有n-r个线性无关的解，而x1,x2,….xn−r𝑥𝑛−𝑟刚好是Ax=0的n-r个线性无关解，所以\nk1x1+k2x2+….+kn−rxn−r𝑘𝑛−𝑟𝑥𝑛−𝑟是Ax=0的解。\n\n例题：\n\n\nA.α1−α2𝛼1−𝛼2是组合系数是1-1=0，α1−α2𝛼1−𝛼2是Ax=0的解\nB.3α1−2α23𝛼1−2𝛼2是Ax=b的解，C,D同理。\n\n 八.对比记忆1.\n\n矩阵A的tr(A)：tra(A)=矩阵A的迹=对角线元素之和\n2.对于秩为1的n阶矩阵A或A=αβT𝛼𝛽𝑇(或βTα𝛽𝑇𝛼)（a,β都是n维非零列向量），其特征值为λ1λ2λ3….λn−1𝜆1𝜆2𝜆3….𝜆𝑛−1=0，λn=∑ni=1aii=βTα𝜆𝑛=∑𝑖=1𝑛𝑎𝑖𝑖=𝛽𝑇𝛼（或αTβ𝛼𝑇𝛽） \n\n3.\n\n例题1：\n\n例题2：\n\n九.相似与正交存在n阶可逆矩阵P，使得P−1AP=B𝑃−1𝐴𝑃=𝐵,则称A相似于B，记为A~B\n\n若A~B\n① |A|=|B|\n② r(A)=r(B)\n③ tr(A)=tr(B)\n④ λA=λB𝜆𝐴=𝜆𝐵（|λE−A|=|λE−B||𝜆𝐸−𝐴|=|𝜆𝐸−𝐵|）\n⑤ r(λE−A)=r(λE−B)𝑟(𝜆𝐸−𝐴)=𝑟(𝜆𝐸−𝐵)\n\\⑥ A，B各阶主子式之和分别相同**\n\n\n也就是说，A与B即使特征值相同，但也不一定相似。但是如果A，B都是实对称矩阵，那么相似，则一定特征值相同（实对称矩阵一定能相似对角化，特征值相同一定能相似于同一个对角矩阵，根据传递性A~B）。\n那么怎么判定矩阵相似呢？\n\n① 定义法\n存在n阶可逆矩阵P，使得P−1AP=B𝑃−1𝐴𝑃=𝐵\n② 传递法\nA~ΛΛ，ΛΛ~B，则A~B，其中ΛΛ为对角阵\n这就要说到矩阵的相似对角化\n\n矩阵可相似对角化的条件：\n\n充要条件：\n① n阶矩阵A可相似对角化↔有n个线性无关的特征向量。\n② n阶矩阵A可相似对角化↔A对应于每个k重特征值都有k个线性无关的特征向量\n必要条件：\n③ n阶矩阵A有n个不同特征值→A可相似对角化\n④ n阶矩阵为实对称矩阵→A可相似对角化\n\n对于矩阵相似对角化的步骤：\n\n① 求特征值\n② 求特征向量\n③ 正交化（如果需要的话），单位化η1η2η3….ηn𝜂1𝜂2𝜂3….𝜂𝑛\n④ 令Q=[η1η2η3….ηn𝜂1𝜂2𝜂3….𝜂𝑛],则Q为正交矩阵，且Q−1AQ=QTAQ=Λ𝑄−1𝐴𝑄=𝑄𝑇𝐴𝑄=Λ\n\n上面提到了实对称矩阵，实对称矩阵就是组成A的元素都是实数。对于实对称矩阵（AT=A𝐴𝑇=𝐴）要记住：\n\n\n对于正交，你需要记住：① αTβ=0𝛼𝑇𝛽=0，则，是正交向量\n② 若满足ATA=E𝐴𝑇𝐴=𝐸，则A是正交矩阵\nATA=E𝐴𝑇𝐴=𝐸↔A−1=AT𝐴−1=𝐴𝑇\n\n例题：\n\n不可对角化的矩阵怎么判断相似：\n 例题：\n\n\n如果A与B相似，那么：\n对于任意实数k和整数n，有(A+kE)n(𝐴+𝑘𝐸)𝑛与(B+kE)n(𝐵+𝑘𝐸)𝑛相似\n对于上面这道题，取k=-1，n=1，判断哪两个矩阵相似。\n\n矩阵相似还可得出：\n\n① A~B，Ak=Bk𝐴𝑘=𝐵𝑘，f(A)=f(B)\n② 若A~B，且A可逆，则A−1𝐴−1~B−1𝐵−1，f(A−1𝐴−1)=f(B−1𝐵−1)\n③ 若A~B，A∗𝐴∗~B∗𝐵∗\n④ 若A~B，AT𝐴𝑇~BT𝐵𝑇\n\n\n注： \n 十.合同设A，B为n阶矩阵，若存在可逆矩阵C，使得CTAC=B𝐶𝑇𝐴𝐶=𝐵，则称A与B合同，即A≅B𝐴≅𝐵。A与B合同，就是指同一个二次型在可逆线性变换下的两个不同状态的联系。\n\n\n\n注：由于我们已经规定，对称矩阵才是二次型矩阵，所以二次型矩阵都是对称矩阵，相应的和对称矩阵合同的矩阵也是对称矩阵。\n例题：\n\n\n\n\n 十一.二次型关于二次型化标准型或规范型的方法：配方法，正交变化有总结如下：\n\n所以我们可以进一步得到\n等价，合同和相似的关系：\n注：相似一定合同的前提条件是A，B都是实对称矩阵\n\n例题：\n\n\n关于配方法和正交变换分别给一个例题：配方法：\n\n正交变换：\n\n\n① 若λ1=λ2𝜆1=𝜆2，那么两个同一特征值对应的特征向量需要正交化，如果本来就正交可以不做这一步，所以在计算特征值的时候，可以将两个特征向量写为正交的，这样就免去了施密特正交化，直接进入单位化即可。\n② λ1≠λ2≠λ3𝜆1≠𝜆2≠𝜆3，那么不用进行施密特正交，直接单位化即可。\n\n常见题型：\n\n\n这里记录一个例题：\n\n\n若二次型中只有混合项，没有平方项，要怎么做？\n\n十二.二次型正定\n二次型正定的充要条件：n元二次型f=xTAx𝑓=𝑥𝑇𝐴𝑥正定↔对任意x≠0，有xTAx𝑥𝑇𝐴𝑥&gt;0（定义）\n① ↔f的正惯性指数p=n\n② ↔存在可逆矩阵D，使得A=DTD𝐴=𝐷𝑇𝐷\n③ ↔A≅E𝐴≅𝐸，A与E合同\n② ③推导：\n\n④↔A的特征值λ𝜆&gt;0\n⑤↔A的全部顺序主子式&gt;0\n二次型正定的必要条件：\n① aii𝑎𝑖𝑖&gt;0，对角线元素全部大于0\n② |A|&gt;0\n\n最好是使用充要条件① ④ ⑤判断二次型是否正定，如果非要用定义法，来看个例题：\n\n注意上题，不能直接将f判定为正定：\n因为将二次型化为标准型的过程一定要做可逆线性变换\n\n例题1：\n\n\n例题2：\n\n\n\n.png)\n","categories":["笔记"]},{"title":"typora图床设置","url":"/Arknight-notes/posts/39599.html","content":"兰空图床安装可以去看另一篇文章 搭建一个属于自己的图床\n一、安装和配置picgo\n首先到picgo的官方仓库下载安装包 Molunerfinn/PicGo: A simple &amp; beautiful tool for pictures uploading built by vue-cli-electron-builder (github.com) 安装过程一路next就ok，安装完成后的界面：\n\n\n安装兰空图床插件\n这里可以直接到picgo的插件设置里面搜索兰空安装插件，或者是直接到官方github下载并且手动安装，链接：hellodk34/picgo-plugin-lankong: A PicGo uploader for 兰空图床 lsky-pro，支持 V1 和 V2。 (github.com)教程在链接里面有。\n\n\n获取兰空图床token\n这里使用postman请求一个token，信息按照图片里的填就ok，记得把域名换成你自己图床的域名。\n\n\n设置picgo\n\n打开图床设置，选择lankong，照着写即可。\n\n\n检测效果\n图床选lankong，随便上传一张图片，看看能不能成功。\n\n\n\n\n二、对接typora打开typora，前往偏好设置，进行如下设置：\n\n并点击验证图片上传选项：\n\n能出现如图界面说明成功了。\n现在你往typora拖拽图片能自动上传到兰空图床图床\n","categories":["博客美化"]},{"title":"关于Jupyter汉化问题","url":"/Arknight-notes/posts/26795.html","content":"解决新版Jupyter notebook(v7.0.0及以上)汉化、默认保存路径等问题一. Jupyter notebook v7.0.0及以上汉化注意！在环境变量中添加如下用户变量仅适用于Jupyter v6及以下版本，不再适用于Jupyter v7Jupyter v7汉化方法如下\n1.打开命令行或者Anaconda Prompt，运行如下代码\npip install jupyterlab-language-pack-zh-CN\n2.运行Jupyter notebook，选择settings中的Language，替换中文\n二. 修改Jupyter notebook默认保存路径这里先介绍一种万能（不嫌麻烦）的方法1.打开命令行或者Anaconda Prompt，运行如下代码，其中D:\\JupyterWorkspace可以修改成你想要Jupyter保存的任意路径\njupyter notebook D:\\JupyterWorkspace\n这种方法的优点是很灵活缺点是每次启动都需要用命令行或者Anaconda Prompt\n下面介绍一种一本万利（fu za）的方法1.打开命令行或者Anaconda Prompt，运行如下代码\njupyter notebook --generate-config\n2.运行后会提示创建完jupyter_notebook_config.py文件，以及它所在的路径，我们直接复制路径找到这个.py文件3.用记事本打开它，CTRL+F查找notebook_dir，会搜索到这一行（适用旧版）3.用记事本打开它，CTRL+F查找root_dir，会搜索到这一行（适用新版）\n\n#c.NotebookApp.notebook_dir = ‘path’ # 旧版查找这一行#c.ServerApp.root_dir = ‘path’ # 更正，最新版应该查找这一行\n\n有些电脑搜到的可能是#c.ServerApp.notebook_dir = ‘path’，不过没什么影响4.将path替换成自己想要保存的路径，直接复制文件夹路径的话一定要将 \\ 改成 // ，并将这一行前面的#去掉**，保存文件5.右键Jupyter notebook选择属性，按下图设置即可a.png)\n"},{"title":"自定义VSCode背景图片","url":"/Arknight-notes/posts/31443.html","content":"关于如何自定义VSCode背景图片1.以管理员身份运行VS Code，安装background插件\n2.打开setting，在搜索框中输入background，选择扩展中的plugin background，选择在setting.json中编辑\n3.在用户设置中输入以下代码，修改完后保存，会提示重启VS Code，点击确定后即可完成修改//background 的相关配置    \"update.enableWindowsBackgroundUpdates\": true,    \"background.customImages\": [        \"file:///F:/Picture/Yukino/vs_background.png\"//图片地址（支持http    ],    \"background.style\": {        \"content\":\"''\",        \"pointer-events\":\"none\",        \"position\":\"absolute\",//图片位置        \"width\":\"100%\",        \"height\":\"100%\",        \"z-index\":\"99999\",        \"background.repeat\":\"no-repeat\",        \"background-size\":\"25%,25%\",//图片大小        \"opacity\":0.2 //透明度    },    \"background.useFront\": true,    \"background.useDefault\": false,//是否使用默认图片\n\n效果如下：\n.webp)\n","categories":["随记"]},{"title":"制作自己的校园网路由器","url":"/Arknight-notes/posts/25450.html","content":"\n怎么制作自己的校园网路由器（广州大学版）\n2024年更\n庆已使用web端进行校园网认证，路由器已经不再需要使用插件登录模拟登录\n但是同时一个账户只能有一台设备通过web登录，包括无感登录的设备，即最多只有两台设备可以直接接入校园网\n而使用锐捷认证的不记在内，也就是说可以同时有3台设备直接接入校园网，如果带多台设备上课的话体验有比较大的提升\n对于多人使用的情况，使用插件登录也不会占用某人的校园网账号，导致某人无法使用校园网wifi，有利于宿舍和谐\n我现在是使用方式是在宿舍的电脑用web登录，在教学区通过手机热点让其他设备接入，勉强能用（校园网本来就烂，经过手机转发雪上加霜，导致远程桌面延时明显提升）\n最后，这项技术对于普通的同学意义已经不是很大了，但也算是10年代技术大佬为后人留下的丰碑吧\n\n庆用的是锐捷的系统，你能买到的锐捷校园网路由器都大同小异，直接购买即可\n此文主要是写给愿意折腾的同学，将我本人组all in one服务器踩到的一些坑分享给大家，如果你想用树莓派软路由、x86虚拟机软路由抑或是自行刷机，甚至是想做路由器赚钱，都可以参考此文\n不多bb，我们所要做的就是在路由器上安装一个插件，用这个插件客户端进行认证，以此来接入校园网\n\nhyrathb/mentohust: mentohust加入v4支持 (github.com)\n和其算法开发的minieap\nupdateing/minieap: 可扩展的 802.1x 客户端，带有锐捷 v3 (v4) 算法插件支持 (github.com)\nminieap庆内亲测可用，以下以minieap为例\n一、装系统主流的开源路由器系统为openwrt，各种插件也是基于此开发的，先给你的机子安装上openwrt，方法各异自行百度，也可以直接买刷好op的\n二、搞到插件openwrt是基于linux的，不同的处理器都可以安装openwrt，但编译好的固件只能用于一种架构的处理器，如果网上找不到，只能自行编译插件（编译环境的处理器架构和最终成品的处理器架构没关系）\n我们需要编译minieap-gzhu、luci-proto-minieap，前者为认证插件本体，后者为其界面，openwrt的软件包是ipk文件\n\n个人编译的x86架构插件，x86软路由或者x86虚拟机可直接用\n链接：https://pan.baidu.com/s/16GR_BS3LvcJf1Y4KcQuuDA提取码：6tmt\n本文参考 动手编译适合自己路由器的 ipk | 雪山深处 (talaxy.site) 另一位学长的教程\n\n0. 准备好魔法环境dddd\n1. 安装linux环境推荐使用wsl或者其他虚拟机（虚拟机网络请使用nat模式）方法自行百度\n1.5 推荐使用ssh控制linux用scp拷文件（直接在虚拟机钟使用图形化界面也不是不行）安装ssh服务\nsudo apt-get install openssh-server\n宿主机推荐使用winscp客户端连接虚拟机ssh\n2. 安装编译环境依赖终端钟敲入以下代码\nsudo apt-get updatesudo apt-get install git-core build-essential libssl-dev libncurses5-dev unzipgawk subversion mercurialsudo apt-get install ccache\n3. 下载openwrt sdk（openwrt编译工具）并解压推荐解压目录到~目录，否则有报错的可能，注意，不可使用root账户编译\ncd ~wget https://downloads.openwrt.org/releases/21.02.0/targets/x86/64/openwrt-sdk-21.02.0-x86-64_gcc-8.4.0_musl.Linux-x86_64.tar.xzxz -dk openwrt-sdk-21.02.0-x86-64_gcc-8.4.0_musl.Linux-x86_64.tar.xztar xvf openwrt-sdk-21.02.0-x86-64_gcc-8.4.0_musl.Linux-x86_64.tar\n该命令目的在于把文件sdk文件解压到~/目录，如果上述命令执行失败，可以手动将压缩包解压后上传linux\n4. 开始编译a. 编译minieap-gzhucd ~/openwrt-sdk-21.02.0-x86-64_gcc-8.4.0_musl.Linux-x86_64\n\n进入sdk目录下\ngit clone https://github.com/ysc3839/openwrt-minieap.git -b gzhu package/minieap\n\n将插件源码克隆到本地\nmake menuconfig\n\n进入编译菜单，依次选择 “Network” “minieap” “save” “OK” 然后退出到命令行\nmake package/minieap/compile V=s\n\n开始编译\nipk 文件就在 bin/packages/(处理器架构)/base/\nb. 编译luci-proto-minieapcd ~/openwrt-sdk-21.02.0-x86-64_gcc-8.4.0_musl.Linux-x86_64\n进入sdk目录下\n./scripts/feeds update luci./scripts/feeds install-a\n安装 luci feed\ngit clone https://github.com/ysc3839/luci-proto-minieap.git package/luci-proto-minieap\n将插件源码克隆到本地\nmake menuconfig\n进入编译菜单，依次选择依次选择 “LuCI” “Protocols” “luci-proto-minieap” “save” “OK” 然后退出\nmake package/luci-proto-minieap/compile V=s\n开始编译\nipk 文件就在 bin/packages/(处理器架构)/base/\n三、 安装插件将刚刚得到的ipk包传入openwrt系统中，如果你的openwrt安装了文件传输插件，那可以直接用，如果没有，也可以用ssh传上去，以下演示假设传到了根目录上\n\n菜单栏选择“系统”&gt;&gt; “软件包”（外观不同，但是选项应该是一样的）\n\n直接点击安装即可，如果没有文件管理插件或者是你的文件管理插件没有这个功能\n\n\n点击确认即可安装\n四、 使用插件\n点击“网络”&gt;&gt; “接口”\n\n选择“新接口”\n\n协议选择“MiniEAP client”，名字随便，接口选择你的wan口，每个接口对应一个物理接口或者虚拟接口，需要根据自己的实际情况选择，该接口要连接到宿舍校园网网口\n\n账户密码就是你校园网的，Packet plugins选我这个\n\n然后将DHCP type改成我这个\n不出意外的话就可以愉快使用了\n转自：怎么制作自己的校园网路由器（广州大学版） - carry blogavb6x)\n","categories":["笔记"],"tags":["校园网"]},{"title":"创建一个针对Ethereum网络的协议解包器","url":"/Arknight-notes/posts/57783.html","content":"Enabling security analysis and education of the Ethereum platform本篇论文旨在探讨如何通过创建一个Wireshark网络包解码器来分析和教育以太坊平台的安全性。使用了定制化的私人以太坊Docker网络来促进Go Ethereum执行客户端之间的通信，并使Wireshark解码器能够捕获实时网络数据。最后，作者还使用了解码器来比较DiscoveryV4和DiscoveryV5的区别，并跟踪RLPx协议中的交易在网络上的传输过程。本文的研究方法包括创建Wireshark解码器、使用定制化的私人以太坊Docker网络以及对比不同版本的DiscoveryV4和DiscoveryV5协议。最终结果表明，该解码器可以有效地帮助人们理解和分析以太坊平台的安全性和网络流量。 \n方法描述该论文提出了一种新的网络包解码器（dissector），用于分析以太坊DEVP2P协议套件中的数据包。该解码器能够解析UDP基的DiscoveryV4、DiscoveryV5以及RLPx协议，并支持其子协议ETH和SNAP的消息能力。这个解码器使用Wireshark作为平台来实现，通过拦截网络流量并提供实时视图，可以识别协议、解码数据、跟踪流和对话、计算统计信息等。\n方法改进传统的网络包解码器通常用于调试、协议分析、安全性和可扩展性分析以及教育目的。目前有两种已知的以太坊DEVP2P协议解码器：一个是基于Wireshark插件引擎使用LUA编程语言构建的；另一个是使用C编程语言编译Wireshark源代码而构建的。然而，这两种解码器都存在一些限制，只支持加密发现V4，而不支持在EIP-868中于2019年10月发布的新型数据包类型。此外，它们也不支持DiscoveryV5和RLPx及其任何子协议，如ETH和SNAP。\n这两个项目都已经被放弃，原因是复杂度高，需要社区完成这项工作。由于RLPx的数据包解码过程比较复杂，因为TCP连接是使用ECIES（椭圆曲线集成加密方案）加密的，因此需要私钥才能解密通信。私钥因素包括我们的私钥、节点的公钥以及一个随机生成的临时密钥。\n解决的问题该解码器解决了现有的解码器无法处理新型数据包类型的问题，同时也填补了DiscoveryV5和RLPx及其子协议的安全性和性能分析方面的空白。此外，该解码器还可以帮助证明其价值，为社区和教育者提供更深入的分析，包括安全性和性能差异的比较，以及交易和块传播等方面的研究。\n 论文实验本文介绍了作者使用Wireshark创建一个针对Ethereum网络的协议解包器，并对不同协议进行了分析和展示。在实验中，作者构建了一个私有开发网络，并通过MetaMask连接了该网络上的账户，演示了如何在两个节点之间进行交易。以下是每个实验的详细介绍：\n\n实验目的：创建Wireshark解包器并分析不同协议\n在这个实验中，作者的主要目的是创建一个Wireshark解包器来解析Ethereum网络中的不同协议。这包括DiscoveryV4、DiscoveryV5和RLPx协议以及它们的子协议ETH和SNAP。作者还创建了一个名为PYDEVP2P的Python库作为后台支持，提供大部分解码、解密和数据布局工具，以帮助Wireshark显示数据包信息。\n\n实验步骤：构建私有开发网络并进行交易\n在这个实验中，作者构建了一个私有开发网络，其中包括一个Bootnode和三个节点。每个节点都运行在一个Docker容器中，并且使用GETH客户端。作者使用MetaMask连接到该网络，并从不同的账户向另一个账户发送了200个ETH。整个过程被记录下来并在后续章节中进行分析。\n\n实验结果：性能和安全性的分析\n在这个实验中，作者分析了DiscoveryV4和DiscoveryV5协议的性能和安全性，并比较了它们与RLPx协议的不同之处。此外，作者还对实际交易进行了详细的分析，以了解在网络层面上发生了什么。\n\n\n总的来说，本文旨在展示如何使用Wireshark创建一个用于Ethereum网络的协议解包器，并展示了如何在私有开发网络上进行交易。作者还对不同协议的性能和安全性进行了分析，以便更好地理解Ethereum网络的工作原理。\n\n\n总结该论文主要介绍了以太坊网络及其相关协议，并通过两个现有分解器的比较，探讨了如何使用分解器来解析网络数据包以及理解底层协议。该论文的优点包括：\n\n全面深入地介绍了以太坊网络及协议，包括公共和私人网络、节点类型、网络协议等。\n提供了两种现有的分解器的比较，帮助读者了解它们之间的差异和优缺点。\n论文作者在介绍过程中提供了大量的代码示例和详细的解释，使读者更容易理解和应用所学知识。\n\n方法创新点该论文的方法创新点在于，通过对已有分解器的比较，提出了一些改进和完善的想法，例如可以将ENRRequest和ENRResponse添加到C dissector中，以便更好地支持新版本的DiscoveryV4协议。此外，该论文还提出了一个基于用户界面的演示应用程序，可以帮助用户更直观地观察和理解以太坊网络中的数据传输过程。\n未来展望随着以太坊网络的发展和技术的进步，未来的展望包括：\n\n进一步完善已有的分解器，使其能够更好地支持新的协议和功能。\n开发更加高效和智能的分解器，能够自动识别和解析更多的数据包类型和协议。\n利用机器学习和人工智能技术，实现对以太坊网络数据的自动化分析和预测，为用户提供更好的服务和支持。\n\n\n附1：实现方式项目概述该项目通过构建一个自定义的 Docker 网络环境来模拟以太坊节点之间的通信，并使用 Wireshark 和自定义的 Lua 解析器插件来捕获和分析这些通信。具体来说，它包括以下组件：\n\nGo-Ethereum (Geth) 定制源代码：用于暴露私有会话密钥。\nDocker 环境：包含多个 Geth 节点和一个路由器容器，用于模拟小型私有以太坊网络。\nLua 解析器插件：用于在 Wireshark 中解剖 DEVP2P 协议的数据包。\nPYDEVP2P 库：用于 Python 和 Lua 之间的交互。\n\n操作与实现步骤1. 环境设置确保安装了必要的软件和库：\nsudo apt-get update &amp;&amp; sudo apt-get upgradesudo apt-get install lua5.2 liblua5.2-dev wireshark python3.10\n2. 设置 Lunatic-Python 桥接Lunatic-Python 是一个双向桥接库，允许 Lua 和 Python 之间的交互。\n# 克隆 Lunatic-Python 仓库git clone https://github.com/jmkemp20/lunatic-python.gitcd lunatic-python# 确保 Lua 5.3 已安装lua5.3# 查找 Python 版本ldconfig -p | grep python# 准备构建cmake -B./build -H. -DPYTHON_INCLUDE_DIR=/usr/include/python3.10 \\  -DPYTHON_LIBRARY=/usr/lib/x86_64-linux-gnu/libpython3.10.so# 构建cmake --build ./build# 复制生成的库文件到 Lua 目录sudo chmod +x build/bin/python.sosudo cp build/bin/python.so /usr/local/lib/lua/5.2/\n3. 克隆并安装 LUA Dissector 和 PYDEVP2P# 克隆 LUA Dissector 和 PYDEVP2Pgit clone https://github.com/jmkemp20/lua-devp2p-wireshark-dissector.gitgit clone https://github.com/jmkemp20/pydevp2p.git# 安装 PYDEVP2P PIP 包cd pydevp2ppip install -e .sudo pip install -e .# 创建 Wireshark 插件目录（如果不存在）mkdir -p ~/.local/lib/wireshark/plugins# 符号链接或复制 .lua 解析器文件（也可以直接复制到该目录sudo ln -s &lt;location_of_cloned_dissector&gt;/rlpx.lua ~/.local/lib/wireshark/plugins/rlpx.luasudo ln -s &lt;location_of_cloned_dissector&gt;/discovery.lua ~/.local/lib/wireshark/plugins/discovery.lua# 对于 root 用户（如果使用 sudo 运行 Wireshark）（也可以直接复制到该目录sudo mkdir -p /usr/local/lib/wireshark/pluginssudo ln -s &lt;location_of_cloned_dissector克隆的地址&gt;/rlpx.lua /usr/local/lib/wireshark/plugins/rlpx.luasudo ln -s &lt;location_of_cloned_dissector克隆的地址&gt;/discovery.lua /usr/local/lib/wireshark/plugins/discovery.lua\n\n使用本地 .pcapng 文件测试：\nwireshark-r final.pcapng\n这将运行 Wireshark 并加载捕获的 .pcapng 文件。您可以查看解剖后的 DEVP2P 数据包。\n\n实时捕获网络流量：\n\n启动 Wireshark 并选择适当的接口捕获数据包。\n观察和分析捕获的数据包，特别是 RLPx 握手和 DiscoveryV5 数据包。\n\n\n\n\n4. 构建 Docker 环境# 克隆 GETH-Docker 仓库git clone https://github.com/jmkemp20/geth-docker.gitcd geth-docker# 构建自定义 Docker 镜像./build-dockers.sh# 启动路由器容器docker-compose up -d bridge-router# 打开 Wireshark 并附加到 10.1.0.1 或任何 10.1.X.X 网络sudo wireshark# 启动每个 GETH 节点/客户端容器docker-compose up -d geth-ubuntu-bootnodedocker-compose up -d geth-client-1docker-compose up -d geth-client-2docker-compose up -d geth-client-3\n5.安装编译和运行自定义的 Go Ethereum 客户端：1. 克隆自定义的 Go Ethereum 源代码首先，你需要克隆自定义的 Go Ethereum 源代码仓库。\ngit clone https://github.com/jmkemp20/go-ethereum.git\n2. 安装 Geth 或所有 Go Ethereum 工具进入克隆的 go-ethereum 目录，并编译 geth 或所有工具。\n安装 Go 1.20确保你已经安装了 Go 1.20 或更高版本。如果没有，请按照以下步骤安装：\n# 下载 Go 1.20wget https://mirrors.aliyun.com/golang/go1.20.6.linux-amd64.tar.gz# 解压并安装sudo tar -C /usr/local -xzf go1.20.6.linux-amd64.tar.gz# 设置环境变量nano ~/.bashrc# 或者nano ~/.zshrc# 添加以下内容export GOROOT=/usr/local/goexport GOPATH=$HOME/goexport PATH=$GOPATH/bin:$GOROOT/bin:$PATH# 使配置生效source ~/.bashrc# 或者source ~/.zshrc# 验证 Go 版本go version\n编译 geth 或所有工具进入 go-ethereum 目录并编译 geth 或所有工具。\ncd go-ethereum# 清理 Go 模块缓存go clean -modcache# 更新 Go 模块go mod tidy# 编译 gethmake geth# 如果你想编译所有工具make all\n3. 运行 Geth编译完成后，你可以运行 geth。确保 geth 可执行文件在你的 PATH 中，或者直接在 go-ethereum/build/bin 目录下运行它。\n# 如果 geth 在 PATH 中geth# 如果 geth 不在 PATH 中./build/bin/geth\n成功安装并运行自定义的 Go Ethereum 客户端\n项目结构\nDockerfile：用于构建 Docker 镜像的配置文件。\ndocker-compose.yml：用于启动和管理 Docker 容器。\nlua-devp2p-wireshark-dissector：Lua 解析器插件，用于在 Wireshark 中解剖 DEVP2P 数据包。\npydevp2p：Python 库，用于处理以太坊 DEVP2P 协议中的 ECIES 和其他加密操作。\nlunatic-python：Lua 和 Python 之间的桥接库。\n\n总结通过上述步骤，设置并运行一个自定义的 Docker 环境来模拟以太坊节点之间的通信，并使用 Wireshark 和自定义的 Lua 解析器插件来捕获和分析这些通信。有助于进行安全分析和教育，深入理解以太坊网络的工作原理。\n附2：原文翻译（结论篇）6.1 引言和回顾本论文提出了一种为以太坊的 DEVP2P 点对点协议套件创建 Wireshark 剖析器的新方法，包括带有 ETH 和 SNAP 子协议的 DiscoveryV4、DiscoveryV5 和 RLPx。正如我们所讨论的，以太坊网络促进了以太坊网络节点之间的相互通信，为去中心化的应用程序和账户提供了便利。因此，为了满足创建支持 RLP 解码和 ECIES 解密的 Wireshark 剖析器插件的要求，涵盖了许多贡献。首先，讨论了利用自定义的 Go Ethereum 源创建一个私有的 Ethereum docker 网络。接下来，介绍了 LUA Wireshark 插件的实际实现;首先是支持 DEVP2P 发现协议的 “discovery.lua” 插件，然后是 “rlpx.lua”，它允许剖析 RLPx，包括 ETH 和 SNAP 子协议。然后，我们深入研究了 PYDEVP2P，这是一个基于 python 的最小第三方依赖库，为 RLP 解码、ECIES 解密和解剖辅助函数提供了工具。最后，利用剖析器和PYDEVP2P分析了椭圆曲线数字签名算法 （ECDSA） 椭圆曲线 Diffie-Hellman 背后的技术细节。\nWireshark 是一种广泛使用的网络分析工具，允许用户检查和解码网络数据包。但是，Wireshark 本身不支持以太坊的 DEVP2P 协议，这限制了研究人员和开发人员监控和理解以太坊节点行为的能力。最重要的是，Wireshark 支持使用解剖插件，这些插件是 Wireshark 解剖功能的插件。正如我们所讨论的，当前由 BCSEC Org 和 ConsenSys 提供的两个剖析器插件并不完全支持 DiscoveryV4 的最新消息结构，并且对 DiscoveryV5 和 RLPx 的支持为零。为了解决这一差距，本论文在 LUA 中开发了一个自定义 Wireshark 剖析器插件，该插件可以以用户友好的格式解析和显示 DEVP2P 数据包。该插件利用 PYDEVP2P，这是一个基于 python 的库，用于协助解码 RLP（递归长度前缀）和解密 DEVP2P 协议使用的 ECIES（椭圆曲线集成加密方案）。\n此外，本论文还创建了一个具有自定义 Go Ethereum 映像的私有 docker 网络，该网络可生成真实的 DEVP2P 流量，用于开发、测试和分析目的。使用这个剖析器插件和环境，本论文演示了 Wireshark 剖析器如何分析 DEVP2P 数据包流的各个方面，例如跟踪交易在整个网络中的传播、分析 DiscoveryV4 椭圆曲线数字签名算法 （ECDSA） 和 DiscoveryV5 对椭圆曲线 Diffie-Hellman （ECDH） 的使用。本论文为研究以太坊的点对点通信层和增强去中心化应用程序的透明度和安全性提供了实用工具，为区块链研究领域、以太坊社区成员和教育工作者做出了贡献。\n6.2 解剖和分析结果本论文介绍了 Wireshark 剖析器插件的设计和实现，用于剖析 DEVP2P 的 DiscoveryV4、DiscoveryV5 和 RLPx 协议。剖析器插件可以解码和显示以太坊节点之间交换的各种消息，这些消息要么是实时网络，要么是事后捕获数据包。此外，剖析器插件还支持使用从握手过程中派生的会话密钥来解码 DiscoveryV5 和 RLPx 消息。\n创建剖析器的过程和剖析器的众多功能在第 4 章中展示。具体来说，DEVP2P 剖析器支持在 DiscoveryV4 中找到的所有消息，如第 4.3.1 章所述，包括 Ping、Pong、FindNode、Neighbors、ENRRequest 和 ENRResponse。由于新的“enr-seq”字段，以前的剖析器（包括 BSECORG 的 LUA 剖析器插件和 ConsenSys 的 C 剖析器）无法完全剖析 Ping 和 Pong 消息的较新消息架构。这些以前的剖析器也不支持 EIP-868 中描述的最新 ENRRequest 和 ENRResponse 数据包，这些数据包已于 2019 年 10 月添加到协议中。\n接下来，新的剖析器支持第 4.3.2 章中讨论的 DiscoveryV5 的最新实现，包括 Ping、Pong、FindNode、Nodes、TalkReq 和 TalkResp。以前的剖析器不支持此功能，因为协议的性质会混淆数据包标头信息和 ECDH 握手以交换会话密钥以进行加密通信。但是，这种新的 DEVP2P 剖析器提供了维护在网络上的已知节点之间创建的会话的所有功能，从而无缝解密和破译捕获的网络数据。\nDEVP2P 剖析器插件可以分析和破译 RLPx 促进的以太坊节点之间经过身份验证和加密的通信。这包括使用 AuthInit 和 AuthAck RLPx 消息在节点之间创建会话密钥的握手过程，然后是内置的 RLPx 功能“P2P”Hello 消息，如第 4.4 章所示。剖析器支持其他 RLPx P2P 消息、Ping、Pong 和 Disconnect。由于 RLPx 用作多种功能的 TCP 传输，因此剖析器可以解码、解密和剖析 RLPx 下的两个主要子协议或功能 ETH 和 SNAP。这些协议支持区块传播、链同步和交易，然后是状态管理和 SNAP 同步。剖析器支持 2 条 RLPx 握手消息、4 条 RLPx P2P 消息、13 条 ETH 功能消息和 6 条 SNAP 功能消息。\n关于区块链状态和交易的 Connected Peer 节点。剖析器还可以显示消息格式的详细信息，例如 RLP 编码和解码、数据包标头和尾部以及消息类型和内容。该工具允许轻松访问 DEVP2P 的内部工作原理，并为研究人员、一般区块链社区和类似领域的教育工作者提供帮助。\n6.3 限制与未来工作剖析器是对以太坊网络分析的新颖贡献，因为它是第一个在统一且用户友好的界面中剖析所有三种 DEVP2P 协议的工具。剖析器可以帮助研究人员和开发人员了解 Ethereum 网络的行为和性能，并识别和缓解潜在的安全威胁。剖析器还可以通过使椭圆曲线密码学在实际应用中更易于访问来帮助教育工作者，同时帮助开发和测试以太坊网络的新协议或功能，同时提供可靠的\n为未来改进和扩展对现有协议的支持奠定了基础。\n但是，剖析器也有一些局限性和缺点，必须在未来的工作中解决：\n剖析器需要自定义 Go Ethereum 源代码，其中包括每个节点在 RLPx 握手期间生成的随机私钥，用于会话密钥共享和后续数据包的加密。剖析器不支持使用官方 GETH 或 Ethereum 客户端进行 RLPx 剖读。\n剖析需要 Python 配合 PYDEVP2P 使用， 在幕后处理剖析、解码和解密的主要逻辑。这增加了剖析器设置和执行的复杂性和开销，需要安装 Python PIP 包的 PYDEVP2P 以及 LUA 和 Lunatic-Python 桥。\n剖析器存在不完整的消息错误，当某些消息大于特定大小时，会导致它们被截断或跳过。此错误会影响捕获握手数据包或格式错误的数据包时剖分结果的准确性和完整性。\n剖析器不会在 Wireshark 显示屏上以清晰的人类可读格式显示 DiscoveryV5 消息的未屏蔽“authdata”，其中包含节点 ID、签名和临时公钥等基本信息。\n随着以太坊及其底层网络的复杂性不断增长并随着时间的推移而发展，未来工作可能会有一些可能的改进或扩展：\n在权益证明环境中使用剖析器，查看权益证明共识算法网络中的执行客户端中使用了哪些 DEVP2P 协议和消息。看看哪些 DEVP2P RLPx 功能消息被新协议改编或未使用，以进行权益证明，这将是一件有趣的事情。\n剖析 LIBP2P 并将其与 DEVP2P 进行比较。LIBP2P 是以太坊共识客户端使用的另一个点对点网络堆栈。在功能、性能和安全性方面对 LIBP2P 和 DEVP2P 进行比较和对比会很有用。\n添加 LES、PIP、WIP 和其他 RLPx 子协议的剖析。剖析器目前仅支持 ETH 和 SNAP 子协议。这些其他子协议用于不同的目的，例如轻以太坊子协议 （LES） 支持、奇偶校验轻协议 （PIP） 支持和以太坊见证协议 （WIT）。剖析器也应该扩展以支持这些子协议。\n调查网络发现泄漏，这是 DiscoveryV4 中发现的问题。网络发现泄漏是一个问题，即为特定链/网络 ID 设置的 Ethereum 节点会错误地通信并发现其他 Ethereum 网络上的节点。\n实施 DiscoveryV4 和 DiscoveryV5 拒绝服务 （DoS） 攻击。DiscoveryV4 协议容易受到拒绝服务 （DoS） 攻击，这些攻击可能会用虚假的 ping 或 pong 消息淹没节点。这些消息会消耗节点的带宽和处理资源，并可能阻止它们响应合法消息。剖析器可以通过捕获网络上的此类恶意数据包来帮助检测和监控此类攻击。\n实施 RLPx 已知明文攻击。RLPx 协议使用 AES-CTR 加密，每条消息使用固定的 IV（初始化向量）。这使得它容易受到已知的明文攻击，如果攻击者知道一些明文-密文对，该攻击可以恢复加密密钥。剖析器可以通过随机化每条消息的 IV 或使用不同的加密方案来帮助避免这种攻击。\n执行 Wireshark 统计分析。Wireshark 提供各种统计网络流量分析工具，例如图形、图表、表格、过滤器等。剖析器可以利用这些工具对 DEVP2P 协议进行更高级和全面的分析，例如吞吐量、延迟、数据包丢失、消息分发、节点行为等。\n6.4 最后的思考解剖器的设计、实现及其结果的分析证明了它对社区、教育工作者、开发者和研究者的有用性。LUA Wireshark 解析插件和 PYDEVP2P 库为教育工作者、研究人员及开发者提供了理解以太坊网络内部运作所需的所有工具。该解析器还允许可视化流行的密码学概念，利用椭圆曲线密码学（ECC），同时帮助理解递归长度前缀（RLP）编码的工作方式。在创建此解析器的过程中克服了许多障碍，无论是更新文档还是实现以太坊特有的ECIES技术细节。本文档中穿插的大多数技术细节直接来自以太坊DEVP2P GitHub规范页面以及最常用的执行客户端源代码Go Ethereum。因此，这些方法对于更广泛的以太坊社区成员、分析师尤其是教育者来说并不容易获得。\n本文讨论的贡献使得进入以太坊节点网络通信变得更加容易，并且克服了由大型区块链技术解决方案公司ConsenSys指出的一些障碍。这包括可以使用单个命令启动一个完整的私有以太坊网络的Go Ethereum Docker网络，随后是只需几个简单步骤即可安装的LUA Wireshark插件和PYDEVP2P库。正如所讨论的那样，PYDEVP2P库还提供了易于理解的椭圆曲线加密实现，让教育工作者和学生能够在一个实际环境中亲身体验并理解这些底层概念。\n本文档的主要目标是提供所有必要的工具来支持未来的改进，为教育者提供一种轻松访问的工具来展示ECIES密码技术，同时也为了安全分析师能够进一步增强点对点区块链网络的健壮性。\n。\n","categories":["笔记"]},{"title":"（旧）创建一个网络包解码器分析DEVP2P协议","url":"/Arknight-notes/posts/30370.html","content":"\n本项目最新版本\n link 本项目最新版本, https://zhongye1.github.io/posts/1104.html, https://pic1.zhimg.com/80/v2-593dd0a3b84d023b3827b97e81e0242a_720w.webp \n附注：此页面使用wsl构建不可行\n\n\n\n安装配置WSL2（ubuntu20.04）Windows Subsystem for Linux（简称WSL），Windows下的Linux子系统，是一个在Windows 10上能够运行原生Linux二进制可执行文件（ELF格式）的兼容层。它是由微软与Canonical公司合作开发，其目标是使纯正的Ubuntu、Debian等映像能下载和解压到用户的本地计算机，并且映像内的工具和实用工具能在此子系统上原生运行。\n1.安装Windows TerminalWindow Terminal 安装以及使用(2021最新) - 知乎\n一个目前在用的windows命令行工具\n可以直接从 Microsoft Store 下载安装，而且Github仓库上发布有内部版本。 \n2.安装wslWindows 10 安装配置WSL2（ubuntu20.04）教程 超详细_win10安装wsl2-CSDN博客\n对于windows10版本可以直接命令符安装\nwsl --install\n设置 WSL 开发环境见微软官方文档设置 WSL 开发环境 | Microsoft Learn完成后打开Windows Terminal找到：\n\n\n3.Docker 安装\nDocker -&gt; 虚拟化容器技术。Docker基于镜像，可以秒级启动各种容器。每一种容器都是一个完整的运行环境，容器之间互相隔离。\n\n\n官网地址\n公共仓库\n安装文档\n\n下载Docker Desktop安装程序：\n\n访问Docker官网下载页面：https://www.docker.com/get-started/\n选择对应版本点击下载安装程序。\n没猜错的话应该被墙了可以找我要安装包\n\n\n\n\n\n运行安装程序：\n\n双击下载的Docker Desktop安装文件。\n在安装向导中，你可以根据个人喜好勾选是否希望建立Docker Desktop的快捷方式或者是否希望Docker Desktop随Windows启动等选项。\n\n\n\n\n完成安装并重启：\n\n完成安装向导后，重启计算机确保设置正确应用。\n\n\n启动Docker Desktop：\n\n在重启后，运行Docker Desktop。当它启动时，Docker图标会出现在系统托盘中。\n系统托盘中的Docker图标表明Docker正在运行，并可能需要一点时间来启动服务。\n电脑要开VM虚拟化\nWindows 10 |VMware开启虚拟化的最全面说明_vmware虚拟化引擎-CSDN博客\n开VM时BIOS不懂的不要瞎搞\n\n\n配置Docker设置：\n\n你可以右键点击系统托盘中的Docker图标，选择“Settings”来调整Docker的配置，如更改镜像存储位置、设置代理服务器等。\n\n\n\n国内网络环境拉不下镜像的话就配置别的源\n\n我用的这几个镜像站配置环境要慎重\n我的配置文件\n{  \"builder\": {    \"gc\": {      \"defaultKeepStorage\": \"20GB\",      \"enabled\": true    }  },  \"experimental\": false,  \"registry-mirrors\": [    \"https://docker.m.daocloud.io\",    \"https://huecker.io\",    \"https://dockerhub.timeweb.cloud\",    \"https://noohub.ru\"  ]}\n\n通过命令行界面测试Docker安装：\n\n打开命令提示符、Powershell或任何你喜欢的终端。\n输入命令 docker --version 来检查Docker版本，确保它已正确安装。\n运行 docker run hello-world 来下载一个测试镜像，并在容器中运行，这可以验证Docker Daemon是否已正确启动并且可以创建容器。\n\n\n\n环境安装准备材料\n\nLua-devp2p-wireshark-dissector: GitHub链接\nPYDEVP2P: GitHub链接\nLunatic-Python: GitHub链接\nGo-Ethereum: GitHub链接\nGETH-Docker: GitHub链接\n\n1 安装Wireshark和特定版本的LUAlinux的python版本要为3.10\nsudo apt-get update &amp;&amp; sudo apt-get upgradesudo apt-get install lua5.2 liblua5.2-dev wireshark python3.10\n2 更改权限并复制Lunatic Python LUA ⇔ Python桥接二进制文件python.so为文章最开始编译得来的\nsudo chmod +x python.socp python.so /usr/local/lib/lua/5.2/\n关于python.so是从哪来的：python在linux编译后的文件为.so这个由编译Lunatic-Python: GitHub链接得来不会编译的可以找我要我编译好的（\n如何编译见项目文档：\nLunatic Python 是一个双向桥接项目，它允许Python和Lua两种语言互相通信。这意味着你可以在Lua中调用Python代码，也可以在Python中调用Lua代码，甚至可以嵌套调用（如Lua中的Python再调用Lua）。这个项目的主要用途之一是为 LUA-devp2p-dissector 提供必要的工具，使其能够调用 pydevp2p 中的函数。\n项目起源\n这个项目是一个fork版本，原始项目来自 labix-lunatic-python。\n另一个相关的版本由 bastibe 维护。\n\n开始使用克隆仓库git clone https://github.com/jmkemp20/lunatic-python.git &amp;&amp; cd lunatic-python\n确保安装了LUA 5.3通过运行 lua5.3 来检查是否已经安装了正确的LUA版本\n查找你的Python版本ldconfig -p | grep python\n这条命令会列出系统中所有可用的Python库路径。你需要找到与你的Python版本相对应的路径。\n准备编译（构建）根据上一步输出的Python版本信息来配置CMake：\ncmake -B./build -H. -DPYTHON_INCLUDE_DIR=/usr/include/python3.10 \\  -DPYTHON_LIBRARY=/usr/lib/x86_64-linux-gnu/libpython3.10.so\n使用的是Python 3.10\n编译（构建）cmake --build ./build\n使用定位二进制文件构建完成后，你会在 build/bin/ 目录下找到两个重要的文件：\n\npython.so 用于在Lua中调用Python\nlua.so 用于在Python中调用Lua\n找不到直接搜\n\n\n然后把编译好的文件移到论文提到的目录下（见上文\n3 克隆LUA解码器和PYDEVP2P项目git clone https://github.com/jmkemp20/lua-devp2p-wireshark-dissector.gitgit clone https://github.com/jmkemp20/pydevp2p.git\n4 从源代码安装PYDEVP2P PIP包cd pydevp2ppip install -e .sudo pip install -e .\n5 创建Wireshark插件目录（本地用户和root）mkdir -p ~/.local/lib/wireshark/pluginssudo mkdir -p /usr/local/lib/wireshark/plugins\nStep 6) 符号链接或复制.lua解码器文件到Wireshark插件目录ln -s &lt;location of cloned dissector&gt;/rlpx.lua ~/.local/lib/wireshark/plugins/rlpx.lualn -s &lt;location of cloned dissector&gt;/discovery.lua ~/.local/lib/wireshark/plugins/discovery.luasudo ln -s &lt;location of cloned dissector&gt;/rlpx.lua /usr/local/lib/wireshark/plugins/rlpx.luasudo ln -s &lt;location of cloned dissector&gt;/discovery.lua /usr/local/lib/wireshark/plugins/discovery.lua\n可以直接复制这些.lua文件而不是创建符号链接。终端里找不到文件用文件资源管理器搜\n\n好的，你提供的步骤是安装自定义的 Go Ethereum 客户端。以下是详细的步骤来从头开始安装和运行自定义的 Go Ethereum 客户端：\nLive GETH Docker StartupStep 1) 确保Docker和Docker Compose已安装并正在运行检查Docker版本：\ndocker --version\n\n检查Docker Compose版本：\ndocker-compose --version\n\nStep 2) 克隆GETH-Docker存储库git clone https://github.com/jmkemp20/geth-docker.gitcd geth-docker\nStep 3) 构建自定义docker镜像./build-dockers.sh\nStep 4) 启动路由器容器docker-compose up -d bridge-router\nStep 5) 打开Wireshark并连接到网络接口sudo wireshark\nStep 6) 依次启动每个GETH节点/客户端容器docker-compose up -d geth-ubuntu-bootnodedocker-compose up -d geth-client-1docker-compose up -d geth-client-2docker-compose up -d geth-client-3\n\n\n接下来新开一个命令行窗口来做论文原文操作：\n7.5 Installing the Custom GO Ethereum Client from ScratchStep 1) 克隆自定义GO Ethereum源代码git clone https://github.com/jmkemp20/go-ethereum.git\nStep 2) 编译GETH或其他所有GO Ethereum工具编译GETH是个大坑，出问题的话可以看文档后面有讲\ncd go-ethereummake geth\nStep 3) 运行GETH文档是\ngeth\n就行，看终端geth编译完后的输出来定，我这边的是\n./build/bin/geth\n不出问题的话终端没报错这里就成功了（一般不太可能，出问题见下\n我的操作：\n编译geth1. 克隆自定义的 Go Ethereum 源代码克隆自定义的 Go Ethereum 源代码仓库。\ngit clone https://github.com/jmkemp20/go-ethereum.git\n2. 安装 Geth 或所有 Go Ethereum 工具进入克隆的 go-ethereum 目录，并编译 geth 或所有工具。\n安装 Go 1.20（版本好像会影响编译，翻了下issue，我当时用的1.20确保你已经安装了 Go 1.20 或更高版本。如果没有，请按照以下步骤安装：\n# 下载 Go 1.20wget https://mirrors.aliyun.com/golang/go1.20.6.linux-amd64.tar.gz# 解压并安装sudo tar -C /usr/local -xzf go1.20.6.linux-amd64.tar.gz# 设置环境变量nano ~/.bashrc# 或者nano ~/.zshrc# 添加以下内容export GOROOT=/usr/local/goexport GOPATH=$HOME/goexport PATH=$GOPATH/bin:$GOROOT/bin:$PATH# 使配置生效source ~/.bashrc# 或者source ~/.zshrc# 验证 Go 版本go version\n编译 geth 或所有工具进入 go-ethereum 目录并编译 geth 或所有工具。\ncd go-ethereum# 清理 Go 模块缓存go clean -modcache# 更新 Go 模块go mod tidy# 编译 gethmake geth# 如果你想编译所有工具make all\n如果没猜错的话国内网络环境go下载依赖会卡住卡在这里\n我看的教程\n解决 go get golang.org/x 包失败\nGOPROXY我们知道从 Go 1.11 版本开始，官方支持了 go module 包依赖管理工具。其实还新增了 GOPROXY 环境变量。如果设置了该变量，下载源代码时将会通过这个环境变量设置的代理地址，而不再是以前的直接从代码库下载。这无疑对我等无法科学上网的开发良民来说是最大的福音。更可喜的是，goproxy.io 这个开源项目帮我们实现好了我们想要的。该项目允许开发者一键构建自己的 GOPROXY 代理服务。同时，也提供了公用的代理服务 https://goproxy.io，我们只需设置该环境变量即可正常下载被墙的源码包了：\n\nexport GOPROXY=https://goproxy.io\n也可以通过置空这个环境变量来关闭，export GOPROXY=。\n对于 Windows 用户，可以在 PowerShell 中设置：\n$env:GOPROXY = \"https://goproxy.io\"\n我这边这样做能正常下载\n3. 运行 Geth编译完成后，你可以运行 geth。确保 geth 可执行文件在你的 PATH 中，或者直接在 go-ethereum/build/bin 目录下运行它。\n# 如果 geth 在 PATH 中geth# 如果 geth 不在 PATH 中./build/bin/geth\n成功安装并运行自定义的 Go Ethereum 客户端\n\n\n最后的截图\n\ng)\n","categories":["笔记"]},{"title":"创建一个网络包解码器分析DEVP2P协议","url":"/Arknight-notes/posts/20624.html","content":"\n      \n        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\n      \n      \n        \n          \n          \n            联系站长以查看密码\n          \n        \n        \n      \n    \n    ","categories":["笔记"]},{"title":"日志2024.9.25（待解决）","url":"/Arknight-notes/posts/13872.html","content":"\n在解析rlpx时出现lua错误在帧列表中，有一个帧（编号 1561）出现了 Lua 错误。具体来说，错误信息是：“Lua Error: /root/local/lib/wireshark/plugins/rlpx.lua:97: attempt to index local ‘dec_msg’ (a nil value)”。在解码器脚本 rlpx.lua 的第 97 行尝试访问一个名为 dec_msg 的局部变量，但它是一个空值（nil），导致解码器无法成功解析数据包\n\n\nrlpx.lua代码如下，lua版本为Lua 5.4.7 ：\nlocal python = require 'python'-- Temporary for development-- local sys = python.import 'sys'-- sys.path.append('/home/jkemp/cs700/pydevp2p/')-- End of Temporary for developmentlocal rlpxBridge = python.import 'pydevp2p.bridge'-- create a new dissectorlocal NAME = \"rlpx\"local PORT = 30305local rlpx = Proto(NAME, \"Ethereum RLPx Protocol\")local fields = rlpx.fieldsfields.auth_size = ProtoField.uint16(NAME .. \".auth_size\", \"Auth Size\")fields.ack_size = ProtoField.uint16(NAME .. \".ack_size\", \"Ack Size\")fields.body = ProtoField.bytes(NAME .. \".body\", \"Data\")fields.frame_header = ProtoField.bytes(NAME .. \".frame_header\", \"Frame Header\")fields.frame_body = ProtoField.bytes(NAME .. \".frame_body\", \"Frame Body\")local known_ports = { 30303, 30304, 30305, 30306, 30307, 30308 }local function table_has_value(tab, val)    for _, value in ipairs(tab) do        if value == val then            return true        end    end    return falseendlocal function array_iterator(array, len)    -- This lets us iterate over a c object (like a python array)    local index = 0    local count = len    -- The closure function is returned    return function()        index = index + 1        if index &lt;= count        then            -- return the current element of the iterator            return array[index]        end    endend-- main dissect packet functionfunction rlpx.dissector(tvb, pinfo, tree)    local subtree = tree:add(rlpx, tvb())    local offset = 0    -- show protocol name in protocol column    pinfo.cols.protocol = rlpx.name    local srcaddr = tostring(pinfo.src)    local dstaddr = tostring(pinfo.dst)    local payload = tostring(tvb:bytes())    -- dissect field one by one, and add to protocol tree    local auth_size = tvb(offset, 2)    if (tvb:len() - auth_size:int() == 2) then        if (table_has_value(known_ports, pinfo.src_port)) then            -- This is most likely a handshake AUTH-ACK packet            offset = offset + 2            subtree:add(fields.ack_size, auth_size)            pinfo.cols.info:set(pinfo.src_port .. \" → \" .. pinfo.dst_port .. \" [HANDSHAKE] AUTH ACK\")            -- print(payload, dstNode)            local dec_msg = rlpxBridge.handleRLPxHandshakeMsg(srcaddr, dstaddr, payload, pinfo.visited, pinfo.number)            local payloadtree = subtree:add(fields.body, tvb(offset))            payloadtree:set_text(\"Handshake AUTH ACK\")            for element in array_iterator(dec_msg, dec_msg[0]) do                payloadtree:add(element)            end        elseif (table_has_value(known_ports, pinfo.dst_port)) then            -- This is most likely a handshake AUTH packet            offset = offset + 2            subtree:add(fields.auth_size, auth_size)            pinfo.cols.info:set(pinfo.src_port .. \" → \" .. pinfo.dst_port .. \" [HANDSHAKE] AUTH INIT\")            -- print(payload, dstNode)            local dec_msg = rlpxBridge.handleRLPxHandshakeMsg(srcaddr, dstaddr, payload, pinfo.visited, pinfo.number)            local payloadtree = subtree:add(fields.body, tvb(offset))            for element in array_iterator(dec_msg, dec_msg[0]) do                payloadtree:add(element)            end        else            subtree:add(fields.body, tvb(offset))        end    else        local dec_msg = rlpxBridge.handleRLPxMsg(srcaddr, dstaddr, payload, pinfo.visited, pinfo.number)        local frame_header = dec_msg[0]        local frame_body = dec_msg[1]        local frame_type = dec_msg[2]        -- Set the column information to the Frame Type        if frame_type ~= nil then            pinfo.cols.info:set(pinfo.src_port .. \" → \" .. pinfo.dst_port .. \" \" .. frame_type)        end        -- Show the frame header information (if available) in Wireshark        if frame_header ~= nil then            local frame_header_tree = subtree:add(fields.frame_header, tvb(0, frame_header.headerSize))            frame_header_tree:add(\"Decrypted Header Data:\", frame_header.header)            frame_header_tree:add(\"Header MAC:\", frame_header.headerMac)            frame_header_tree:add(\"Frame Body MAC:\", frame_header.frameMac)            frame_header_tree:add(\"Frame Size:\", frame_header.frameSize)            frame_header_tree:add(\"Read Size:\", frame_header.readSize)            frame_header_tree:add(\"Header Data:\", frame_header.headerData)            pinfo.cols.info:append(\" Len=\" .. frame_header.readSize)        end        -- Show the frame body information (if available) in Wireshark        if frame_header ~= nil and frame_type ~= nil and frame_body ~= nil and frame_body[0] &gt; 0 then            local frame_body_tree = subtree:add(fields.frame_body, tvb(frame_header.headerSize))            for element in array_iterator(frame_body, frame_body[0]) do                frame_body_tree:add(element)            end        end    endend-- register this dissectorDissectorTable.get(\"tcp.port\"):add(PORT, rlpx)DissectorTable.get(\"tcp.port\"):add(\"30303\", rlpx)DissectorTable.get(\"tcp.port\"):add(\"30304\", rlpx)DissectorTable.get(\"tcp.port\"):add(\"30305\", rlpx)DissectorTable.get(\"tcp.port\"):add(\"30306\", rlpx)DissectorTable.get(\"tcp.port\"):add(\"30307\", rlpx)DissectorTable.get(\"tcp.port\"):add(\"30308\", rlpx)\n不知道怎么改，不懂lua\n可能是lua版本问题，改天看下文档\n\n\n.webp)\n"},{"title":"关于WSL Docker清理","url":"/Arknight-notes/posts/33014.html","content":"Windows下释放Docker所占用的WSL磁盘空间使用下面的命令清理镜像：\ndocker system prune\n在Linux下面可以释放磁盘空间，但是在Windows下却并不能够真正的释放硬盘。\n搜寻了一下，发现有一个文件超级大：\nC:\\Users\\{用户名}\\AppData\\Local\\Docker\\wsl\\data\\ext4.vhdx\n这是WSL的虚拟机文件。这个文件看起来是只增长，不回收硬盘空间的，所以，需要手动回收硬盘空间。\n1. 停止wsl2wsl --shutdown\n2. 运行diskpart释放空间# 代码来自 https://github.com/microsoft/WSL/issues/4699#issuecomment-627133168diskpartselect vdisk file=\"C:\\Users\\&lt;你的用户名&gt;\\AppData\\Local\\Docker\\wsl\\data\\ext4.vhdx\"attach vdisk readonlycompact vdiskdetach vdiskexit\n参考资料\nWSL2 Docker释放磁盘空间\nwsl2 下清理 docker 占用空间\nWSL 2 should automatically release disk space back to the host OS168)\n\n","categories":["笔记"]},{"title":"爬虫实战-爬取广州大学课程表","url":"/Arknight-notes/posts/33971.html","content":"大二上在学python，所以想要用python实现一下课表爬取。\n（虽然python开课爬虫不怎么讲的都\n本文仅供学习使用。 \n广州大学课程信息查询脚本1. 概述本脚本用于自动化登录广州大学教务系统，获取当前学期课程信息，主要功能包括：\n\n通过浏览器自动化（Selenium）模拟用户登录，绕过滑块验证。\n使用获取的Cookie通过requests库发送API请求，获取课程数据。\n结构化处理课程信息，并导出为JSON和CSV格式文件。\n\n\n2. 环境依赖2.1 运行环境\nPython 3.7+\n\n依赖库\npip install selenium requests pandas\n\n\n2.2 配置\n手动输入学号密码（脚本运行时会提示），查询时段的配置请求参数\n后期待完善（\n\n\n3. 功能模块3.1 登录模块功能描述\n通过Selenium启动浏览器，访问教务系统登录页面。\n自动填充学号、密码，并绕过滑块验证。\n判断登录状态，成功后保存Cookie供后续请求使用。\n\n输入参数\n学号（login_username）\n密码（login_password）\n\n关键逻辑\n浏览器配置：禁用自动化检测标志（excludeSwitches: ['enable-automation']），防止被识别为爬虫。\n滑块验证绕过：通过执行JavaScript代码navigator.webdriver = false。\n登录状态检查：通过页面元素或关键词（如登录成功）判断是否登录成功。\n\n\n3.2 课程数据获取模块功能描述\n使用requests库发送POST请求，携带登录后的Cookie和参数，获取课程数据。\n\n数据接口：http://jwxt.gzhu.edu.cn/jwglxt/kbcx/xskbcx_cxXsgrkb.html（F12大法\n\n\n\n\n请求参数data = {    \"xnm\": \"2024\",     # 学年（2024表示2023-2024学年）    \"kzlx\": \"ck\",      # 查询类型（ck=查看）    \"xsdm\": \"\",        # 学生代码（留空）    \"xqm\": \"3\"         # 学期码（3表示秋季学期）}\n请求头（Headers）headers = {    \"User-Agent\": \"Mozilla/5.0 ...\",  # 模拟浏览器请求    \"Referer\": \"http://jwxt.gzhu.edu.cn/...\",  # 来源页面    \"X-Requested-With\": \"XMLHttpRequest\"       # 标识AJAX请求}\n\n3.3 数据处理与导出模块功能描述\nJSON数据处理\n\n从原始响应中提取关键字段（如课程名称kcmc、教室cdmc、节次jc）。\n映射星期代码（xqjmcMap）为中文（如1 → 周一）。\n保存结构化的JSON文件（extracted_courses.json）。\n\n\nCSV导出\n\n使用pandas将JSON数据转换为表格形式。\n\n添加中文表头（如“课程名称”、“教室”）。\n\n导出为CSV文件（courses.csv），兼容Excel打开。\n\n\n\n\n\n字段映射表\n\n\n\n原始字段\n中文表头\n说明\n\n\n\n\nkcmc\n课程名称\n课程全称\n\n\ncdmc\n教室\n上课地点\n\n\njc\n节数\n课程节次（如1-2节）\n\n\nxqjmc\n日期\n星期几（周一至日）\n\n\nkcxszc\n课时安排\n周次范围（如1-16周）\n\n\n\n\n\n4. 代码详解4.1 登录流程# 防止打开浏览器后闪退options = webdriver.ChromeOptions()options.add_experimental_option('detach', True)# options.add_argument('--headless')  # 无头模式# 开发者模式，防止被各大网站识别出来使用了Seleniumoptions.add_experimental_option('excludeSwitches', ['enable-automation'])# 启动浏览器browser = webdriver.Chrome(options=options)browser.get(login_url)# 绕过滑块验证browser.execute_script('Object.defineProperties(navigator,{webdriver:{get:()=&gt;false}})')# 查找用户名和密码输入框所在元素username_input = browser.find_element(By.ID, 'un')username_input.click()username_input.send_keys(login_username)\n# 等待响应time.sleep(2)# 输入信息模拟登录password_input = browser.find_element(By.XPATH, \"//input[@name='pd']\")password_input.click()password_input.send_keys(login_password)login_button = browser.find_element(By.ID, 'index_login_btn')login_button.click()time.sleep(5)# 检查登录是否成功if '登录成功' in browser.page_source or 'index_login_btn' not in browser.page_source:    print(\"登录成功\")else:    print(\"登录失败\")cookies = browser.get_cookies()print(\"Cookies:\", cookies)cookie_dict = {cookie['name']: cookie['value'] for cookie in cookies}# 关闭浏览器browser.quit()\n4.2 数据请求# 请求头headers = {    \"Accept\": \"*/*\",    \"Accept-Encoding\": \"gzip, deflate\",    \"Accept-Language\": \"zh-CN,zh;q=0.9\",    \"Connection\": \"keep-alive\",    \"Content-Length\": \"28\",    \"Content-Type\": \"application/x-www-form-urlencoded;charset=UTF-8\",    \"Host\": \"jwxt.gzhu.edu.cn\",    \"Origin\": \"http://jwxt.gzhu.edu.cn\",    \"Referer\": \"http://jwxt.gzhu.edu.cn/jwglxt/kbcx/xskbcx_cxXskbcxIndex.html?gnmkdm=███████&amp;layout=default\",    \"User-Agent\": \"Mozilla/███████ (Windows NT ███████; Win64; x64) AppleWebKit/███████ (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36\",    \"X-Requested-With\": \"XMLHttpRequest\"}# 表单数据(学年和学期)data = {    \"xnm\": \"2024\",    \"kzlx\": \"ck\",    \"xsdm\": \"\",    \"xqm\": \"3\"}session = requests.Session()for name, value in cookie_dict.items():    session.cookies.set(name, value)# POST请求response = session.post(target_url, headers=headers, data=data)# 检查请求是否成功if response.status_code == 200:    try:        response_data = response.json()        formatted_data = json.dumps(response_data, indent=4, ensure_ascii=False)        with open('course_schedule.json', 'w', encoding='utf-8') as file:            file.write(formatted_data)            print(\"返回的数据已经保存至course_schedule.json\")    except ValueError:        print(\"无法解析JSON数据\")else:    print(f\"请求失败，状态码: {response.status_code}\")\n4.3 JSON数据处理# 提取字段并重构数据courses = []for course in data['kbList']:    course_info = {        \"课程名称\": course.get('kcmc', ''),        \"教室\": course.get('cdmc', ''),        # ... 其他字段映射    }    courses.append(course_info)\n4.4 CSV导出逻辑# 使用pandas转换并导出df = pd.DataFrame(courses)df.to_csv('courses.csv', index=False, encoding='utf-8-sig')  # 兼容Excel中文编码\n \n滑块验证更新：若教务系统更新滑块验证逻辑，需调整JavaScript绕过代码。\n\n接口稳定性：课程查询接口（xskbcx_cxXsgrkb.html）若变更URL，需同步更新。\n\n\n\n6. 输出示例6.1 JSON文件（extracted_courses.json）和谐了部分隐私信息（\n{            \"bklxdjmc\": \"无\",            \"cd_id\": \"1015170\",            \"cdlbmc\": \"多媒体\",            \"cdmc\": \"███████517\",            \"cxbj\": \"0\",            \"cxbjmc\": \"无\",            \"date\": \"二○二四年十一月十五日\",            \"dateDigit\": \"2024年11月15日\",            \"dateDigitSeparator\": \"2024-11-15\",            \"day\": \"15\",            \"jc\": \"3-4节\",            \"jcor\": \"3-4\",            \"jcs\": \"3-4\",            \"jgh_id\": \"104119\",            \"jgpxzd\": \"1\",            \"jxb_id\": \"1850E3A697E512CAE06███████ACA210\",            \"jxbmc\": \"(2024-2025-1)-216███████-01\",            \"jxbsftkbj\": \"0\",            \"jxbzc\": \"███████\",            \"kcbj\": \"主修\",            \"kch\": \"███████\",            \"kch_id\": \"███████\",            \"kclb\": \"专业课程平台\",            \"kcmc\": \"常微分方程1\",            \"kcxszc\": \"理论:48\",            \"kcxz\": \"专选\",            \"kczxs\": \"48\",            \"khfsmc\": \"考试\",            \"kkzt\": \"1\",            \"lh\": \"███████楼\",            \"listnav\": \"false\",            \"localeKey\": \"zh_CN\",            \"month\": \"11\",            \"oldjc\": \"12\",            \"oldzc\": \"65280\",            \"pageTotal\": 0,            \"pageable\": true,            \"pkbj\": \"1\",            \"px\": \"1\",            \"qqqh\": \"无\",            \"queryModel\": {                \"currentPage\": 1,                \"currentResult\": 0,                \"entityOrField\": false,                \"limit\": 15,                \"offset\": 0,                \"pageNo\": 0,                \"pageSize\": 15,                \"showCount\": 10,                \"sorts\": [],                \"totalCount\": 0,                \"totalPage\": 0,                \"totalResult\": 0            },            \"rangeable\": true,            \"rk\": \"12\",            \"rsdzjs\": 0,            \"sfjf\": \"0\",            \"skfsmc\": \"无\",            \"sxbj\": \"1\",            \"totalResult\": \"0\",            \"userModel\": {                \"monitor\": false,                \"roleCount\": 0,                \"roleKeys\": \"\",                \"roleValues\": \"\",                \"status\": 0,                \"usable\": false            },            \"xf\": \"3\",            \"xkbz\": \"无\",            \"xm\": \"███████\",            \"xnm\": \"2024\",            \"xqdm\": \"0\",            \"xqh1\": \"1,2,\",            \"xqh_id\": \"1\",            \"xqj\": \"1\",            \"xqjmc\": \"星期一\",            \"xqm\": \"3\",            \"xqmc\": \"███████\",            \"xsdm\": \"01\",            \"xslxbj\": \"*\",            \"year\": \"2024\",            \"zcd\": \"9-███████周\",            \"zcmc\": \"███████\",            \"zfjmc\": \"主讲\",            \"zhxs\": \"3\",            \"zxs\": \"48\",            \"zxxx\": \"无\",            \"zyfxmc\": \"███████\",            \"zyhxkcbj\": \"否\",            \"zzrl\": \"███████\"        },\n6.2 CSV文件（courses.csv）\n\n\n\n课程名称\n教室\n节数\n日期\n课时安排\n\n\n\n\n常微分方程1\n███████\n3-4\n周一\n1-16周\n\n\n\n\n\n7. todo\n可视化界面：集成tkinter或Web框架（如Flask）提供GUI操作。\n全校课表爬虫\n\n�**\n","categories":["笔记"]},{"title":"2024一些笔记（概率论）","url":"/Arknight-notes/posts/20561.html","content":"2024的一些笔记（概率论）（共18张）\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nbp)\n","categories":["笔记"],"tags":["概率论"]},{"title":"数据结构-图","url":"/Arknight-notes/posts/18076.html","content":"图是一种比线性表和树更为复杂的数据结构。在图结构中，结点之间的关系可以是任意的，图中任意两个数据元素之间都可能相关。\n图结构在计算机科学和算法设计中有广泛的应用。例如，在社交网络分析中，可以使用图结构来表示用户之间的关系；在路线规划中，可以使用图结构来表示道路网络和城市之间的连接关系；在人工智能领域中，图结构可以用于表示知识图谱和推荐系统等。\n在离散数学中，图论是专门研究图的性质的数学分支，而在数据结构中，则应用图论的知识讨论如何在计算机上实现图的操作，因此主要学习图的存储结构，以及若干图的操作的实现。\n一、定义图（Graph）由两个集合和组成，记为，其中是顶点的有穷非空集合，是中顶点偶对的有穷集合，这些顶点偶对称为边。和通常分别表示图的顶点集合和边集合，可以为空集。若为空，则图只有顶点而没有边。\n\n如上图所示，左图为有向图，右图为无向图。\n对于图，若边集为有向边的集合，则称该图为有向图；若边集为无向边的集合，则称该图为无向图。\n在有向图中，顶点对$是有序的，它称为从顶点到顶点的一条有向边。因此，与是不同的两条边。顶点对用一对尖括号括起来，是有向边的始点，是有向边的终点。$也称作一条弧，其中 x 为弧尾，y 为弧头。\nA ──→ B\n│     │\n↓     ↓\nC ──→ D\n\n 表示从顶点 A 到顶点 B 的有向边\n 表示从顶点 A 到顶点 C 的有向边\n 表示从顶点 B 到顶点 D 的有向边\n 表示从顶点 C 到顶点 D 的有向边\n箭头表示方向， ≠ \n\n在无向图中，顶点对是无序的，它称为与顶点 x 和顶点 y 相关联的一条边。这条边没有特定的方向，与是同一条边。为了有别于有向图，无向图的顶点对用一对圆括号括起来。\nA ---- B\n|      |\n|      |\nC ---- D\n\n(A,B) 表示顶点 A 和顶点 B 之间的无向边\n(A,C) 表示顶点 A 和顶点 C 之间的无向边\n(B,D) 表示顶点 B 和顶点 D 之间的无向边\n(C,D) 表示顶点 C 和顶点 D 之间的无向边\n没有方向性，(A,B) = (B,A)\n\n二、基本术语下面介绍图结构中的一些基本术语（注：n 表示图中顶点数目，e 表示边的数目）。\n\n子图：假设右两个图  和 ，如果   且   ，则称  为  的子图。如下图所示，图（b）是图（a）的子图。\n\n\n\n无向完全图和有向完全图：对于无向图，若具有  条边，则称为无向安全图。对于有向图，若具有  条弧，则称为有向完全图。\n稀疏图和稠密图：边或弧很少（如   ​ ）的图称为稀疏图，反之称为稠密图。\n权和网：若在图的每条边上标上具有某种含义的数值，该数值称为该边上的权值。这些权值可以表示从一个顶点到另一个顶点的距离或耗费。这种带权的图通常称为网。\n邻接点：对于无向图 G，如果图的边   ，则称顶点  和  互为邻接点，即 v 和 v’相邻接。边依附于顶点  和 ，或者说边与顶点  和  相关联。\n度、入度和出度：顶点  的度是指和  相关联的边的数目，记为 。例如，下图（b）中的顶点 ​ 的度是 2。\n对于有向图，顶点 v 的度分为入度和出度。入度是以顶点 v 为头的弧的数目，记为 ；出度是以顶点 v 为尾的弧的数目，记为  。顶点 v 的度为 。\n例如，下图（a）中的顶点   ​ 的入度 ，出度 ，度 \n\n\n\n\n路径和路径长度：在无向图  中，从顶点  到顶点  的路径是一个顶点序列 ​  ，其中 ​  ，  ​。\n如果 G 是有向图，则路径也是有向的，顶点序列应满足  $∈E，1≤j≤m$ ​。路径长度是一条路径上经过的边或弧的数目。\n回路或环：第一个顶点和最后一个顶点相同的路径称为回路或环。\n简单路径、简单回路或简单环：序列中顶点不重复出现的路径称为简单路径。除了第一个顶点和最后一个顶点之外，其余顶点不重复出现的回路，称为简单回路或简单环。\n连通、连通图和连通分量：在无向图  中，如果从顶点  到顶点  有路径，则称  和  是连通的。如果对于图中任意两个顶点 ​  ，​   和   ​ 都是连通的，则称  是连通图。而所谓连通分量，指的是无向图中的极大连通子图。例如，下图（a）就是一个连通图，而图（b）则是非连通图，但它有 3 个连通分量，见图（c）。\n\n\n\n强连通图和强连通分量：在有向图  中，如果对于每一对 ​  ，​  ，从 ​   到 ​   和从 ​   到 ​   都存在路径，则称  是强连通图。有向图中的极大强连通子图称作有向图的强连通分量。例如，下图（a）就是一个强连通图，而图（b）则不是强连通图，但它有两个强连通分量，见图（c）。\n\n\n\n连通图的生成树：一个极小连通子图，它含有图中全部顶点，但只有足以构成一棵树的 n-1 边，这样的连通子图称为连通图的生成树。例如，下图（c）是图（a）的最大连通分量的一棵生成树。如果在一棵生成树上添加一条边，必定构成一个环，因为这条边使得它依附的那两个顶点之间有了第二条路径。\n\n\n\n有向树和生成森林：有一个顶点的入度为 0，其余顶点的入度均为 1 的有向图称为有向树。一个有向图的生成森林由若干棵有向树组成，含有图中全部顶点，但只有足以构成若干棵不相交的有向树的弧。例如，下图（a）是一棵有向树，图（b）是一个有向图，它的森林是图（c）。\n\n\n三、存储结构由于图的结构比较复杂，任意两个顶点之间都可能存在联系，因此无法以数据元素在存储区中的物理位置来表示元素之间的关系，即图没有顺序存储结构，但可以借助二维数组来表示元素之间的关系，即邻接矩阵表示法。\n另一方面，由于图的任意两个顶点间都可能存在关系，因此，用链式存储表示图是很自然的事，图的链式存储有多种，有邻接表、十字链表和邻接多重表，应根据实际需要的不同选择不同的存储结构。\n3.1、邻接矩阵3.1.1、表示法邻接矩阵（Adjacency Matrix）是表示顶点之间相邻关系的矩阵。设 是具有 n 个顶点的图，则  的邻接矩阵是具有如下性质的 n 阶方阵：\n或其他\n例如，下图为一个有向图和它的邻接矩阵:\n\n若 G 是网，则邻接矩阵可以定义为：\n或其他\n其中，​  表示边上的权值，​ ∞  表示计算机允许的、大于所有边上权值的数。例如，下图为一个有向网和它的邻接矩阵:\n\n用邻接矩阵表示法表示图，除了一个用于存储邻接矩阵的二维数组外，还需要用一个一维数组来存储顶点信息。在 C 语言中，图的邻接矩阵类型描述如下：\n// 表示极大值#define MaxInt 32767// 最大顶点数#define MVNum 100​// 假设顶点的数据类型为字符型typedef char VerTexType;​// 假设边的权值类型为整型typedef int ArcType;​typedef struct {    // 顶点表    VerTexType vexs[MVNum];    // 邻接矩阵    ArcType arcs[MVNum][MVNum];    // 图的当前顶点数和边数    int vexnum, arcnum;}AMGraph;\n3.1.2、创建无向网已知一个图的顶点和边，使用邻接矩阵表示法来创建此图的方法比较简单，下面以一个无向网为例来说明创建图的算法。该算法的步骤为：\n\n输入总顶点数和总边数。\n依次输入顶点的信息存入顶点表中。\n初始化邻接矩阵，使每个权值初始化为极大值。\n构造邻接矩阵。依次输入每条边依附的顶点和其权值，确定两个顶点在图中的位置之后，使相应边赋予相应的权值，同时使其对称边赋予相同的权值。\n\n相应的算法描述为：\n// 采用邻接矩阵表示法，创建无向网GStatus CreateUDN(AMGraph &amp;G) {    // 输入总顶点数和总边数    cin&gt;&gt;G.vexnum&gt;&gt;G.arcnum;​    // 依次输入顶点信息    for(i=0; i&lt;G.vexnum; ++i)        cin&gt;&gt;G.vexs[i]​    // 初始化邻接矩阵，边的权值均为极大值MaxInt    for(i=0; i&lt;G.vexnum; ++i)        for(j=0; j&lt;G.vexnum; ++j)            G.arcs[i][j]=MaxInt;​    // 构造邻接矩阵    for(k=0;k&lt;G.arcnum;++k) {        // 输入一条边依附的顶点和其权值        cin&gt;v1&gt;&gt;v2&gt;&gt;w;        // 确定v1和v2在G中的位置，即顶点数组的下标        i=LocateVex(G,v1);        j=LocateVex(G,v2);        // 边&lt;v1, v2&gt;的权值置为w        G.arcs[i][j]=w;        // 置&lt;v1, v2&gt;的对称边&lt;v2, v1&gt;的权值置为w        G.arcs[j][i]=G.arcs[i][j];    }​    return OK;}\n该算法的时间复杂度是   ​\n若要建立无向图，只需对上述算法做两处小的改动：一是初始化邻接矩阵时，将边的权值均初始化为 0；二是构造邻接矩阵时，将权值 w 改为常量值 1 即可。同样，将该算法稍做修改即可建立一个有向网或有向图。\n3.1.3、优缺点邻接矩阵表示法的优点是：\n\n便于判断两个顶点之间是否有边，即根据  或 1 来判断。\n便于计算各个顶点的度。对于无向图，邻接矩阵第 i 行元素之和就是顶点 i 的度；对于有向图，第 i 行元素之和就是顶点 i 的出度，第 i 列元素之和就是顶点 i 的入度。\n\n邻接矩阵表示法的缺点是：\n\n不便于增加和删除顶点。\n不便于统计边的数目，需要扫描邻接矩阵所有元素才能统计完毕，时间复杂度为 ​ O(n2) 。\n空间复杂度高。如果是有向图，n 个顶点需要 ​ n2  个单元存储边。如果是无向图，因其邻接矩阵是对称的，所以对规模较大的邻接矩阵可以采用压缩存储的方法，仅存储下三角（或上三角）的元素，这样需要  个单元即可。但无论以何种方式存储，邻接矩阵表示法的空间复杂度均为   ​，这对于稀疏图而言尤其浪费空间。\n\n3.2、邻接表3.2.1、表示法邻接表（Adjacency List）是图的一种链式存储结构。\n在邻接表中，对图中每个顶点 ​ 建立一个单链表，把与  vi ​ 相邻接的顶点放在这个链表中。邻接表中每个单链表的第一个结点存放有关顶点的信息，把这一结点看成链表的表头，其余结点存放有关边的信息，这样邻接表便由两部分组成：表头结点表和边表。\n表头结点表，由所有表头结点以顺序结构的形式存储，以便可以随机访问任一顶点的边链表。表头结点包括数据域（data）和链域（firstarc）两部分，如下图（a）所示。其中，数据域用于存储顶点 ​ vi  的名称或其他信息；链域用于指向链表中第一结点（即与顶点 ​ vi  相邻接的第一个邻接点）。\n边表，由表示图中顶点间关系的 2n 个边链表组成。边链表中边结点包括邻接点域、数据域和链域三部分，如下图（b）所示。其中，邻接点域指示与顶点  vi ​ 相邻接的点在图中的位置；数据域存储和边相关的信息，如权值等；链域指示与顶点 ​ vi  相邻接的下一个邻接点。\n\n例如，在下图（a）中有两个图，图（b）则是它们对应的邻接表。\n\n在无向图的邻接表中，顶点 ​   的度恰为第 i 个链表中的结点数；而在有向图中，第 i 个链表中的结点个数只是顶点 ​ 的出度，为求入度，必须遍历整个邻接表。在所有链表中，其邻接点域的值为 i 的结点的个数就是顶点    ​ 的入度。有时，为了便于确定顶点的入度，可以建立一个有向图的逆邻接表，即对每个顶点 ​    建立一个链接所有进入 ​    的边的表。例如，下图（c）为有向图 ​ 的逆邻接表。\n\n根据上述讨论，要定义一个邻接表，需要定义存放顶点的头结点和表示边的边结点。在 C 语言中，图的邻接表存储结构的类型描述如下：\n// 最大顶点数#define MVNum 100​// 边结点typedef struct ArcNode {    // 该边所指向的顶点的位置（邻接点域）    int adjvex;    // 指向下一条边的指针（链域）    struct ArcNode *nextarc;    // 和边相关的信息（数据域）    OtherInfo info;}ArcNode;​// 顶点信息typedef struct VNode {    VerTexType data;    // 指向第一条依附该顶点的边的指针    ArcNode *firstarc;}VNode, AdjList[MVNum];​// 邻接表typedef struct {    AdjList vertices;    // 图的当前顶点数和边数    int vexnum, arcnum;}ALGraph;\n3.2.2、创建无向图基于邻接表表示法创建一个图，需要创建其相应的顶点表和边表。下面以一个无向图为例来说明创建图的算法。该算法步骤为：\n\n输入总顶点数和总边数。\n依次输入顶点的信息存入顶点表中，使每个表头结点的指针域初始化为 NULL。\n创建邻接表。依次输入每条边依附的两个顶点，确定这两个顶点的序号 i 和 j 之后，将此边结点分别插入 ​    和    ​ 对应的两个边链表的头部。\n\n相应的算法描述为：\n// 采用邻接表表示法，创建无向图GStatus CreateUDG(ALGraph &amp;G) {    // 输入总顶点数，总边数    cin&gt;&gt;G.vexnum&gt;&gt;G.arcnum;​    // 输入顶点信息，构造表头结点表    for(i=0; i&lt;G.vexnum; ++i) {        // 输入顶点的值        cin&gt;&gt;G.vertices[i].data;        // 初始化表头结点的指针域为NULL        G.vertices[i].firstarc=NULL;    }​    // 输入各边，构造邻接表    for(k=0; k&lt;G.arcnum; ++k) {        // 输入一条边依附的两个顶点        cin&gt;&gt;v1&gt;&gt;v2;        // 确定v1和v2在G中的位置，即顶点在G.vertices中的下标        i=LocateVex(G,v1);        j=LocateVex(G,v2);​        // 生成一个新的边结点*p1        p1=new ArcNode;        // 邻接点序号为j        p2-&gt;adjvex=j;        // 将新结点*p1插入到顶点vi的边表头部        p1-&gt;nextarc=G.vertices[i].firstarc;        G.vertices[i].firstarc=p1;​        // 生成另一个对称的新边结点*p2        p2=new ArcNode;        // 邻接点序号为i        p2-&gt;adjvex=i;        // 将新结点*p2插入到顶点vj的边表头部        p2-&gt;nextarc=G.vertices[j].firstarc;        G.vertices[j].firstarc=p2;    }​    return OK;}\n该算法的时间复杂度是 。\n建立有向图的邻接表与此类似，只是更加简单，每读入一个顶点对序号，仅需生成一个邻接点序号为 j 的边表结点，并将其插入到 ​   的边链表头部即可。若要创建网的邻接表，可以将边的权值存储在 info 域中。\n需要注意的是，一个图的邻接矩阵表示是唯一的，但其邻接表表示不唯一，这是因为在邻接表表示中，各边表结点的链接次序取决于建立邻接表的算法，以及边的输入次序。\n3.2.3、优缺点邻接矩阵和邻接表是图的两种最常用的存储结构，它们各有所长。与邻接矩阵相比，邻接表有其自己的优缺点。其优点是：\n\n便于增加和删除顶点。\n便于统计边的数目，按顶点表顺序扫描所有边表可得到边的数目，时间复杂度为 O(n+e)。\n空间效率高。对于一个具有 n 个顶点 e 条边的图 G，若 G 是无向图，则在其邻接表表示中有 n 个顶点表结点和 2e 个边表结点；若 G 是有向图，则在它的邻接表表示或逆邻接表表示中均有 n 个顶点表结点和 e 个边表结点。因此，邻接表或逆邻接表表示的空间复杂度为 O(n+e)，适合表示稀疏图。对于稠密图，考虑到邻接表中要附加链域，因此常采取邻接矩阵表示法。\n\n其缺点是：\n\n不便于判断顶点之间是否有边，要判定 ​ 和 ​ 之间是否有边，就需扫描第 i 个边表，最坏情况下要耗费 O(n)时间。\n不便于计算有向图各个顶点的度。对于无向图，在邻接表表示中顶点 ​ 的度是第 i 个边表中的结点个数。在有向图的邻接表中，第 i 个边表上的结点个数是顶点 ​ vi  的出度，但求  vi ​ 的入度较困难，需遍历各顶点的边表。若有向图采用逆邻接表表示，则与邻接表表示相反，求顶点的入度容易，而求顶点的出度较难。\n\n3.3、十字链表十字链表（Orthogonal List）是有向图的另一种链式存储结构。它可以看成是将有向图的邻接表和逆邻接表结合起来得到的一种链表。在十字链表中，对应于有向图中每一条弧有一个结点，对应于每个顶点也有一个结点。这些结点的结构形式如下图所示。\n\n在弧结点中有 5 个域：其中尾域 tailvex 和头域 headvex 分别指示弧尾和弧头这两个顶点在图中的位置，链域 hlink 指向弧头相同的下一条弧，而链域 tlink 指向弧尾相同的下一条弧，info 域指向该弧的相关信息。弧头相同弧在同一链表上，弧尾相同的弧也在同一链表上。而它们的头结点即为顶点结点。\n顶点结点由 3 个域组成：其中 data 域存储和顶点相关的信息，如顶点的名称等；firstin 和 firstout 为两个链域，分别指向以该顶点为弧头或弧尾的第一个弧结点。\n例如，下图（b）是下图（a）所示图的十字链表。\n\n若将有向图的邻接矩阵看成是稀疏矩阵的话，则十字链表也可以看成是邻接矩阵的链式存储结构，在图的十字链表中，弧结点所在的链表非循环链表，结点之间相对位置自然形成，不一定按顶点序号有序，表头结点即顶点结点，它们之间不是链接，而是顺序存储。\n在 C 语言中，有向图的十字链表存储结构的类型描述如下：\n#define MAX_VERTEX_NUM 20​typedef struct ArcBox {    // 该弧的尾和头结点的位置    int tailvex,headvex;    // 分别为弧头相同和弧尾相同的弧的链域    struct ArcBox *hlink,*tlink;    // 该弧相关信息的指针    InfoType *info;}ArcBox;​typedef struct VexNode {    VertexType data;    // 分别指向该顶点的第一条入弧和出弧    ArcBox *firstin, *firstout;}VexNode;​typedef struct {    // 表头向量    VexNode xlist[MAX_VERTEX_NUM];    // 有向图的当前顶点数和弧数    int vexnum, arcnum;}QLGraph;\n只要输入 n 个顶点的信息和 e 条弧的信息，便可建立该有向图的十字链表。建立十字链表的时间复杂度和建立邻接表是相同的。在十字链表中既容易找到以 ​ vi  为尾的弧，也容易找到以  vi ​ 为头的弧，因而容易求得顶点的出度和入度（或需要，可在建立十字链表的同时求出）。在某些有向图的应用中，十字链表是很有用的工具。\n3.4、邻接多重表邻接多重表（Adjacency Multilist）是无向图的另一种链式存储结构。虽然邻接表是无向图的一种很有效的存储结构，在邻接表中容易求得顶点和边的各种信息。但是，在邻接表中每一条边  (vi,vj)  有 ​ 两个结点，分别在第 i 个和第 j 个链表中，这给某些图的操作带来不便。例如，在某些图的应用问题中，需要对边进行某种操作，如对已被搜索过的边作记号或删除一条边等，此时需要找到表示同一条边的两个结点。因此，在进行这一类操作的无向图的问题中采用邻接多重表作存储结构更为适宜。\n\n邻接多重表的结构和十字链表类似。在邻接多重表中，每一条边用一个结点表示，它由 6 个域组成。其中，mark 为标志域，可用以标记该条边是否被搜索过；ivex 和 jvex 为该边依附的两个顶点在图中的位置；ilink 指向下一条依附于顶点 ivex 的边；jlink 指向下一条依附于顶点 jvex 的边；info 指向和边相关的各种信息的指针域。\n每一个顶点也用一个结点表示，它由两个域组成。其中，data 域存储和该顶点相关的信息，firstedge 域指示第一条依附于该顶点的边。\n例如，下图（b）是下图（a）所示图的邻接多重表。\n\n在邻接多重表中，所有依附于同一顶点的边串联在同一链表中，由于每条边依附于两个顶点，则每个边结点同时链接在两个链表中。可见，对无向图而言，其邻接多重表和邻接表的差别，仅仅在于同一条边在邻接表中用两个结点表示，而在邻接多重表中只有一个结点。因此，除了在边结点中增加一个标志域外，邻接多重表所需的存储量和邻接表相同。\n在 C 语言中，邻接多重表的类型描述如下：\n#define MAX_VERTEX_NUM 20​typedef enum{unvisited, visited} VisitIf;​typedef struct EBox {    // 访问标记    VisitIf mark;    // 该边依附的两个顶点的位置    int ivex, jvex;    // 分别指向依附这两个顶点的下一条边    struct EBox *ilink, *jlink;    // 该边信息指针    InfoType *info;}Ebox;​typedef struct VexBox {    VertexType data;    // 指向第一条依附该顶点的边    EBox *firstedge;}VexBox;​typedef struct {    VexBox adjmulist[MAX_VERTEX_NUM];    // 无向图的当前顶点数和边数    int vexnum, edgenum;}AMLGraph;\n","categories":["数据结构"],"tags":["数据结构"]},{"title":"hexo集成gitalk时的Error Validation Failed问题","url":"/Arknight-notes/posts/18261.html","content":"hexo集成gitalk时Error: Validation Failed问题Hexo集成Gitalk后，某些文章下方的评论显示Error: Validation Failed\nGitalk会限制Label name的长度，有些文章生成的URL长度会超过限制，所以导致这个问题\n\n解决方案可以集成一个对文章生成唯一id的插件\nhexo-abbrlink在博客根目录下安装\nnpm install --save hexo-abbrlink\n并修改配置文件_config.yml\npermalink: [EveryWordsYouWant]/:abbrlink/\n再 hexo cl &amp;&amp; hexo g &amp;&amp; hexo d 即可\n\n","categories":["Hexo"],"tags":["Hexo"]},{"title":"数据结构-树","url":"/Arknight-notes/posts/19969.html","content":"树是常用的数据结构之一，种类很多比如二叉树，二叉查找树，平衡二叉树，红黑树，B 树，B+树等，本身就是一种递归结构\n什么是树？树是我们计算机中非常重要的一种数据结构，同时使用树这种数据结构，可以描述现实生活中的很多事物，例如家谱、单位的组织架构、等等。\n在计算机科学中，树是一种抽象数据类型（ADT）或是实现这种抽象数据类型的数据结构，用来模拟具有树状结构性质的数据集合。它是由 n（n&gt;0）个有限节点组成一个具有层次关系的集合。把它叫做“树”是因为它看起来像一棵倒挂的树，也就是说它是根朝上，而叶朝下的。它具有以下的特点：\n\n每个节点都只有有限个子节点或无子节点；\n没有父节点的节点称为根节点；\n每一个非根节点有且只有一个父节点；\n除了根节点外，每个子节点可以分为多个不相交的子树；\n树里面没有环路(cycle)\n\n术语\n节点的度：一个节点含有的子树的个数称为该节点的度；\n树的度：一棵树中，最大的节点度称为树的度；\n叶节点或终端节点：度为零的节点；\n非终端节点或分支节点：度不为零的节点；\n父亲节点或父节点：若一个节点含有子节点，则这个节点称为其子节点的父节点；\n孩子节点或子节点：一个节点含有的子树的根节点称为该节点的子节点；\n兄弟节点：具有相同父节点的节点互称为兄弟节点；\n节点的层次：从根开始定义起，根为第 1 层，根的子节点为第 2 层，以此类推；\n深度：对于任意节点 n,n 的深度为从根到 n 的唯一路径长，根的深度为 0；\n高度：对于任意节点 n,n 的高度为从 n 到一片树叶的最长路径长，所有树叶的高度为 0；\n堂兄弟节点：父节点在同一层的节点互为堂兄弟；\n节点的祖先：从根到该节点所经分支上的所有节点；\n子孙：以某节点为根的子树中任一节点都称为该节点的子孙。\n森林：由 m（m&gt;=0）棵互不相交的树的集合称为森林；\n\n                    A (根节点)                   / \\                  B   C                 / \\   \\                D   E   F               /       / \\              G       H   I (叶节点)             / \\            J   K (叶节点)- A是根节点，没有父节点- B是A的子节点，A是B的父节点- B和C是兄弟节点（具有相同父节点A）- G是叶节点（度为0）- B是非终端节点（度不为0，度为2）- 从A到K的路径长度为3，K的深度为3- 树的度为2（B节点的度最大）- B的度为2（有两个子节点D和E）- 整个结构是一个有序树（子节点有左右顺序）\n这个图示展示了以下树的基本概念：\n\n根节点：A 节点，整棵树的起始点\n父节点与子节点关系：如 A 是 B 和 C 的父节点，B 和 C 是 A 的子节点\n兄弟节点：B 和 C 具有相同的父节点 A，所以它们是兄弟节点\n叶节点：G、H、I、J、K 这些没有子节点的节点\n内部节点：A、B、C、D、E、F 这些有子节点的节点\n节点的度：B 的度为 2（有两个子节点），G 的度为 2（有两个子节点）\n树的度：整棵树的最大节点度，这里是 2\n路径与深度：从根节点 A 到任意节点的路径，如 A-&gt;B-&gt;D-&gt;G 的路径长度为 3\n\n树的种类有序/无序：\n\n无序树：树中任意节点的子节点之间没有顺序关系，这种树称为无序树，也称为自由树。\n有序树/搜索树/查找树：树中任意节点的子节点之间有顺序关系，这种树称为有序树。即树的所有节点按照一定的顺序排列，这样进行插入、删除、查找时效率就会非常高\n\n平衡/不平衡：\n\n平衡树\n绝对平衡树：所有叶节点在同一层\n非绝对平衡树\n\n\n不平衡树\n\n节点的分叉情况：\n\n等叉树：是每个节点的键值个数都相同、子节点个数也都相同\n二叉树：每个节点最多含有两个子树的树称为二叉树；\n完全二叉树：除了第 d 层外，其它各层的节点数目均已达最大值，且第 d 层所有节点从左向右连续地紧密排列，这样的二叉树被称为完全二叉树；\n满二叉树：所有叶节点都在最底层的完全二叉树；\n\n\n平衡二叉树、AVL 树：当且仅当任何节点的两棵子树的高度差不大于 1 的二叉树；\n排序二叉树：也称二叉查找树、二叉搜索树、有序二叉树；\n\n\n霍夫曼树：带权路径最短的二叉树称为哈夫曼树或最优二叉树；\n多叉树\n\n\n不等叉树：每个节点的键值个数不一定相同、子节点个数也不一定相同\nB 树：对不等叉树的节点键值数和插入、删除逻辑添加一些特殊的要求，使其能达到绝对平衡的效果。B 树全称 Balance Tree。如果某个 B 树上所有节点的分叉数最大值是 m，则把这个 B 数叫做 m 阶 B 树。\n\n\n\n二叉树二叉树就像它的名字一样，每个元素最多有两个节点，分别称为左节点和右节点。当然并不是每个元素都需要有两个节点，有的可能只有左节点，有的可能只有右节点。\n        A (根节点)       / \\      B   C     / \\   \\    D   E   F   /       / \\  G       H   I (叶节点) / \\J   K (叶节点)\n基于树的存储模式的不同，为了更好的利用存储空间，二叉树又分为完全二叉树和非完全二叉树：\n「完全二叉树」：叶子节点都在最底下两层，最后一层的叶子节点都靠左排列，并且除了最后一层，其他层的节点个数都要达到最大\n１、完全二叉树                    A (根节点)                   / \\                  B   C                 / \\   \\                D   E   F               /       / \\              G       H   I (叶节点)             / \\            J   K (叶节点)完全二叉树的顺序存储数组索引: [0][1][2][3][4][5][6][7][8]存储内容: [1][2][3][4][5][6][7][8][9]\n２、非完全二叉树        1       / \\      2   3     /     \\    4       5   /       / \\  6       7   8         /        9非完全二叉树的顺序存储数组索引: [0][1][2][3][4][5][6][7][8][9][10][11][12][13][14][15][16][17][18]存储内容: [1][2][3][4][ ][ ][5][6][ ][ ][ ][ ][ ][7][8][ ][ ][ ][9]存在大量空位，造成空间浪费\n二叉树的存储模式二叉树的存储模式有两种，一种是基于指针或者引用的二叉链式存储法，一种是基于数组的顺序存储法\n二叉链式存储法链式存储法相对比较简单，理解起来也非常容易，每一个节点都有三个字段，一个字段存储着该节点的值，另外两个字段存储着左右节点的引用。我们顺着跟字节就可以很轻松的把整棵树串起来\n链式存储法结构示意图：    节点A   /     \\  ↓       ↓节点B    节点C/   \\     /   \\↓    ↓   ↓    ↓...  ... ...  ...每个节点的内存结构：┌─────────────┬─────────────┬─────────────┐│    data     │    left     │    right    ││  (节点值)   │  (左子节点) │  (右子节点) │└─────────────┴─────────────┴─────────────┘      ↓              ↓             ↓    节点值       指向左子树    指向右子树                   的指针        的指针\n链式存储法的 C 语言实现：\n#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;// 二叉树节点定义typedef struct TreeNode {    int data;           // 节点数据    struct TreeNode* left;   // 左子节点指针    struct TreeNode* right;  // 右子节点指针} TreeNode;// 创建新节点TreeNode* createNode(int data) {    TreeNode* newNode = (TreeNode*)malloc(sizeof(TreeNode));    newNode-&gt;data = data;    newNode-&gt;left = NULL;    newNode-&gt;right = NULL;    return newNode;}// 示例：构建一个简单的二叉树TreeNode* buildSampleTree() {    TreeNode* root = createNode(1);    root-&gt;left = createNode(2);    root-&gt;right = createNode(3);    root-&gt;left-&gt;left = createNode(4);    root-&gt;left-&gt;right = createNode(5);    return root;}// 释放链式存储的二叉树内存void freeTree(TreeNode* root) {    if (root == NULL) {        return;    }    freeTree(root-&gt;left);    freeTree(root-&gt;right);    free(root);}// 使用示例void demonstrateStorageMethods() {    printf(\"=== 二叉树两种存储方式演示 ===\\n\");    // 1. 链式存储法    printf(\"\\n1. 链式存储法:\\n\");    TreeNode* linkedTree = buildSampleTree();    printf(\"前序遍历结果: \");    preOrderLinked(linkedTree);    printf(\"\\n\");    freeTree(linkedTree);    // 2. 顺序存储法    printf(\"\\n2. 顺序存储法:\\n\");    buildCompleteBinaryTree();    printArrayTree();    printf(\"前序遍历结果: \");    preOrderArray(0);    printf(\"\\n\");}/*对比两种存储方式：1. 链式存储法：   - 优点：灵活，不需要大片连续内存，插入删除节点方便   - 缺点：需要额外空间存储指针，遍历时需要多次内存跳转2. 顺序存储法：   - 优点：节省指针空间，访问节点速度快（通过数组下标直接访问）   - 缺点：对于非完全二叉树会造成空间浪费，插入删除节点复杂*/int main() {    demonstrateStorageMethods();    return 0;}\n顺序存储法顺序存储法是基于数组实现的，数组是一段有序的内存空间，如果我们把跟节点的坐标定位i=1，左节点就是 2  i = 2，右节点 2  i+ 1 = 3，以此类推，每个节点都这么算，然后就将树转化成数组了，反过来，按照这种规则我们也能将数组转化成一棵树。\n于是在这里我们就能发现一个问题：如果这是一颗不平衡的二叉树是不是会造成大量的空间浪费？这就是为什么需要分完全二叉树和非完全二叉树，分别来看看这两种树基于数组的存储模式。\n顺序存储法的 C 语言实现：\n#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#define MAX_TREE_SIZE 100// 用数组表示二叉树int treeArray[MAX_TREE_SIZE];int treeSize = 0;// 初始化数组void initTreeArray() {    for (int i = 0; i &lt; MAX_TREE_SIZE; i++) {        treeArray[i] = -1; // -1表示空节点    }}// 在指定位置插入节点void insertNode(int index, int data) {    if (index &gt;= MAX_TREE_SIZE) {        printf(\"数组越界\\n\");        return;    }    treeArray[index] = data;    if (index &gt;= treeSize) {        treeSize = index + 1;    }}// 获取父节点索引int getParentIndex(int index) {    if (index &lt;= 0) return -1;    return (index - 1) / 2;}// 获取左子节点索引int getLeftChildIndex(int index) {    int leftIndex = 2 * index + 1;    return (leftIndex &lt; MAX_TREE_SIZE) ? leftIndex : -1;}// 获取右子节点索引int getRightChildIndex(int index) {    int rightIndex = 2 * index + 2;    return (rightIndex &lt; MAX_TREE_SIZE) ? rightIndex : -1;}// 示例：构建完全二叉树void buildCompleteBinaryTree() {    initTreeArray();    // 构建一个简单的完全二叉树: 1, 2, 3, 4, 5    //       1    //      / \\    //     2   3    //    / \\    //   4   5    insertNode(0, 1);  // 根节点    insertNode(1, 2);  // 1的左子节点    insertNode(2, 3);  // 1的右子节点    insertNode(3, 4);  // 2的左子节点    insertNode(4, 5);  // 2的右子节点}// 打印数组表示的二叉树（层序遍历）void printArrayTree() {    printf(\"数组存储的二叉树: \");    for (int i = 0; i &lt; treeSize; i++) {        if (treeArray[i] != -1) {            printf(\"%d \", treeArray[i]);        } else {            printf(\"NULL \");        }    }    printf(\"\\n\");}// 前序遍历（数组实现）void preOrderArray(int index) {    if (index &gt;= treeSize || treeArray[index] == -1) {        return;    }    printf(\"%d \", treeArray[index]);    preOrderArray(2 * index + 1);  // 左子树    preOrderArray(2 * index + 2);  // 右子树}// 前序遍历（链式存储）void preOrderLinked(TreeNode* root) {    if (root == NULL) {        return;    }    printf(\"%d \", root-&gt;data);    preOrderLinked(root-&gt;left);    preOrderLinked(root-&gt;right);}\n对比两种存储方式：\n\n链式存储法：\n\n优点：灵活，不需要大片连续内存，插入删除节点方便\n缺点：需要额外空间存储指针，遍历时需要多次内存跳转\n\n\n顺序存储法：\n\n优点：节省指针空间，访问节点速度快（通过数组下标直接访问）\n缺点：对于非完全二叉树会造成空间浪费，插入删除节点复杂\n\n\n\n完全二叉树顺序存储法完全二叉树结构：        1       / \\      2   3     / \\ / \\    4  5 6  7   /  8数组存储方式（索引从0开始）：索引:  [0][1][2][3][4][5][6][7]值:    [1][2][3][4][5][6][7][8]父子节点关系：- 父节点索引为 i，则左子节点索引为 2*i+1，右子节点索引为 2*i+2- 子节点索引为 j，则父节点索引为 (j-1)/2（整数除法）具体对应关系：- 节点1(索引0): 左子节点2(索引1), 右子节点3(索引2)- 节点2(索引1): 左子节点4(索引3), 右子节点5(索引4)- 节点3(索引2): 左子节点6(索引5), 右子节点7(索引6)- 节点4(索引3): 左子节点8(索引7), 无右子节点- 节点5-8(索引4-7): 均为叶节点，无子节点\n非完全二叉树顺序存储法完全二叉树结构：        1       / \\      2   3     / \\ / \\    4  5 6  7   /  8数组存储方式（索引从0开始）：索引:  [0][1][2][3][4][5][6][7]值:    [1][2][3][4][5][6][7][8]父子节点关系：- 父节点索引为 i，则左子节点索引为 2*i+1，右子节点索引为 2*i+2- 子节点索引为 j，则父节点索引为 (j-1)/2（整数除法）具体对应关系：- 节点1(索引0): 左子节点2(索引1), 右子节点3(索引2)- 节点2(索引1): 左子节点4(索引3), 右子节点5(索引4)- 节点3(索引2): 左子节点6(索引5), 右子节点7(索引6)- 节点4(索引3): 左子节点8(索引7), 无右子节点- 节点5-8(索引4-7): 均为叶节点，无子节点\n从图中将树转化成数组之后可以看出，完全二叉树用数组来存储只浪费了一个下标为 0 的存储空间，非完全二叉树则浪费了大量的空间。「如果树为完全二叉树，用数组存储比链式存储节约空间，因为数组存储不需要存储左右节点的信息」\n\n二叉树遍历要了解二叉树的遍历，我们首先需要实例化出一颗二叉树，我们采用链式存储的方式来定义树，实例化树需要树的节点信息，用来存放该节点的信息，因为我们才用的是链式存储，所以我们的节点信息如下。\n/** * 定义一棵树 *//* 树节点的定义 */#define MAX_TREE_SIZE 100typedef struct{  TElemType data;  int parent; /* 父节点位置域 */} PTNode;typedef struct{  PTNode nodes[MAX_TREE_SIZE];  int n; /* 节点数 */} PTree;/* 二叉树节点的定义 */typedef struct TreeNode {    int data;    struct TreeNode* left;    struct TreeNode* right;} TreeNode;\n\n使用  PTNode  结构体表示树的节点，包含：\ndata：存储节点数据（类型为  TElemType）\nparent：存储父节点在数组中的索引位置\n\n\n使用  PTree  结构体表示整棵树，包含：\nnodes：节点数组，最多可容纳  MAX_TREE_SIZE  个节点\nn：实际节点数量\n\n\n\n定义完节点信息之后，我们就可以初始化一颗树啦，下面是初始化树的过程:\nTreeNode* buildTree() {// 创建测试用的二叉树TreeNode* t1 = (TreeNode*)malloc(sizeof(TreeNode));TreeNode* t2 = (TreeNode*)malloc(sizeof(TreeNode));TreeNode* t3 = (TreeNode*)malloc(sizeof(TreeNode));TreeNode* t4 = (TreeNode*)malloc(sizeof(TreeNode));TreeNode* t5 = (TreeNode*)malloc(sizeof(TreeNode));TreeNode* t6 = (TreeNode*)malloc(sizeof(TreeNode));TreeNode* t7 = (TreeNode*)malloc(sizeof(TreeNode));TreeNode* t8 = (TreeNode\\*)malloc(sizeof(TreeNode));    t1-&gt;data = 1;    t2-&gt;data = 2;    t3-&gt;data = 3;    t4-&gt;data = 4;    t5-&gt;data = 5;    t6-&gt;data = 6;    t7-&gt;data = 7;    t8-&gt;data = 8;    t1-&gt;left = t2;    t1-&gt;right = t3;    t2-&gt;left = t4;    t4-&gt;right = t7;    t3-&gt;left = t5;    t3-&gt;right = t6;    t6-&gt;left = t8;    t2-&gt;right = NULL;    t3-&gt;left = t5;    t3-&gt;right = t6;    t4-&gt;left = NULL;    t4-&gt;right = t7;    t5-&gt;left = NULL;    t5-&gt;right = NULL;    t6-&gt;left = t8;    t6-&gt;right = NULL;    t7-&gt;left = NULL;    t7-&gt;right = NULL;    t8-&gt;left = NULL;    t8-&gt;right = NULL;    return t1;}\n经过上面步骤之后，我们的树就长成下图所示的样子，数字代表该节点的值。\n构建的二叉树结构：        1       / \\      2   3     /   / \\    4   5   6     \\     /      7   8t1-&gt;left = t2; // 节点1的左子节点是节点2t1-&gt;right = t3; // 节点1的右子节点是节点3t2-&gt;left = t4; // 节点2的左子节点是节点4t4-&gt;right = t7; // 节点4的右子节点是节点7t3-&gt;left = t5; // 节点3的左子节点是节点5t3-&gt;right = t6; // 节点3的右子节点是节点6t6-&gt;left = t8; // 节点6的左子节点是节点8节点连接关系：- 节点1是根节点，左子节点为2，右子节点为3- 节点2的左子节点为4，右子节点为NULL- 节点3的左子节点为5，右子节点为6- 节点4的左子节点为NULL，右子节点为7- 节点5的左子节点为NULL，右子节点为NULL- 节点6的左子节点为8，右子节点为NULL- 节点7和8都是叶节点，没有子节点\n有了树之后，我们就可以对树进行遍历二叉树的遍历有三种方式，前序遍历，中序遍历，后续遍历三种遍历方式，三种遍历方式与节点输出的顺序有关系\n前序遍历「前序遍历」：对于树中的任意节点来说，先打印这个节点，然后再打印它的左子树，最后打印它的右子树。\n\n理解了前序遍历的概念和看完前序遍历执行流程动态图之后，你心里一定很想知道，在代码中如何怎么实现树的前序遍历？二叉树的遍历非常简单，一般都是采用递归的方式进行遍历，我们来看看前序遍历的代码：\n// 先序遍历，递归实现 先打印本身，再打印左节点，在打印右节点void preOrder(TreeNode\\* root) {if (root == NULL) {return;}// 输出本身printf(\"%d \", root-&gt;data);// 遍历左节点preOrder(root-&gt;left);// 遍历右节点preOrder(root-&gt;right);}\n中序遍历「中序遍历」：对于树中的任意节点来说，先打印它的左子树，然后再打印它本身，最后打印它的右子树。\n跟前序遍历一样，我们来看看中序遍历的执行流程动态图。\n\n中序遍历的代码：\n// 中序遍历 先打印左节点，再输出本身，最后输出右节点void inOrder(TreeNode\\* root) {if (root == NULL) {return;}inOrder(root-&gt;left);printf(\"%d \", root-&gt;data);inOrder(root-&gt;right);}\n后序遍历「后序遍历」：对于树中的任意节点来说，先打印它的左子树，然后再打印它的右子树，最后打印这个节点本身。\n跟前两种遍历一样，理解概念之后，我们还是先来看张图。\n\n后序遍历的实现代码：\n// 后序遍历 先打印左节点，再输出右节点，最后才输出本身void postOrder(TreeNode\\* root) {if (root == NULL) {return;}postOrder(root-&gt;left);postOrder(root-&gt;right);printf(\"%d \", root-&gt;data);}\n二叉树有三种遍历方式，但都是一样的，只是输出的顺序不一样\n接下来还有一种常用而且比较特殊的二叉树：「二叉查找树」\n二叉查找树二叉查找树又叫二叉搜索树，从名字中我们就能够知道，这种树在查找方面一定有过人的优势，事实确实如此，二叉查找树确实是为查找而生的树，但是它不仅仅支持快速查找数据，还支持快速插入、删除一个数据\n「二叉查找树」：在树中的任意一个节点，其左子树中的每个节点的值，都要小于这个节点的值，而右子树节点的值都大于这个节点的值，下面定义了一颗二叉查找树\n        62       /  \\      58   88     /  \\ /  \\    47  51 73  99   /           /  35          93   \\    37   /  \\  36  39       \\        42- 对于任意节点，其左子树中的所有节点值都小于该节点值- 其右子树中的所有节点值都大于该节点值- 根节点 `62`：左子树所有节点（58, 47, 35, 37, 36, 39, 42, 51）都小于 62；右子树所有节点（88, 73, 99, 93）都大于 62- 节点 `58`：左子树（47, 35, 37, 36, 39, 42）都小于 58；右子树（51）大于 58- 节点 `88`：左子树（73）小于 88；右子树（99, 93）大于 88\n根据二叉查找树的定义，每棵树的左节点的值要小于这父节点，右节点的值要大于父节点下面从二叉查找树的查找开始学习二叉查找树\n二叉查找树的查找操作由于二叉查找树的特性，我们需要查找一个数据，先跟跟节点比较，如果值等于跟节点，则返回根节点，如果小于根节点，则必然在左子树这边，只要递归查找左子树就行，如果大于，这在右子树这边，递归右子树即可。这样就能够实现快速查找，因为每次查找都减少了一半的数据，跟二分查找有点相似，快速插入、删除都是居于这个特性实现的。\n下面用一幅动态图来加强对二叉查找树查找流程的理解，在上面的这颗二叉查找树中找出值等于 37 的节点：\n\n\n1、先用 37 跟 62 比较，37 &lt; 62 ，在左子树中继续查找\n２、左子树的节点值为 58，37 &lt; 58 ，继续在左子树中查找\n３、左子树的节点值为 47，37 &lt; 47，继续在左子树中查找\n４、左子树的节点值为 35，37 &gt; 35，在右子树中查找\n５、右子树中的节点值为 37，37 = 37 ，返回该节点\n\n讲完了查找的概念之后，我们一起来看看二叉查找树的查找操作的代码实现\n/** * 在二叉查找树中查找指定值的节点 * @param tree 二叉查找树的根节点 * @param data 要查找的数据值 * @return 找到的节点指针，如果未找到则返回NULL */TreeNode* find(TreeNode* tree, int data) {    // 从根节点开始遍历    TreeNode* current = tree;    // 当当前节点不为空时继续查找    while (current != NULL) {        // 如果要查找的值小于当前节点值，在左子树中查找        if (data &lt; current-&gt;data) {            current = current-&gt;left;        }        // 如果要查找的值大于当前节点值，在右子树中查找        else if (data &gt; current-&gt;data) {            current = current-&gt;right;        }        // 如果值相等，找到了目标节点        else {            return current;        }    }    // 未找到目标节点    return NULL;}\n二叉查找树的插入操作插入跟查找差不多，也是从根节点开始找，如果要插入的数据比节点的数据大，并且节点的右子树为空，就将新数据直接插到右子节点的位置；如果不为空，就再递归遍历右子树，查找插入位置。同理，如果要插入的数据比节点数值小，并且节点的左子树为空，就将新数据插入到左子节点的位置；如果不为空，就再递归遍历左子树，查找插入位置。\n假设我们要插入 63 ，我们用一张动态图来看看插入的流程。\n\n\n1、63 &gt; 62 ，在树的右子树继续查找.\n2、63 &lt; 88 ，在树的左子树继续查找\n3、63 &lt; 73 ,因为 73 是叶子节点，所以 63 就成为了 73 的左子树。\n\n我们来看看二叉查找树的插入操作实现代码\n/** * 在二叉查找树中查找指定值的节点 * @param tree 二叉查找树的根节点 * @param data 要查找的数据值 * @return 找到的节点指针，如果未找到则返回NULL */TreeNode* find(TreeNode* tree, int data) {    // 从根节点开始遍历    TreeNode* current = tree;    // 当当前节点不为空时继续查找    while (current != NULL) {        // 如果要查找的值小于当前节点值，在左子树中查找        if (data &lt; current-&gt;data) {            current = current-&gt;left;        }        // 如果要查找的值大于当前节点值，在右子树中查找        else if (data &gt; current-&gt;data) {            current = current-&gt;right;        }        // 如果值相等，找到了目标节点        else {            return current;        }    }    // 未找到目标节点    return NULL;}\n二叉查找树的删除操作删除的逻辑要比查找和插入复杂一些，删除分一下三种情况：\n「第一种情况」：如果要删除的节点没有子节点，我们只需要直接将父节点中，指向要删除节点的指针置为 null。比如图中的删除节点 51。\n「第二种情况」：如果要删除的节点只有一个子节点（只有左子节点或者右子节点），我们只需要更新父节点中，指向要删除节点的指针，让它指向要删除节点的子节点就可以了。比如图中的删除节点 35。\n「第三种情况」：如果要删除的节点有两个子节点，这就比较复杂了。我们需要找到这个节点的右子树中的最小节点，把它替换到要删除的节点上。然后再删除掉这个最小节点，因为最小节点肯定没有左子节点（如果有左子结点，那就不是最小节点了），所以，我们可以应用上面两条规则来删除这个最小节点。比如图中的删除节点 88\n前面两种情况稍微简单一些，第三种情况，我制作了一张动态图，希望能对你有所帮助。\n\n我们来看看二叉查找树的删除操作实现代码\nvoid delete(TreeNode** tree, int data) {    TreeNode* p = *tree; // p指向要删除的节点，初始化指向根节点    TreeNode* pp = NULL; // pp记录的是p的父节点    while (p != NULL &amp;&amp; p-&gt;data != data) {        pp = p;        if (data &gt; p-&gt;data) p = p-&gt;right;        else p = p-&gt;left;    }    if (p == NULL) return; // 没有找到    // 要删除的节点有两个子节点    if (p-&gt;left != NULL &amp;&amp; p-&gt;right != NULL) { // 查找右子树中最小节点        TreeNode* minP = p-&gt;right;        TreeNode* minPP = p; // minPP表示minP的父节点        while (minP-&gt;left != NULL) {            minPP = minP;            minP = minP-&gt;left;        }        p-&gt;data = minP-&gt;data; // 将minP的数据替换到p中        p = minP; // 下面就变成了删除minP了        pp = minPP;    }    // 删除节点是叶子节点或者仅有一个子节点    TreeNode* child; // p的子节点    if (p-&gt;left != NULL) child = p-&gt;left;    else if (p-&gt;right != NULL) child = p-&gt;right;    else child = NULL;    if (pp == NULL) *tree = child; // 删除的是根节点    else if (pp-&gt;left == p) pp-&gt;left = child;    else pp-&gt;right = child;    free(p); // 释放被删除节点的内存}\n二叉查找树在极端情况下会退化成链表，例如每个节点都只有一个左节点，这是时间复杂度就变成了 O(n)，为了避免这种情况，又出现了一种新的树叫「平衡二叉查找树」，之后再开坑讲\n还有个前缀树，之后也会开坑讲一下\n","categories":["数据结构"],"tags":["数据结构"]},{"title":"记一次配置Obsidian配合Hexo写博客","url":"/Arknight-notes/posts/t2zf3s.html","content":"测试，现在新写了个插件，晚上回来整\n看网上教程又是整Templates又是整quickadd太麻烦，遂自己写了一个插件\n地址 https://github.com/Zhongye1/obsidian-with-hexo\n\n\n首先使用 obsidian 打开现有Hexo项目的 source/_posts 作为文章目录，然后什么博客文章操作一键完成就行了\n差不多，没啥好水的\n","categories":["笔记"],"tags":["日志"]},{"title":"2025-10-24-10.20课题","url":"/Arknight-notes/posts/45309.html","content":"设定：​​\n存在两个独立的、我们无法直接观测的随机过程 B和 S。它们分别服从泊松分布：\nB ~ Poisson(b)： 参数为 b\nS ~ Poisson(q)： 参数为 q\n我们唯一能观测到的是它们的总和 Y = B + S由于泊松分布的可加性，Y本身也服从泊松分布：Y ~ Poisson(b + q)现在引入了另一个可观测的变量 W ~ Poisson(m * b)于是同时拥有了两个可观测变量：Y和 W\n目标是利用 (Y, W)的联合观测数据，来估计出那些未知的参数：b, q, 以及可能的 m​\n含隐变量的模型​​复合分布问题​​参数估计问题​​解决这类问题最常用的方法是 ​​最大似然估计​​ 和 ​​期望最大化算法​​\n","categories":["归档"],"tags":["日志"]},{"title":"数据结构-队列","url":"/Arknight-notes/posts/27379.html","content":"队列（queue）是只允许在一端进行插入操作，在另一端进行删除操作的线性表\n这个的特点是先进先出（First In First Out）然后是允许插入的一端称为队尾（rear），允许删除的一端称为队头(front)。向队列中插入新的数据元素称为入队。从队列中删除队头元素称为出队。\n队列示意图（先进先出 FIFO）：    ┌─────┬─────┬─────┬─────┬─────┐    │  A  │  B  │  C  │  D  │     │    └─────┴─────┴─────┴─────┴─────┘       ↑                       ↑    队头(front)             队尾(rear)元素入队过程：1. 空队列：    [     ][     ][     ][     ]                  ↑            front/rear2. A入队：    [  A  ][     ][     ][     ]                 ↑     ↑               front  rear3. B入队：    [  A  ][  B  ][     ][     ]                 ↑      ↑               front   rear4. C入队：    [  A  ][  B  ][  C  ][     ]                 ↑             ↑               front          rear元素出队过程：1. A出队：    [     ][  B  ][  C  ][     ]                        ↑      ↑                      front   rear2. B出队：    [     ][     ][  C  ][     ]                        ↑      ↑                      front   rear\n队列的顺序存储结构顺序队列用一组地址连续的存储单元，依次存放从队头到队尾的数据元素，称为顺序队列。实现顺序队列需要设两个指针：队头指针（front）和队尾指针（rear），分别指向队头元素和队尾元素。\n顺序队列结构示意图：数组索引:  [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]存储内容:  [A]  [B]  [C]  [D]  [  ] [  ] [  ] [  ]            ↑              ↑          front          rear队列状态：- 队头元素：A（位于索引0）- 队尾元素：D（位于索引3）- 下一个插入位置：索引4- 队列长度：4个元素插入操作：- 新元素将插入到 rear 指针位置- 插入后 rear 指针向后移动一位删除操作：- 从 front 指针位置删除元素- 删除后 front 指针向后移动一位\n如果在插入 E 的基础上再插入元素 F，将会插入失败。因为 rear == MAXSIZE，尾指针已经达到队列的最大长度。但实际上队列存储空间并未全部被占满，这种现象叫做假溢出\n假溢出问题：数组索引:  [0]  [1]  [2]  [3]  [4]  [5]存储内容:  [  ] [  ] [  ] [C]  [D]  [E]                           ↑         ↑                          front    rear问题分析：- 实际可用空间：索引0、1、2（3个位置）- rear指针已到达数组末尾（索引5）- 即使前面有空闲空间，也无法继续插入新元素- 这种现象称为&quot;假溢出&quot;\n通过上图可以发现队头出队、对尾入队造成了数组前面的空间未被利用而出现假溢出。\n为了解决“假溢出”现象，使得队列的存储空间得到充分利用，一个非常巧妙的方法就是将顺序队列的数组看成一个头尾相接的循环结构。\n循环队列graph TD    subgraph &quot;循环队列 (大小=5)&quot;        Cell0[0: a6] --&gt; Cell1[1: 空] --&gt; Cell2[2: a3] --&gt; Cell3[3: a4] --&gt; Cell4[4: a5]        Cell4 -.-&gt; Cell0    end    Front[front指针] --&gt; Cell2    Rear[rear指针] --&gt; Cell1    style Cell2 fill:#e8f5e8    style Cell1 fill:#fff3e0\n现在队满了，但是队头指针和队尾指针相等（队空的时候也是这样）。那么该怎么判断队空还是队满？\n\n两种解决方案\n\n\n设置一个计数器，开始的时候为 0，当有元素入队时+1，有元素出队时-1，值为 MAXSIZE 时队满\n保留一个元素空间，当队尾指针指的空单元的下一个单元是队头指针所指单元是为对满\n\n队满的条件（Queue.rear+1）%MAXSIZE == Queue.front队空的条件 Queue.rear=Queue.front\n循环队列结构\n#define MAXSIZE 20/*循环队列的存储结构*/typedef structQueue&#123;    int data[MAXSIZE];    int front;    //头指针    int rear;    //尾指针&#125;Queue;\n操作\n/*初始化空队列*/int InitSeQueue(Queue* queue);/*获得队列长度*/int GetLength(Queue* queue);/*判空*/bool isEmpty(Queue* queue);/*判满*/bool isFull(Queue* queue);/*入队操作*/int EnterQueue(Queue* queue, int e);/*出队操作*/int ExitQueue(Queue* queue, int e);\n初始化空队列void InitSeQueue(Queue* queue)&#123;    queue-&gt;front = 0;    queue-&gt;rear = 0;    return 0;&#125;\n获得队列长度int GetLength(Queue* queue)&#123;    return (queue-&gt;rear-queue-&gt;front+MAXSIZE)%MAXSIZE;&#125;\n判空bool isEmpty(Queue* queue)&#123;    return queue-&gt;front==queue-&gt;rear;&#125;\n判满bool isFull(Queue* queue)&#123;    return (queue-&gt;rear+1)%MAXSIZE==queue-&gt;front;&#125;\n入队void EnterQueue(Queue* queue, int e)&#123;    if (isFull(queue))    &#123;        printf(&quot;队列满了\\n&quot;);        return;    &#125;    else    &#123;        queue-&gt;data[queue-&gt;rear] = e;        queue-&gt;rear = (queue-&gt;rear + 1) % MAXSIZE;//求模，rear的值就在[0,MAXSIZE-1]循环    &#125;&#125;\nqueue-&gt;data[queue-&gt;rear] = e;将要入队的元素 e 存储到队尾指针 rear 所指向的位置，这是实际的数据插入操作\nqueue-&gt;rear = (queue-&gt;rear + 1) % MAXSIZE;将队尾指针 rear 向后移动一位使用模运算(queue-&gt;rear + 1) % MAXSIZE 实现循环效果当 rear 到达数组末尾时，会自动回到数组开头（索引 0）,利用了数组的存储空间，避免了顺序队列的”假溢出”问题\n出队void ExitQueue(Queue* queue, int*e)&#123;     if (isEmpty(queue))    &#123;        printf(&quot;已经是空队列了\\n&quot;);        return;    &#125;    else    &#123;        *e = queue-&gt;data[queue-&gt;front];        queue-&gt;front = (queue-&gt;front + 1) % MAXSIZE;//注意不要写成(queue-&gt;front - 1)    &#125;&#125;\n其中 *e = queue-&gt;data[queue-&gt;front];\nqueue-&gt;front是队头指针，指向队列的第一个有效元素位置queue-&gt;data[queue-&gt;front]表示获取队头位置存储的数据元素e是一个指向整型变量的指针*e表示对这个指针进行解引用，访问指针指向的内存位置\n整体操作： - 将队头元素的值赋给调用者传入的变量地址 - 这样调用函数就能获取到出队的元素值\n队列的链式存储结构链队列由单链表组成，队头指针指向链表的头结点，队尾指针指向尾节点。空队列时队头指针和队尾指针都指向头节点。\n链队列结构示意图：空队列状态：    front → [头节点] ← rear              ↓             NULL入队元素A后：    front → [头节点] → [A] ← rear             ↓          ↓            [A]       NULL入队元素B后：    front → [头节点] → [A] → [B] ← rear               ↓        ↓     ↓              [A]      [B]   NULL入队元素C后：    front → [头节点] → [A] → [B] → [C] ← rear              ↓         ↓     ↓     ↓             [A]       [B]   [C]   NULL出队元素A后：    front → [头节点] → [B] → [C] ← rear             ↓         ↓      ↓            [B]       [C]    NULL使用单链表实现，front 指针指向头节点rear 指针指向队尾节点头节点不存储数据，仅作为队列的起始标记入队操作在队尾进行，出队操作在队头进行不存在假溢出问题，可根据需要动态分配内存空间\n链队列结构\n/*结点结构*/typedef struct Node&#123;    int data;    struct Node *next;&#125;Node;/*链队列结构*/typedef struct LinkQueue&#123;    Node* front,rear;//队头、队尾指针&#125;LinkQueue;\n初始化链队列void InitLinkQueue(LinkQueue* LinkQ)&#123;    Node* head = malloc(sizeof(Node));    if (LinkQ != NULL &amp;&amp; head != NULL)    &#123;        LinkQ-&gt;front = LinkQ-&gt;rear = head;        head-&gt;next = NULL;    &#125;&#125;\n判空bool isEmpty(LinkQueue* LinkQ)&#123;    return LinkQ-&gt;front == LinkQ-&gt;rear;&#125;\n入队void EnterLinkQueue(LinkQueue* LinkQ, int x)&#123;    /* 创建新节点并分配内存空间 */    Node* node = malloc(sizeof(Node));    /* 将待插入数据存入新节点 */    node-&gt;data = x;    /* 设置新节点的后继指针为空 */    node-&gt;next = NULL;    /* 将新节点连接到当前队尾节点之后 */    LinkQ-&gt;rear-&gt;next = node;    /* 更新队尾指针，指向新插入的节点 */    LinkQ-&gt;rear = node;&#125;\n链队列的入队操作：\n创建新节点：动态分配内存创建新节点设置节点数据：将入队元素 x 存入新节点连接节点：将新节点链接到当前队尾节点之后更新队尾指针：将队尾指针指向新加入的节点\n出队void ExitLinkQueue(LinkQueue* LinkQ, int* x)&#123;    if (isEmpty(LinkQ)) //首先判断队列是否为空，如果为空则直接返回        return;    Node* node = malloc(sizeof(Node));    //保留删除结点的信息    node = LinkQ-&gt;front-&gt;next;    *x = LinkQ-&gt;front-&gt;data; //将队头节点的数据赋值给输出参数x    //建立新联系    LinkQ-&gt;front-&gt;next = node-&gt;next; // 跳过被删除节点，将队头直接连接到下一个节点    //如果队尾出队了，那么就是空队    if (LinkQ-&gt;rear == node)        LinkQ-&gt;front = LinkQ-&gt;rear;    free(node);&#125;\n","categories":["数据结构"],"tags":["数据结构"]},{"title":"2024一些笔记（常微分）","url":"/Arknight-notes/posts/40883.html","content":"2024的一些笔记（常微分）（共20张）\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nebp)\n","categories":["笔记"],"tags":["常微分"]},{"title":"2025-10-28-常用杂记","url":"/Arknight-notes/posts/40483.html","content":"综合查找：端口-&gt;进程-&gt;工作目录lsof -i :3001 | awk ‘NR&gt;1 {print $2}’ | xargs -I {} pwdx {} 2&gt;/dev/null\n或者更详细的版本lsof -i :3001 | awk ‘NR&gt;1 {print Extra close brace or missing open brace2}’ | while read pid; do   echo “PID: pid”  echo “工作目录: pid 2&gt;/dev/null)”  echo “命令: pid -o command= 2&gt;/dev/null)”  echo “—-“done\nlsof -ti:3001 | xargs kill -9\n","categories":["归档"],"tags":["日志"]},{"title":"2025-11-02 组会朝花夕拾","url":"/Arknight-notes/posts/26939.html","content":"设定：\n存在两个独立的、我们无法直接观测的泊松过程  和 。它们分别服从泊松分布：：参数为 ：参数为 我们唯一能观测到的是它们的总和 \n由于泊松分布的可加性， 本身也服从泊松分布：现在引入了另一个可观测的变量 于是同时拥有了两个可观测变量： 和 \n\n目标：利用  的联合观测数据，来估计出那些未知的参数：, , 以及可能的 \n\n\n\n\n\n，\n构造 \n可观测的对象：，\n现在需要对  做推断/检验，看有无区间严格保证 \n两个方法：\n\n参考之前文章的 idea 直接推\n用随机加权的 IM 方法\n\n随机加权的 IM 方法的话就是：\n利用随机加权的 IM 方法为参数 构造置信区间\n差不多研究下相关的文献之后再研究\nY = B + S S ~ P(lambda) B ~ P(b) ==&gt; Y ~ P(STA) STA = lambda + b\n构造 W ~ P(m * b)\n可观测 obser： Y = y ， W = w问题 QUS：对 lambda 做推断/检验 看有无区间严格保证 1- a 属于 I\n两个方法：\n\n参考之前文章的 idea 直接推\n用随机加权的 ificent model\n\n随机加权的 ificent model：\nstep1：\nQ： Y~P(STA) STA = lambda + b\nF_STA(Y-1) &lt;= u &lt; F_STA(Y)u,v ~ Unif(0,1)\nF_mb(w-1) &lt;= v &lt;= F_mb(w)\nstep2:\nG(STA): w_1: F_STA(Y-1)+(1-w_1)F_STA(Y) = u (关于 STA 的递减函数)H(mb): w_2: F_mb(w-1) + (1-w_2)F_mb(w) =v\nstep3:\nSTA = [G(u)]^(-1) , b = [H(v)]^(-1)/m ==&gt;lambda = [G(u)]^(-1)-[H(v)]^(-1)\nstep4:\n模拟验证：\n对 U,V ~ Unif(0,1) -&gt; 生成 10000 个样本\nW1，W2 ~ Unif(0,1) -&gt; 10000\nfor 循环 for u,v,W_1,W_2\nlambda = [G(u)]^(-1)-[H(v)]^(-1) -&gt; 10000 个解\n得到[lambda上区间，lambda下区间] = [lambda_0.025，lambda_0.095] lambda 的上分位数下分位数\n10000 次样本有无落入其中： true lambda = STA - b\n关注作差后覆盖率好不好 N/ 10000 (能否保证)\n结果如何\n好-》 成功不好—》 h 函数继续优化\n","categories":["归档"],"tags":["日志"]},{"title":"2025-11-04-JavaScript 常用方法速查","url":"/Arknight-notes/posts/36778.html","content":"JavaScript 常用方法速查\n数组\n\n\n\n方法\n说明\n示例\n返回值/副作用\n\n\n\n\npush(...items)\n末尾添加元素\narr.push(4) → 修改原数组\n返回新数组长度\n\n\npop()\n删除末尾元素\narr.pop() → 修改原数组\n返回被删除元素\n\n\nunshift(...items)\n开头添加元素\narr.unshift(0) → 修改原数组\n返回新数组长度\n\n\nshift()\n删除开头元素\narr.shift() → 修改原数组\n返回被删除元素\n\n\nslice(start, end)\n截取数组片段（不修改原数组）\narr.slice(1, 3)\n返回新数组\n\n\nsplice(start, deleteCount, ...items)\n删除/替换元素\narr.splice(1, 2, 'a') → 修改原数组\n返回被删除元素组成的数组\n\n\nmap(callback)\n遍历并返回新数组\n[1,2,3].map(x =&gt; x*2) → [2,4,6]\n新数组\n\n\nfilter(callback)\n过滤符合条件的元素\n[1,2,3].filter(x =&gt; x&gt;1) → [2,3]\n新数组\n\n\nreduce(callback, initialValue)\n累计计算（如求和、统计）\n[1,2,3].reduce((sum, x) =&gt; sum + x, 0) → 6\n最终累计值\n\n\nfind(callback)\n查找第一个符合条件的元素\n[1,2,3].find(x =&gt; x&gt;1) → 2\n元素或  undefined\n\n\nfindIndex(callback)\n查找第一个符合条件的索引\n[1,2,3].findIndex(x =&gt; x&gt;1) → 1\n索引或  -1\n\n\nincludes(value)\n判断是否包含某元素（ES6）\n[1,2,3].includes(2) → true\n布尔值\n\n\nflat(depth)\n扁平化嵌套数组（ES2019）\n[1, [2]].flat() → [1, 2]\n新数组\n\n\n\n\n字符串\n\n\n\n方法\n说明\n示例\n返回值\n\n\n\n\nsplit(separator)\n按分隔符拆分为数组\n\"a,b,c\".split(\",\") → [\"a\", \"b\", \"c\"]\n数组\n\n\nsubstring(start, end)\n截取子字符串（不包含  end  索引）\n\"Hello\".substring(1, 3) → \"el\"\n新字符串\n\n\nslice(start, end)\n截取子字符串（支持负数索引）\n\"Hello\".slice(-3) → \"llo\"\n新字符串\n\n\nreplace(searchValue, newValue)\n替换匹配内容（支持正则表达式）\n\"abc\".replace(\"a\", \"A\") → \"Abc\"\n新字符串\n\n\ntoUpperCase()\n转为大写\n\"hello\".toUpperCase() → \"HELLO\"\n新字符串\n\n\ntoLowerCase()\n转为小写\n\"HELLO\".toLowerCase() → \"hello\"\n新字符串\n\n\ntrim()\n去除首尾空格（ES5）\n\" hello \".trim() → \"hello\"\n新字符串\n\n\nstartsWith(str)\n判断是否以某字符串开头（ES6）\n\"hello\".startsWith(\"he\") → true\n布尔值\n\n\nendsWith(str)\n判断是否以某字符串结尾（ES6）\n\"hello\".endsWith(\"lo\") → true\n布尔值\n\n\npadStart(length, padStr)\n头部填充字符串（ES2017）\n\"5\".padStart(3, \"0\") → \"005\"\n新字符串\n\n\n\n\n对象方法\n\n\n\n方法\n描述\n\n\n\n\nObject.assign()\n方法用于将所有可枚举属性的值从一个或多个源对象复制到目标对象。它将返回目标对象。\n\n\nObject.create()\n方法创建一个新对象，使用现有的对象来提供新创建的对象的proto。\n\n\nObject.defineProperties()\n方法直接在一个对象上定义新的属性或修改现有属性，并返回该对象。\n\n\nObject.defineProperty()\n方法会直接在一个对象上定义一个新属性，或者修改一个对象的现有属性，并返回此对象。\n\n\nObject.entries()\n方法返回一个给定对象自身可枚举属性的键值对数组，其排列与使用 for…in 循环遍历该对象时返回的顺序一致。\n\n\nObject.freeze()\n方法可以冻结一个对象。\n\n\nObject.fromEntries()\n方法把键值对列表转换为一个对象。\n\n\nObject.getOwnPropertyDescriptor()\n方法返回指定对象上一个自有属性对应的属性描述符。\n\n\nObject.getOwnPropertyDescriptors()\n方法用来获取一个对象的所有自身属性的描述符。\n\n\nObject.getOwnPropertyNames()\n方法返回一个由指定对象的所有自身属性的属性名（包括不可枚举属性但不包括 Symbol 值作为名称的属性）组成的数组。\n\n\nObject.getOwnPropertySymbols()\n方法返回一个给定对象自身的所有 Symbol 属性的数组。\n\n\nObject.getPrototypeOf()\n方法返回指定对象的原型（内部[[Prototype]]属性的值）。\n\n\nObject.is()\n方法判断两个值是否为同一个值。\n\n\nObject.isExtensible()\n方法判断一个对象是否是可扩展的（是否可以在它上面添加新的属性）。\n\n\nObject.isFrozen()\n方法判断一个对象是否被冻结。\n\n\nObject.preventExtensions()\n方法让一个对象变的不可扩展，也就是永远不能再添加新的属性。\n\n\nObject.isSealed()\n方法判断一个对象是否被密封。\n\n\nObject.keys()\n方法会返回一个由一个给定对象的自身可枚举属性组成的数组，数组中属性名的排列顺序和正常循环遍历该对象时返回的顺序一致 。\n\n\nObject.setPrototypeOf()\n方法设置一个指定的对象的原型到另一个对象。\n\n\nObject.values()\n方法返回一个给定对象自身的所有可枚举属性值的数组。\n\n\nObject.seal()\n方法封闭一个对象，阻止添加新属性并将所有现有属性标记为不可配置。\n\n\n\n\nNumber 方法Number 对象本身有一些静态属性和方法，而 Number 实例的方法是通过 Number.prototype 定义的，但通常我们使用数字字面量时可以直接调用这些方法（因为 JavaScript 会自动装箱）\n\n\n\n\n名称\n描述\n\n\n\n\nconstructor\n返回对创建此对象的 Number 函数的引用。\n\n\nisFinite()\n检查值是否是有限数。\n\n\nisInteger()\n检查值是否为整数。\n\n\nisNaN()\n检查值是否为 Number.NaN。\n\n\nparseFloat()\n检查值是否为整数。\n\n\nparseInt()\n检查值是否为整数。\n\n\nprototype\n允许您向对象添加属性和方法。\n\n\ntoFixed(x)\n把数字转换为字符串，结果的小数点后有指定位数的数字。\n\n\ntoPrecision(x)\n把数字格式化为指定的长度。\n\n\ntoString()\n把数字转换为字符串。\n\n\nvalueOf()​\n返回数字的原始值（基本数字值）。\n\n\n\n\nMath 方法Math 对象是一个静态对象，它包含了许多数学常数和函数。\n\n\n\n\n方法名\n描述\n\n\n\n\nMath.abs(x)\n返回一个数的绝对值。\n\n\nMath.ceil(x)\n返回大于或等于一个数的最小整数（向上取整）。\n\n\nMath.floor(x)\n返回小于或等于一个数的最大整数（向下取整）。\n\n\nMath.round(x)\n返回一个数四舍五入后的整数。\n\n\nMath.max([value1[, value2[, …]]])\n返回一组数中的最大值。\n\n\nMath.min([value1[, value2[, …]]])\n返回一组数中的最小值。\n\n\nMath.pow(x, y)\n返回 x 的 y 次幂。\n\n\nMath.sqrt(x)\n返回一个数的平方根。\n\n\nMath.random()\n返回一个 0 到 1 之间的伪随机数。\n\n\nMath.sin(x)\n返回一个数的正弦值。\n\n\nMath.cos(x)\n返回一个数的余弦值。\n\n\nMath.tan(x)\n返回一个数的正切值。\n\n\nMath.log(x)\n返回一个数的自然对数。\n\n\nMath.exp(x)\n返回 e 的 x 次幂。\n\n\n\n\nDate 对象方法Date 对象用于处理日期和时间\n静态方法\n\n\n\n方法名\n描述\n\n\n\n\nDate.now()\n返回自 1970 年 1 月 1 日 00:00:00 UTC 到当前时间的毫秒数。\n\n\nDate.parse(dateString)\n解析一个表示日期的字符串，并返回从 1970-1-1 00:00:00 UTC 所经过的毫秒数。\n\n\nDate.UTC(year, month[, day[, hour[, minute[, second[, millisecond]]]]])\n接受和构造函数最长形式的参数相同的参数，并返回从 1970-1-1 00:00:00 UTC 所经过的毫秒数。\n\n\n\n\n实例方法\n\n\n\n方法名\n描述\n\n\n\n\ngetFullYear()\n根据本地时间返回指定日期对象的年份。\n\n\ngetMonth()\n根据本地时间返回指定日期对象的月份（0-11）。\n\n\ngetDate()\n根据本地时间返回指定日期对象的日期（1-31）。\n\n\ngetDay()\n根据本地时间返回指定日期对象的星期（0-6）。\n\n\ngetHours()\n根据本地时间返回指定日期对象的小时（0-23）。\n\n\ngetMinutes()\n根据本地时间返回指定日期对象的分钟（0-59）。\n\n\ngetSeconds()\n根据本地时间返回指定日期对象的秒数（0-59）。\n\n\ngetMilliseconds()\n根据本地时间返回指定日期对象的毫秒数。\n\n\ngetTime()\n返回从 1970-1-1 00:00:00 UTC 到该日期经过的毫秒数。\n\n\nsetFullYear(year, [month], [day])\n根据本地时间设置指定日期对象的年份。\n\n\nsetMonth(month, [day])\n根据本地时间设置指定日期对象的月份。\n\n\nsetDate(day)\n根据本地时间设置指定日期对象的日期。\n\n\nsetHours(hour, [min], [sec], [ms])\n根据本地时间设置指定日期对象的小时。\n\n\nsetMinutes(min, [sec], [ms])\n根据本地时间设置指定日期对象的分钟。\n\n\nsetSeconds(sec, [ms])\n根据本地时间设置指定日期对象的秒数。\n\n\nsetMilliseconds(ms)\n根据本地时间设置指定日期对象的毫秒数。\n\n\nsetTime(time)\n通过指定从 1970-1-1 00:00:00 UTC 开始经过的毫秒数来设置日期对象。\n\n\ntoISOString()\n返回一个 ISO 格式的字符串：YYYY-MM-DDTHH:mm:ss.sssZ。\n\n\ntoLocaleString()\n返回一个表示日期对象的字符串，该字符串与当地环境的语言相对应。\n\n\n\n\nJSON 对象的方法\n\n\n\n方法名\n描述\n\n\n\n\nJSON.parse(text[, reviver])\n将一个 JSON 字符串转换为对象。\n\n\nJSON.stringify(value[, replacer[, space]])\n将一个值转换为 JSON 字符串。\n\n\n\n\nMap 对象的方法\n\n\n\n方法名\n描述\n\n\n\n\nset(key, value)\n设置 Map 对象中键的值，返回该 Map 对象。\n\n\nget(key)\n返回键对应的值，如果不存在，则返回 undefined。\n\n\nhas(key)\n返回一个布尔值，表示 Map 实例是否包含键对应的值。\n\n\ndelete(key)\n删除 Map 中的元素，删除成功返回 true，否则返回 false。\n\n\nclear()\n移除 Map 对象中的所有元素。\n\n\nkeys()\n返回一个新的 Iterator 对象，它按插入顺序包含了 Map 对象中每个元素的键。\n\n\nvalues()\n返回一个新的 Iterator 对象，它按插入顺序包含了 Map 对象中每个元素的值。\n\n\nentries()\n返回一个新的 Iterator 对象，它按插入顺序包含了 Map 对象中每个元素的[key, value]数组。\n\n\nforEach(callbackFn[, thisArg])\n按插入顺序，为 Map 对象里的每一键值对调用一次 callbackFn 函数。\n\n\n\n\nSet 对象的方法\n\n\n\n方法名\n描述\n\n\n\n\nadd(value)\n在 Set 对象尾部添加一个元素，返回该 Set 对象。\n\n\nhas(value)\n返回一个布尔值，表示该值在 Set 中存在与否。\n\n\ndelete(value)\n移除 Set 中与这个值相等的元素，返回 Set.prototype.has(value)在这个操作前返回的值。\n\n\nclear()\n移除 Set 对象内的所有元素。\n\n\nkeys()\n返回一个新的 Iterator 对象，该对象包含 Set 对象中的按插入顺序排列的所有元素的值。\n\n\nvalues()\n与 keys()方法相同，返回一个新的 Iterator 对象。\n\n\nentries()\n返回一个新的 Iterator 对象，该对象包含 Set 对象中的按插入顺序排列的所有元素的值的[value, value]数组。\n\n\nforEach(callbackFn[, thisArg])\n按照插入顺序，为 Set 对象中的每一个值调用一次 callBackFn。\n\n\n\n\nPromise 对象的方法\n\n\n\n方法名\n描述\n\n\n\n\nPromise.all(iterable)\n返回一个新的 Promise，它在 iterable 中所有的 Promise 都成功时才成功，只要有一个失败就失败。\n\n\nPromise.race(iterable)\n返回一个新的 Promise，它在 iterable 中任意一个 Promise 解决或拒绝时立即解决或拒绝。\n\n\nPromise.resolve(value)\n返回一个以给定值解析后的 Promise 对象。\n\n\nPromise.reject(reason)\n返回一个带有拒绝原因的 Promise 对象。\n\n\n\n\n函数与高阶方法\n\n\n\n方法/语法\n说明\n示例\n\n\n\n\nbind(thisArg, ...args)\n绑定  this  并返回新函数\nfunc.bind(obj) → 新函数\n\n\ncall(thisArg, ...args)\n立即调用函数并指定  this\nfunc.call(obj, 1, 2)\n\n\napply(thisArg, [args])\n立即调用函数并指定  this（参数为数组）\nfunc.apply(obj, [1, 2])\n\n\nsetTimeout(callback, delay)\n延迟执行函数（返回定时器 ID）\nsetTimeout(() =&gt; {}, 1000) → ID\n\n\nsetInterval(callback, delay)\n循环执行函数（返回定时器 ID）\nsetInterval(() =&gt; {}, 1000) → ID\n\n\n\n\nRegExp 方法\n\n\n\n方法名\n描述\n\n\n\n\nexec(string)\n在一个指定字符串中执行一个搜索匹配。返回一个结果数组或 null。\n\n\ntest(string)\n执行一个检索，用来查看正则表达式与指定的字符串是否匹配。返回 true 或 false。\n\n\n\n\n其他\n\n\n\n方法名\n描述\n\n\n\n\neval(string)\n执行字符串形式的 JavaScript 代码。\n\n\nisNaN(value)\n判断一个值是否是 NaN。注意：全局的 isNaN 会先将参数转换为数值再判断。\n\n\nisFinite(value)\n判断一个值是否是有限数字。\n\n\nparseFloat(string)\n将字符串解析成浮点数。\n\n\nparseInt(string, radix)\n将字符串解析成整数。\n\n\n\n\n【待补充】\n","categories":["归档"],"tags":["前端开发"]},{"title":"2025-11-09-关于软考高项网规","url":"/Arknight-notes/posts/53411.html","content":"\n\n早八去东风路考试，上午选择大概考了网络基础概念 OSI 模型、编码传输之类，另外就是问企业内部网络规划（VLAN、路由交换）、路由协议（OSPF、BGP）、传输应用层（TCP/IP、DNS）及网络管理（SNMP），差不多还有广域网接入、无线与 IPv6，问了下网络安全解决方案（防火墙、VPN、加密认证）、服务器存储与容灾技术，网络规划设计与实施能力，加上一些操作系统、项目管理，专业英语之类的八股\n然后案例分析问了网络安全、无线网络规划和存储容灾之类的内容，第一题问一家公司网络中存在大量用户敏感信息，还不进行网络安全等级保护测评，业务烂的要死被勒索病毒攻击事件还不立马断网还查资料把整个单位崩了之类的情况让你分析 （安全问题加钱就完了，开月薪 3000 谁给你写 waf）\n第二题问在图书馆、教学楼、宿舍、操场、体育馆等不同场景下进行无线网络部署的工作，​ 比较 2.4G、5G、6G 等不同无线频段的特性（答了穿透性、速率、干扰、信道数量），再问设备选型之类（密集放装型、面板型、室外定向天线），还问怎么写一万人使用的网络设计方案\n第三题问某公司的数据备份和存储架构规划，问备份策略（全量/增量通过 IPSec VPN 传输）的不足（一眼带宽占用大、恢复时间长），提出改进措施（如改用专线、增量永久合成等技术，一时半会没想到都），然后就是问提升集中式存储可靠性的技术（如 RAID、双控制器、快照、镜像等）。再问技术选型，对比集中式存储和分布式存储在架构、冗余机制、扩展性和性能等方面的差异，比较堆叠和 MLAG 这两种提高网络可靠性的技术差异之类。\n论文是讲国家教育数字化战略，推进智慧校园建设相关的内容，“论智慧校园网络规划与设计”，比如智慧校园要如何满足同城双校区网络互联，无线网络覆盖，智慧教室专网，校园安防专网等基本需求。说是要结合自身参与规划、设计和实施的智慧校园网络建设项目，详细论述规划和设计方案，包括项目整体规划，网络架构，设备选型等，再结合自身参与实施的项目，分析智慧校园网络规划与设计中的难点和创新点。（哪个大三的会有这经验）\n吃 408 计网老本还有平时一些积累考的，区别在于感觉题目更侧重问通信工程相关，做起来没啥太大压力，论文的话感觉没两年工作经验写不动，只能靠先前准备的内容糊上去，感觉会被卡 10%通过率，大概率寄了痛失两百块，下次考也许工作后罢。\n","categories":["归档"],"tags":["日志"]},{"title":"2025-11-16-ES6相关","url":"/Arknight-notes/posts/9503.html","content":"ES61、let 和 const\n\n\n\n名称\n描述\n\n\n\n\nlet\n声明变量的关键字，let 声明的变量只在 let 命令所在的代码块内有效\n\n\nconst\n声明常量的关键字，const 声明一个只读的常量，一旦声明，常量的值就不能改变。\n\n\n\n\n2、模板字符串 和 箭头函数\n\n\n\n名称\n描述\n\n\n\n\n``\n使用反引号``包裹的字符串\n\n\n() =&gt;{}\n使用箭头（=&gt;）声明函数，不用再书写 function 关键字 示例： const add = () =&gt;{ console.log(‘add’)}\n\n\nthis\n1、非箭头函数中的 this 指向函数的调用者 2、箭头函数中的 this 指向定义时所在的对象 3、全局作用域中 this 指向 window\n\n\n\n\n3、解构赋值\n\n\n\n名称\n描述\n\n\n\n\n[] = []\n数组的解构赋值 示例：let [a, b, c] = [1, 2, 3]; 可以从数组中提取值，按照对应位置，给左侧变量赋值\n\n\n{} = {}\n对象的解构赋值 示例：let { bar，foo } = { foo: ‘aaa’, bar: ‘bbb’ }; 按照对应的属性，给左侧的变量赋值，等号左边的两个变量的书写顺序，与等号右边两个同名属性的顺序可以不一致\n\n\n[] = “” ，{} = “”\n字符串的解构赋值，在解构前，字符串被转换成了一个类似数组的对象 （不常用，了解即可） 1、以数组的形式解构，const [a, b, c, d, e] = ‘hello’ 2、以对象的形式解构，let { 0: a } = ‘hello’\n\n\n\n\n4、剩余参数，展开运算符\n\n\n\n名称\n描述\n\n\n\n\n…arg\n将一个不定数量的参数表示为一个数组\n\n\n…\n将内容展开\n\n\n\n\n5、数据结构\n\n\n\n名称\n描述\n\n\n\n\nSet\n是一系列无序、没有重复值的集合\n\n\nMap\n是键值对的集合，但是“键”的范围不限于字符串，各种类型的值（包括对象）都可以当作键\n\n\n\n\n6、Set 和 Map 共有的方法和属性\n\n\n\n名称\n描述\n\n\n\n\nhas()\n判断该值是否为 Set/Map 的成员。\n\n\ndelete()\n删除某个成员\n\n\nclear()\n删除所有成员\n\n\nforEach()\n遍历每个成员\n\n\nsize\n返回 Set/Map 实例的成员总数\n\n\n\n\n7、Set 和 Map 实例的方法\n\n\n\n方法名\n描述\n\n\n\n\nadd()\nSet 实例的方法，添加成员\n\n\nset()\nMap 实例的方法，添加成员\n\n\nget()\nMap 实例的方法，获取成员\n\n\n\n\n8、遍历器\n\n\n\n名称\n描述\n\n\n\n\nIterator\n为各种不同的数据结构提供统一的访问机制\n\n\nfor…of\n遍历成员，for…of 循环可以使用的范围包括数组、 Set 和 Map 结构、某些类似数组的对象（比如 arguments 对象、DOM NodeList 对象）\n\n\n\n\n9、数组的新增方法\n\n\n\n方法名称\n描述\n\n\n\n\nkeys()\n遍历索引\n\n\nvalues()\n遍历值\n\n\nentries()\n遍历索引和值\n\n\nincludes()\n判断数组中是否含某个成员（不常用，了解即可）\n\n\nArray.from()\n将其他数据类型转换为数组\n\n\nfind()\n返回第一个符合条件的数组成员\n\n\nfindIndex()\n返回第一个符合条件的数组成员的位置\n\n\n\n\n10、字符串的新增方法\n\n\n\n方法名称\n描述\n\n\n\n\nincludes()\n判断字符串中是否包含某些字符\n\n\npadStart()\n补全字符串的长度，用于头部补全（不常用，了解即可）\n\n\npadEnd()\n补全字符串的长度，用于尾部补全（不常用，了解即可）\n\n\ntrimLeft() ，trimStart()\n清除字符串头部的空格（不常用，了解即可）\n\n\ntrimEnd() ，trimRight()\n清除字符串尾部的空格（不常用，了解即可）\n\n\n\n\n11、对象的新增方法\n\n\n\n方法名称\n描述\n\n\n\n\nassign()\n合并对象\n\n\nObject.keys()\n返回一个数组，成员是键名\n\n\nObject.values()\n返回一个数组，成员是键值\n\n\nObject.entries()\n返回一个数组，成员是键名和键值\n\n\n\n\n","categories":["归档"],"tags":["前端开发"]},{"title":"2025-11-17-Arch-Linux运行AppImage相关","url":"/Arknight-notes/posts/11830.html","content":"\nAppImage是一种可执行文件格式，类似于 Windows 的 exe 文件，macOS 的 app 文件，不过 AppImage 是运行在 Linux 上的可执行文件，而且是可以运行在不同发行版本的 Linux，如 Ubuntu, Debian, openSUSE, RHEL, CentOS, Fedora, Arch Linux …\n\n运行时\n\n切换到文件路径 cd [文件路径]\n设置文件可以执行权限，chmod +x my.AppImage\n运行 AppImage ./my.AppImage\n\n第一次执行的时候可能会碰到FUSE相关的问题\ndlopen(): error loading libfuse.so.2AppImages require FUSE to run.You might still be able to extract the contents of this AppImageif you run it with the --appimage-extract option.See https://github.com/AppImage/AppImageKit/wiki/FUSEfor more information\n此时在 Arch Linux 上需要安装fuse2\nsudo pacman -S fuse2\n更多关于 FUSE 的问题可以查看：I get some errors related to something called “FUSE”\n在 Arch Linux 中创建 Desktop Entry（桌面条目）可以让你在应用启动器（如 GNOME、KDE 等）中显示应用图标。以下是创建步骤：\n创建 .desktop文件在以下目录之一创建 .desktop文件：\n系统级（所有用户可用）：/usr/share/applications/用户级（仅当前用户可用）：~/.local/share/applications/\n例如，为用户创建条目：\nmkdir -p ~/.local/share/applicationsnano ~/.local/share/applications/myapp.desktop\n\n模板参考（以 VSCode 为例）：\n[Desktop Entry]Version=1.0Type=ApplicationName=My ApplicationComment=应用描述Exec=/path/to/application/executableIcon=/path/to/icon/image.pngTerminal=falseCategories=Utility;Development;\nType: 固定为 Application（也可以是 Link或 Directory）Name: 显示在菜单中的名称Exec: 可执行文件的绝对路径（支持参数，如 %F表示文件）Icon: 图标路径（支持绝对路径或主题图标名，如 firefox）Terminal: 是否在终端中运行（true/false）Categories: 应用分类（参考 freedesktop 规范）\n设置权限chmod +x ~/.local/share/applications/myapp.desktop\n验证语法desktop-file-validate ~/.local/share/applications/myapp.desktop\n更新数据库update-desktop-database ~/.local/share/applications/\n这时候就可以看到桌面上有相关的应用了\n","categories":["归档"]},{"title":"2025-11-21-canvas项目杂记","url":"/Arknight-notes/posts/14933.html","content":"分析要做的就是一个类 Canva / Figma 的在线图形绘板，完整需求优先级和覆盖范围如下：\n\n\n\n\n优先级\n功能模块\n具体需求\n是否必须\n难度\n\n\n\n\nP0\n基础渲染\n矩形、圆形、三角形任意填充色、边框色、边框宽度、圆角、透明度\nYes\n★☆\n\n\nP0\n图片支持\n上传 png/jpg/webp，任意缩放、圆角、模糊、灰度、亮度调节、裁剪掩模\nYes\n★★\n\n\nP0\n富文本\n字体、字号、颜色、加粗、斜体、下划线、删除线、文本背景色、文字对齐、行距、局部样式支持\nYes\n★★★★\n\n\nP0\n基本交互\n单选、多选（框选 + Shift）、拖拽、删除、复制粘贴、缩放把手（8 个方向）、旋转把手\nYes\n★★\n\n\nP0\n无限画布 + 缩放平移\nCtrl+滚轮缩放、空格拖拽平移、无限滚动\nYes\n★☆\n\n\nP0\n数据持久化\n自动 localStorage 保存、打开页面自动恢复\nYes\n★☆\n\n\nP1\n高级交互\n组合（Group）、解散组合、图层排序、辅助对齐线、吸附、旋转任意角度\nYes\n★★★\n\n\nP1\n工具栏 &amp; 属性面板\n顶部工具栏（切换文本/形状/图片模式）、右侧属性面板实时编辑属性\nYes\n★★\n\n\nP1\n历史记录\nUndo / Redo（支持跨会话）\nYes\n★★\n\n\nP1\n性能要求\n100 个复杂元素（图片+富文本）打开 &lt; 3s，拖拽 60fps 不闪烁\nYes\n★★★★\n\n\nP2\n未来可扩展\n实时协同编辑、离线编辑、模板库、导出 PNG/SVG/PDF、激光笔、箭头、自由画笔等\nNo\n★★★★\n\n\n\n\n架构方案\n渲染层：PixiJS (WebGL) 处理高性能图形渲染 + HTML DOM 处理文本编辑/输入框。\n状态管理：Zustand / Pinia (管理庞大的 JSON 画布数据)。\n逻辑层：自定义 Class 结构（如  Shape, Tool, History）实现面向对象编程。\n\n二、项目设计要素\n\n\n\n设计维度\n推荐技术方案\n\n\n\n\n\n1. 渲染引擎\nPixiJS v8（WebGL） + HTMLText\nWebGL 抗锯齿完美 + 高分屏不模糊；HTMLText 是目前唯一能轻松实现富文本局部样式的方案\n\n\n2. 状态管理\nZustand（或 Jotai + signals）\n轻量、响应式、支持中间件（持久化、历史栈）\n\n\n3. 元素对象缓存\nMap 永久缓存（一个元素一个 Container，永不 destroy）\n彻底解决闪烁、拖拽中断、光标丢失的根本方案\n\n\n4. 历史栈\nCommand Pattern + structuredClone 快照（每操作记录 before/after）\n简单可靠，支持跨页面 Undo\n\n\n5. 选中/变换系统\n单独的 SelectionManager + TransformHandles（旋转、缩放把手层也缓存）\ntldraw/Figma 标配\n\n\n6. 辅助对齐线\n拖拽时实时遍历所有元素 bounds，差值 &lt; 5px 就吸附并画蓝线\n提升专业感\n\n\n7. 组合（Group）\n元素加 groupId 字段；选中时绘制大虚线框；拖拽/缩放/旋转时整体应用矩阵变换\n必须有，属于 P1 核心\n\n\n8. 数据持久化\nZustand middleware persist + localForage（IndexedDB）\n防止 localStorage 炸掉\n\n\n9. 图片处理\nSprite + Graphics mask（圆角）+ BlurFilter + ColorMatrixFilter\nPixiJS 原生支持\n\n\n10. 架构分层\n- store（纯数据） - rendering（Pixi 元素缓存 &amp; 更新） - interaction（拖拽、选中逻辑） - ui（React 面板）\n\n\n\n\ninstalled pixi.js@8.14.3installed zustand@5.0.8installed nanoid@5.1.6\n数据驱动视图”（Data-Driven View）  模式，采用了  React (UI) + Zustand (数据) + PixiJS (渲染)  的三层分离架构\n这种架构的核心理念是：PixiJS 实例不保存“业务状态”，它只是 Zustand 数据的“投影”\n\n其中，\n\nReact 只负责 UI 和事件入口\nZustand 是唯一的真实数据源（纯 JSON，可持久化、可协同）\nPixiJS 层只做“渲染 + 交互计算”，所有对象永久缓存（Map），绝不每帧重建\n所有变换（拖拽、缩放、旋转、组合）都在 Pixi 层完成，最后再同步回 Zustand（单向数据流）\n\n三层架构详解第一层：数据层 (The Source of Truth) - canvasStore.ts这是整个应用的大脑。\n\n职责：只存储纯 JSON 数据（Serializable），不包含任何 UI 实例或 Pixi 对象。\n存储内容：\nelements: 一个 Map 对象（Record），存储所有矩形、圆形的坐标、颜色等。\nselectedIds: 当前选中的 ID 列表。\ntool: 当前使用的工具。\n\n\n特点：\n单一数据源：画布上显示什么，完全由这里的数据决定。\n无副作用：这里的 Action 只修改数据，不直接操作 DOM 或 Canvas。\n\n\n\n第二层：适配层 (The Bridge) - StageManager.ts这是连接 React/Zustand 和 PixiJS 的胶水层，也是架构中最复杂的部分。\n\n职责：将“声明式”的数据（Zustand）转换为“命令式”的 Pixi 调用。\n核心机制 - 增量更新 (Diffing)：\n它维护了一个  spriteMap (Map)。\n订阅 (Subscribe)：它监听 Store 的变化。\n同步 (Sync/Render Loop)：\nCreate: Store 有 ID，Map 里没有 -&gt; new PIXI.Graphics()。\nUpdate: Store 有，Map 里也有 -&gt; 更新  x, y, width, color。\nDelete: Store 没有，Map 里有 -&gt; destroy()。\n\n\n\n\n事件转换：\n它监听 Pixi 的  pointerdown/move/up  事件，将屏幕坐标转换为逻辑坐标，然后调用 Store 的 Action。\n\n\n\n第三层：视图层 (The Container) - Canvas.tsx这是 React 组件层。\n\n职责：\n提供  div  容器供 Pixi 挂载。\n渲染 HTML UI（工具栏、属性面板）。\n生命周期管理：组件 Mount 时初始化  StageManager，Unmount 时销毁。\n\n\n\n—-\n3. 关键数据流转 (Data Flow)让我们以  “拖拽矩形移动”  为例，看数据如何在架构中流转：\nInput (输入):\n\n用户在画布上按住矩形并移动鼠标。\nStageManager  的  onPointerMove  被触发。\n\nLogic (逻辑处理):\n\nStageManager  计算鼠标的偏移量  (dx, dy)。\n它不直接修改 Pixi 图形的  graphics.x (这是关键！)。\n它调用  store.updateElement(id, { x: newX, y: newY })。\n\nState Update (状态更新):\n\nZustand Store 更新内部的 JSON 数据。\nZustand 触发订阅回调 (subscribe)。\n\nRender Sync (渲染同步):\n\nStageManager  的  render  方法被调用。\n它从  spriteMap  找到对应的 Pixi 实例。\n执行  graphic.position.set(newX, newY)。\nPixiJS 在下一个  requestAnimationFrame  自动重绘 Canvas。\n\n—-\n4. 为什么选择这种架构？优点：解耦 (Decoupling)：渲染引擎可以随时替换（比如换成 Konva 或原生 Canvas），只需要重写  StageManager，数据层和 UI 层不需要动。\n协同编辑 (Collaboration) 友好：\n\n如果要实现多入协同，只需要监听 WebSocket 消息，然后更新 Zustand Store。StageManager  会自动把队友的操作画出来，无需写额外的同步绘图逻辑。撤销/重做 (Undo/Redo) 容易：\n因为所有状态都在 Store 里，只需要保存/恢复 Store 的快照（或 Patch）即可。序列化/反序列化：\n保存项目只需  JSON.stringify(store.elements)。\n\n潜在挑战（及优化方案）：性能瓶颈：\n\n问题：高频触发  Store Update -&gt; Diff  循环可能在元素极多时（&gt;2000 个）产生开销。\n优化：对于拖拽这种 60FPS 的操作，可以引入“临时层” (Transient State)。即拖拽时直接修改 Pixi 对象，鼠标松开时再同步到 Store。复杂性：\n相比直接用 Canvas API 画图，这种架构代码量更大，需要维护 ID 映射和 Diff 逻辑。\n\nfeat(canvas): 重构画布实现，应项目要求，删除了基于tldraw的实现转而选择PixiJS 库重构以进行渲染操作，基于Zustand 进行状态管理。新增的文件中canvasStore.ts主要负责维护整个画布项目的全局可序列化状态，是渲染画布系统中唯一数据来源。Pixi_stageManager.ts 负责将声明式数据（Zustand）实时、高性能地映射为命令式渲染实例（PixiJS），并处理所有用户交互的计算与反馈。canvas下的index.ts最轻量的一层，仅负责生命周期管理与组件组装。三层数据驱动架构详情可见文档\n","categories":["归档"]},{"title":"2025-11-22- 关于前端包管理器npm,pnpm,yarn和bun以及我为何选择后者","url":"/Arknight-notes/posts/15722.html","content":"因为快。\n2025 年，Bun 作为一个「全能型」运行时 + 包管理器，在实际项目中对传统包管理器（npm/yarn/pnpm）确实有相当大的优势，很多人已经开始抛弃 npm/yarn/pnpm，转用 Bun 作为前端项目的包管理器\n初识 Bun 管理器Bun 是 JavaScript 和 TypeScript 应用程序的一站式工具包。它作为一个名为bun的单个可执行文件提供。\n其核心是 Bun 运行时，这是一个快速的 JavaScript 运行时，设计为 Node.js 的即插即用替代品。它是用 Zig 编写的，在底层由 JavaScriptCore 驱动，大大减少了启动时间和内存使用。\n对比其他包管理器1. npm（Node Package Manager）核心实现：\n\n依赖存储与解析：使用扁平化依赖树（flattened dependency tree，自 v3+ 引入），但仍依赖传统的 node_modules 目录结构。每个包及其子依赖都会下载 tarball（压缩包），然后解压到本地 node_modules 中。如果有版本冲突，会创建嵌套的 node_modules 子目录（hoisting 机制试图扁平化，但不总是完美）。\n锁文件：package-lock.json，记录精确的依赖树和哈希值，确保可重现安装。\n缓存机制：全局缓存在 ~/.npm（或 Windows 的 %AppData%\\npm-cache），存储 tarball 和元数据。安装时先检查缓存，命中则直接解压。\n下载与并行：自 v7+ 支持并行下载（自 v5+），使用 HTTP/1.1 或 HTTP/2，但解析依赖树时仍依赖 JavaScript 引擎（Node.js），导致启动开销大。\nmonorepo 支持：基本支持（通过 workspaces），但需手动配置，效率一般。\n\n技术栈：纯 Node.js 实现，CLI 基于 npm-cli。\n2. pnpm（Performant NPM）核心实现：\n\n依赖存储与解析：引入内容寻址存储（content-addressable store），所有包统一存储在全局 .pnpm/store（硬链接 + 符号链接）。项目中只生成一个扁平的 node_modules/.pnpm 目录，通过符号链接（symlinks）指向全局包，避免重复下载。严格的 peer dependency 隔离，防止“幽灵依赖”（phantom dependencies）。\n锁文件：pnpm-lock.yaml，YAML 格式，记录依赖图和完整哈希链。\n缓存机制：全局 store + 硬链接，安装时直接链接现有包（无解压开销）。支持范围补丁（patching），允许动态修改依赖。\n下载与并行：并行下载 + 增量更新，自 v8+ 优化为“聪明缓存”，只下载变化部分。monorepo 原生支持（workspace 协议），通过过滤命令（如 pnpm -r）高效处理多包。\nmonorepo 支持：最佳，原生高效，节省 70-80% 磁盘。\n\n技术栈：Node.js 实现，但使用 Rust-like 的高效链接系统（实际是 JS + 文件系统优化）。\n3. Yarn Berry（Yarn v2+）核心实现：\n\n依赖存储与解析：革命性 Plug’n’Play (PnP) 模式，默认完全消除 node_modules。依赖通过 .pnp.cjs（或 .pnp.js）文件映射（类似虚拟文件系统），运行时动态解析路径，而非物理目录。备选 nodeLinker: node-modules 模式回退到传统结构。\n锁文件：yarn.lock（v2+ 格式），包含完整依赖树、校验和和 ZIP 存档引用。\n缓存机制：项目级 .yarn/cache，存储 ZIP 压缩的包（可提交到 Git，实现“零安装”——clone 后直接运行）。支持“零安装”（zero-installs），CI/CD 无需重新下载。\n下载与并行：并行下载 + 增量缓存，自 v3+ 引入 Constraints（依赖规则检查）。monorepo 通过 Workspaces + Plug’n’Play 实现高效共享。\nmonorepo 支持：优秀，支持 Constraints 和 Patch 协议，适合大型团队。\n\n技术栈：Node.js 实现，但 PnP 使用自定义加载器（loader）拦截模块解析。\n4. Bun核心实现：\n\n依赖存储与解析：无 node_modules，所有包存储在全局单例缓存（~/.bun/install/cache），项目只生成极小的 .bun 文件夹（二进制锁文件）。使用极致压缩 + 硬链接，运行时直接从缓存加载（跳过解压）。兼容 npm 注册表，但内置 JSR（JavaScript Registry）支持。\n锁文件：bun.lockb，二进制格式（超小、超快解析）。\n缓存机制：全局缓存 + 内容哈希，安装时并行下载并验证哈希。支持“热缓存”（hot cache），CI 复用率近 100%。\n下载与并行：使用 Zig 语言编写的超快解析器（非 JS），HTTP/3 支持 + 原生并行。monorepo 自动识别，无需额外配置。\nmonorepo 支持：优秀，极速安装，但生态仍在完善（2025 年已稳定）。\n\n技术栈：Zig + JavaScriptCore（WebKit 引擎），非 Node.js 依赖，实现全栈（包管理 + bundler + 测试运行器）。\n基于 pnpm 官方基准（2025-11-16 更新）、Bun 团队报告和社区测试，四个包管理器中Bun 整体最快，pnpm/Yarn Berry 在磁盘效率上领先，npm 最稳但最慢。\n安装Bun 支持 Linux（x64 和 arm64）和 macOS（x64 和 Apple Silicon）。\n# 使用npmnpm install -g bun\n升级bun upgrade\n使用bun命令行工具实现了测试运行器、脚本运行器和与 Node.js 兼容的包管理器。Bun 的内置工具明显比现有选项快，并且在现有 Node.js 项目中几乎不需要进行任何更改。\nbun test                      # 运行测试bun run start                 # 运行`package.json`中的`start`脚本bun install &lt;pkg&gt;             # 安装包bunx cowsay 'Hello, world!'   # 执行包bun run index.tsx             # 默认支持TS和JSX\n","categories":["Github项目"],"tags":["前端开发"]},{"title":"2025-11-19-重拾编程语言设计与计科相关概念","url":"/Arknight-notes/posts/29484.html","content":"计算机类专业结果这些都得自己学，整理一套编程语言设计与计算机科学核心概念集，日后开坑学习，博客狠狠写，知识学爆\n一、内存管理基础概念\n指针（Pointer）\n引用（Reference）\n堆（Heap）\n栈（Stack）\n内存布局（Memory Layout）\n垃圾回收（Garbage Collection）\n内存泄漏（Memory Leak）\n悬挂指针/引用（Dangling Pointer/Reference）\n内存序（Memory Ordering）\n写时复制（Copy-on-Write）\n内存映射文件（Memory-mapped Files）\n缓存一致性协议（Cache Coherence Protocol）\n虚拟内存机制（Virtual Memory）\n内存屏障（Memory Barrier）\n内存对齐（Memory Alignment）\n内存分配器（Memory Allocator）\n内存池（Memory Pool）\n引用计数（Reference Counting）\n弱引用（Weak Reference）\n循环引用（Circular Reference）\n内存碎片（Memory Fragmentation）：包括内部碎片和外部碎片\n分页与分段（Paging and Segmentation）：虚拟内存管理技术\n垃圾回收算法：如标记-清除、复制、标记-整理等具体算法\n内存管理单元（Memory Management Unit）\n内存保护（Memory Protection）\n内存访问（Memory Access）\n\n存储类别\n自动存储期（Automatic Storage Duration）\n静态存储期（Static Storage Duration）\n动态存储期（Dynamic Storage Duration）\n线程存储期（Thread Storage Duration）\n寄存器变量（Register Variable）\n\n二、程序执行模型函数调用机制\n调用栈（Call Stack）\n栈帧（Stack Frame）\n调用约定（Calling Convention）\n参数传递（Parameter Passing）\n尾调用优化（Tail Call Optimization）\n尾递归（Tail Recursion）\nTrampoline 机制\nThunk：延迟计算的代码块\nThunk 函数：用于实现惰性求值的技术\n\n执行上下文\n作用域（Scope）\n词法作用域（Lexical Scope）\n动态作用域（Dynamic Scope）\n作用域链（Scope Chain）\n闭包（Closure）\n执行上下文（Execution Context）\n变量环境（Variable Environment）\n词法环境（Lexical Environment）\n延续（Continuation）\n协程（Coroutine）\n生成器（Generator）\n\n控制流\n事件循环（Event Loop）\n计算器模型（Evaluator Model）\n消息传递接口（Message Passing）\nActor 模型\nCSP（Communicating Sequential Processes）\n控制流图（Control Flow Graph）\n数据流分析（Data Flow Analysis）\n\n三、并发与并行并发模型\n并发（Concurrency）\n并行（Parallelism）\n绿色线程（Green Threads）\n内核线程（Kernel Threads）\n用户态线程（User-level Threads）\n线程池（Thread Pool）\n工作窃取（Work Stealing）\n屏障（Barrier）：同步原语\nfork-join 模型：并行任务执行模型\n数据竞争（Data Race）：并发访问共享数据的问题\n\n同步机制\n原子操作（Atomic Operations）\n比较并交换（Compare-and-Swap）\n锁（Lock）\n自旋锁（Spinlock）\n互斥锁（Mutex）\n读写锁（Read-Write Lock）\n信号量（Semaphore）\n条件变量（Condition Variable）\n无锁编程（Lock-free Programming）\n内存模型（Memory Model）\n顺序一致性（Sequential Consistency）\n释放获取语义（Release-Acquire Semantics）\n\n异步编程\nPromise/Future\nasync/await\n响应式编程（Reactive Programming）\n数据并行（Data Parallelism）\n任务并行（Task Parallelism）\n事务内存（Transactional Memory）\n\n四、类型系统类型分类\n静态类型（Static Typing）\n动态类型（Dynamic Typing）\n强类型（Strong Typing）\n弱类型（Weak Typing）\n基本数据类型（Primitive Data Types）\n复合数据类型（Composite Data Types）\n引用类型（Reference Types）\n值类型（Value Types）\n类型推导（Type Inference）\n类型检查（Type Checking）\n类型擦除（Type Erasure）\n类型转换（Type Casting）\n类型别名（Type Alias）\n类型注解（Type Annotation）\n泛型（Generics）\n类型参数（Type Parameter）\n类型变量（Type Variable）\n类型约束（Type Constraint）\n类型构造器（Type Constructor）\n类型等价（Type Equality）\n类型子类型（Type Subtyping）\n类型上界（Type Upper Bound）\n类型下界（Type Lower Bound）\n类型推断（Type Inference）\n类型检查（Type Checking）\n子类型（Subtyping）：类型之间的关系\n型变（Covariance/Contravariance）：更详细的变型规则说明\n不透明类型（Opaque Types）：隐藏实现细节的类型\n\n高级类型概念\n行多态（Row Polymorphism）\n存在类型（Existential Types）\n高阶类型（Higher-Kinded Types）\n依赖类型（Dependent Types）\n渐进类型（Gradual Typing）\n类型类（Type Classes）\n泛型（Generics）\n变型（Variance）：协变、逆变、不变\n类型安全（Type Safety）\n类型擦除（Type Erasure）\n单态化（Monomorphization）\n\n五、函数与抽象函数概念\n高阶函数（Higher-Order Function）\n回调函数（Callback）\n递归（Recursion）\n匿名函数（Anonymous Function）\nLambda 表达式\n柯里化（Currying）\n部分应用（Partial Application）\n函数组合（Function Composition）\n\n抽象机制\n控制抽象（Control Abstraction）\n数据抽象（Data Abstraction）\n迭代器（Iterator）\n流处理（Stream Processing）\n声明式编程（Declarative Programming）\n函子（Functor）：映射结构的抽象概念\n单子（Monad）：具有绑定操作的计算容器\n\n六、面向对象编程核心概念\n类（Class）\n对象（Object）\n封装（Encapsulation）\n继承（Inheritance）\n多态（Polymorphism）\n接口（Interface）\n抽象类（Abstract Class）\n混入（Mixin）\n特质（Trait）\n\n对象模型\n虚函数表（Virtual Method Table）\n方法解析顺序（Method Resolution Order）\n对象布局（Object Layout）\n多重继承（Multiple Inheritance）\n虚继承（Virtual Inheritance）\n原型继承（Prototypal Inheritance）\n消息传递（Message Passing）：对象间的通信机制\n委托（Delegation）：替代继承的复用机制\n\n七、元编程与反射元编程技术\n反射（Reflection）\n内省（Introspection）\n宏系统（Macro System）\n卫生宏（Hygienic Macro）\n语法宏（Syntax Macro）\n过程宏（Procedural Macro）\n模板元编程（Template Metaprogramming）\n注解处理（Annotation Processing）\n属性导向编程（Attribute-Oriented Programming）\n\n运行时元编程\n动态代理（Dynamic Proxy）\n方法缺失处理（Method Missing）\n代码生成（Code Generation）\nAST 操作（Abstract Syntax Tree Manipulation）\n\n八、编译与解释编译原理\n词法分析（Lexical Analysis）\n语法分析（Syntax Analysis）\n语义分析（Semantic Analysis）\n中间代码生成（Intermediate Code Generation）\n代码优化（Code Optimization）\n目标代码生成（Target Code Generation）\n编译器架构（Compiler Architecture）\n编译器设计（Compiler Design）\n编译器实现（Compiler Implementation）\n链接时优化（Link Time Optimization, LTO）：跨模块优化技术\nProfile-Guided Optimization (PGO)：基于运行时信息的优化\n\n执行引擎\n解释器（Interpreter）\n字节码（Bytecode）\n即时编译（Just-In-Time Compilation）\n抽象语法树（Abstract Syntax Tree, AST）\n单态化（Monomorphization）\n类型擦除（Type Erasure）\n中间表示（Intermediate Representation）\nSSA 形式（Static Single Assignment）\n\n九、系统接口操作系统交互\n系统调用（System Call）\n文件描述符（File Descriptor）\nABI（Application Binary Interface）\n系统 V ABI\nTLS（Thread Local Storage）\n信号处理（Signal Handling）\n\n十、异常与错误处理错误处理机制\n异常处理（Exception Handling）\n返回值错误（Error Return Values）\nResult 类型\n可选值（Option/Maybe）\n断言（Assertion）\n契约编程（Design by Contract）\n\n资源管理\nRAII（Resource Acquisition Is Initialization）\n所有权系统（Ownership System）\n借用检查（Borrow Checking）\n生命周期（Lifetime）\n析构函数（Destructor）\nfinally 块\n\n十一、模块化与代码组织代码组织\n模块化（Modularity）\n命名空间（Namespace）\n包管理（Package Management）\n依赖注入（Dependency Injection）\n接口隔离（Interface Segregation）\n\n链接与加载\n静态链接（Static Linking）\n动态链接（Dynamic Linking）\n符号解析（Symbol Resolution）\n重定位（Relocation）\n名称修饰（Name Mangling）\n\n十二、性能优化编译器优化\n内联优化（Inlining）\n常量传播（Constant Propagation）\n死代码消除（Dead Code Elimination）\n循环优化（Loop Optimization）\n向量化（Vectorization）\n分支目标缓冲（Branch Target Buffer）：提高分支预测准确性的硬件机制\n指令级并行（Instruction Level Parallelism）：CPU 级别的并行执行\n\n运行时优化\n内联缓存（Inline Cache）\n方法缓存（Method Cache）\n逃逸分析（Escape Analysis）\n栈上替换（On-Stack Replacement）\n热点代码检测（Hotspot Detection）\n\n硬件优化\n缓存局部性（Cache Locality）\n分支预测（Branch Prediction）\n流水线冒险（Pipeline Hazard）\n预取（Prefetching）\nSIMD（Single Instruction Multiple Data）\n\n十三、形式化方法与理论形式化验证\n霍尔逻辑（Hoare Logic）\n指称语义（Denotational Semantics）\n操作语义（Operational Semantics）\n公理语义（Axiomatic Semantics）\n进展定理（Progress Theorem）\n保持定理（Preservation Theorem）\n\n计算理论\nλ 演算（Lambda Calculus）\n组合子逻辑（Combinatory Logic）\n图灵完备性（Turing Completeness）\n邱奇-图灵论题（Church-Turing Thesis）\n停机问题（Halting Problem）\n\n十四、现代语言特性语言设计趋势\n空安全（Null Safety）\n模式匹配（Pattern Matching）\n异步/等待（Async/Await）\n记录类型（Record Types）\n代数数据类型（Algebraic Data Types）\n效应系统（Effect System）\n资源安全（Resource Safety）\n所有权与借用（Ownership and Borrowing）：Rust 中的内存安全机制\n异构编程（Heterogeneous Programming）：利用多种计算设备的编程模型\n\n表达式问题\n表达式问题（Expression Problem）\n访问者模式（Visitor Pattern）\n模式匹配解构\n\n十五、编程范式主要范式\n命令式编程（Imperative Programming）\n声明式编程（Declarative Programming）\n函数式编程（Functional Programming）\n逻辑编程（Logic Programming）\n面向对象编程（Object-Oriented Programming）\n面向方面编程（Aspect-Oriented Programming）\n\n混合范式\n多范式编程（Multi-paradigm Programming）\n函数响应式编程（Functional Reactive Programming）\n元对象协议（Metaobject Protocol）\n\n十六、软件开发基础基础概念\n表达式与语句（Expressions vs Statements）\n控制流（Control Flow）\n数据结构（Data Structures）\n算法（Algorithms）\n复杂度分析（Complexity Analysis）\n设计模式（Design Patterns）：常见问题的标准解决方案\nSOLID 原则：面向对象设计的五个基本原则\n\n","categories":["笔记"],"tags":["日志"]},{"title":"2025-11-22- 使用 GitHub Actions 自动部署基于vite的项目到 GitHub Pages","url":"/Arknight-notes/posts/33040.html","content":"这篇笔记主要讲在新创建前端项目后，如何通过 GitHub-Actions 实现每次 push 到 main 分支后，GitHub 自动构建 → 自动发布页面的操作\n参考 https://zhongye1.github.io/BDdraw_DEV/#/其从仓库 https://github.com/Zhongye1/BDdraw_DEV 实现自动构建和部署\n0.前置条件\nGitHub 账户 + 一个 public 仓库（私有仓库需要 GitHub Pro 才能开 Pages）\n\n1. 创建 GitHub Actions 工作流在仓库根目录创建文件： .github/workflows/deploy.yml\nname: Deploy to GitHub Pageson:  push:    branches: [main]  workflow_dispatch:permissions:  contents: read  pages: write  id-token: writejobs:  deploy:    environment:      name: github-pages      url: ${{ steps.deployment.outputs.page_url }}    runs-on: ubuntu-latest    steps:      - name: Checkout        uses: actions/checkout@v4      - name: Setup Bun        uses: oven-sh/setup-bun@v1        with:          bun-version: latest      - name: Install dependencies        run: bun install      - name: Build        run: bun run build      - name: Setup Pages        uses: actions/configure-pages@v5      - name: Upload artifact        uses: actions/upload-pages-artifact@v3        with:          path: \"./dist\"      - name: Deploy to GitHub Pages        id: deployment        uses: actions/deploy-pages@v4\n2. 配置 vite.config.ts 的 base打开 vite.config.ts\nimport { defineConfig } from 'vite'import react from '@vitejs/plugin-react'export default defineConfig({  plugins: [react()],  base: '/BDdraw_DEV/',   // 必须和仓库名完全一致！大小写也要一样})\n如果想让它在本地开发和 GitHub Pages 都正常，可以写成动态 base：\nexport default defineConfig({  plugins: [react()],  base: process.env.NODE_ENV === 'production' ? '/BDdraw_DEV/' : '/',})\n3. GitHub 仓库设置 Pages 为 Actions 模式\n进入仓库 → Settings → Pages（左侧菜单）\nBuild and deployment → Source 选 GitHub Actions\n保存\n\n4. 提交代码触发第一次部署git add .git commit -m \"chore: 新建 GitHub Actions 部署工作流\"git push origin main\n然后去仓库 → Actions 标签页，就能看到正在跑的 “Deploy to GitHub Pages” 工作流。\n成功后可以前往对应的 GitHub Pages 地址查看效果\n\n只要 push 到 main 分支，GitHub Actions 就会自动触发工作流，实现自动部署。\n\n如果是私有仓库，需要 GitHub Pro 才能开 Pages\n\n","categories":["Github"],"tags":["前端开发"]},{"title":"2025-11-23-Undo/Redo机制具体实现","url":"/Arknight-notes/posts/52695.html","content":"1. 模块摘要 (Executive Summary)Undo/Redo 机制是画布应用中实现操作撤销和重做的核心功能模块。它基于命令模式（Command Pattern）实现来，管理操作历史、执行撤销/重做操作和防止操作冲突，通过维护撤销栈和重做栈来管理用户的操作历史。\n\n项目结构树：\nsrc/├── lib/│   ├── UndoRedoManager.ts        # 撤销重做管理器核心实现│   └── UpdateElementCommand.ts   # 元素更新命令实现└── stores/    └── canvasStore.ts            # 状态存储，命令操作的目标\n\nCommand Pattern：设计模式，用于封装操作命令\nZustand：状态管理库，作为命令操作的目标\nTypeScript：提供类型安全和代码可维护性\n\n\n\n2. Props 和相关类型定义2.1 UndoRedoManager 核心方法撤销重做管理器提供了一系列核心方法用于管理操作命令。\n\n\n\n\n方法名\n参数\n返回值\n描述\n\n\n\n\nexecuteCommand\ncommand: Command\nvoid\n执行并记录命令\n\n\nundo\n无\nvoid\n执行撤销操作\n\n\nredo\n无\nvoid\n执行重做操作\n\n\nlock\n无\nvoid\n锁定管理器，防止记录新命令\n\n\nunlock\n无\nvoid\n解锁管理器\n\n\nisLocked\n无\nboolean\n检查管理器是否被锁定\n\n\ncanUndo\n无\nboolean\n检查是否可以撤销\n\n\ncanRedo\n无\nboolean\n检查是否可以重做\n\n\n\n\n2.2 核心类型定义Command 接口：定义了命令对象必须实现的方法。\nexport interface Command {  execute(): void; // 执行命令  undo(): void; // 撤销命令  redo(): void; // 重做命令}\nUpdateOperation 接口：定义了元素更新操作的数据结构。\ninterface UpdateOperation {  id: string; // 元素ID  initialAttrs: Partial&lt;CanvasElement&gt;; // 修改前的属性  finalAttrs: Partial&lt;CanvasElement&gt;; // 修改后的属性}\n3. 核心状态管理 (State Architecture)\n⚠️ 为防止在执行撤销/重做操作时记录新的命令，系统实现了锁定机制。在执行命令时会先锁定管理器，执行完成后再解锁，确保操作的原子性。\n\n3.1 内部状态 (Local State)UndoRedoManager 维护以下内部状态用于管理操作历史：\n\n\n\n\n状态名\n类型\n描述\n\n\n\n\nundoStack\nCommand[]\n撤销命令栈，存储可以撤销的命令\n\n\nredoStack\nCommand[]\n重做命令栈，存储可以重做的命令\n\n\nlocked\nboolean\n锁定状态，防止在执行命令时记录新命令\n\n\n\n\n3.2 外部状态 (Global/Server State)Undo/Redo 机制通过 Zustand 状态管理库操作外部状态：\n\n\n\n\n状态名\n类型\n描述\n\n\n\n\nelements\nRecord\n所有画布元素数据，命令操作的目标\n\n\n\n\n3.3 状态同步机制graph TD    A[用户操作] --&gt; B{StageManager}    B --&gt; C[创建命令对象]    C --&gt; D[UndoRedoManager.executeCommand]    D --&gt; E{管理器锁定?}    E --&gt;|是| F[忽略命令]    E --&gt;|否| G[执行命令]    G --&gt; H[命令入撤销栈]    H --&gt; I[清空重做栈]    I --&gt; J[Zustand 状态更新]        subgraph 撤销操作      K[UndoRedoManager.undo]      K --&gt; L{撤销栈空?}      L --&gt;|是| M[无法撤销]      L --&gt;|否| N[弹出命令]      N --&gt; O[执行命令.undo]      O --&gt; P[命令入重做栈]      P --&gt; Q[Zustand 状态更新]    end        subgraph 重做操作      R[UndoRedoManager.redo]      R --&gt; S{重做栈空?}      S --&gt;|是| T[无法重做]      S --&gt;|否| U[弹出命令]      U --&gt; V[执行命令.redo]      V --&gt; W[命令入撤销栈]      W --&gt; X[Zustand 状态更新]    end        style A fill:#e1f5fe    style J fill:#e8f5e8    style Q fill:#e8f5e8    style X fill:#e8f5e8    style F fill:#ffebee\n4. 命令管理机制Undo/Redo 机制采用命令模式（Command Pattern）来管理操作命令，通过定义统一的接口和不同的实现类来处理各种操作。\n4.1 命令类型系统中主要有两种命令类型：\n\n快照命令（SnapshotCommand）：用于记录整个画布状态的变化，通常用于添加元素、删除元素等较大范围的操作，保存完整的状态快照\n\n更新元素命令（UpdateElementCommand）：用于记录特定元素的属性变化，主要用于拖拽移动和调整大小操作，只保存相关元素的特定属性变化\n\n\n4.2 命令接口定义所有命令都实现统一的 Command 接口：\nexport interface Command {  execute(): void; // 执行命令  undo(): void; // 撤销命令  redo(): void; // 重做命令}\n4.3 快照命令（SnapshotCommand）快照命令用于记录整个画布状态的变化，适用于影响范围较大的操作。\n核心实现：\nexport class SnapshotCommand implements Command {  private prevState: any;  private nextState: any;  private commandId: number;  private type: string;  constructor(prevState: any, nextState: any, type: any) {    // 使用 structuredClone 进行深拷贝，确保状态隔离    this.prevState = structuredClone(prevState);    this.nextState = structuredClone(nextState);    this.type = type;    // 生成唯一的命令ID用于调试    this.commandId = Date.now() % 1000000;  }  execute(): void {    // execute在添加到命令栈之前已经执行了  }  undo(): void {    // 恢复到之前的状态    useStore.setState(this.prevState);  }  redo(): void {    // 恢复到之后的状态    useStore.setState(this.nextState);  }}\n4.4 更新元素命令（UpdateElementCommand）更新元素命令用于记录特定元素的属性变化，适用于影响范围较小的精细操作。\n核心实现：\ninterface UpdateOperation {  id: string;  initialAttrs: Partial&lt;CanvasElement&gt;; // 修改前的属性  finalAttrs: Partial&lt;CanvasElement&gt;; // 修改后的属性}export class UpdateElementCommand implements Command {  private commandId: string;  constructor(    private operations: UpdateOperation[],    private operationType: string = \"更新元素\"  ) {    // 生成唯一命令ID    this.commandId = `UpdateElementCommand-${Math.random()      .toString(36)      .slice(2, 11)}`;  }  execute(): void {    // 应用最终状态    const updates: Record&lt;string, Partial&lt;CanvasElement&gt;&gt; = {};    this.operations.forEach((op) =&gt; {      updates[op.id] = op.finalAttrs;    });    useStore.setState((state) =&gt; {      const newElements = { ...state.elements };      Object.entries(updates).forEach(([id, attrs]) =&gt; {        if (newElements[id]) newElements[id] = { ...newElements[id], ...attrs };      });      return { elements: newElements };    });  }  undo(): void {    // 撤销：恢复到 initialAttrs    const updates: Record&lt;string, Partial&lt;CanvasElement&gt;&gt; = {};    this.operations.forEach((op) =&gt; {      updates[op.id] = op.initialAttrs;    });    useStore.setState((state) =&gt; {      const newElements = { ...state.elements };      Object.entries(updates).forEach(([id, attrs]) =&gt; {        if (newElements[id]) newElements[id] = { ...newElements[id], ...attrs };      });      return { elements: newElements };    });  }  redo(): void {    // 重做：恢复到 finalAttrs    const updates: Record&lt;string, Partial&lt;CanvasElement&gt;&gt; = {};    this.operations.forEach((op) =&gt; {      updates[op.id] = op.finalAttrs;    });    useStore.setState((state) =&gt; {      const newElements = { ...state.elements };      Object.entries(updates).forEach(([id, attrs]) =&gt; {        if (newElements[id]) newElements[id] = { ...newElements[id], ...attrs };      });      return { elements: newElements };    });  }}\n4.5 命令生命周期命令的生命周期包括创建、执行、撤销和重做四个阶段：\ngraph TD    A[命令创建] --&gt; B[命令执行]    B --&gt; C{用户操作}    C --&gt;|撤销| D[执行undo方法]    C --&gt;|重做| E[执行redo方法]    D --&gt; F[命令状态切换]    E --&gt; F    F --&gt; G[状态更新完成]        style A fill:#e1f5fe    style B fill:#f3e5f5    style D fill:#fff3e0    style E fill:#fff3e0    style G fill:#e8f5e8\n5. 命令栈管理机制撤销/重做机制使用两个栈来管理命令历史：\n\n撤销栈（Undo Stack）：\n\n存储用户可以撤销的操作命令，栈顶是最近执行的命令，执行新命令时，命令被推入此栈，执行撤销操作时，命令从此栈弹出并推入重做栈\n\n重做栈（Redo Stack）：\n\n存储用户可以重做的操作命令，在执行撤销操作时，被撤销的命令被推入此栈，执行重做操作时，命令从此栈弹出并推入撤销栈，执行新命令时，此栈被清空\n5.1 命令栈操作流程graph TD    A[执行新命令] --&gt; B[命令入撤销栈]    B --&gt; C[清空重做栈]        D[执行撤销] --&gt; E{撤销栈空?}    E --&gt;|是| F[无操作]    E --&gt;|否| G[弹出命令]    G --&gt; H[执行命令.undo]    H --&gt; I[命令入重做栈]        J[执行重做] --&gt; K{重做栈空?}    K --&gt;|是| L[无操作]    K --&gt;|否| M[弹出命令]    M --&gt; N[执行命令.redo]    N --&gt; O[命令入撤销栈]        style A fill:#e1f5fe    style B fill:#f3e5f5    style C fill:#f3e5f5    style D fill:#e1f5fe    style H fill:#fff3e0    style I fill:#fff3e0    style J fill:#e1f5fe    style N fill:#e8f5e8    style O fill:#e8f5e8\n5.2 不同类型的命令撤销栈中并不全是快照命令。系统中至少有两种不同类型的命令：\n\n快照命令（SnapshotCommand）：\n\n用于记录整个画布状态的变化\n通常用于添加元素、删除元素等较大范围的操作\n保存完整的状态快照\n\n\n更新元素命令（UpdateElementCommand）：\n\n用于记录特定元素的属性变化\n主要用于拖拽移动和调整大小操作\n只保存相关元素的特定属性变化\n\n\n\n5.3 操作序列和撤销栈状态变化示例初始状态撤销栈：空重做栈：空\n1. 创建元素 A当创建元素 A 时，系统会生成一个快照命令，记录整个画布状态的变化。撤销栈：[SnapshotCommand_A] (大小: 1)重做栈：空\n2. 移动 A 到一个位置当移动元素 A 时，系统会生成一个更新元素命令（UpdateElementCommand），只记录 A 元素位置的变化。撤销栈：[SnapshotCommand_A, UpdateElementCommand_MoveA] (大小: 2)重做栈：空\n3. 创建元素 B当创建元素 B 时，系统会生成另一个快照命令，记录添加 B 元素后的状态。撤销栈：[SnapshotCommand_A, UpdateElementCommand_MoveA, SnapshotCommand_B] (大小: 3)重做栈：空\n4. 缩放 B 到一个位置当缩放元素 B 时，系统会生成一个更新元素命令，记录 B 元素尺寸和位置的变化。撤销栈：[SnapshotCommand_A, UpdateElementCommand_MoveA, SnapshotCommand_B, UpdateElementCommand_ResizeB] (大小: 4)重做栈：空\n5. 移动 B 到一个位置当再次移动元素 B 时，系统会生成另一个更新元素命令，记录 B 元素位置的新变化。撤销栈：[SnapshotCommand_A, UpdateElementCommand_MoveA, SnapshotCommand_B, UpdateElementCommand_ResizeB, UpdateElementCommand_MoveB] (大小: 5)重做栈：空\n5.4 执行撤销操作时的状态变化第一次撤销（移动 B 操作）\n从撤销栈弹出最后一个命令：UpdateElementCommand_MoveB\n执行该命令的 undo()方法，将 B 元素恢复到缩放后的位置\n将该命令推入重做栈\n\n撤销栈：[SnapshotCommand_A, UpdateElementCommand_MoveA, SnapshotCommand_B, UpdateElementCommand_ResizeB] (大小: 4)重做栈：[UpdateElementCommand_MoveB] (大小: 1)\n第二次撤销（缩放 B 操作）\n从撤销栈弹出最后一个命令：UpdateElementCommand_ResizeB\n执行该命令的 undo()方法，将 B 元素恢复到刚创建时的尺寸和位置\n将该命令推入重做栈\n\n撤销栈：[SnapshotCommand_A, UpdateElementCommand_MoveA, SnapshotCommand_B] (大小: 3)重做栈：[UpdateElementCommand_MoveB, UpdateElementCommand_ResizeB] (大小: 2)\n第三次撤销（创建 B 操作）\n从撤销栈弹出最后一个命令：SnapshotCommand_B\n执行该命令的 undo()方法，将整个画布状态恢复到创建 B 之前的状态（即只包含 A 元素的状态）\n将该命令推入重做栈\n\n撤销栈：[SnapshotCommand_A, UpdateElementCommand_MoveA] (大小: 2)重做栈：[UpdateElementCommand_MoveB, UpdateElementCommand_ResizeB, SnapshotCommand_B] (大小: 3)\n第四次撤销（移动 A 操作）\n从撤销栈弹出最后一个命令：UpdateElementCommand_MoveA\n执行该命令的 undo()方法，将 A 元素恢复到初始位置\n将该命令推入重做栈\n\n撤销栈：[SnapshotCommand_A] (大小: 1)重做栈：[UpdateElementCommand_MoveB, UpdateElementCommand_ResizeB, SnapshotCommand_B, UpdateElementCommand_MoveA] (大小: 4)\n第五次撤销（创建 A 操作）\n从撤销栈弹出最后一个命令：SnapshotCommand_A\n执行该命令的 undo()方法，将整个画布状态恢复到初始状态（空画布）\n将该命令推入重做栈\n\n撤销栈：空重做栈：[UpdateElementCommand_MoveB, UpdateElementCommand_ResizeB, SnapshotCommand_B, UpdateElementCommand_MoveA, SnapshotCommand_A] (大小: 5)\n6. 逻辑流程 (Logic Flow)6.1 交互时序图 (Mermaid)sequenceDiagram    participant U as 用户    participant SM as StageManager    participant URM as UndoRedoManager    participant C as Command    participant ZS as Zustand Store        U-&gt;&gt;SM: 执行操作（如拖拽元素）    SM-&gt;&gt;SM: 记录操作初始状态    SM-&gt;&gt;ZS: 更新元素状态    SM-&gt;&gt;C: 创建 UpdateElementCommand    SM-&gt;&gt;URM: executeCommand(command)    URM-&gt;&gt;C: command.execute()    C-&gt;&gt;URM: 命令入撤销栈    URM-&gt;&gt;URM: 清空重做栈        U-&gt;&gt;URM: 执行撤销 (Ctrl+Z)    URM-&gt;&gt;URM: 锁定管理器    URM-&gt;&gt;C: command.undo()    C-&gt;&gt;ZS: 恢复初始状态    C-&gt;&gt;URM: 命令入重做栈    URM-&gt;&gt;URM: 解锁管理器        U-&gt;&gt;URM: 执行重做 (Ctrl+Y)    URM-&gt;&gt;URM: 锁定管理器    URM-&gt;&gt;C: command.redo()    C-&gt;&gt;ZS: 恢复最终状态    C-&gt;&gt;URM: 命令入撤销栈    URM-&gt;&gt;URM: 解锁管理器\n6.2 核心函数解析executeCommand 函数：当用户完成一个操作（如创建、更新、删除元素）时触发，执行命令并将命令添加到撤销栈，同时清空重做栈\nexecuteCommand(command: Command) {  if (this.locked) {    // 如果管理器被锁定，忽略命令    return  }  // 执行命令  command.execute()  // 将命令添加到撤销栈  this.undoStack.push(command)  // 清空重做栈  this.redoStack = []}\nundo 函数：当用户执行撤销操作（如按 Ctrl+Z）时触发，从撤销栈弹出命令，执行命令的 undo 方法，并将命令放入重做栈\nundo() {  if (this.undoStack.length === 0) {    // 撤销栈为空，无法撤销    return  }  this.lock()  // 锁定管理器  const command = this.undoStack.pop()!  // 弹出命令  command.undo()  // 执行撤销  this.redoStack.push(command)  // 命令入重做栈  this.unlock()  // 解锁管理器}\nredo 函数：当用户执行重做操作（如按 Ctrl+Y）时触发，从重做栈弹出命令，执行命令的 redo 方法，并将命令放入撤销栈\nredo() {  if (this.redoStack.length === 0) {    // 重做栈为空，无法重做    return  }  this.lock()  // 锁定管理器  const command = this.redoStack.pop()!  // 弹出命令  command.redo()  // 执行重做  this.undoStack.push(command)  // 命令入撤销栈  this.unlock()  // 解锁管理器}\n7. UI 与样式实现 (UI Implementation)Undo/Redo 机制通过快捷键和控制台界面与用户交互：\ngraph TD    A[用户交互] --&gt; B{交互方式}    B --&gt; C[键盘快捷键]    B --&gt; D[控制台界面]    C --&gt; E[Ctrl+Z 撤销]    C --&gt; F[Ctrl+Y 重做]    D --&gt; G[命令栈控制台]    G --&gt; H[撤销按钮]    G --&gt; I[重做按钮]    G --&gt; J[清空按钮]        style A fill:#e1f5fe    style C fill:#f3e5f5    style D fill:#f3e5f5    style E fill:#e8f5e8    style F fill:#e8f5e8    style G fill:#fff3e0\n","categories":["归档"],"tags":["前端开发","状态管理"]},{"title":"2025-11-23-canvas项目相关-状态管理层","url":"/Arknight-notes/posts/61173.html","content":"1. 模块摘要 (Executive Summary)状态管理层管理画布元素数据、选中状态、工具状态、剪贴板数据等核心业务数据，是整个画布应用的数据核心，负责维护所有画布元素的状态信息和用户交互相关的全局状态。它采用了 Zustand 作为状态管理库，实现了数据的集中管理和状态变更的响应式更新\n\n项目结构树：\nsrc/└── stores/    └── canvasStore.ts        # Zustand 状态管理核心文件\n\nZustand：轻量级状态管理库，用于管理全局状态\nnanoid：用于生成唯一 ID\nstructuredClone：用于深拷贝状态数据\n\n\n\n2. Props 和相关类型定义2.1 useStore 参数状态管理模块通过 useStore Hook 提供状态访问和更新功能。\n\n\n\n\n参数名\n类型\n必填\n默认值\n描述\n\n\n\n\nsetTool\nFunction\n是\n无\n设置当前使用的工具类型\n\n\naddElement\nFunction\n是\n无\n添加新元素到画布\n\n\nupdateElement\nFunction\n是\n无\n更新指定元素的属性\n\n\nremoveElements\nFunction\n是\n无\n从画布中移除指定元素\n\n\nsetSelected\nFunction\n是\n无\n设置当前选中的元素\n\n\nsetEditingId\nFunction\n是\n无\n设置当前正在编辑的元素\n\n\ncopyElements\nFunction\n是\n无\n复制指定元素到剪贴板\n\n\npasteElements\nFunction\n是\n无\n从剪贴板粘贴元素到画布\n\n\n\n\n代码示例：\n// 设置工具类型useStore.getState().setTool(\"rect\");// 添加元素useStore.getState().addElement({  id: \"element1\",  type: \"rect\",  x: 100,  y: 100,  width: 200,  height: 150,  fill: \"#ff0000\",  stroke: \"#000000\",  strokeWidth: 2,});// 更新元素useStore.getState().updateElement(\"element1\", { fill: \"#00ff00\" });// 移除元素useStore.getState().removeElements([\"element1\"]);\n2.2 核心类型定义CanvasElement 类型：定义了画布上所有元素的基本属性和可选属性。\ninterface CanvasElement {  id: string; // 元素唯一标识符  type: ToolType; // 元素类型  x: number; // 元素左上角 x 坐标  y: number; // 元素左上角 y 坐标  width: number; // 元素宽度  height: number; // 元素高度  fill: string; // 填充颜色  stroke: string; // 描边颜色  strokeWidth: number; // 描边宽度  alpha?: number; // 透明度  points?: number[][]; // 点坐标数组（用于线条类元素）  rotation?: number; // 旋转角度（弧度制）  text?: string; // 文本内容（HTML 格式）  fontSize?: number; // 字体大小  fontFamily?: string; // 字体族  textAlign?: \"left\" | \"center\" | \"right\"; // 文本对齐方式  imageUrl?: string; // 图片 URL  filter?: \"none\" | \"blur\" | \"brightness\" | \"grayscale\"; // 图片滤镜  radius?: number; // 圆角半径}\nToolType 类型：定义了用户可选择的工具类型。\ntype ToolType =  | \"select\" // 选择工具  | \"hand\" // 手型工具  | \"rect\" // 矩形工具  | \"circle\" // 圆形工具  | \"triangle\" // 三角形工具  | \"diamond\" // 菱形工具  | \"line\" // 直线工具  | \"arrow\" // 箭头工具  | \"pencil\" // 铅笔工具  | \"text\" // 文本工具  | \"image\" // 图片工具  | \"eraser\"; // 橡皮擦工具\n3. 核心状态管理 (State Architecture)状态管理层维护以下内部状态：\n\n\n\n\n状态名\n类型\n描述\n\n\n\n\ntool\nToolType\n当前选中的工具类型\n\n\nelements\nRecord&lt;string, [CanvasElement](/src/pages/canvas/Pixi_STM_modules/core/types.ts#L15-L15)&gt;\n所有画布元素的集合\n\n\nselectedIds\nstring[]\n当前选中的元素 ID 数组\n\n\neditingId\nstring \\\nnull\n当前正在编辑的元素 ID\n\n\nclipboard\nCanvasElement[] \\\nnull\n剪贴板数据\n\n\npasteOffset\nnumber\n粘贴偏移计数\n\n\ncurrentStyle\nObject\n当前样式设置\n\n\n\n\n3.3 状态同步机制graph TD    A[Zustand Store 状态变更] --&gt; B{订阅者监听}    B --&gt; C[StageManager 订阅]    B --&gt; D[UI 组件订阅]    C --&gt; E[触发渲染层更新]    D --&gt; F[触发 UI 更新]        style A fill:#e1f5fe    style E fill:#e8f5e8    style F fill:#fff3e0\n4. 逻辑流程 (Logic Flow)4.1 交互时序图 (Mermaid)sequenceDiagram    participant U as 用户    participant C as CanvasStore    participant SM as StageManager    participant R as 渲染层        U-&gt;&gt;C: 调用 Action (如 addElement)    C-&gt;&gt;C: 更新内部状态    C-&gt;&gt;SM: 通知状态变更    SM-&gt;&gt;R: 触发重新渲染    R-&gt;&gt;R: 更新 PIXI 对象    R-&gt;&gt;U: 显示更新结果\n4.2 核心函数addElement 函数：当用户创建新元素时调用，创建新元素并添加到 elements 集合中\naddElement: (el) =&gt;  originalSet((state) =&gt; ({    elements: { ...state.elements, [el.id]: el },  }));\nupdateElement 函数：当用户修改元素属性时调用，更新指定元素的属性并保持其他元素不变\nupdateElement: (id, attrs) =&gt;  originalSet((state) =&gt; {    if (!state.elements[id]) return state;    return {      elements: {        ...state.elements,        [id]: { ...state.elements[id], ...attrs },      },    };  });\n状态管理层作为纯数据层，不直接涉及 UI 和样式实现，但为上层 UI 提供了必要的状态支持，通过状态结构支持上层组件的布局逻辑和状态中的样式属性支持上层组件的样式实现\n","categories":["归档"],"tags":["前端开发","Zustand"]},{"title":"2025-11-23-canvas项目相关-渲染层","url":"/Arknight-notes/posts/8350.html","content":"1. 模块摘要 (Executive Summary)渲染层是基于 PixiJS 构建的可视化层，负责将存储在 Zustand 状态管理器中的画布元素数据转化为可视化的图形界面，并处理用户的交互操作。它主要包括元素渲染（ElementRenderer）和变换控制器渲染（TransformerRenderer）两大部分，分别负责绘制元素本身和元素的选中状态、控制手柄等辅助 UI。\n其项目结构树如下：\nsrc/└── pages/    └── canvas/        ├── Pixi_stageManager.ts               # 整合StageManager各模块的入口文件        ├── index.tsx                          # 画布页面组件，整合渲染层到React组件中        └── Pixi_STM_modules/                  # StageManager模块目录            ├── STM_modules.md                 # 模块设计文档            ├── core/            │   ├── StageManagerCore.ts        # 核心类，整合渲染、交互和状态管理            │   └── types.ts                   # 类型定义文件            ├── rendering/            │   ├── ElementRenderer.ts         # 元素渲染器，负责渲染各类画布元素            │   └── TransformerRenderer.ts     # 变换控制器渲染器，负责渲染选中元素的手柄等            ├── interaction/            │   └── InteractionHandler.ts      # 交互处理器，绑定和处理各种交互事件            └── utils/                └── cursorUtils.ts             # 光标工具函数\n该模块主要负责将状态管理层的数据渲染成可视化图形，并处理用户交互反馈\n\npixi.js：WebGL 渲染引擎\npixi-viewport：视口管理插件\nzustand：状态管理库（虽然不是渲染层直接依赖，但与其紧密协作）\n\n2. Props 和相关类型定义渲染层接收来自逻辑层的 props 参数，用于驱动元素渲染和交互控制。这些参数主要包括元素数据、状态信息和事件回调函数。\n2.1 ElementRenderer.renderElements 方法参数ElementRenderer 负责将画布元素数据渲染为 PIXI 可视化对象，其 renderElements 方法接收以下参数：\n\n\n\n\n字段名\n类型\n必填\n默认值\n描述\n\n\n\n\nelements\nRecord\n是\n无\n包含所有画布元素的数据对象\n\n\nelementLayer\nPIXI.Container\n是\n无\n用于承载所有可视元素的容器\n\n\ndestroyed\nboolean\n是\nfalse\n标识组件是否已被销毁\n\n\n\n\n// elements对象结构示例{  \"element1\": {    id: \"element1\",    type: \"rect\",    x: 100,    y: 100,    width: 200,    height: 150,    fill: \"#ff0000\"  },  \"element2\": {    id: \"element2\",    type: \"text\",    x: 50,    y: 50,    width: 300,    height: 100,    text: \"&lt;p&gt;示例文本&lt;/p&gt;\"  }}\nelementLayer: PIXI.Container - PIXI.js 中的容器对象，用于承载所有画布元素的可视化对象。ElementRenderer 会将创建的 PIXI 对象添加到这个容器中，以便在画布上显示。\n// 在StageManagerCore.ts中创建elementLayerprivate elementLayer: PIXI.Container = new PIXI.Container()// 然后传给ElementRendererthis.elementRenderer.renderElements(elements, this.elementLayer, this.state.destroyed)\ndestroyed: boolean - 标识渲染器是否已被销毁。当组件被销毁时，此参数防止在销毁后继续执行渲染操作，避免内存泄漏。\npublic renderElements(elements: Record&lt;string, CanvasElement&gt;, elementLayer: PIXI.Container, destroyed: boolean) {  if (destroyed) return; // 如果已销毁，直接返回不执行渲染  // ... 其他渲染逻辑}\n2.2 TransformerRenderer.renderTransformer 方法参数TransformerRenderer 负责渲染选中元素的变换控制器（手柄、边框等），其 renderTransformer 方法接收以下参数：\n\n\n\n\n参数名\n类型\n描述\n\n\n\n\nelements\nRecord\n所有画布元素的数据\n\n\nselectedIds\nstring[]\n当前选中元素的 ID 数组\n\n\nspriteMap\nMap\n元素 ID 到 PIXI 可视化对象的映射\n\n\nonHandleDown\nFunction\n手柄按下事件的回调函数\n\n\nviewportScale\nnumber\n当前视口的缩放比例\n\n\n\n\nelements: Record - 与 ElementRenderer 中的 elements 相同，提供所有画布元素的数据。TransformerRenderer 需要访问元素数据来计算选中元素的边界框和位置信息。\nselectedIds: string[] - 包含当前选中元素 ID 的数组。TransformerRenderer 根据这个数组决定是否以及如何绘制变换控制器（选中框和手柄）。\n// selectedIds数组示例;['element1', 'element3'] // 表示element1和element3被选中\nspriteMap: Map&lt;string, PIXI.Graphics | PIXI.HTMLText | PIXI.Sprite&gt; - 提供元素 ID 到 PIXI 可视化对象的映射。TransformerRenderer 需要访问实际的 PIXI 对象来准确计算元素的边界（特别是文本元素）。\n// spriteMap结构示例Map(2) {  \"element1\" =&gt; Graphics {},     // 矩形元素的PIXI.Graphics对象  \"element2\" =&gt; HTMLText {}      // 文本元素的PIXI.HTMLText对象}\nonHandleDown: Function - 手柄按下事件的回调函数。当用户点击变换控制器上的手柄时，会调用这个函数开始变换操作（如缩放、旋转）。\n// 在StageManagerCore.ts中定义并传递给TransformerRendererprivate onHandleDown = (e: PIXI.FederatedPointerEvent, handle: HandleType | 'p0' | 'p1', elementId: string) =&gt; {  // 处理手柄按下事件  this.state.mode = 'resizing';  this.state.activeHandle = handle as HandleType | null;  // ... 其他逻辑}\nviewportScale: number - 当前视口的缩放比例。TransformerRenderer 使用这个值来调整手柄和控制器的大小，确保在不同缩放级别下都有合适的尺寸。\n// 在StageManagerCore.ts中获取并传递视口缩放比例this.transformerRenderer.renderTransformer(  elements,  selectedIds,  this.elementRenderer.getSpriteMap(),  this.onHandleDown,  this.viewport.scale.x, // 传递视口缩放比例)\n2.3 核心类型定义渲染层涉及到的关键类型定义如下：\nCanvasElement 类型定义了画布元素的基本属性和可选属性：\ninterface CanvasElement {  id: string;  type:    | \"rect\"    | \"circle\"    | \"triangle\"    | \"text\"    | \"image\"    | \"line\"    | \"arrow\"    | \"pencil\";  x: number;  y: number;  width: number;  height: number;  fill: string;  stroke: string;  strokeWidth: number;  // 根据元素类型可能包含额外属性  text?: string; // 文本元素  imageUrl?: string; // 图片元素  points?: number[][]; // 线条/铅笔元素  fontSize?: number; // 文本元素  fontFamily?: string; // 文本元素  alpha?: number; // 透明度  radius?: number; // 圆角矩形}\nHandleType 类型定义了变换控制器上各种手柄的类型：\ntype HandleType =  | \"tl\" // top-left 左上角  | \"t\" // top 顶部中间  | \"tr\" // top-right 右上角  | \"r\" // right 右侧中间  | \"br\" // bottom-right 右下角  | \"b\" // bottom 底部中间  | \"bl\" // bottom-left 左下角  | \"l\" // left 左侧中间  | \"p0\" // 线段起点  | \"p1\" // 线段终点  | \"rotate\"; // 旋转手柄\n3. 核心状态管理 (State Architecture)渲染层采用内外结合的状态管理模式，既维护自身的局部状态，又与外部的 Zustand 状态管理库协同工作。\n3.1 内部状态 (Local State)渲染层维护一组局部状态，用于管理 PIXI 对象和渲染优化：\n\n\n\n\n状态名\n类型\n描述\n\n\n\n\nspriteMap\n`Map&lt;string, PIXI.Graphics \\\nPIXI.HTMLText \\\nPIXI.Sprite&gt;`\n存储元素 ID 到 PIXI 图形对象的映射关系，用于快速查找和更新元素\n\n\ntextureCache\nMap&lt;string, PIXI.Texture&gt;\n图片纹理缓存，避免重复加载相同图片\n\n\nloadingSet\nSet&lt;string&gt;\n正在加载中的图片 URL 集合，防止重复加载\n\n\nimageUpdateTimers\nMap&lt;string, NodeJS.Timeout&gt;\n图像元素更新检查定时器映射\n\n\ntransformerGraphic\nPIXI.Graphics\n用于绘制变换控制器（选中框、手柄等）的图形对象\n\n\n\n\n// ElementRenderer 内部状态示例private spriteMap: Map&lt;string, PIXI.DisplayObject&gt; = new Map()private textureCache: Map&lt;string, PIXI.Texture&gt; = new Map()private loadingSet: Set&lt;string&gt; = new Set()private imageUpdateTimers: Map&lt;string, NodeJS.Timeout&gt; = new Map()// TransformerRenderer 内部状态示例private transformerGraphic: PIXI.Graphics = new PIXI.Graphics()\n3.2 外部状态 (Global/Server State)渲染层通过订阅 Zustand 状态管理库中的 canvasStore 来获取画布元素数据和选中状态：\n\n\n\n\n状态名\n类型\n描述\n\n\n\n\nelements\nRecord&lt;string, CanvasElement&gt;\n所有画布元素的数据对象\n\n\nselectedIds\nstring[]\n当前选中元素的 ID 数组\n\n\n\n\n// StageManagerCore.ts 中订阅外部状态的方式useStore.subscribe(  (state) =&gt; ({ elements: state.elements, selectedIds: state.selectedIds }),  ({ elements, selectedIds }) =&gt; {    // 当 elements 或 selectedIds 发生变化时触发重新渲染    this.render();  },  { equalityFn: shallow });\n3.3 状态同步机制渲染层通过增量更新（Diffing）算法实现高效的状态同步：\ngraph TDA[Zustand Store 状态变更] --&gt; B{StageManager 订阅}B --&gt; C{Diff 算法对比}C --&gt;|新增元素| D[创建 PIXI 对象]C --&gt;|更新元素| E[更新 PIXI 对象属性]C --&gt;|删除元素| F[销毁 PIXI 对象]D --&gt; G[添加到 spriteMap]E --&gt; GF --&gt; H[从 spriteMap 移除]G --&gt; I[PixiJS 渲染]H --&gt; I    style A fill:#e1f5fe    style I fill:#e8f5e8    style G fill:#fff3e0    style H fill:#ffebee\n4. 逻辑流程 (Logic Flow)4.1 交互时序图 (Mermaid)sequenceDiagram\tparticipant U as 用户\tparticipant SM as StageManagerCore\tparticipant ER as ElementRenderer\tparticipant TR as TransformerRenderer\tparticipant S as Zustand Store\t    U-&gt;&gt;SM: 触发状态变更 (添加/更新元素)    SM-&gt;&gt;S: 更新elements数据    S-&gt;&gt;SM: 通知状态变更    SM-&gt;&gt;ER: 调用renderElements()    ER-&gt;&gt;ER: 根据元素类型创建/更新PIXI对象    ER-&gt;&gt;SM: 更新spriteMap        U-&gt;&gt;SM: 选择元素    SM-&gt;&gt;S: 更新selectedIds    S-&gt;&gt;SM: 通知选中状态变更    SM-&gt;&gt;TR: 调用renderTransformer()    TR-&gt;&gt;TR: 根据选中元素绘制变换控制器\n\n4.2 核心函数解析\nElementRenderer.renderElements():\n\n触发时机: 当画布元素数据发生变更时，通过状态订阅机制触发。每当 Zustand store 中的 elements 对象发生变化时，StageManagerCore 会调用此方法进行重新渲染。\n\n逻辑闭环: 遍历所有元素数据，根据元素类型创建或更新对应的 PIXI 对象，并将其添加到容器中。通过 diff 算法比较现有 spriteMap 和新元素数据（遍历 spriteMap 中的所有元素 ID，检查哪些元素在新的 elements 数据中不存在，这些元素需要被删除，遍历新的 elements 数据中的所有元素 ID，检查哪些是新增的元素需要创建，哪些是已存在的元素需要更新），确定需要创建、更新或删除的元素，最终保持 PIXI 对象与数据状态同步。\n\n核心实现:\n// 核心渲染逻辑public renderElements(  elements: Record&lt;string, CanvasElement&gt;,  elementLayer: PIXI.Container,  destroyed: boolean) {  if (destroyed) return;  // 获取当前所有元素ID  const elementIds = Object.keys(elements);  // 删除已移除的元素  for (const id of this.spriteMap.keys()) {    if (!elementIds.includes(id)) {      const sprite = this.spriteMap.get(id)!;      sprite.destroy({ children: true });      this.spriteMap.delete(id);    }  }  // 更新或创建元素  for (const id of elementIds) {    const data = elements[id];    if (this.spriteMap.has(id)) {      // 更新现有元素      this.updateElement(data, this.spriteMap.get(id)!);    } else {      // 创建新元素      const sprite = this.createElement(data);      elementLayer.addChild(sprite);      this.spriteMap.set(id, sprite);    }  }}\n\n差异化渲染处理:\n// 根据不同类型元素进行差异化渲染处理private createElement(data: CanvasElement): PIXI.DisplayObject {  switch (data.type) {    case 'rect':    case 'circle':    case 'triangle':      // 几何图形处理逻辑：使用Graphics API绘制形状      return this.createGraphicsElement(data);    case 'text':      // 文本元素处理逻辑：使用HTMLText组件渲染富文本      return this.createTextElement(data);    case 'image':      // 图片元素处理逻辑：加载纹理并创建Sprite      return this.createImageElement(data);    case 'line':    case 'arrow':    case 'pencil':      // 线条/铅笔元素处理逻辑：使用Graphics API绘制线条      return this.createLineElement(data);    default:      throw new Error(`Unsupported element type: ${data.type}`);  }}\n\n\n\nTransformerRenderer.renderTransformer():\n\n触发时机: 当选中元素发生变更时触发。每当 Zustand store 中的 selectedIds 数组发生变化时，StageManagerCore 会调用此方法更新变换控制器的显示。\n\n逻辑闭环: 根据选中元素的数量和类型，绘制相应的变换控制器（如缩放手柄、旋转手柄等）。通过清除之前的控制器图形并根据当前选中状态重新绘制，保持变换控制器与选中状态同步。\n\n核心实现:\n// 变换控制器渲染逻辑public renderTransformer(  elements: Record&lt;string, CanvasElement&gt;,  selectedIds: string[],  spriteMap: Map&lt;string, PIXI.DisplayObject&gt;,  onHandleDown: (    e: PIXI.FederatedPointerEvent,    handle: HandleType | 'p0' | 'p1',    elementId: string  ) =&gt; void,  viewportScale: number) {  // 清除之前的变换控制器  this.transformerGraphic.clear();  if (selectedIds.length === 0) return;  if (selectedIds.length === 1) {    // 单个元素选中逻辑    const element = elements[selectedIds[0]];    const sprite = spriteMap.get(selectedIds[0]);    if (sprite) {      this.drawSingleElementTransformer(element, sprite, onHandleDown, viewportScale);    }  } else {    // 多个元素选中逻辑    this.drawMultiElementTransformer(elements, selectedIds, spriteMap, onHandleDown, viewportScale);  }}\n\n\n\n\nUI 与样式实现 (UI Implementation)\n布局策略: 使用 PIXI 的容器系统进行布局管理，分为 elementLayer（元素层）和 uiLayer（UI 层）两个层级，通过坐标系统定位元素\n\nelementLayer: 用于承载所有画布元素的容器层，包括矩形、圆形、文本、图像等各种元素的 PIXI 对象都添加到这一层。这是渲染层的主要内容，负责显示用户创建的所有图形元素。\n\nuiLayer: 用于承载所有 UI 元素的容器层，包括选区框、橡皮擦指示器、变换控制器等辅助 UI 元素。这一层位于元素层之上，确保 UI 元素始终显示在图形元素的前面。\n\n\n// 在 StageManagerCore.ts 中创建两个容器层private elementLayer: PIXI.Container = new PIXI.Container()private uiLayer: PIXI.Container = new PIXI.Container()// 将两个容器层添加到视口中this.viewport.addChild(this.elementLayer)this.viewport.addChild(this.uiLayer)\n\n样式方案:\n\n几何图形使用 PIXI 的绘图 API 进行绘制，支持描边、填充、透明度等样式\n文本元素使用 HTMLText 组件支持富文本渲染\n图片元素使用 PIXI.Sprite 并支持滤镜效果（模糊、亮度、灰度等）\n变换控制器统一使用紫色 (#8b5cf6) 作为主题色\n\n\n条件渲染:\n\n根据元素类型选择不同的渲染方式\n根据选中状态决定是否显示变换控制器\n根据选中元素数量显示不同的控制器形态（单选手柄 vs 群组控制器）\n\n\n\ngraph TD\tA[Viewport] --&gt; B[elementLayer]\tA --&gt; C[uiLayer]\tB --&gt; D[图形元素 1]\tB --&gt; E[图形元素 2]\tB --&gt; F[文本元素]\tB --&gt; G[图像元素]\tC --&gt; H[选区框]\tC --&gt; I[橡皮擦指示器]\tC --&gt; J[变换控制器]\t    style A fill:#e1f5fe    style B fill:#f3e5f5    style C fill:#e8f5e8    style D fill:#fce4ec    style E fill:#fce4ec    style F fill:#fce4ec    style G fill:#fce4ec    style H fill:#fff3e0    style I fill:#fff3e0    style J fill:#fff3e0\n","categories":["笔记"],"tags":["前端开发"]},{"title":"2025-11-05-基于随机加权推断模型（IM）的参数估计算法","url":"/Arknight-notes/posts/10893.html","content":"基于随机加权推断模型（IM）的参数估计方法不可观测的泊松过程  和 ，观测值  和辅助变量 ，目标是估计参数 、m?\n现提出基于随机加权推断模型（Inferential Model, IM）的算法通过引入随机权重处理离散分布，来构造置信区间\n方法概述随机加权 IM 方法的核心是通过引入均匀随机变量和权重，将离散泊松分布连续化，从而逆解参数该方法假设  已知算法分为四个步骤：建立关联模型、引入随机权重连续化、逆解参数、模拟验证覆盖率\n算法步骤1: 建立关联模型对观测值 ，其分布函数为 ，其中 引入辅助变量 ，建立关联：\nF_{θ}(Y-1) \\leq u < F_{θ}(Y)对观测值 ，其分布函数为 ，引入辅助变量 ，建立关联：\nF_{mb}(W-1) \\leq v \\leq F_{mb}(W)2: 引入随机权重进行连续化引入随机权重 ，构造方程：\nG(θ): w_1 F_{θ}(Y-1) + (1-w_1) F_{θ}(Y) = uH(mb): w_2 F_{mb}(W-1) + (1-w_2) F_{mb}(W) = v 和  是关于参数的函数，且由于泊松分布函的单调性，逆函数  和  存在\n3: 逆解参数，使用 brentq 函数进行二分法求根从上述方程解出  和 ：\nθ = G^{-1}(u), \\quad mb = H^{-1}(v)推导参数：\nb = \\frac{H^{-1}(v)}{m}, \\quad q = θ - b = G^{-1}(u) - \\frac{H^{-1}(v)}{m}得到  和  的表达式\n4: 验证覆盖率\n模拟目标：检查构造的置信区间覆盖真实  的概率是否接近 95%\n\n步骤：\n\n\n生成观测数据：从分布生成一对观测值 \n对于固定 ，生成大量样本（如  个）的 \n计算  的候选值：对于每个样本，计算 \n构造置信区间：从 10000 个 q 值中取分位数，得到置信区间 \n检查覆盖率：重复步骤 2-5 多次（  次），每次生成新的 ，计算区间覆盖真实  的比例覆盖率 覆盖次数\n算法实现import numpy as npimport pandas as pdfrom scipy.stats import poisson, gammafrom scipy.optimize import brentqimport matplotlib.pyplot as pltimport seaborn as snsfrom tqdm import tqdmimport warningswarnings.filterwarnings('ignore')# 设置全局字体为 SimHei (黑体) 或其他中文字体plt.rcParams['font.sans-serif'] = ['SimHei']plt.rcParams['axes.unicode_minus'] = Falseclass PoissonSignalInference:    \"\"\"    基于随机加权IM方法的泊松信号推断类    用于估计背景率b、信号率q和尺度参数m    \"\"\"    def __init__(self, b_true=None, q_true=None, m_true=None):        \"\"\"        初始化真实参数值        \"\"\"        self.b_true = b_true        self.q_true = q_true        self.m_true = m_true        self.STA_true = b_true + q_true if b_true is not None and q_true is not None else None    def generate_data(self, n_samples=1):        \"\"\"        生成观测数据Y和W        当前有不可观测的泊松过程 B ∼ Poisson(b) 和 S ∼ Poisson(q)        可观测对象有 Y = B + S ∼ Poisson(b + q) 和辅助变量 W ∼ Poisson(m · b)        目标是估计参数 b、q 和可能的 m        \"\"\"        if self.b_true is None or self.q_true is None or self.m_true is None:            raise ValueError(\"必须先设置真实参数值\")        if self.STA_true is None:            self.STA_true = self.b_true + self.q_true        Y = np.random.poisson(self.STA_true, n_samples)        W = np.random.poisson(self.m_true * self.b_true, n_samples)        return Y, W    def poisson_cdf(self, k, theta):        \"\"\"        计算泊松分布的累积分布函数        \"\"\"        return poisson.cdf(k, theta) #泊松分布的CDF公式，参数为 k 和 theta    def solve_G_inverse(self, u, Y, w1, bracket_low=0, bracket_high=100):        \"\"\"        求解方程 G(STA) = u 的逆函数，得到STA        使用二分法求解 G(STA): w_1 F_{STA}(Y-1) + (1-w_1) F_{STA}(Y) = u        计算泊松混合分布的累积分布函数值与目标值的差值        该函数计算一个泊松混合分布的CDF值，该混合分布由两个泊松分布组成，权重分别为w1和(1-w1)，        然后减去目标值u，通常用于求解分位数或进行概率计算        参数:            Y (int or array-like): 观测值，泊松分布的计数变量            STA (float or array-like): 泊松分布的参数λ（均值）            w1 (float): 第一个泊松分布的权重，取值范围[0,1]            u (float): 目标概率值，用于比较或求解        返回:        \"\"\"        def equation(STA): #返回值:(float or array-like): 泊松混合分布的CDF值与目标值u的差值            if Y == 0:                # 当Y=0时，F_STA(-1)=0，方程简化为F_STA(0)=u                return self.poisson_cdf(0, STA) - u            else:                return w1 * self.poisson_cdf(Y-1, STA) + (1-w1) * self.poisson_cdf(Y, STA) - u                # 求加权泊松混合分布                # 第一项：权重w1乘以P(X &lt;= Y-1)的概率                # 第二项：权重(1-w1)乘以P(X &lt;= Y)的概率                # 最后减去目标值u        try:            \"\"\"            使用二分法求解 G(STA) = u 方程中的 STA 值            \"\"\"            # 设置上下界来初始化搜索区间            low = max(0.00001, bracket_low) #bracket_low下界（）            high = max(10 * Y, bracket_high) if Y &gt; 0 else bracket_high #bracket_high上界，根据观测值 Y 调整上界            # 检查边界值            f_low = equation(low)            f_high = equation(high)            if f_low * f_high &gt; 0:                # 如果 f_low * f_high &gt; 0（同号），则自动扩大搜索区间                attempts = 0                while f_low * f_high &gt; 0 and attempts &lt; 10:                    high *= 2 #最多尝试10次，每次将上界翻倍：high *= 2                    f_high = equation(high)                    attempts += 1            STA_solution = brentq(equation, low, high, xtol=1e-6)            \"\"\"            参数为要求解的方程（加权泊松混合分布），上下区间，精度            使用 brentq 函数进行二分法求根            求解 w1 * self.poisson_cdf(Y-1, STA) + (1-w1) * self.poisson_cdf(Y, STA) - u = 0            即求解方程 G(STA) = u            得到STA            \"\"\"            return STA_solution #返回求解得到的 STA 值        except (ValueError, RuntimeError):            # 如果求解失败，返回保守估计            print(\"ERR solve_G_inverse 求解失败，返回保守估计\")            return max(0.001, Y)    def solve_H_inverse(self, v, W, w2, m, bracket_low=0, bracket_high=100):        \"\"\"        求解方程 H(mb) = v 的逆函数，得到mb        H(mb): w_2 F_{mb}(W-1) + (1-w_2) F_{mb}(W) = v        \"\"\"        def equation(mb):            if W == 0:                return self.poisson_cdf(0, mb) - v            else:                return w2 * self.poisson_cdf(W-1, mb) + (1-w2) * self.poisson_cdf(W, mb) - v        try:            low = max(0.001, bracket_low)            high = max(10 * W, bracket_high) if W &gt; 0 else bracket_high            f_low = equation(low)            f_high = equation(high)            if f_low * f_high &gt; 0:                attempts = 0                while f_low * f_high &gt; 0 and attempts &lt; 10:                    high *= 2                    f_high = equation(high)                    attempts += 1            mb_solution = brentq(equation, low, high, xtol=1e-6)            return mb_solution        except (ValueError, RuntimeError):            return max(0.001, W)    def estimate_parameters_IM(self, Y_obs, W_obs, m_known=True, n_inner_samples=10000):        \"\"\"        使用随机加权IM方法估计三个参数q、b和STA        Y_obs：观测值Y        W_obs：观测值W        m_known：一个布尔值，表示参数m是否已知        n_inner_samples：内部采样次数，默认为10000        \"\"\"        if not m_known:            raise NotImplementedError(\"m未知\")        # 创建三个列表存储候选参数值        q_candidates = []        b_candidates = []        STA_candidates = []        for _ in range(n_inner_samples):            # 生成4个均匀分布的随机权重（u, v, w1, w2）            u = np.random.uniform(0, 1)            v = np.random.uniform(0, 1)            w1 = np.random.uniform(0, 1)            w2 = np.random.uniform(0, 1)            # 使用solve_G_inverse和solve_H_inverse方法计算STA和mb的估计值            STA_est = self.solve_G_inverse(u, Y_obs, w1)            mb_est = self.solve_H_inverse(v, W_obs, w2, self.m_true)            # G(STA): w_1 F_{STA}(Y-1) + (1-w_1) F_{STA}(Y) = u ==&gt; 求解STA            # H(mb): w_2 F_{mb}(W-1) + (1-w_2) F_{mb}(W) = v ==&gt; 求解mb            # 可以得到            # STA = G⁻¹(u), mb = H⁻¹(v)            # 计算b和q            # b = H⁻¹(v)/m            # q = STA - b = G⁻¹(u) - H⁻¹(v)/m            if self.m_true is None:                raise ValueError(\"参数 m_true 未设置，无法计算 b_est\")            b_est = mb_est / self.m_true            q_est = STA_est - b_est            # 确保非负            q_est = max(0, q_est)            b_est = max(0, b_est)            #每次计算出新的 q_est 值后，会将其添加到 q_candidates 列表中            q_candidates.append(q_est)            b_candidates.append(b_est)            STA_candidates.append(STA_est)        return {            'q_candidates': np.array(q_candidates),            'b_candidates': np.array(b_candidates),            'STA_candidates': np.array(STA_candidates)        }    def calculate_confidence_intervals(self, candidates_dict, alpha=0.05):        \"\"\"        计算参数的置信区间        \"\"\"        intervals = {}        for param, values in candidates_dict.items():            # 移除'_candidates'后缀，使键名简化            simple_param = param.replace('_candidates', '')            lower = np.quantile(values, alpha/2)            upper = np.quantile(values, 1 - alpha/2)            intervals[simple_param] = (lower, upper)        return intervals    def coverage_simulation(self, n_outer_trials=1000, n_inner_samples=1000, alpha=0.05):        \"\"\"        进行覆盖率模拟验证        \"\"\"        coverage_results = {            'q': 0.0,            'b': 0.0,            'STA': 0.0        }        interval_lengths = {            'q': [],            'b': [],            'STA': []        }        print(\"正在进行覆盖率模拟...\")        for i in tqdm(range(n_outer_trials)):            # 生成新的观测数据            Y_obs, W_obs = self.generate_data(1)            Y_obs, W_obs = Y_obs[0], W_obs[0]            # 估计参数            candidates_dict = self.estimate_parameters_IM(Y_obs, W_obs,                                                         n_inner_samples=n_inner_samples)            # 计算置信区间            intervals = self.calculate_confidence_intervals(candidates_dict, alpha)            # 检查覆盖率            if intervals['q'][0] &lt;= self.q_true &lt;= intervals['q'][1]:                coverage_results['q'] += 1            if intervals['b'][0] &lt;= self.b_true &lt;= intervals['b'][1]:                coverage_results['b'] += 1            if intervals['STA'][0] &lt;= self.STA_true &lt;= intervals['STA'][1]:                coverage_results['STA'] += 1            # 记录区间长度            interval_lengths['q'].append(intervals['q'][1] - intervals['q'][0])            interval_lengths['b'].append(intervals['b'][1] - intervals['b'][0])            interval_lengths['STA'].append(intervals['STA'][1] - intervals['STA'][0])        # 计算覆盖率        for param in coverage_results:            coverage_results[param] = coverage_results[param] / n_outer_trials        return coverage_results, interval_lengths    def plot_results(self, candidates_dict, intervals, Y_obs, W_obs):        \"\"\"        可视化结果        \"\"\"        fig, axes = plt.subplots(2, 2, figsize=(15, 10))        # q的分布        axes[0, 0].hist(candidates_dict['q_candidates'], bins=50, alpha=0.7, density=True)        axes[0, 0].axvline(self.q_true, color='red', linestyle='--', linewidth=2, label=f'真实 q = {self.q_true}')        axes[0, 0].axvline(intervals['q'][0], color='green', linestyle='--', linewidth=1, label=f'{100*(1-0.05)}% CI')        axes[0, 0].axvline(intervals['q'][1], color='green', linestyle='--', linewidth=1)        axes[0, 0].set_xlabel('q')        axes[0, 0].set_ylabel('密度')        axes[0, 0].set_title('q的后验分布')        axes[0, 0].legend()        # b的分布        axes[0, 1].hist(candidates_dict['b_candidates'], bins=50, alpha=0.7, density=True)        axes[0, 1].axvline(self.b_true, color='red', linestyle='--', linewidth=2, label=f'真实 b = {self.b_true}')        axes[0, 1].axvline(intervals['b'][0], color='green', linestyle='--', linewidth=1, label=f'{100*(1-0.05)}% CI')        axes[0, 1].axvline(intervals['b'][1], color='green', linestyle='--', linewidth=1)        axes[0, 1].set_xlabel('b')        axes[0, 1].set_ylabel('密度')        axes[0, 1].set_title('b的后验分布')        axes[0, 1].legend()        # STA的分布        axes[1, 0].hist(candidates_dict['STA_candidates'], bins=50, alpha=0.7, density=True)        axes[1, 0].axvline(self.STA_true, color='red', linestyle='--', linewidth=2, label=f'真实 STA = {self.STA_true}')        axes[1, 0].axvline(intervals['STA'][0], color='green', linestyle='--', linewidth=1, label=f'{100*(1-0.05)}% CI')        axes[1, 0].axvline(intervals['STA'][1], color='green', linestyle='--', linewidth=1)        axes[1, 0].set_xlabel('STA')        axes[1, 0].set_ylabel('密度')        axes[1, 0].set_title('STA的后验分布')        axes[1, 0].legend()        # 观测数据信息        axes[1, 1].axis('off')        text_str = f'观测数据:\\nY = {Y_obs}\\nW = {W_obs}\\n\\n真实参数:\\nb = {self.b_true}\\nq = {self.q_true}\\nm = {self.m_true}\\nSTA = {self.STA_true}'        axes[1, 1].text(0.1, 0.9, text_str, transform=axes[1, 1].transAxes, fontsize=12,                    verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))        plt.tight_layout()        plt.show()def main():    \"\"\"    主函数：演示完整的推断流程    \"\"\"    # 设置真实参数    b_true = 3.0  # b    q_true = 2.0  # q    m_true = 0.8  # 尺度参数（已知）    STA_true = b_true + q_true    print(\"=== 泊松推断演示 ===\")    print(f\"真实参数: b={b_true}, q={q_true}, m={m_true}, STA={STA_true}\")    # 初始化推断器    inference = PoissonSignalInference(b_true, q_true, m_true)    # 生成单次观测数据    Y_obs, W_obs = inference.generate_data(1)    Y_obs, W_obs = Y_obs[0], W_obs[0]    print(f\"\\n生成的观测数据: Y={Y_obs}, W={W_obs}\")    # 使用IM方法进行参数估计    print(\"\\n正在进行参数估计...\")    candidates_dict = inference.estimate_parameters_IM(Y_obs, W_obs, n_inner_samples=10000)    # 计算置信区间    alpha = 0.05  # 0.95置信区间    intervals = inference.calculate_confidence_intervals(candidates_dict, alpha)    print(\"\\n=== 估计结果 ===\")    for param, (lower, upper) in intervals.items():        true_value = getattr(inference, f\"{param.replace('_candidates', '')}_true\", None)        if true_value is not None:            print(f\"{param}: [{lower:.3f}, {upper:.3f}] (真实值: {true_value:.3f})\")        else:            print(f\"{param}: [{lower:.3f}, {upper:.3f}]\")    # 可视化结果    print(\"\\n生成可视化图表...\")    inference.plot_results(candidates_dict, intervals, Y_obs, W_obs)    # 进行覆盖率模拟（样本量较小以加快演示速度）    print(\"\\n正在进行覆盖率模拟...\")    coverage_results, interval_lengths = inference.coverage_simulation(        n_outer_trials=500,  # 减少试验次数以加快演示        n_inner_samples=1000,  # 减少内部样本数        alpha=0.05    )    print(\"\\n=== 覆盖率结果 ===\")    for param, coverage in coverage_results.items():        print(f\"{param}的覆盖率: {coverage:.3f} (目标: {1-alpha:.3f})\")    # 绘制区间长度分布    plt.figure(figsize=(12, 4))    for i, (param, lengths) in enumerate(interval_lengths.items()):        plt.subplot(1, 3, i+1)        plt.hist(lengths, bins=30, alpha=0.7)        plt.xlabel(f'{param}区间长度')        plt.ylabel('频数')        plt.title(f'{param}置信区间长度分布')    plt.tight_layout()    plt.show()if __name__ == \"__main__\":    main()\n","categories":["归档"],"tags":["日志"]},{"title":"2025-11-23-canvas项目相关-逻辑层","url":"/Arknight-notes/posts/62457.html","content":"1. 模块摘要 (Executive Summary)逻辑层负责协调状态管理层和渲染层之间的交互。它通过 StageManagerCore 类实现，主要处理用户交互、协调状态更新、管理渲染流程、维护交互状态\n\n项目结构树：\nsrc/└── pages/    └── canvas/        ├── Pixi_stageManager.ts               # StageManager 入口文件        └── Pixi_STM_modules/                  # StageManager 模块目录            ├── core/            │   ├── StageManagerCore.ts        # 核心类            │   └── types.ts                   # 类型定义文件            ├── rendering/            │   ├── ElementRenderer.ts         # 元素渲染器            │   └── TransformerRenderer.ts     # 变换控制器渲染器            ├── interaction/            │   └── InteractionHandler.ts      # 交互处理器            └── utils/                └── cursorUtils.ts             # 光标工具函数\n\nPixiJS：WebGL 渲染引擎，负责图形渲染\npixi-viewport：视口管理插件，处理画布缩放和平移\nZustand：状态管理库，与状态管理层对接\nnanoid：用于生成唯一 ID\n\n\n\n2. Props 和相关类型定义2.1 StageManagerCore 构造函数参数StageManagerCore 类通过构造函数接收容器元素参数。\n\n\n\n\n参数名\n类型\n必填\n默认值\n描述\n\n\n\n\ncontainer\nHTMLElement\n是\n无\n用于挂载 PixiJS 应用的 DOM 容器\n\n\n\n\n代码示例：\n// 创建 StageManager 实例const stageManager = new StageManagerCore(containerElement);\n2.2 核心类型定义StageManagerState 类型：定义了 StageManager 的核心状态。\ninterface StageManagerState {  mode: InteractionMode; // 当前交互模式  startPos: { x: number; y: number }; // 起始坐标  currentId: string | null; // 当前操作元素 ID  initialElementsMap: Record&lt;string, Partial&lt;CanvasElement&gt;&gt; | null; // 初始元素映射  initialGroupBounds: {    x: number;    y: number;    width: number;    height: number;  } | null; // 初始群组边界  initialElementState: Partial&lt;CanvasElement&gt; | null; // 初始元素状态  resizeInitialStates: Record&lt;string, Partial&lt;CanvasElement&gt;&gt; | null; // 调整大小初始状态  dragInitialStates: Record&lt;string, Partial&lt;CanvasElement&gt;&gt; | null; // 拖拽初始状态  activeHandle: HandleType | null; // 激活的手柄  isSpacePressed: boolean; // 空格键是否按下  destroyed: boolean; // 是否已销毁}\nInteractionMode 类型：定义了用户与画布交互的各种模式。\ntype InteractionMode =  | \"idle\" // 空闲状态  | \"panning\" // 画布平移  | \"selecting\" // 选择元素  | \"dragging\" // 拖拽元素  | \"resizing\" // 调整元素大小  | \"drawing\" // 绘制元素  | \"texting\" // 文本编辑  | \"erasing\"; // 擦除元素\n3. 核心状态管理 (State Architecture)3.1 内部状态 (Local State)StageManagerCore 维护以下内部状态：\n\n\n\n\n状态名\n类型\n描述\n\n\n\n\napp\nPIXI.Application\nPixiJS 应用实例\n\n\nviewport\nViewport\npixi-viewport 实例\n\n\nelementLayer\nPIXI.Container\n元素图层容器\n\n\nuiLayer\nPIXI.Container\nUI 图层容器\n\n\nelementRenderer\nElementRenderer\n元素渲染器实例\n\n\ntransformerRenderer\nTransformerRenderer\n变换控制器渲染器实例\n\n\ninteractionHandler\nInteractionHandler\n交互处理器实例\n\n\nstate\nStageManagerState\n交互状态对象\n\n\nselectionRectGraphic\nPIXI.Graphics\n选区框图形对象\n\n\neraserGraphic\nPIXI.Graphics\n橡皮擦指示器图形对象\n\n\n\n\n3.2 外部状态 (Global/Server State)逻辑层通过 Zustand 状态管理库订阅外部状态：\n\n\n\n\n状态名\n类型\n描述\n\n\n\n\nelements\nRecord\n所有画布元素数据\n\n\nselectedIds\nstring[]\n当前选中的元素 ID 数组\n\n\ntool\nToolType\n当前工具类型\n\n\n\n\n3.3 状态同步机制graph TD    A[Zustand Store 状态变更] --&gt; B{StageManager 订阅}    B --&gt; C{状态处理}    C --&gt; D[ElementRenderer.renderElements]    C --&gt; E[TransformerRenderer.renderTransformer]    C --&gt; F[更新视口状态]    C --&gt; G[更新光标样式]    D --&gt; H[PixiJS 渲染元素]    E --&gt; I[PixiJS 渲染变换控制器]        style A fill:#e1f5fe    style H fill:#e8f5e8    style I fill:#e8f5e8    style F fill:#fff3e0    style G fill:#fff3e0\n4. 逻辑流程 (Logic Flow)4.1 交互时序图 (Mermaid)sequenceDiagram    participant U as 用户    participant SM as StageManagerCore    participant IH as InteractionHandler    participant ZS as Zustand Store    participant ER as ElementRenderer    participant TR as TransformerRenderer        U-&gt;&gt;IH: 触发交互事件 (点击/拖拽等)    IH-&gt;&gt;SM: 调用处理函数 (onPointerDown等)    SM-&gt;&gt;SM: 更新内部状态 (mode, startPos等)    SM-&gt;&gt;ZS: 更新画布数据 (addElement等)    ZS-&gt;&gt;SM: 通知状态变更    SM-&gt;&gt;ER: 调用renderElements()    SM-&gt;&gt;TR: 调用renderTransformer()    ER-&gt;&gt;ER: 更新 PIXI 元素    TR-&gt;&gt;TR: 更新变换控制器\n4.2 核心函数解析onPointerDown 函数：当用户在画布上按下鼠标时触发，根据当前工具和点击位置处理不同的交互逻辑（选择、绘制、拖拽等）\nprivate onPointerDown = (e: PIXI.FederatedPointerEvent) =&gt; {  // 处理防抖  this.triggerDebounceSnapshot()  // 获取当前状态  const state = useStore.getState()  const tool = state.tool  const worldPos = e.getLocalPosition(this.viewport)  // 根据工具类型处理不同逻辑  if (tool === 'text') {    // 处理文本工具  } else if (tool === 'eraser') {    // 处理橡皮擦工具  } else if (e.target &amp;&amp; e.target.label) {    // 处理元素点击  } else {    // 处理绘制或选择  }}\nonPointerMove 函数：当用户在画布上移动鼠标时触发，根据当前交互模式处理不同的移动逻辑（绘制、拖拽、调整大小等）\nprivate onPointerMove = (e: PIXI.FederatedPointerEvent) =&gt; {  // 处理防抖  this.triggerDebounceSnapshot()  if (this.state.mode === 'idle') return  const state = useStore.getState()  const currentPos = e.getLocalPosition(this.viewport)  switch (this.state.mode) {    case 'selecting':      // 处理选择框绘制      break    case 'erasing':      // 处理橡皮擦操作      break    case 'dragging':      // 处理元素拖拽      break    case 'resizing':      // 处理元素调整大小      break    case 'drawing':      // 处理元素绘制      break  }}\n5. UI 与样式实现 (UI Implementation)逻辑层通过管理不同图层来实现 UI 布局：\ngraph TD    A[Viewport] --&gt; B[elementLayer]    A --&gt; C[uiLayer]    B --&gt; D[图形元素]    C --&gt; E[选区框]    C --&gt; F[橡皮擦指示器]    C --&gt; G[变换控制器]        style A fill:#e1f5fe    style B fill:#f3e5f5    style C fill:#e8f5e8    style D fill:#fce4ec    style E fill:#fff3e0    style F fill:#fff3e0    style G fill:#fff3e0\n使用 PixiJS 的容器系统管理图层，分为元素层和 UI 层，通过 PIXI.Graphics API 实现图形绘制，通过 CSS 控制光标样式\n","categories":["归档"],"tags":["前端开发","PixiJS"]},{"title":"前端项目安装和配置 Vite + React + TypeScript + Tailwind CSS","url":"/Arknight-notes/posts/39845.html","content":"一般写的多的话直接留一个现有的装好依赖就用了反正记录一下\nVite + React + TypeScript + Tailwind CSS 脚手架搭建指南本文记录从零搭建 Vite + React + Tailwind CSS 项目，省去一个个官网去查阅文档，旨在方便快速丝滑的创建项目\n概览\nVite 4.2.0 - 新一代构建工具，提供极快的冷启动和热更新。基于原生 ES 模块实现，开发时按需编译，相比传统打包工具具有显著的速度优势。\nReact 18.2.0 - 流行的前端 UI 库，采用组件化架构和虚拟 DOM 技术，提供高效的渲染性能和良好的开发体验。\nTypeScript 5.3.3 - JavaScript 的超集，提供静态类型检查，在编译阶段发现潜在错误，增强代码可维护性和开发效率。\nTailwind CSS 3.3.1 - 实用优先的 CSS 框架，通过组合预定义的原子类来构建界面，无需编写自定义 CSS 即可实现复杂设计。\nESLint &amp; Prettier - 代码规范和格式化工具。ESLint 用于检测代码质量问题和潜在错误，Prettier 专注于代码格式统一，共同保障代码质量。\nHusky &amp; lint-staged - Git 钩子工具，用于提交前代码检查。Husky 简化 Git 钩子配置，lint-staged 仅对暂存文件执行操作，提升提交前检查效率。\nReact Router DOM 6 - React 应用的路由管理工具，提供声明式路由配置，支持动态路由、嵌套路由等特性，是构建单页应用的核心组件。\n\n结构BDdraw_DEV/├── .husky/                     # Git hooks 配置├── .vscode/                    # VSCode 配置├── docs/                       # 文档目录├── public/                     # 静态资源目录├── src/                        # 源代码主目录│   ├── api/                    # API 接口定义│   ├── assets/                 # 静态资源文件│   ├── components/             # 公共组件│   ├── hooks/                  # 自定义 React Hooks│   ├── lib/                    # 工具库和核心功能模块│   ├── pages/                  # 页面组件│   ├── router/                 # 路由配置│   │   └── router.tsx          # 路由定义│   ├── stores/                 # 状态管理│   ├── styles/                 # 样式文件│   ├── app.tsx                 # 应用入口组件│   ├── main.tsx                # 主入口文件│   └── vite-env.d.ts           # Vite 环境声明文件├── .editorconfig               # 编辑器配置├── .eslintrc                  # ESLint 配置├── .gitignore                 # Git 忽略文件配置├── .prettierrc.js             # Prettier 配置├── .stylelintrc.json          # Stylelint 配置├── commitlint.config.cjs      # Commitlint 配置├── components.json            # 组件配置├── index.html                 # HTML 入口├── lint-staged.config.js      # Lint-staged 配置├── package.json               # 项目依赖和脚本配置├── postcss.config.js          # PostCSS 配置├── tailwind.config.js         # Tailwind CSS 配置├── transmart.config.ts        # Transmart 配置├── tsconfig.json              # TypeScript 配置├── tsconfig.node.json         # Node.js TypeScript 配置├── vite.config.ts             # Vite 配置└── README.md                  # 项目说明文档\n初始化项目使用 Vite 创建项目\nnpm create vite@latest [项目名] -- --template react-tscd [项目名]\n安装依赖\nnpm install\n集成 Tailwind CSS v3Tailwind CSS 是一个功能类优先的 CSS 框架，它提供了大量的实用类，可以直接在 HTML 中组合使用来构建任何设计。通过配置文件可以自定义主题、颜色、间距等设计系统，并且只生成实际使用的样式，使得最终的 CSS 文件非常精简。其 JIT（Just-In-Time）模式可以按需生成样式，大大提高了编译速度并支持更多功能。\n安装 Tailwind CSS v3 及其依赖\nnpm install -D tailwindcss postcss autoprefixernpx tailwindcss init -p\n如果出问题可以去翻一下官方文档，v4 改变了一些部署方式\n配置 Tailwind CSS\n编辑 tailwind.config.js 文件：\n/** @type {import('tailwindcss').Config} */module.exports = {  content: [\"./index.html\", \"./src/**/*.{js,ts,jsx,tsx}\"],  theme: {    extend: {},  },  plugins: [],};\n引入 Tailwind CSS v3在 src/index.css 文件中添加：\n@tailwind base;@tailwind components;@tailwind utilities;\n并在入口文件中导入该 CSS 文件：\nTailwind CSS 的三个核心层：\n\n@tailwind base - 包含 Normalize.css 和一些基础样式重置\n@tailwind components - 包含框架的组件类，可用于添加结构样式\n@tailwind utilities - 包含所有实用类，这是 Tailwind 的核心部分\n\n通过这种分层方式，Tailwind 提供了一种灵活的方式来组织和扩展样式。\n配置 TypeScriptTypeScript 是 JavaScript 的超集，添加了可选的静态类型。它可以帮助开发者在编码阶段捕获错误，提供更好的代码补全和重构支持。通过配置 tsconfig.json，我们可以控制 TypeScript 编译器的行为，如目标 JavaScript 版本、模块解析策略、严格性级别等。在本项目中，我们启用了严格的类型检查，同时配置了 React JSX 支持。\n项目中的 tsconfig.json 文件已经包含了基本的 TypeScript 配置。根据项目需求，我们可以对其进行定制：\n{  \"compilerOptions\": {    \"target\": \"ESNext\",    \"useDefineForClassFields\": true,    \"lib\": [\"DOM\", \"DOM.Iterable\", \"ESNext\"],    \"allowJs\": false,    \"skipLibCheck\": true,    \"esModuleInterop\": false,    \"allowSyntheticDefaultImports\": true,    \"strict\": true,    \"forceConsistentCasingInFileNames\": true,    \"module\": \"ESNext\",    \"moduleResolution\": \"Node\",    \"resolveJsonModule\": true,    \"isolatedModules\": true,    \"noEmit\": true,    \"jsx\": \"react-jsx\"  },  \"include\": [\"src\"],  \"references\": [{ \"path\": \"./tsconfig.node.json\" }]}\n配置 ESLint 和 PrettierESLint 是一个可插拔的 JavaScript 和 TypeScript 代码质量检查工具，它可以识别语法错误和代码风格问题。Prettier 是一个代码格式化工具，专注于代码风格统一。两者结合使用可以确保团队代码质量和风格的一致性。通过配置规则，我们可以自定义检查标准，例如是否使用分号、引号类型、缩进大小等。\n安装相关依赖\nnpm install -D eslint prettier eslint-config-prettier eslint-plugin-prettier eslint-plugin-react eslint-plugin-react-hooks @typescript-eslint/eslint-plugin @typescript-eslint/parser\n配置 ESLint\n创建 .eslintrc 文件：\n{  \"env\": {    \"browser\": true,    \"es2021\": true  },  \"extends\": [    \"eslint:recommended\",    \"plugin:@typescript-eslint/recommended\",    \"plugin:react/recommended\",    \"plugin:react-hooks/recommended\",    \"prettier\"  ],  \"parser\": \"@typescript-eslint/parser\",  \"parserOptions\": {    \"ecmaVersion\": \"latest\",    \"sourceType\": \"module\"  },  \"plugins\": [\"@typescript-eslint\", \"react\", \"prettier\"],  \"rules\": {    \"prettier/prettier\": \"error\",    \"react/react-in-jsx-scope\": \"off\"  },  \"settings\": {    \"react\": {      \"version\": \"detect\"    }  }}\n配置 Prettier\n创建 .prettierrc 文件：\n{  \"semi\": false,  \"singleQuote\": true,  \"tabWidth\": 2,  \"trailingComma\": \"es5\"}\n配置 Git HooksGit Hooks 允许我们在 Git 操作的不同阶段执行自定义脚本。通过 Husky 和 lint-staged，我们可以在代码提交前自动运行 ESLint 和 Prettier，确保只有符合规范的代码才能进入代码库。lint-staged 只会针对暂存区的文件运行检查，提高效率。这有助于保持整个项目的代码质量和一致性。\n使用 Husky 和 lint-staged 在代码提交前自动运行代码检查和格式化。\n安装依赖\nnpm install -D husky lint-staged\n初始化 Husky\nnpx husky install\n配置 lint-staged\n创建 lint-staged.config.js 文件：\nmodule.exports = {  \"*.{ts,tsx}\": [\"eslint --fix\", \"prettier --write\"],  \"*.{css,md}\": \"prettier --write\",};\n添加 pre-commit 钩子\nnpx husky add .husky/pre-commit \"npx lint-staged\"\n集成 React RouterReact Router 是 React 应用中最流行的路由解决方案，它允许我们构建单页应用程序(SPA)，通过 URL 的变化来展示不同的视图组件。它提供了声明式的路由配置，支持嵌套路由、动态路由参数、编程式导航等功能。通过使用 React Router，我们可以轻松地管理应用的不同页面和视图之间的导航关系。\n安装 React Router\nnpm install react-router-domnpm install -D @types/react-router-dom\n创建路由配置\n创建 src/router/router.tsx 文件：\nimport { createBrowserRouter } from \"react-router-dom\";import Home from \"../pages/Home\";import About from \"../pages/About\";const router = createBrowserRouter([  {    path: \"/\",    element: &lt;Home /&gt;,  },  {    path: \"/about\",    element: &lt;About /&gt;,  },]);export default router;\n在应用中使用路由\n更新 src/App.tsx 文件：\nimport { RouterProvider } from \"react-router-dom\";import router from \"./router/router\";function App() {  return &lt;RouterProvider router={router} /&gt;;}export default App;\n创建页面组件\n创建 src/pages/Home.tsx 和 src/pages/About.tsx 文件：\n// src/pages/Home.tsximport React from \"react\";const Home: React.FC = () =&gt; {  return (    &lt;div&gt;      &lt;h1&gt;首页&lt;/h1&gt;    &lt;/div&gt;  );};export default Home;\n// src/pages/About.tsximport React from \"react\";const About: React.FC = () =&gt; {  return (    &lt;div&gt;      &lt;h1&gt;关于&lt;/h1&gt;    &lt;/div&gt;  );};export default About;\nReact Router 是 React 应用中最流行的路由解决方案，它允许我们构建单页应用程序(SPA)，通过 URL 的变化来展示不同的视图组件。它提供了声明式的路由配置，支持嵌套路由、动态路由参数、编程式导航等功能。通过使用 React Router，我们可以轻松地管理应用的不同页面和视图之间的导航关系。\n配置 Vite项目的 vite.config.ts 文件配置如下：\nimport { defineConfig } from \"vite\";import react from \"@vitejs/plugin-react\";import path from \"path\";// https://vitejs.dev/config/export default defineConfig({  plugins: [react()],  resolve: {    alias: {      \"@\": path.resolve(__dirname, \"./src\"),    },  },  css: {    postcss: \"./postcss.config.js\",  },  server: {    port: 3000,  },});\n配置 PostCSSPostCSS 是一个使用 JavaScript 插件转换 CSS 的工具。在这个项目中，我们使用了两个关键插件：\n\nTailwind CSS 插件：处理 Tailwind CSS 相关的样式生成\nAutoprefixer 插件：自动添加厂商前缀以确保样式在不同浏览器中的兼容性\n\n通过 PostCSS，我们可以自动化处理 CSS，减少手动工作并提高样式兼容性。\npostcss.config.js 文件配置如下：\nmodule.exports = {  plugins: {    tailwindcss: {},    autoprefixer: {},  },};\n添加常用组件和工具通过创建可复用的 UI 组件和自定义 Hooks，可以大大提高开发效率并保证界面一致性。路径别名的配置使得导入模块更加简洁，避免了复杂的相对路径引用。\n创建基础 UI 组件：在 src/components/ui 目录下创建一些基础 UI 组件，例如按钮、输入框等\n创建自定义 Hooks：在 src/hooks 目录下创建常用的自定义 Hooks，例如 useLocalStorage、useToggle 等\n配置路径别名：在 tsconfig.json 中配置路径别名，方便导入模块：\n{  \"compilerOptions\": {    // ... 其他配置    \"baseUrl\": \".\",    \"paths\": {      \"@/*\": [\"src/*\"]    }  }}\n通过创建可复用的 UI 组件和自定义 Hooks，可以大大提高开发效率并保证界面一致性。路径别名的配置使得导入模块更加简洁，避免了复杂的相对路径引用。\n其他重要配置文件说明.gitignore.gitignore 文件用于指定 Git 应当忽略的文件和目录，防止不必要的文件被提交到代码仓库。在本项目中，该文件包含了以下几类被忽略的内容：\n\n系统文件：如 macOS 系统生成的 .DS_Store 文件\n日志文件：如 npm、yarn 等生成的日志文件\n依赖目录：如 node_modules/ 目录\n构建输出：如构建工具生成的 dist/、.next/ 等目录\n缓存文件：如各种工具生成的缓存文件\n环境变量文件：如 .env 及其变体文件，防止敏感信息泄露\n编辑器配置：如编辑器生成的临时文件\n\n通过合理配置 .gitignore，可以减小代码仓库体积，保护敏感信息，并避免无关文件干扰开发。\n.editorconfig.editorconfig 文件用于统一不同编辑器和 IDE 的代码格式设置。在团队协作中，不同开发者可能使用不同的编辑器，该文件可以确保所有人使用相同的编码规范：\n\n使用空格缩进，缩进大小为 2 个空格\n行尾符使用 LF (Unix 风格)\n字符编码使用 UTF-8\n自动删除行尾空白字符\n文件末尾自动添加新行\n\n这有助于保持代码风格的一致性，避免因编辑器差异导致的格式混乱。\n.prettierrc.jsPrettier 配置文件，用于统一代码格式化风格：\n\n不使用分号结尾\n对象和数组末尾保留逗号\n使用单引号而非双引号\n单行最大宽度为 120 字符\n缩进使用 2 个空格\n行尾符自动适应操作系统\n\nPrettier 会在保存文件或执行格式化命令时自动应用这些规则，确保整个项目的代码风格统一。\ncommitlint.config.cjsCommitlint 配置文件，用于校验 Git 提交信息的格式。它继承了 @commitlint/config-conventional 规则，要求提交信息遵循约定式提交规范：\n&lt;type&gt;[optional scope]: &lt;description&gt;[optional body][optional footer(s)]\n其中 type 必须是以下几种之一：\n\nfeat: 新功能\nfix: 修复 bug\nchore: 构建过程或辅助工具的变动\ndocs: 文档更新\nstyle: 代码格式调整\nrefactor: 重构\nperf: 性能优化\ntest: 测试用例\n\n这有助于生成标准化的变更日志，便于团队理解和维护项目历史。\n.stylelintrc.jsonStylelint 配置文件，用于检查 CSS/LESS 样式代码的质量和风格。该项目配置了：\n\n继承标准规则集和 Prettier 推荐规则\n支持 LESS 语法\n启用 Prettier 规则\n自定义类名命名规范（小写字母和连字符）\n允许未知的 at-rule（为了支持 LESS 特性）\n\n通过 Stylelint 可以确保样式代码的一致性和质量，避免常见的样式错误。\nlint-staged.config.jsLint-staged 配置文件，用于对 Git 暂存区的文件执行检查和格式化：\n\n对 TypeScript 文件执行 ESLint 和 Prettier\n对 JavaScript 文件执行 ESLint 和 Prettier\n对 LESS 和 CSS 文件执行 Stylelint\n对其他文件执行相应检查\n\n这确保只有符合规范的代码才能被提交到仓库，提升整体代码质量。\n开发环境和生产环境配置开发环境启动\nnpm run dev\n构建生产版本\nnpm run build\n预览生产构建\nnpm run preview\n","categories":["Github"],"tags":["前端开发"]},{"title":"2025-11-27-前端安全Vol.1-关于XSS与CRSF及其相关对策","url":"/Arknight-notes/posts/33361.html","content":"跨站脚本攻击（XSS）和跨站请求伪造（CSRF）跨站脚本攻击（Cross-Site Scripting，简称 XSS）和跨站请求伪造（Cross-Site Request Forgery，简称 CSRF 或 XSRF）是 Web 应用中最常见的两种安全漏洞。尽管名称相似，但攻击原理、影响和防御方式完全不同。\n1. 跨站脚本攻击（XSS）定义：XSS 是一种代码注入攻击，攻击者将恶意客户端脚本（通常为 JavaScript）注入到网页中，当受害者访问该页面时，恶意脚本在受害者的浏览器中执行，从而窃取信息或执行恶意操作。\n分类：XSS 攻击主要分为三种类型。首先是反射型 XSS（Reflected XSS），恶意脚本通过 URL 参数、表单提交等反射回响应页面，常用于钓鱼攻击，例如用户点击含有alert(document.cookie)的链接。其次是存储型 XSS（Stored/Persistent XSS），恶意脚本被永久存储在服务器（如数据库中的评论、帖子），所有访问该内容的用户均受影响，危害最大。最后是基于 DOM 的 XSS（DOM-based XSS），恶意脚本通过客户端 JavaScript 操作 DOM 注入，通常不涉及服务器反射。\n攻击后果：XSS 攻击可能导致多种严重后果。攻击者可以窃取 Cookie、Session Token，导致会话劫持；伪造请求、钓鱼、键盘记录；还可以对页面进行篡改（Defacement）。\n防御措施：针对 XSS 攻击有多种防御措施。输出编码（Output Encoding）是在 HTML、JavaScript、CSS、URL 等上下文中对用户输入进行适当转义（如使用 DOMPurify 净化 HTML）；内容安全策略（Content Security Policy, CSP）通过 HTTP 头限制脚本来源；输入验证则是严格验证和过滤用户输入；HttpOnly Cookie 可以防止 JavaScript 访问 Cookie；使用安全库如 DOMPurify、OWASP Java Encoder 等也是有效手段。\n详细防御策略：在具体实施中，HTML 编码将特殊字符（&lt;、&gt;、&amp;、”、’）转换为 HTML 实体，防止浏览器将其解释为标签。JavaScript 编码在 JavaScript 上下文中使用用户输入前，将特殊字符转义为 JavaScript 字符串或正则表达式格式。CSS 编码在 CSS 上下文中使用用户输入时，需要转义特殊字符。URL 编码则对 URL 参数进行编码，确保 URL 安全。\nCSP 实施示例可以通过 HTTP 头设置：\nContent-Security-Policy: default-src 'self';script-src 'self' 'unsafe-inline' https://trusted-cdn.example.com;object-src 'none'; frame-ancestors 'none';\n也可以在 HTML 中设置\n&lt;meta  http-equiv=\"Content-Security-Policy\"  content=\"default-src 'self'; script-src 'self' 'unsafe-inline';\"/&gt;\n使用模板引擎的安全特性也很重要，如 Jinja2、Handlebars 等模板引擎通常内置 XSS 防护，使用时避免使用”raw”或”unsafe”过滤器。同时需要进行严格的输入验证，不仅在服务端验证输入，也要在客户端进行验证（虽然客户端验证可被绕过，但可以改善用户体验）。\n2. 跨站请求伪造（CSRF）定义：CSRF 是一种利用用户已认证身份的攻击。攻击者诱导已登录的用户在不知情情况下向目标网站发送恶意请求，利用浏览器自动携带 Cookie 的特性执行敏感操作。\n攻击原理：首先，用户已登录目标网站（如银行网站），浏览器保存了认证 Cookie。然后，攻击者通过钓鱼邮件、恶意网站诱导用户访问含有恶意表单或图像的页面，例如 HTML 中的&lt;img src=\"https://bank.com/transfer?amount=1000&amp;to=attacker\"&gt;最后，浏览器自动携带 Cookie 发送请求，完成转账等操作\n攻击后果：CSRF 攻击可能导致未经授权执行敏感操作（如转账、修改密码、删除账户）。虽然它不直接窃取数据，但可利用用户权限造成破坏。\n防御措施：针对 CSRF 有多种防御措施。CSRF Token（同步器令牌）是在表单或请求中加入服务器生成的随机 Token，服务器验证 Token 是否匹配且有效，主流框架（如 Django、Spring、Rails）内置支持。SameSite Cookie 是设置 Cookie 的 SameSite 属性（Lax 或 Strict），限制跨站请求携带 Cookie，其中 SameSite=Lax 允许顶级导航（如 GET 链接），阻止大多数 CSRF；SameSite=Strict 完全阻止跨站请求携带 Cookie。双重提交 Cookie（Double Submit Cookie）是将 Token 同时存入 Cookie 和表单，服务器比对两者（适用于无状态应用）。验证 Referer/Origin 头是检查请求来源是否合法（可被伪造或禁用，不推荐单独使用）。使用安全的 HTTP 方法是敏感操作仅允许 POST、PUT、DELETE 等非幂等方法。\n详细防御策略：CSRF Token 的实现包括几个步骤：服务器生成随机的 CSRF Token（如使用加密安全的随机数生成器）；将 Token 放入表单隐藏字段或 HTTP 头中；用户提交请求时，服务器验证 Token 是否匹配且未过期；Token 应在每次会话或关键操作后更新。\nSameSite Cookie 设置示例包括设置 SameSite 属性：\nSet-Cookie: sessionId=abc123;Path=/;HttpOnly;SameSite=StrictSet-Cookie: sessionId=abc123; Path=/; HttpOnly; SameSite=Lax\n自定义请求头验证要求所有 API 请求包含自定义头部（如 X-Requested-With 或 X-CSRF-Token），因为浏览器在跨站请求中不会自动添加这些头部。验证码机制对高风险操作（如修改密码、转账）要求用户输入验证码或进行二次确认。登出确认在登出页面添加确认步骤，防止攻击者诱导用户登出。\nXSS 与 CSRF 的对比总结\n\n\n\n项目\nXSS\nCSRF\n\n\n\n\n攻击目标\n浏览器中的信任（执行恶意脚本）\n网站对用户的信任（利用已认证会话）\n\n\n是否需要注入代码\n是（注入 JavaScript）\n否（仅诱导发送请求）\n\n\n主要危害\n窃取数据、会话劫持、页面篡改\n伪造用户操作（如转账、改密）\n\n\n典型场景\n用户输入未过滤的评论、搜索框\n登录后访问恶意网站\n\n\n核心防御\n输出编码、CSP、输入验证\nCSRF Token、SameSite Cookie\n\n\n是否可相互利用\nXSS 可绕过 CSRF 防御（直接读 Token）\nCSRF 无法直接引发 XSS\n\n\n\n\n综合防御策略：在实际安全防护中，需要采用多种策略。分层防御是结合多种防御措施，而不是依赖单一方法。安全默认值是在系统设计时就考虑安全因素，而不是事后补救。定期安全审计使用自动化工具和手动测试来识别潜在的安全漏洞。开发者培训提高团队对安全问题的认识和防范能力。监控和日志记录可疑活动，及时发现攻击尝试。\n实际应用示例：在实际开发中，我们通常会组合使用多种防御策略。例如 JavaScript 代码示例中，createSecureForm 函数首先验证输入数据，然后对输出进行编码，最后添加 CSRF Token，这样就结合了多种安全措施。\n// 一个安全的表单处理示例function createSecureForm(data) {  // 1. 验证输入数据  if (!isValidInput(data)) {    throw new Error(\"Invalid input\");  }  // 2. 输出编码  const safeData = encodeForHTML(data);  // 3. 添加 CSRF Token  const csrfToken = getCSRFToken();  return `    &lt;form method=\"POST\" action=\"/submit\"&gt;      &lt;input type=\"hidden\" name=\"csrf_token\" value=\"${csrfToken}\"&gt;      &lt;div&gt;${safeData}&lt;/div&gt;      &lt;button type=\"submit\"&gt;提交&lt;/button&gt;    &lt;/form&gt;  `;}// 通过 CSP 策略进一步保护// Content-Security-Policy: default-src 'self'; script-src 'self'; style-src 'self' 'unsafe-inline';\n攻击者若成功执行 XSS，可轻松绕过 CSRF Token（通过脚本读取并发送 Token），因此，在 Web 安全开发中，必须同时防御这两种漏洞。\n","categories":["前端"],"tags":["前端开发"]},{"title":"2025-12-06-杂记-前端图拓扑渲染优化","url":"/Arknight-notes/posts/7900.html","content":"\n性能优化 (Web Workers): 目前的数据获取、解析和Diff算法都在主线程运行。当拓扑变大时，计算Diff会导致页面卡顿。建议将这部分移至 Web Worker。\n\nD3 渲染优化: 目前的设计倾向于每次更新都全量替换 filteredNodes，这会导致 D3 力导向图重新初始化或位置抖动。应该利用 Diff 结果进行增量渲染 (Enter/Update/Exit)。\n\n状态管理解耦: useTopologyData 承担了太多职责（数据存储、UI状态、标签逻辑）。应该拆分为“数据层”和“视觉层”。\n\n数据结构优化: 数组查找（.find）效率低，应更多使用 Map/Set 索引。\n\n\n优化后文件结构采用了 Core (数据核心) + Visual (视觉逻辑) + Worker (后台计算) 的分层结构。\ncodeText\nsrc/  ├── types/  │   └── topology.ts           // (保持不变) 类型定义  ├── workers/  │   └── topology.worker.ts    // [新] 负责Fetch、解析数据、计算Diff  ├── composables/  │   ├── useTopologyCore.ts    // [优化] 负责与Worker通信，持有原始数据  │   ├── useTopologyVisual.ts  // [拆分] 负责过滤、标签、高亮等UI逻辑  │   └── useD3Renderer.ts      // [新] 封装D3的具体操作，接受Diff指令  └── components/      └── EthereumTopology.vue  // [优化] 变得很薄，只负责组装\n现在的以太坊拓扑渲染架构采用了 “分层响应式架构” (Layered Reactive Architecture)，结合了 Web Worker 多线程计算 和 D3 增量渲染 技术。\n这是一种高性能、低耦合的现代前端架构，专门为了处理大量节点（数千级）的实时动态拓扑而设计。\n以下是该架构的详细层级解析：\n1. 架构总览图数据流向是单向的，状态管理是响应式的：\ncodeMermaid\ngraph TD    BackEnd[FastAPI 后端] --&gt;|JSON Stream| Worker[Web Worker (后台线程)]        subgraph \"Main Thread (主线程)\"        Worker --&gt;|Diff Update (增量/全量)| Store[useTopologyCore (数据层)]        Store --&gt;|Raw Data| Visual[useTopologyVisual (视觉层)]                subgraph \"UI Components (视图层)\"            Visual --&gt;|Filtered Data| Renderer[useD3Renderer (渲染层)]            Visual --&gt;|Filters/Mode| Controls[TopologyVisualization (控制面板)]            Renderer --&gt;|Click Event| Details[PhysicalTopology (详情抽屉)]        end    end        Renderer --&gt;|Draw| DOM[SVG/Canvas]\n\n2. 核心层级详细解析第一层：数据处理层 (Worker Thread)文件: workers/topology.worker.ts这是架构的“发动机”，完全脱离主线程运行。\n\n职责：\n\n数据拉取：直接发起 Fetch 请求，不占用主线程网络资源。\n\n数据清洗：解析复杂的 JSON 结构，标准化为 TopologyNode 和 TopologyLink。\n\n智能 Diff (差异计算)：\n\n这是性能优化的关键。它对比新旧数据，计算出新增、删除和更新的节点。\n\n坐标继承：在 Worker 中将旧节点的 x, y 坐标赋值给新节点，防止 D3 在数据更新时重新计算布局导致视图“爆炸”或闪烁。\n\n\n\n\n\n\n第二层：状态管理层 (Composables)这一层利用 Vue 3 的 Composition API 将业务逻辑拆分为独立的模块。\n\n数据持有 (useTopologyCore.ts)：\n\n与 Worker 通信的桥梁。\n\n使用 shallowRef 存储庞大的拓扑数据。优化点：shallowRef 不会深度监听节点内部属性的变化（如 x, y 坐标），这极大减轻了 Vue 响应式系统的负担，因为 D3 会直接操作这些原生对象。\n\n\n\n视觉逻辑 (useTopologyVisual.ts)：\n\n纯粹的计算层。它不关心数据怎么来的，只关心怎么显示。\n\n动态过滤：利用 computed 属性，根据 filters（如隐藏共识节点）实时生成 filteredNodes。\n\n样式映射：集中管理颜色 (getNodeColor) 和标签 (getNodeLabel) 逻辑，实现逻辑与渲染分离。\n\n\n\n\n第三层：渲染驱动层 (Render Engine)文件: useD3Renderer.ts这是 D3.js 与 Vue 的结合点。\n\n生命周期接管：它在 onMounted 时初始化 D3 仿真器。\n\n增量渲染 (Incremental Rendering)：\n\n使用 Vue 的 watch 监听过滤后的数据。\n\n利用 D3 的 enter(), update(), exit() 模式。\n\nEnter: 新节点淡入。\n\nExit: 被过滤或删除的节点淡出移除。\n\nUpdate: 现有节点平滑移动到新位置。\n\n\n\n事件桥接：将 D3 的 click、drag 事件转换为 Vue 的回调函数，传递给上层组件。\n\n\n第四层：视图组装层 (View Integration)文件: EthereumTopology.vue (父组件)这是架构的“容器”和“胶水”。\n\n依赖注入 (Dependency Injection)：\n\n父组件通过 provide(‘topology-state’, …) 将 mode、filters 等状态下发。\n\n子组件 TopologyVisualization 通过 inject 直接获取并修改这些状态。避免了深层 Prop 传递（Prop Drilling）。\n\n\n\n组件编排：\n\n负责布局：左上角悬浮控制面板、中间 D3 画布、右侧详情抽屉。\n\n负责联动：当 D3 点击节点时，控制 showPhysicalDetails 变量来弹出侧边栏。\n\n\n\n\n\n3. 关键性能优化点总结\n非阻塞主线程 (Off-Main-Thread):\n\n旧架构：在组件内 fetch 数据 -&gt; 解析 -&gt; 赋值。数据量大时 UI 会卡顿。\n\n新架构：所有数据处理都在 Worker 中完成，主线程只负责接收“准备好渲染”的数据。\n\n\n\n浅层响应式 (Shallow Reactivity):\n\n使用 shallowRef 代替 ref 存储节点数组。D3 内部高频修改 node.x 和 node.y 时，不会触发 Vue 的依赖更新系统，显著提升动画帧率。\n\n\n状态保持 (State Preservation):\n\nWorker 在处理新数据时，会查找旧数据的 ID，并将 x, y, vx, vy (速度向量) 复制给新数据。这保证了在轮询更新时，节点不会重置位置，实现了“流式”的平滑更新效果。\n\n\n按需计算 (Computed Filtering):\n\n连接 (links) 的过滤依赖于节点 (nodes) 的过滤结果。新架构使用了 Set 来建立索引，将连接过滤的时间复杂度从 O(N*M) 降低到 O(M)（其中 N 是节点数，M 是连接数）。\n\n\n\n4. 总结现在的架构是一个 “重后台、轻前台、数据驱动视图” 的专业可视化架构。\n\nWorker 负责“脏活累活”（数据处理）。\n\nD3 负责“精细活”（物理仿真和绘图）。\n\nVue 负责“指挥”（状态管理和组件通信）。\n\n\n这种架构非常适合需要长时间运行、实时监控网络状态的生产级系统。\n\n根据提供的代码（EthereumTopologyHandler 和 RealTopologyService），以太坊网络拓扑的处理流程是一个分层获取、数据融合、格式化输出的过程。核心逻辑依赖于 Neo4j 图数据库（存储P2P关系）和 Docker 守护进程（提供容器运行时信息）。\n以下是详细的处理步骤解析：\n1. 数据源获取 (Data Acquisition)系统主要通过两个渠道获取数据：\n\nNeo4j 数据库 (核心数据源)：存储了爬虫或客户端上报的节点发现数据，包含节点ID、IP、以及节点间的 P2P 连接关系。\n\nDocker Client (辅助数据源)：用于获取运行中容器的实时状态、名称映射和网络设置。\n\n\n2. 核心处理流程整个拓扑生成的逻辑主要集中在 _get_real_topology_from_neo4j 和 _convert_topology_format 方法中。\n步骤 A：从 Neo4j 提取原始拓扑结构代码通过 Cypher 查询语句分三步提取数据：\n\n查询执行层 (Execution Layer)：\n\n查找所有 ExecNode 标签的节点。\n\n查找 EXEC_PEERS_WITH 关系，获取该节点的对等节点（Peers）。\n\n\n\n查询共识层 (Consensus Layer)：\n\n查找所有 ConsNode 标签的节点。\n\n查找 CONS_PEERS_WITH 关系。\n\n\n\n查询验证者 (Validators)：\n\n查找与共识节点通过 MANAGES_VALIDATOR 关系连接的 Validator 节点。\n\n这反映了哪个信标节点（Beacon Node）管理着哪些验证者客户端。\n\n\n\n\n步骤 B：容器身份映射 (Container Mapping)\n目的：数据库中只有 IP 地址，但在前端展示时，最好能显示具体的 Docker 容器名称（如 geth-node-1）。\n\n实现：_create_ip_to_container_mapping 方法遍历所有 Docker 容器，提取其网络设置中的 IP 地址，建立 IP -&gt; ContainerName 的映射表。\n\n\n步骤 C：构建拓扑对象 (Topology Construction)系统将原始数据转换为前端可视化的 JSON 格式，包含 nodes 和 links。\n1. 节点生成 (Nodes):代码根据逻辑自动计算节点的坐标 (x, y) 以便可视化布局：\n\n执行层节点：\n\ntype: execution\n\n位置：固定在 Y=150 的水平线上。\n\n\n\n共识层节点：\n\ntype: consensus\n\n位置：固定在 Y=350 的水平线上（位于执行层下方）。\n\n\n\n验证者节点：\n\ntype: validator\n\n位置：簇拥在所属共识节点的下方 (y + 60)，通过计算偏移量排成小方阵。\n\n\n\n\n2. 连接生成 (Links):系统构建了四种类型的连接：\n\n执行层 P2P (exec_peer)：基于 Neo4j 中的 EXEC_PEERS_WITH 关系，表示 Geth/Nethermind 节点间的 Gossip 协议连接。\n\n共识层 P2P (cons_peer)：基于 CONS_PEERS_WITH 关系，表示 Lighthouse/Prysm 节点间的连接。\n\n管理关系 (manages_validator)：连接共识节点和它管理的验证者节点。\n\n跨层连接 (cross_layer)：关键逻辑。代码会自动匹配 IP 地址相同的执行层节点和共识层节点，并创建一个垂直连接。这代表了以太坊客户端组合（Engine API 通信，例如 Geth &lt;-&gt; Lighthouse 在同一台机器/Pod内）。\n\n\n3. 容错与缓存机制为了保证性能和稳定性，代码中包含了以下机制：\n\n缓存 (Caching)：\n\n使用 self.cache 存储计算好的拓扑。\n\n设置 cache_ttl (20-30秒)，防止频繁查询 Neo4j 导致数据库过载。\n\n\n\n降级模式 (Fallback - 仅在 Service 中)：\n\n如果 Neo4j 连接失败或返回空数据，RealTopologyService 会调用 _get_container_based_topology。\n\nFallback 逻辑：直接扫描 Docker 容器，如果发现名为 ethereum 的容器，就根据容器数量“伪造”一个链式的拓扑结构（非网状），以确保界面上至少能看到节点存在，而不是一片空白。\n\n\n\n\n4. 统计与验证 (Statistics &amp; Validation)EthereumTopologyHandler 还提供了额外的高级功能：\n\n独立查询：get_nodes 和 get_links 可以不依赖完整拓扑逻辑，直接查询特定层的数据，提高效率。\n\n拓扑验证：validate_topology 检查数据一致性：\n\n节点 ID 是否唯一。\n\n连接的源/目标节点是否存在。\n\n是否存在孤立节点。\n\nIP 地址分布是否异常（例如一个 IP 运行了超过2个主要节点）。\n\n\n\n\n总结该系统处理以太坊拓扑的核心思想是：“数据库定义逻辑关系，Docker 定义物理属性，代码负责视觉组装”。\n\n逻辑层：谁连谁？由 Neo4j 决定。\n\n物理层：你是谁？由 Docker IP 映射决定。\n\n视觉层：你在哪？由代码中的分层坐标计算逻辑决定（执行层在上，共识层在中，验证者在下）。\n\n\n\n目前的实现逻辑虽然功能完整，但在性能上存在几个显著的瓶颈，特别是在节点数量增多或 Docker 容器较多时，响应速度会明显下降。\n以下是针对代码的具体性能优化方案，按提升幅度从大到小排序：\n1. 痛点分析：目前的性能瓶颈在哪里？\nDocker API 调用过于频繁 (主要瓶颈)：\n\n_create_ip_to_container_mapping 每次生成拓扑都会被调用。它会遍历所有容器并检查网络设置。Docker API 的响应通常是毫秒级到秒级的，如果不缓存，这会严重阻塞主线程。\n\n在物理拓扑中，_get_link_bandwidth 会对每个连接进入容器执行 tc 命令。如果有 50 个连接，就要串行执行 50 次 docker exec，这是极慢的 IO 操作。\n\n\n\n串行数据库查询：\n\n在 _get_real_topology_from_neo4j 中，执行层查询及处理完之后，才开始共识层的查询。这两者没有依赖关系，完全可以并行。\n\n\n计算密集型的重复操作：\n\n每次请求都重新计算所有节点的坐标和映射关系，即使数据没有变化。\n\n\n\n\n2. 优化方案一：Docker 数据的独立缓存与后台更新Docker 的元数据（IP、容器名）变化频率远低于 P2P 网络连接的变化频率。不要在每次请求拓扑时都去查询 Docker。\n优化策略： 使用“读写分离”的策略，后台任务更新 Docker 映射，前台请求只读内存变量。\ncodePython\nimport asyncioclass EthereumTopologyHandler(TopologyProvider):    def __init__(self):        # ... 原有初始化 ...        self.ip_container_map_cache = {}        self.map_last_update = 0        self.map_update_lock = asyncio.Lock()                # 启动时预热        # 注意：实际代码中建议使用 apscheduler 或 asyncio.create_task 在后台循环运行            async def _get_ip_to_container_map_optimized(self) -&gt; Dict[str, str]:        \"\"\"        优化后的获取映射方法：        1. 优先返回内存缓存        2. 缓存过期（如5分钟）才异步更新        \"\"\"        current_time = time.time()        # 缓存有效期设为 300秒 (Docker容器IP不会频繁变动)        if current_time - self.map_last_update &lt; 300 and self.ip_container_map_cache:            return self.ip_container_map_cache        # 如果需要更新，且未被锁定        if not self.map_update_lock.locked():             async with self.map_update_lock:                 # 二次检查                 if time.time() - self.map_last_update &lt; 300:                      return self.ip_container_map_cache                                  # 执行耗时的 Docker 查询                 # 建议：在一个线程池中运行同步的 docker client 操作，避免阻塞事件循环                 loop = asyncio.get_running_loop()                 self.ip_container_map_cache = await loop.run_in_executor(                     None, self._create_ip_to_container_mapping                 )                 self.map_last_update = time.time()                return self.ip_container_map_cache\n3. 优化方案二：物理拓扑带宽检测的“非阻塞化”在 RealTopologyService 中，物理连接的带宽检测（tc 命令）是极其耗时的。绝对不能在用户请求 API 时实时去跑 tc 命令。\n优化策略： 将带宽数据设为“最终一致性”。主接口只返回拓扑结构，带宽字段先返回缓存值或 “Checking…”，后台任务专门负责轮询更新带宽。\ncodePython\nclass RealTopologyService:    def __init__(self):        # ...        self.bandwidth_cache = {} # Key: \"container_ip\", Value: \"100Mbit\"            async def _get_dynamic_physical_topology_from_containers(self):        # ... 前面生成 nodes 和 links 的逻辑保持不变 ...                # --- 优化点：移除实时 await _get_link_bandwidth ---        for link in links:            target_id = link['target']            target_node = nodes_by_id[target_id]            container_name = target_node['container_name']            link_ip = target_node['networks'].get(link['shared_network'])                        # 1. 尝试从缓存获取            cache_key = f\"{container_name}::{link_ip}\"            cached_bw = self.bandwidth_cache.get(cache_key)                        if cached_bw:                link['bandwidth'] = cached_bw            else:                link['bandwidth'] = \"Querying...\"                # 2. 触发后台更新任务 (Fire and Forget)                asyncio.create_task(self._update_bandwidth_cache(container_name, link_ip, cache_key))                        return nodes, links    async def _update_bandwidth_cache(self, container_name, link_ip, cache_key):        \"\"\"后台单独更新带宽\"\"\"        bw = await self._get_link_bandwidth(container_name, link_ip)        self.bandwidth_cache[cache_key] = bw\n4. 优化方案三：Neo4j 并发查询Neo4j 的 Python Driver (尤其是 Bolt 协议) 支持并发。执行层和共识层的查询是独立的，可以使用 asyncio.gather 同时发起查询。\n注意：这需要你的 database_manager 支持异步操作。如果底层是同步驱动，可以用 run_in_executor 包装。\ncodePython\n# 在 EthereumTopologyHandler 中    async def _get_real_topology_from_neo4j(self) -&gt; Tuple[Dict, Dict]:        try:            # ... 连接检查 ...            # 定义查询函数            async def fetch_exec():                # 这里假设 database_manager 提供了某种异步执行方式，                # 或者我们将同步的 session.run 放入线程池                def run_query():                    with self.database_manager.neo4j.session() as session:                        result = session.run(\"MATCH (n:ExecNode)...\") # 填入完整的 Cypher                        return {r['node_id']: ... for r in result} # 处理结果                                loop = asyncio.get_running_loop()                return await loop.run_in_executor(None, run_query)            async def fetch_cons_and_validators():                def run_query():                    with self.database_manager.neo4j.session() as session:                        # 合并共识节点和验证者的查询逻辑，减少一次 session 创建开销                        cons_result = session.run(\"MATCH (n:ConsNode)...\")                         # ... 处理共识 ...                        validator_result = session.run(\"MATCH ... validators ...\")                        # ... 处理验证者 ...                        return cons_data                                loop = asyncio.get_running_loop()                return await loop.run_in_executor(None, run_query)            # 并发执行            exec_nodes_data, cons_nodes_data = await asyncio.gather(                fetch_exec(),                 fetch_cons_and_validators()            )            return exec_nodes_data, cons_nodes_data        except Exception as e:            # ... Error handling\n5. 优化方案四：Cypher 查询语句优化目前的 Cypher 使用了 OPTIONAL MATCH 和 collect，这在数据量大时比较慢。\n原查询：\ncodeCypher\nMATCH (n:ExecNode)OPTIONAL MATCH (n)-[r:EXEC_PEERS_WITH]-&gt;(p:ExecNode)RETURN ... collect(...)\n如果在节点很多的情况下，这个查询会扫描整个图。\n优化建议：\n\n分批次：如果节点超过 1000 个，不要一次性 collect 所有 Peers。前端通常不需要展示所有几千条连线（会卡死浏览器）。可以限制返回的 Peer 数量，例如 LIMIT 10。\n\n索引：确保 node_id, ip 在 Neo4j 中建立了索引 (CREATE INDEX ON :ExecNode(node_id)).\n\n只查 ID：先查出所有 Node 的基础信息，再查 Relation 表（Links），在内存中组装，通常比 Graph DB 做复杂的聚合（Map/Collect）要快。\n\n\n6. 综合改进后的代码结构建议这里给出一个集成优化思路的 EthereumTopologyHandler 核心方法重构示例：\ncodePython\nclass EthereumTopologyHandler(TopologyProvider):    # ... init ...    async def get_topology(self) -&gt; Dict[str, Any]:        \"\"\"获取完整的以太坊拓扑 (优化版)\"\"\"        # 1. 检查拓扑缓存 (Short TTL: e.g., 5s)        # 拓扑结构变化很快，缓存时间短一点        if self._is_cache_valid(\"full_ethereum_topology\", ttl=5):            return self.cache[\"full_ethereum_topology\"]        # 2. 并行获取数据        # A. 获取 Docker 映射 (从长效缓存或后台任务获取，极快)        # B. 获取 Neo4j 数据 (并发查询)                task_docker = self._get_ip_to_container_map_optimized() # 优化点1        task_neo4j = self._get_real_topology_from_neo4j()       # 优化点3 (并发内部实现)                ip_map, (exec_data, cons_data) = await asyncio.gather(task_docker, task_neo4j)        # 3. 转换数据 (CPU 密集型)        # 如果节点数非常多 (&gt;5000)，可以考虑放入 ProcessPoolExecutor        nodes, links = self._convert_topology_format_optimized(exec_data, cons_data, ip_map)        topology_data = {            'nodes': nodes, 'links': links, 'timestamp': time.time(),            # ...        }        # 更新缓存        self.cache[\"full_ethereum_topology\"] = topology_data        self.last_update = time.time()                return topology_data    def _convert_topology_format_optimized(self, exec_data, cons_data, ip_map):        \"\"\"        优化点：        1. 使用 ip_map.get 避免重复循环        2. 预计算 positions 字典，避免列表遍历查找        \"\"\"        nodes = []        links = []        # 使用字典加速查找: key=node_id, value={idx, type, ...}        node_lookup = {}                 # ... 处理 Exec 节点 ...        for i, (nid, data) in enumerate(exec_data.items()):            # 直接查预热好的 Map，O(1)            container = ip_map.get(data['ip'], f\"exec-{data['ip']}\")            # ... 创建 node ...            node_lookup[nid] = {'type': 'execution', 'id': f'{nid}-exec'}                    # ... 处理 Cons 节点 ...                # ... 处理连接 ...        # 只需要遍历一次 exec_data 的 peers，利用 node_lookup 快速验证        for nid, data in exec_data.items():             source_full_id = f\"{nid}-exec\"             for peer in data.get('peers', []):                 target_nid = peer['peer_id']                 # O(1) 检查目标是否存在                 if target_nid in node_lookup and node_lookup[target_nid]['type'] == 'execution':                     links.append({                         'source': source_full_id,                         'target': f\"{target_nid}-exec\",                         # ...                     })                             return nodes, links\n总结要进行性能优化，最关键的修改是：\n\nDocker 映射：改为后台定时更新或长缓存，不要每秒都去 inspect 容器。\n\n物理带宽 (tc)：改为异步/后台获取，不要阻塞 API 响应。\n\nNeo4j：使用并发查询，并限制 Cypher 复杂度。\n\n\n\n攻击方式（Attack Strategies）系统目前支持以下6种攻击方式：\n1. 节点断网攻击（Node Disconnection Attack）通过网络隔离手段切断目标节点与其他节点的连接。支持的方法包括：\n\ninterface_down: 禁用网络接口\nroute_flush: 清除路由表\nfirewall_block: 防火墙阻断\np2p_block: P2P连接阻断\n\n2. 通信干扰攻击（Communication Interference Attack）通过大量无效通信干扰目标节点正常通信。支持的方法包括：\n\njson_rpc_flood: JSON-RPC请求泛洪\np2p_flood: P2P消息泛洪\nmemory_exhaustion: 内存耗尽攻击\n\n3. 时间攻击（Timestamp Attack）针对共识机制的时间同步进行攻击。支持的方法包括：\n\ntime_shift: 时间偏移\nntp_block: 阻断NTP时间同步\ntime_drift: 时间漂移\n\n4. 简化Sybil攻击（Simplified Sybil Attack）创建虚假节点来影响网络。可以配置：\n\n虚假节点数量（1-20）\n节点类型（轻节点、全节点、验证者节点）\n网络环境（主网、测试网、开发网）\n连接真实节点选项\n\n5. 存储攻击（Storage Attack）针对节点存储系统的攻击。支持的方法包括：\n\ndisk_fill: 磁盘空间填充\ndatabase_corruption: 数据库损坏\nstate_pollution: 状态污染\nchain_data_spam: 链上数据垃圾信息\n\n6. Geth/Lighthouse客户端攻击（Geth/Lighthouse Attack）针对特定以太坊客户端的攻击。支持的方法包括：\n\nprocess_kill: 终止进程\ndb_corruption: 数据库损坏\nport_blocking: 端口阻断\nconfig_modification: 配置文件修改\n\n攻击模式（Execution Modes）系统支持三种攻击执行模式：\n1. 一次性攻击（One-shot）执行一次攻击，持续指定时间后自动清理恢复。 配置参数：\n\nduration_seconds: 攻击持续时间（秒）\n\n2. 重复攻击（Repeated）按指定间隔重复执行多次攻击。 配置参数：\n\ninterval_seconds: 攻击间隔时间（秒）\nrepeat_count: 重复次数\nduration_seconds: 每次攻击持续时间（秒）\n\n3. 持续攻击（Continuous）持续不断地执行攻击，直到手动停止。 配置参数：\n\ninterval_seconds: 攻击间隔时间（秒）\nduration_seconds: 每次攻击持续时间（秒）\n\n动态目标攻击系统还支持一种特殊的动态目标攻击功能，可以根据网络拓扑分析结果自动选择攻击目标。支持的中心性指标包括：\n\n度中心性（Degree Centrality）\n介数中心性（Betweenness Centrality）\n接近中心性（Closeness Centrality）\n特征向量中心性（Eigenvector Centrality）\n\n通过这些攻击方式和模式的组合，系统可以模拟各种真实的以太坊网络攻击场景，帮助评估网络的安全性和鲁棒性。\n\n1. 发起普通攻击 (Standard Attack)此接口用于对明确指定的静态 IP 列表发起攻击。\nPrompt / 接口说明:\n\n接口地址: POST /api/simulate\n\n功能: 发起针对特定静态目标（IP/ID列表）的攻击模拟。\n\n逻辑约束:\n\nparameters.target_nodes 必须是字符串数组 [“ip1”, “ip2”]。\n\n支持所有三种执行模式 (one_shot, repeated, continuous)。\n\n\n\n请求体构建规则:\n\nLevel 1 (执行配置): 决定攻击的时间维度。\n\n若是 one_shot: 仅需 duration_seconds。\n\n若是 repeated: 需额外提供 interval_seconds 和 repeat_count。\n\n\n\nLevel 2 (策略参数): 决定攻击的具体手段。\n\n必须包含 strategy 字段（枚举值）。\n\n其余字段根据 strategy 变化（如 storage_attack 需要 size_mb，而 node_disconnection 不需要）。\n\n\n\n\n\n\n请求示例 (JSON):\ncodeJSON\n// 场景：对两个节点进行重复的 P2P 洪水攻击{  \"execution_config\": {    \"mode\": \"repeated\",    \"duration_seconds\": 30,    \"interval_seconds\": 60,    \"repeat_count\": 5  },  \"parameters\": {    \"strategy\": \"communication_interference\",    \"method\": \"p2p_flood\",    \"intensity\": \"high\",    \"target_nodes\": [\"192.168.1.10\", \"192.168.1.11\"]  }}\n\n2. 发起自适应攻击 (Adaptive Attack)此接口用于动态目标攻击，系统会在每一轮攻击开始前重新计算受害者（例如：总是攻击网络中连接数最多的节点）。\nPrompt / 接口说明:\n\n接口地址: POST /api/simulate/adaptive\n\n功能: 发起自适应攻击，目标由后端实时计算。\n\n关键区别:\n\n不支持 one_shot 模式（因为一次性攻击不需要”自适应”变化）。必须是 repeated 或 continuous。\n\nparameters.target_nodes 必须是特定格式的字符串指令，以 dynamic: 开头。\n\n\n\n目标指令语法: dynamic:{指标}:{选择策略}\n\n示例: dynamic:degree:top:5 (度中心性最高的前5个)\n\n示例: dynamic:betweenness:highest (介数中心性最高的1个)\n\n\n\n\n请求示例 (JSON):\ncodeJSON\n// 场景：持续攻击网络中度中心性最高的前5个节点{  \"execution_config\": {    \"mode\": \"continuous\",    \"duration_seconds\": 60,    \"interval_seconds\": 30  },  \"parameters\": {    \"strategy\": \"node_disconnection\",    \"method\": \"firewall_block\",    \"target_nodes\": \"dynamic:degree:top:5\" // 注意这里是字符串  }}\n\n3. 前端分流逻辑 (Frontend Logic)这是前端 Vue 组件如何决定调用哪个接口的核心逻辑说明。\nPrompt / 逻辑说明:\n前端在点击”发起攻击”按钮时，必须执行以下判断逻辑：\n\n检查目标类型:\n\n获取用户在表单中输入的目标配置。\n\n如果目标是字符串指令且以 dynamic: 开头 -&gt; 标记为 isDynamic。\n\n如果目标是手动输入的 IP 列表 -&gt; 标记为 isStatic。\n\n\n\n检查执行模式:\n\n获取用户选择的模式 (one_shot, repeated, continuous)。\n\n\n路由决策树:\n\nIF (isDynamic == True AND mode == one_shot):\n\n❌ 报错: 自适应攻击不支持一次性模式。\n\n\nIF (isDynamic == True AND mode != one_shot):\n\n✅ 调用接口: POST /api/simulate/adaptive\n\n注意: 此时 target_nodes 字段发送字符串。\n\n\n\nELSE (即静态目标，无论什么模式):\n\n✅ 调用接口: POST /api/simulate\n\n注意: 此时 target_nodes 字段必须转换为数组 [] 发送。\n\n\n\n\n\n\n\n4. 停止攻击 (Stop Attack)Prompt / 接口说明:\n\n接口地址: DELETE /api/simulations/{attack_id}\n\n功能: 立即终止一个正在运行 (running) 或挂起 (pending) 的攻击任务。\n\n适用场景:\n\n用户点击”紧急停止”按钮。\n\n用于中断 continuous (无限持续) 类型的攻击。\n\n用于中断剩余轮次尚未执行的 repeated 攻击。\n\n\n\n后端行为:\n\n取消对应的 asyncio.Task。\n\n执行清理逻辑（如恢复防火墙规则、删除垃圾文件）。\n\n将数据库中的状态更新为 stopped。\n\n\n\n\n\n5. 状态轮询与监控 (Monitoring)Prompt / 接口说明:\n为了在前端展示”实时状态”和”系统日志”，需要配合使用以下两个接口：\n\n获取活跃列表: GET /api/simulations/active\n\n用途: 判断当前是否有攻击在跑 (isRunning 状态)。\n\n频率: 建议每 3-5 秒轮询一次。\n\n返回: 包含 progress (进度百分比) 和 current_round (当前轮次)。\n\n\n\n获取详情/日志: GET /api/simulations/{attack_id}\n\n用途: 获取特定攻击的详细日志流。\n\n返回: 包含 logs 数组 ([“Attack started”, “Round 1 finished”])。\n\n前端展示: 将 logs 渲染到控制台面板中。\n\n\n\n\n\n总结：数据结构对照表 (Type Mapping)\n\n\n\n\n\n\n\n\n\n\n参数字段\n描述\n类型限制\n\n\nexecution_config\n\n\n\n\nmode\n执行模式\n“one_shot” \\\n“repeated” \\\n“continuous”\n\n\nduration_seconds\n单次持续时长\nInteger (秒)\n\n\ninterval_seconds\n轮次间隔\nInteger (秒), 仅 repeated/continuous 有效\n\n\nrepeat_count\n重复次数\nInteger, 仅 repeated 有效\n\n\nparameters\n\n\n\n\nstrategy\n攻击策略\n“node_disconnection” \\\n“storage_attack” …\n\n\ntarget_nodes\n攻击目标\nArray [str] (普通) OR String dynamic:… (自适应)\n\n\nmethod\n具体手段\n依赖于 strategy (如 firewall_block, disk_fill)\n\n\n…\n其他参数\n依赖于 strategy (如 size_mb, intensity)\n\n\n\n\n\n1. 全局枚举定义 (Global Enums)这些枚举值用于填充请求体中的特定字段。\n\n\n\n\n\n\n\n\n\n\n\n\n枚举类型\n字段名\n可选值 (Value)\n说明\n\n\n执行模式\nmode\none_shot\n一次性：执行一次，持续指定时间后恢复。\n\n\n\n\nrepeated\n重复执行：按间隔重复执行多次。\n\n\n\n\ncontinuous\n持续执行：按间隔无限执行，直到手动停止。\n\n\n攻击策略\nstrategy\nnode_disconnection\n节点断连攻击\n\n\n\n\ncommunication_interference\n通信干扰攻击\n\n\n\n\nstorage_attack\n存储耗尽攻击\n\n\n\n\ntimestamp_attack\n时间/NTP攻击\n\n\n\n\nsimplified_sybil_attack\n简化版女巫攻击\n\n\n\n\ngeth_lighthouse_attack\n客户端特定攻击 (Geth/Lighthouse)\n\n\n\n\n\n2. 执行配置 (execution_config)根据 mode 的不同，所需字段不同。注意：自适应攻击接口 (/simulate/adaptive) 不支持 one_shot。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n模式 (Mode)\n字段名\n类型\n必填\n默认值\n约束/说明\n\n\n通用\nduration_seconds\nInt\n✅\n30\n攻击生效持续时间 (秒)，&gt;=1\n\n\nRepeated\ninterval_seconds\nInt\n✅\n60\n轮次间隔时间 (秒)，&gt;=1\n\n\n(重复)\nrepeat_count\nInt\n✅\n-\n重复执行的总轮数，&gt;=1\n\n\nContinuous\ninterval_seconds\nInt\n✅\n60\n轮次间隔时间 (秒)，&gt;=1\n\n\n\n\n\n3. 策略参数详情 (parameters)此部分为多态结构，根据 strategy 字段的值，JSON 结构发生变化。\n3.1 节点断连 (node_disconnection)\n\n\n\n\n\n\n\n\n\n\n\n\n字段名\n类型\n必填\n默认值\n描述/选项\n\n\nmethod\nString\n✅\n-\ninterface_down (网卡下线), route_flush (清空路由), firewall_block (防火墙), p2p_block (P2P阻断)\n\n\ntarget_nodes\nArray/Str\n✅\n-\n静态IP列表 或 动态指令 (见第4节)\n\n\n\n\n3.2 通信干扰 (communication_interference)\n\n\n\n\n\n\n\n\n\n\n\n\n字段名\n类型\n必填\n默认值\n描述/选项\n\n\nmethod\nString\n✅\n-\njson_rpc_flood (RPC泛洪), p2p_flood (P2P泛洪), memory_exhaustion (内存耗尽)\n\n\nintensity\nString\n❌\nmedium\nlow, medium, high, extreme\n\n\ntarget_nodes\nArray/Str\n✅\n-\n静态IP列表 或 动态指令\n\n\n\n\n\n\n\n\n\n\n3.3 存储攻击 (storage_attack)\n\n\n\n\n\n\n\n\n\n\n\n\n字段名\n类型\n必填\n默认值\n描述/选项\n\n\nmethod\nString\n✅\n-\ndisk_fill (填充), database_corruption (脏数据), state_pollution (状态污染), chain_data_spam (链上垃圾)\n\n\nsize_mb\nInt\n❌\n1000\n填充大小 (MB)，100 - 10000\n\n\nfile_count\nInt\n❌\n100\n生成文件数量，10 - 1000\n\n\ntarget_nodes\nArray/Str\n✅\n-\n静态IP列表 或 动态指令\n\n\n\n\n3.4 时间攻击 (timestamp_attack)\n\n\n\n\n\n\n\n\n\n\n\n\n字段名\n类型\n必填\n默认值\n描述/选项\n\n\nmethod\nString\n✅\n-\ntime_shift (平移), ntp_block (NTP阻断), time_drift (漂移)\n\n\ntime_shift\nString\n❌\n+1 hour\n偏移量 (如 +1 hour, -30 minutes)，仅 time_shift 方法有效\n\n\ndrift_seconds\nInt\n❌\n3600\n漂移秒数，-86400 到 86400，仅 time_drift 方法有效\n\n\ntarget_nodes\nArray/Str\n✅\n-\n静态IP列表 或 动态指令\n\n\n\n\n3.5 女巫攻击 (simplified_sybil_attack)\n\n\n\n\n\n\n\n\n\n\n\n\n字段名\n类型\n必填\n默认值\n描述/选项\n\n\nfake_node_count\nInt\n❌\n5\n虚假节点数量 (1-20)\n\n\nnode_type\nString\n❌\nlight\nlight (轻节点), full (全节点), validator (验证者)\n\n\nnetwork\nString\n❌\ntestnet\nmainnet, testnet, devnet\n\n\nconnect_to_real\nBool\n❌\nTrue\n是否连接真实节点\n\n\nmin_connections\nInt\n❌\n3\n最小连接数 (0-10)\n\n\ntarget_nodes\n-\n-\n-\n注意：此策略通常不需要指定具体目标节点\n\n\n\n\n3.6 客户端攻击 (geth_lighthouse_attack)\n\n\n\n\n\n\n\n\n\n\n\n\n字段名\n类型\n必填\n默认值\n描述/选项\n\n\nmethod\nString\n✅\n-\nprocess_kill, db_corruption, port_blocking, config_modification\n\n\nattack_type\nString\n✅\n-\ngeth, lighthouse (指定攻击的客户端类型)\n\n\ntarget_nodes\nArray/Str\n✅\n-\n静态IP列表 或 动态指令\n\n\n\n\n\n4. 目标节点配置 (target_nodes)target_nodes 字段在不同接口下有严格的格式要求。\n\n\n\n\n\n\n\n\n\n\n\n\n接口端点\n格式类型\n数据结构示例\n说明\n\n\n/api/simulate\n静态列表\n[“192.168.1.10”, “node_id_123”]\n明确指定要攻击的节点列表。\n\n\n/api/simulate/adaptive\n动态指令\n“dynamic:degree:top:5”\n字符串格式，后端自动计算目标。\n\n\n\n\n动态指令语法: dynamic:{指标}:{选择器}\n\n指标 (Metric):\n\ndegree (度中心性)\n\nbetweenness (介数中心性)\n\ncloseness (接近中心性)\n\neigenvector (特征向量中心性)\n\n\n\n选择器 (Selector):\n\nhighest (选最高的1个)\n\ntop:N (选前 N 个，N为数字)\n\n\n\n\n\n5. 防护配置 (/defense/enable)\n\n\n\n\n\n\n\n\n\n\n\n\n字段名\n类型\n必填\n示例\n说明\n\n\nenabled\nBool\n❌\ntrue\n是否启用防护\n\n\nrules\nObject\n✅\n{“rate_limit”: 100}\n防护规则字典，具体Key由后端逻辑决定\n\n\n\n\n\n6. 响应结构概览所有接口通常遵循统一的响应格式：\ncodeJSON\n{  \"status\": \"success\",  // 或 \"error\"  \"message\": \"操作描述\",  \"data\": { ... }       // 具体业务数据}\n关键数据字段 (data):\n\nattack_id: (String) 攻击任务的唯一标识符。\n\nstatus: (Enum) pending, running, completed, failed, stopped, cancelled。\n\nlogs: (Array[Str]) 攻击日志列表。\n\n\n{  “nodes”: [    {      “id”: “0xdAC17F958D2ee523a2206206994597C13D831ec7”,      “name”: “Tether USD (USDT)”,      “type”: “ERC20”,      “ip_address”: “”,      “status”: “active”,      “layer”: “contract”,      “container_name”: null,      “neighbor_count”: 5    },    {      “id”: “0xA0b86991c6218b36c1d19D4a2e9Eb0cE3606eB48”,      “name”: “USD Coin (USDC)”,      “type”: “ERC20”,      “ip_address”: “”,      “status”: “active”,      “layer”: “contract”,      “container_name”: null,      “neighbor_count”: 3    },    {      “id”: “0x1f9840a85d5aF5bf1D1762F925BDADdC4201F984”,      “name”: “Uniswap V3: Router”,      “type”: “Router”,      “ip_address”: “”,      “status”: “active”,      “layer”: “contract”,      “container_name”: null,      “neighbor_count”: 8    },    {      “id”: “0x68b3465833fb72A70ecDF485E0e4C7bD8665Fc45”,      “name”: “Uniswap V3: SwapRouter02”,      “type”: “SwapRouter”,      “ip_address”: “”,      “status”: “active”,      “layer”: “contract”,      “container_name”: null,      “neighbor_count”: 6    },    {      “id”: “0xE592427A0AEce92De3Edee1F18E0157C05861564”,      “name”: “Uniswap V3: Quoter”,      “type”: “Quoter”,      “ip_address”: “”,      “status”: “active”,      “layer”: “contract”,      “container_name”: null,      “neighbor_count”: 4    },    {      “id”: “0x7a250d5630B4cF539739dF2C5dAcb4c659F2488D”,      “name”: “Uniswap V2: Router”,      “type”: “Router”,      “ip_address”: “”,      “status”: “active”,      “layer”: “contract”,      “container_name”: null,      “neighbor_count”: 7    },    {      “id”: “0x881D40237659C251811CEC9c364ef91dC08D300C”,      “name”: “Curve: 3pool Controller”,      “type”: “CurvePool”,      “ip_address”: “”,      “status”: “active”,      “layer”: “contract”,      “container_name”: null,      “neighbor_count”: 4    },    {      “id”: “0xbEbc44782C7dB0a1A60Cb6fe97d0b483032FF1C7”,      “name”: “Curve: 3pool Gauge”,      “type”: “Gauge”,      “ip_address”: “”,      “status”: “active”,      “layer”: “contract”,      “container_name”: null,      “neighbor_count”: 2    }  ],  “links”: [    { “source”: “0xdAC17F958D2ee523a2206206994597C13D831ec7”, “target”: “0x68b3465833fb72A70ecDF485E0e4C7bD8665Fc45”, “type”: “transfer_approve” },    { “source”: “0x68b3465833fb72A70ecDF485E0e4C7bD8665Fc45”, “target”: “0xdAC17F958D2ee523a2206206994597C13D831ec7”, “type”: “swap_out” },    { “source”: “0x68b3465833fb72A70ecDF485E0e4C7bD8665Fc45”, “target”: “0xA0b86991c6218b36c1d19D4a2e9Eb0cE3606eB48”, “type”: “swap_in” },    { “source”: “0xA0b86991c6218b36c1d19D4a2e9Eb0cE3606eB48”, “target”: “0x1f9840a85d5aF5bf1D1762F925BDADdC4201F984”, “type”: “call” },    { “source”: “0x1f9840a85d5aF5bf1D1762F925BDADdC4201F984”, “target”: “0xE592427A0AEce92De3Edee1F18E0157C05861564”, “type”: “quote” },    { “source”: “0xdAC17F958D2ee523a2206206994597C13D831ec7”, “target”: “0x7a250d5630B4cF539739dF2C5dAcb4c659F2488D”, “type”: “approve” },    { “source”: “0x7a250d5630B4cF539739dF2C5dAcb4c659F2488D”, “target”: “0xdAC17F958D2ee523a2206206994597C13D831ec7”, “type”: “swap” },    { “source”: “0xdAC17F958D2ee523a2206206994597C13D831ec7”, “target”: “0x881D40237659C251811CEC9c364ef91dC08D300C”, “type”: “deposit” },    { “source”: “0x881D40237659C251811CEC9c364ef91dC08D300C”, “target”: “0xbEbc44782C7dB0a1A60Cb6fe97d0b483032FF1C7”, “type”: “stake” }  ],  “timestamp”: 1765095677.891234,  “data_source”: “real_web3”,  “topology_type”: “contract”}\ngraph TB    A[ETH前端] --&gt; B[src]    A --&gt; C[package.json]    A --&gt; D[index.html]    A --&gt; E[vite.config.ts]    A --&gt; F[README.md]    A --&gt; G[public]        B --&gt; H[__tests__]    B --&gt; I[api]    B --&gt; J[assets]    B --&gt; K[components]    B --&gt; L[composables]    B --&gt; M[router]    B --&gt; N[services]    B --&gt; O[types]    B --&gt; P[utils]    B --&gt; Q[views]    B --&gt; R[App.vue]    B --&gt; S[main.ts]        I --&gt; T[api_docs]    I --&gt; U[attack]        J --&gt; V[styles]    V --&gt; W[global.css]    V --&gt; X[tailwind.css]        K --&gt; Y[blockchain]    K --&gt; Z[common]    K --&gt; AA[layout]    K --&gt; AB[tabs]    K --&gt; AC[topology]        Y --&gt; AD[BlockchainCanvas.vue]    Y --&gt; AE[BlockchainInfoPanel.vue]    Y --&gt; AF[BlockchainModal.vue]    Y --&gt; AG[BlockchainVisualization.vue]    Y --&gt; AH[composables]    Y --&gt; AI[types]        AH --&gt; AJ[useBlockchainAPI.ts]    AH --&gt; AK[useBlockchainAnimations.ts]    AH --&gt; AL[useBlockchainData.ts]    AH --&gt; AM[useBlockchainEvents.ts]    AH --&gt; AN[useBlockchainRenderer.ts]    AH --&gt; AO[useBlockchainScrolling.ts]        Z --&gt; AP[ContainerTerminal.vue]    Z --&gt; AQ[DEP-TERM.vue]    Z --&gt; AR[StandaloneTerminal.vue]    Z --&gt; AS[Terminal.vue]    Z --&gt; AT[websocket_terminal8080.vue]        AA --&gt; AU[DashboardHeader.vue]    AA --&gt; AV[LeftPanel.vue]    AA --&gt; AW[PanelSplitter.vue]    AA --&gt; AX[RightPanel.vue]        AB --&gt; AY[AttackMonitoringTab.vue]    AB --&gt; AZ[Attack_sys]    AB --&gt; BA[BlockchainBrowserTab.css]    AB --&gt; BB[BlockchainBrowserTab.vue]    AB --&gt; BC[ContainerListTab.vue]    AB --&gt; BD[NetworkTopologyTab.vue]    AB --&gt; BE[sections]    AB --&gt; BF[tabstyle.css]        AZ --&gt; BG[AttackSystemTab.vue]    BE --&gt; BH[Network-analysis.vue]    BE --&gt; BI[NodeInfoPanel.vue]    BE --&gt; BJ[RealTimeMonitoring.vue]        AC --&gt; BK[ContractTopology.vue]    AC --&gt; BL[Ethereum_Topology]    AC --&gt; BM[Physical_Topology]    AC --&gt; BN[TopologyVisualization.vue]    AC --&gt; BO[TransactionTopology.vue]    AC --&gt; BP[composables]    AC --&gt; BQ[types]        BL --&gt; BR[types]    BL --&gt; BS[workers]    BL --&gt; BT[EthereumTopology_new.vue]    BL --&gt; BU[useD3Renderer.ts]    BL --&gt; BV[use_topology_core.ts]    BL --&gt; BW[use_topology_visuals.ts]        BM --&gt; BX[composables]    BM --&gt; BY[PhysicalTopology.vue]        BP --&gt; BZ[index.ts]    BP --&gt; CA[topology.css]    BP --&gt; CB[useTopologyAPI.ts]    BP --&gt; CC[useTopologyData.ts]    BP --&gt; CD[useTopologyRendererBase.ts]        L --&gt; CE[useDashboardData.ts]    L --&gt; CF[useDashboardLayout.ts]    L --&gt; CG[useDashboardTabs.ts]        M --&gt; CH[index.ts]        N --&gt; CI[analysis.ts]    N --&gt; CJ[api.ts]    N --&gt; CK[apiService.ts]    N --&gt; CL[attack.ts]    N --&gt; CM[blockchain.ts]    N --&gt; CN[daily-operations.ts]    N --&gt; CO[device-monitoring.ts]    N --&gt; CP[execution.ts]    N --&gt; CQ[foundation.ts]    N --&gt; CR[monitoring.ts]    N --&gt; CS[readme.md]    N --&gt; CT[root-api.ts]    N --&gt; CU[security.ts]    N --&gt; CV[temporal.ts]    N --&gt; CW[topology.ts]        O --&gt; CX[topology.ts]        P --&gt; CY[http.ts]    P --&gt; CZ[index.ts]    P --&gt; DA[types.ts]        Q --&gt; DB[BlockchainTest.vue]    Q --&gt; DC[Dashboard.vue]","categories":["归档"]},{"title":"2025-12-05-字节工训营画布项目相关设计","url":"/Arknight-notes/posts/17798.html","content":"BDdraw_DEV代码仓库：https://github.com/Zhongye1/BDdraw_DEV\n现代协同 2D 画布编辑器 · React 18 + TypeScript + Vite + TailwindCSS + Zustand + PixiJS v8\n技术栈 · Tech Stack             \n运行项目frontend\ngit clone git@github.com:Zhongye1/BDdraw_DEV.gitcd BDdraw_DEV (进入项目)bun install (安装依赖包)bun start (启动服务)\nbackend\ncd BDdraw_DEV/ALD_Backend/bun install #安装依赖bun index.ts  #启动后端服务\n推荐使用 bun 包管理器，见个人博客\n关于包管理器 npm,pnpm,yarn 和 bun 以及我为何选择后者\nDocker 部署项目支持通过 Docker 进行容器化部署，使用 Node 22 和 Bun 包管理器。\n开发环境部署：\ndocker-compose up -d\n生产环境部署：\ndocker-compose -f docker-compose.prod.yml up -d\n部署完成后，可以通过以下地址访问：\n\n前端应用: http://localhost:5000/BDdraw_DEV/\n后端 API 文档: http://localhost:3000/swagger-ui\n\n整体架构设计项目采用了模块化的架构设计，将不同的功能划分为独立的模块，以方便后续维护和扩展\n特性\n60 FPS 渲染（得益于 PixiJS WebGL）\n完整撤销/重做（Command Pattern + 防抖快照）\n多元素选择与群组操作\n画布元素变换控制器\n富文本所见即所得编辑（WanngEditor + PIXI.HTMLText）\n图片插入 + 内置滤镜（模糊、亮度、灰度等）\n插件式元素系统\n插件式元素系统\n完整的 TypeScript 类型支持\n现代开发体验（Vite + ESLint + Prettier + Husky）\n集成 GitHub-Actions 支持， 实现每次 push 到 main 分支后，GitHub 自动构建 → 自动发布页面的操作\n\n\n技术选型这时候需要简单做一个技术选型分析，根据任务拆解，选择了如下技术栈\n【框架】【技术方案：采用 React 18 + TypeScript 5 构建应用，React 提供完整的 UI 生态，TypeScript 提供更清晰可靠的类型安全，相比 JavaScript 更易于维护】\n【构建工具】【技术方案：使用 Vite 5 作为构建工具，其开发服务器启动和热模块替换（HMR）速度明显快于 Webpack】\n【路由】【技术方案：采用 React Router DOM 6 实现路由管理，API 稳定且文档完善】\n【样式】【技术方案：使用 Tailwind CSS 3 + PostCSS 处理样式，开发时编写样式更快，生产环境会自动进行 tree-shaking 优化，相比 CSS Modules 和 styled-components 更高效且原子化更直观，对 AI 工具友好】\n【样式扩展】【技术方案：少量使用 Less 覆盖 Tailwind 主题变量，保持兼容性】\n【SVG 处理】【技术方案：使用 SVGR 1.5 处理 SVG，Vite 原生支持，可以将 SVG 作为 React 组件使用，比直接使用 SVG 或 SVG sprite 更灵活】\n【UI 组件库】【技术方案：采用 shadcn/ui（latest）和 Arco Design 2 实现 UI 组件，易于使用，符合字节项目使用字节组件库的习惯】\n【全局状态】【技术方案：采用 Zustand 4 管理全局状态，API 简洁、性能良好且无样板代码，相比 Redux Toolkit、Pinia、Jotai 代码量更少且配有 Devtools】\n【图形/画布】【技术方案：使用 PixiJS 8 + pixi-viewport 实现图形和画布功能，基于 WebGL 渲染，适合处理大量精灵元素，相比其他可选方案性能更高】\n【富文本编辑器】【技术方案：采用 WangEditor 5 作为富文本编辑器，轻量且文档和社区均为中文，相比 Slate/TipTap 等编辑器，默认输出的 HTML 可直接给 PixiJS HTMLText 进行渲染】\n【图标】【技术方案：使用 Lucide React 图标库，图标数量多、风格统一且支持 Tree-shaking】\n【工具库】【技术方案：采用 nanoid 3 为画布元素生成唯一标识符等操作，轻量实用】\n【代码质量】【技术方案：使用 ESLint + Stylelint + Prettier + Husky + lint-staged + commitlint 保证团队代码风格一致，这是中大型项目的基本配置，有利于多人协作开发】\n此外，还配置了 react 开发者工具 react-dev-inspector，配置了一下，开发环境下 ctrl+q 可以实现点击页面上的组件，在 VSCode 中自动跳转到对应文件，并定位到对应行号，方便调试（先前写 vue 也用过类似的）\n项目 https://react-dev-inspector.zthxxx.me/docs\n功能要素和方案分析以上需求，查阅相关资料后，进行各个核心模块的技术方案选型，确定初步实现方案\n【基础渲染引擎】【技术方案：PixiJS v8（WebGL）提供高性能 2D 渲染，根据不同元素类型创建对应的 Pixi 对象（图形、文本、图像），通过 pixi-viewport 实现无限画布的视口控制，支持缩放、拖拽等交互】\n【无限画布视口】【技术方案：pixi-viewport（内置 zoom、drag、decelerate、clampZoom）库创建无限画布，在 StageManagerCore.ts 中初始化 viewport，并添加拖拽、缩放等交互功能，支持鼠标中键拖拽画布、滚轮缩放等常见操作】\n【富文本编辑】【技术方案：WangEditor 5 作为富文本编辑器，提供完整的文本编辑功能，编辑结果以 HTML 格式存储在元素的 text/string 属性中，元素使用 PixiJS 内置的 HTMLText 进行渲染实现富文本效果】\n【状态管理与数据结构】【技术方案：Zustand 作为全局状态管理库，通过 structuredClone 函数手动创建状态快照，管理画布元素、选中状态、工具类型等，通过中间件监听状态变化并触发重渲染，在特定的 ts 中定义所有状态和操作方法】\n【图片上传显示与滤镜】【技术方案：PixiJS 内置 Filter 系统包括 BlurFilter、ColorMatrixFilter（黑白、对比度、饱和度）实现图像处理效果，支持模糊、亮度调整、灰度等多种滤镜效果，在 ElementRenderer.ts 中根据元素的 filter 属性应用相应滤镜，支持 blur（模糊）、brightness（亮度）、grayscale（灰度）等滤镜类型】\n【选中与变换系统】【技术方案：SelectionManager + TransformOverlay（8 个把手 + 旋转把手）实现变换控件渲染，支持单个元素选中和多个元素群组选中，提供 8 个控制点和 1 个旋转点进行变换操作，根据不同元素类型提供不同的控制方式】\n【旋转与组合嵌套】【技术方案：每个元素维护自己的 matrix（局部矩阵），组合后父容器统一应用矩阵变换，支持多层级嵌套和复杂变换】\n【Minimap】【技术方案：单独一个小的 Pixi.Application（共享 texture 缓存）实现缩略图功能，主画布所有容器使用 cacheAsBitmap 后生成低分辨率 texture，实时更新到小画布，视口框用一个半透明矩形表示在主画布中的位置】\n【元素永久缓存】【技术方案：使用 spriteMap 来存储 PIXI 对象，元素更新时只修改属性并设置 container.dirty = true，而不是销毁重建，来解决拖拽中断、光标丢失、闪烁等问题】\n【辅助对齐线】【技术方案：拖拽时实时遍历所有元素 bounds，计算对齐情况（水平/垂直/间距相等），差值&lt;6px 就吸附并画蓝线，支持水平、垂直对齐以及等间距对齐等多种对齐方式，当距离小于阈值时自动吸附并对齐】\n【Undo/Redo】【技术方案：Command Pattern + structuredClone 完整快照（每步 before/after）实现撤销/重做功能，通过管理命令栈（undo，redo 栈），使用 structuredClone 创建状态快照，记录操作前后的完整状态，来支持添加元素、删除元素、修改元素属性等操作的撤销/重做，针对拖拽和调整大小操作的命令生成逻辑可能还要具体再处理一套】\n【数据持久化与离线】【技术方案：Zustand-persist + localForage（IndexedDB）实现数据持久化和离线使用，使用 Zustand 的持久化中间件保存状态，通过 localForage 将数据存储到 IndexedDB 中，实现数据的自动保存和恢复功能】\n【实时协同】【技术方案：Y.js + y-websocket（或自己写 CRDT）+ Operation Transform 合并策略实现无冲突的实时协同编辑，通过 y-websocket 插件实现服务端同步（问的 AI），有个思路是把操作打给时间 tag，然后然后按时间合并】\n\n项目架构树BDdraw_DEV/├── ALD_Backend/                    # 后端服务目录│   ├── src/                        # 后端源代码│   │   ├── api/                    # API接口目录│   │   │   ├── Room_management/    # 房间管理相关API│   │   │   │   ├── types/          # 房间管理相关类型定义│   │   │   │   │   ├── Room_CRUD_types.ts  # 房间增删改查类型定义│   │   │   │   │   ├── Room_List_types.ts  # 房间列表类型定义│   │   │   │   │   ├── Room_users_types.ts # 房间用户类型定义│   │   │   │   │   └── index.ts            # 类型索引文件│   │   │   │   ├── CORE.ts         # 核心房间管理逻辑│   │   │   │   ├── Room_CRUD.ts    # 房间增删改查操作实现│   │   │   │   ├── Room_List.ts    # 房间列表管理实现│   │   │   │   └── Room_users.ts   # 房间用户管理实现│   │   │   ├── USER_management/    # 用户管理相关API│   │   │   │   ├── auth_API.ts     # 用户认证API实现│   │   │   │   └── auth_API_types.ts  # 用户认证类型定义│   │   │   └── index.ts            # API索引文件│   │   ├── auth.ts                 # 认证模块实现│   │   ├── collab.ts               # 协作功能模块实现│   │   └── db.ts                   # 数据库连接和操作实现│   ├── ARCHITECTURE.md             # 后端架构说明文档│   ├── README.md                   # 后端说明文档│   ├── index.ts                    # 后端服务入口文件│   ├── package.json                # 后端依赖配置文件│   └── tsconfig.json               # 后端TypeScript配置├── src/                            # 前端源代码目录│   ├── api/                        # 前端API客户端│   │   ├── types/                  # API类型定义│   │   │   ├── Room_management/    # 房间管理相关类型定义│   │   │   │   ├── Room_CRUD_types.ts  # 房间增删改查类型定义│   │   │   │   ├── Room_List_types.ts  # 房间列表类型定义│   │   │   │   ├── Room_users_types.ts # 房间用户类型定义│   │   │   │   └── index.ts            # 类型索引文件│   │   │   ├── auth_API_types.ts   # 认证相关类型定义│   │   │   └── index.ts            # API类型索引文件│   │   ├── utils/                  # API工具函数│   │   │   └── apiClient.ts        # API客户端工具│   │   ├── apiService.ts           # API服务封装实现│   │   └── index.ts                # API索引文件│   ├── components/                 # React组件目录│   │   ├── Richtext_editor/        # 富文本编辑器组件│   │   │   ├── BottomTextEditor.tsx    # 底部文本编辑器实现│   │   │   └── Richtext_editor.tsx     # 富文本编辑器主组件│   │   ├── canvas_toolbar/         # 画布工具栏组件│   │   │   ├── ContextMenu.tsx     # 上下文菜单实现│   │   │   └── TopToolbar.tsx      # 顶部工具栏实现│   │   ├── collaboration/          # 协作功能组件│   │   │   ├── CollaboratorCursors.tsx # 协作者光标显示组件│   │   │   └── RemoteSelectionLayer.tsx # 远程选择层组件│   │   ├── error-page/             # 错误页面组件│   │   │   └── index.tsx           # 错误页面实现│   │   ├── header/                 # 页面头部组件│   │   │   ├── contents/           # 头部内容组件│   │   │   │   ├── ExportCanvasModal.tsx   # 导出画布模态框│   │   │   │   └── StageManagerContext.tsx # 舞台管理上下文│   │   │   └── index.tsx           # 头部组件入口│   │   ├── image-insert-modal/     # 图片插入模态框组件│   │   │   └── index.tsx           # 图片插入模态框实现│   │   ├── layout/                 # 布局组件│   │   │   └── index.tsx           # 布局组件实现│   │   ├── minimap/                # 小地图组件│   │   │   └── Minimap.tsx         # 小地图实现│   │   ├── property-panel/         # 属性面板组件│   │   │   └── index.tsx           # 属性面板实现│   │   ├── settings/               # 设置组件│   │   │   └── setting.tsx         # 设置组件实现│   │   ├── ui/                     # 基础UI组件│   │   │   ├── blackwhitebutton.tsx    # 黑白按钮组件│   │   │   ├── button.tsx          # 按钮组件│   │   │   ├── icon-circle.tsx     # 圆形图标组件│   │   │   ├── icon-clear.tsx      # 清除图标组件│   │   │   ├── icon-rect.tsx       # 矩形图标组件│   │   │   ├── icon-select.tsx     # 选择图标组件│   │   │   └── icon-triangle.tsx   # 三角形图标组件│   │   ├── AnimatedRoutes.tsx      # 动画路由组件│   │   ├── ParallaxBackground.tsx  # 视差背景组件│   │   └── WipeTransition.tsx      # 擦除过渡动画组件│   ├── hooks/                      # 自定义React Hooks│   │   ├── use-localstorage-state.ts   # localStorage状态管理Hook│   │   └── use_React_hotkeys_management.ts # 快捷键管理Hook│   ├── lib/                        # 工具库和核心功能模块│   │   ├── AddElementCommand.ts    # 添加元素命令实现│   │   ├── RemoveElementCommand.ts # 删除元素命令实现│   │   ├── UndoRedoManager.ts      # 撤销重做管理器实现│   │   ├── UpdateElementCommand.ts # 更新元素命令实现│   │   ├── UpdateElementPropertyCommand.ts # 更新元素属性命令实现│   │   ├── constants.ts            # 常量定义文件│   │   ├── env.ts                  # 环境变量配置│   │   ├── minimapUtils.ts         # 小地图工具函数│   │   └── utils.ts                # 通用工具函数│   ├── pages/                      # 页面组件目录│   │   ├── auth/                   # 认证相关页面│   │   │   ├── Login.tsx           # 登录页面实现│   │   │   └── Register.tsx        # 注册页面实现│   │   ├── canvas/                 # 画布主页面│   │   │   ├── Pixi_STM_modules/   # Pixi.js状态管理模块│   │   │   │   ├── core/           # 核心类和初始化逻辑│   │   │   │   │   ├── Core_StageManager.ts    # 核心舞台管理器│   │   │   │   │   ├── ElementRender.ts        # 元素渲染器│   │   │   │   │   ├── TF_controler_Renderer.ts # 变换控制器渲染器│   │   │   │   │   └── types.ts                # 核心类型定义│   │   │   │   ├── interaction/    # 交互处理模块│   │   │   │   │   ├── Base_InteractionHandler.ts   # 基础交互处理器│   │   │   │   │   └── Stage_InteractionHandler.ts  # 舞台交互处理器│   │   │   │   ├── shared/         # 共享类型定义│   │   │   │   │   └── types.ts    # 共享类型定义文件│   │   │   │   ├── utils/          # 工具函数目录│   │   │   │   │   ├── commandUtils.ts      # 命令工具函数│   │   │   │   │   ├── cursorUtils.ts       # 光标工具函数│   │   │   │   │   ├── destroyUtils.ts      # 销毁工具函数│   │   │   │   │   ├── dragUtils.ts         # 拖拽工具函数│   │   │   │   │   ├── drawingUtils.ts      # 绘图工具函数│   │   │   │   │   ├── eraserUtils.ts       # 橡皮擦工具函数│   │   │   │   │   ├── geometryUtils.ts     # 几何工具函数│   │   │   │   │   ├── guidelineUtils.ts    # 辅助线工具函数│   │   │   │   │   ├── interactionUtils.ts  # 交互工具函数│   │   │   │   │   ├── renderUtils.ts       # 渲染工具函数│   │   │   │   │   ├── resizeUtils.ts       # 调整大小工具函数│   │   │   │   │   ├── rotationUtils.ts     # 旋转工具函数│   │   │   │   │   ├── scaleUtils.ts        # 缩放工具函数│   │   │   │   │   ├── selectionUtils.ts    # 选择工具函数│   │   │   │   │   └── stateUtils.ts        # 状态工具函数│   │   │   │   └── STM_modules.md  # 状态管理模块说明文档│   │   │   ├── Pixi_stageManager.ts    # Pixi舞台管理器入口│   │   │   └── index.tsx           # 画布页面入口文件│   │   ├── home/                   # 主页│   │   │   ├── contents/           # 主页内容组件│   │   │   │   └── AKN.tsx         # AKN内容组件│   │   │   └── index.tsx           # 主页入口文件│   │   ├── intro/                  # 介绍页面│   │   │   └── index.tsx           # 介绍页面实现│   │   └── room/                   # 房间管理页面│   │       └── RoomManagement.tsx  # 房间管理页面实现│   ├── router/                     # 路由配置目录│   │   └── router.tsx              # 路由配置实现│   ├── stores/                     # 状态存储目录(Zustand)│   │   ├── canvasStore.ts          # 画布状态存储│   │   ├── persistenceStore.ts     # 持久化状态存储│   │   └── themeStore.ts           # 主题状态存储│   ├── app.tsx                     # 应用根组件│   ├── main.tsx                    # 应用入口文件│   └── vite-env.d.ts               # Vite环境声明文件├── README.md                       # 项目说明文档├── components.json                 # 组件配置文件├── index.html                      # HTML入口文件├── lint-staged.config.js           # Lint-staged配置├── package.json                    # 项目依赖和脚本配置├── postcss.config.js               # PostCSS配置├── tailwind.config.js              # Tailwind CSS配置├── transmart.config.ts             # Transmart配置├── tsconfig.json                   # TypeScript配置├── tsconfig.node.json              # Node.js TypeScript配置└── vite.config.ts                  # Vite构建配置\n项目架构设计项目采用数据驱动视图（Data-Driven View）模式，使用React (UI) + Zustand (数据) + PixiJS (渲染)的三层架构\nReact 只负责 UI 和事件入口Zustand 是唯一的真实数据源（纯 JSON，可持久化、可协同）PixiJS 层只做”渲染 + 交互计算”，所有对象永久缓存（Map），绝不每帧重建所有变换（拖拽、缩放、旋转、组合）都在 Pixi 层完成，最后再同步回 Zustand（单向数据流）\n项目主要划分为三个层次：渲染层、状态管理层和逻辑层，来实现关注点分离，提高代码的可维护性和可扩展性。\n渲染层主要由 PixiJS (WebGL) 负责处理图形渲染，包括创建、更新和删除图形对象。这一层负责将状态管理层的数据转换为可视化的图形元素，并处理用户的交互操作，如拖拽、缩放和旋转等\n状态管理层采用 Zustand 管理 JSON 画布数据。先定义一个 CanvasState 接口（JSON 数据结构，包含 id, type, x, y, width, height 等属性）\ninterface CanvasState {  tool: ToolType // 当前工具类型  elements: Record&lt;string, CanvasElement&gt; // 画布元素集合  selectedIds: string[] // 选中元素ID列表  editingId: string | null // 正在编辑的元素ID  clipboard: CanvasElement[] | null // 剪贴板数据  pasteOffset: number // 粘贴偏移计数  currentStyle: {    fill: string    stroke: string    strokeWidth: number    // ... 其他样式属性  }}\n使用 Zustand 状态管理库，其中 elements 被定义为 Record类型，表示一个以 id 为键，CanvasElement 为值的对象，用于存储画布上的所有元素。更新元素时使用 structuredClone 函数来克隆状态数据。后续持久化存储和撤销重做机制也是基于这一套状态管理来实现。这一层作为数据核心，主要维护画布上所有元素的状态信息，通过集中管理状态，确保了数据的一致性，便于后续的协同编辑和撤销重做功能的开发。\n逻辑层核心是 StageManagerCore 类，通过 StageManagerState 接口管理交互状态，包括当前交互模式、起始位置、当前元素 ID、初始元素状态等，处理多种交互模式：\nidle - 空闲状态panning - 画布平移selecting - 选择元素dragging - 拖拽元素resizing - 调整元素大小drawing - 绘制元素texting - 文本编辑erasing - 擦除元素\n处理多种元素操作逻辑：\n创建元素 - 根据不同工具类型创建相应元素选择元素 - 支持单选和多选拖拽元素 - 记录初始状态，计算偏移量调整大小 - 通过控制手柄调整元素尺寸删除元素 - 通过橡皮擦工具删除元素\n通过这种方式来实现面向对象编程并封装业务逻辑，提高代码的可维护性，利用后续拓展\n\n数据流程\ngraph TD    A[用户交互] --&gt; B{交互类型}    B --&gt;|创建元素| C[StageManagerCore.onPointerDown]    B --&gt;|拖拽元素| D[StageManagerCore.onPointerMove]    B --&gt;|调整大小| E[StageManagerCore.onHandleDown]    B --&gt;|选择元素| F[StageManagerCore.onPointerUp]    C --&gt; G[Zustand Store.addElement]    D --&gt; H[Zustand Store.updateElement]    E --&gt; I[Zustand Store.updateElement]    F --&gt; J[Zustand Store.setSelected]    G --&gt; K[Zustand 状态更新]    H --&gt; K    I --&gt; K    J --&gt; K    K --&gt; L{状态变化}    L --&gt;|元素变化| M[ElementRenderer.renderElements]    L --&gt;|选择变化| N[TransformerRenderer.renderTransformer]    M --&gt; O[PixiJS 图形渲染]    N --&gt; O    O --&gt; P[用户看到更新结果]    K --&gt; Q[Zustand 持久化]    Q --&gt; R[本地存储/IndexedDB]    K --&gt; S[撤销/重做管理]    S --&gt; T[命令栈管理]    style A fill:#e1f5fe    style O fill:#e8f5e8    style K fill:#fff3e0    style Q fill:#fce4ec\n流程如下：\n用户交互输入所有用户交互事件由 StageManagerCore 处理用户通过鼠标、键盘等方式与画布进行交互：\n\n创建新元素（点击工具栏选择图形类型后在画布上绘制）\n拖拽元素（选中元素后拖动）\n调整元素大小（拖拽元素控制点）\n选择元素（点击或框选元素）\n\n创建元素流程\n用户在画布上按下鼠标开始绘制\nonPointerDown捕获事件，创建新元素\n调用 Zustand store 的addElement方法添加元素\n\n\n创建元素时的中间状态要锁定撤销/重做管理器防止记录中间的一堆状态\n\n拖拽元素流程\n用户按下并拖动已选中的元素\nonPointerMove持续捕获鼠标移动事件\n实时调用 Zustand store 的updateElement更新元素位置\n\n\n拖拽元素时也是中间状态要锁定撤销/重做管理器防止记录中间的一堆状态\n\n调整大小流程\n用户拖拽元素的控制点（resize handle）\nonHandleDown捕获控制点拖拽事件\nonPointerMove计算缩放比例并更新元素大小\n调用 Zustand store 的updateElement更新元素属性\n\n\n调整元素大小时也是中间状态要锁定撤销/重做管理器防止记录中间的一堆状态\n\n交互结束处理\n用户释放鼠标按键，onPointerUp处理交互结束,解锁撤销/重做管理器\n创建相应的命令（UpdateElementCommand并添加到命令栈中\n清理临时状态\n\n状态更新Zustand 作为全局状态管理器，处理所有状态更新：\n\n状态更新：自定义一套originalSet方法更新状态\n撤销/重做处理：创建状态快照并生成命令对象\n状态订阅：通知所有订阅者状态变化\n\n渲染更新Zustand 状态变化触发 StageManagerCore 的订阅回调：\n\nElementRenderer.renderElements 根据元素数据更新 PixiJS 图形对象\nTransformerRenderer.renderTransformer 更新选中元素的变换控制器\nPixiJS 自动进行渲染\n\n撤销/重做管理通过命令模式实现撤销/重做功能：\n\n每个操作生成对应的命令对象（UpdateElementCommand、SnapshotCommand等）\n命令对象保存操作前后的状态快照\n通过UndoRedoManager管理命令栈，实现撤销和重做功能\n\n数据持久化阶段Zustand 状态变化同时触发数据持久化：\n\n状态通过persist中间件自动保存到本地存储\n数据存储在 IndexedDB 中，来支持离线使用\n\n\n这一块还在写\n\n\n设计的相关考虑解耦：渲染层、状态管理层和逻辑层相互独立，便于维护和扩展\n便于后续的协同编辑：实现多人协同，要监听 WebSocket 消息，然后更新 Zustand Store。StageManager 可以去监听到 Store 的变化，并作出相应的渲染更新\n对撤销/重做的实现：因为所有状态都在 Store 里，只需要保存/恢复 Store 的快照\n序列化/反序列化：保存项目只需 JSON.stringify(store.elements)\n目前的问题【待补充】\n项目预览部署地址：https://zhongye1.github.io/BDdraw_DEV/\nTODO【P0】基础渲染\n支持图形渲染，需要支持至少 3 种不同图形，比如矩形、圆角矩形、圆形、三角形等。需要支持以下图形属性：\n背景色（background）\n边框宽度（border-width）\n边框颜色（border-color）\n\n\n支持图片渲染，需要支持 png、jpeg 格式，支持设置三种简单滤镜\n支持富文本文字渲染，需要支持以下文本属性：\n字体（font-family）\n字号（font-size）\n颜色（color）\n背景色（background）\nBIUS（加粗、斜体、下划线、删除线）\n\n\n\n【P0】画布交互\n支持无限画布的缩放、滚动、拖拽\n支持无限画布滚动条\n支持无限画布的 minimap 功能\n\n\n支持选区功能：\n点击选中单个元素\n框选选中多个元素\n\n\n支持数据持久化，每次操作后自动保存数据，刷新页面数据仍然存在\n快捷键复制选中元素\n支持辅助线功能\n\n【P0】调参工具栏\n浮动工具栏\n当选中文本元素时出现在上方，支持设置不同文本属性（做了个编辑器）\n当选中图形元素时出现在上方，支持设置不同图形属性\n选中文本元素的部分文字时也能够出现，支持设置局部文本的文本属性（编辑器内编辑可实现）\n\n\n\n【P0】元素编辑\n支持双击文本进入编辑，可以输入/删除文本内容\n支持对选中元素（单个或多个）删除\n支持对选中元素（单个或多个）拖拽\n支持对选中元素（单个或多个）缩放\n支持对选中元素（单个或多个）旋转\n支持对多个元素进行组合操作，组合可以嵌套\n支持对多个元素进行打组、解组(组操作 bug 复现了，目前在修)（已修复）\n\n【P0】性能优化\n画布存在 100 个元素，打开页面到渲染完成 &lt; 3s\n同时操作 100 个元素，FPS 50+\n\n【P1】协同\n支持 undo &amp; redo 操作 （大体实现了，可能要修一下 undo，redo 栈，有个不能稳定复现的 bug）（已实现）\n支持协同编辑，多人打开同一个画布可以协同编辑 (写了个 Node.js 后端)\n支持离线编辑，断网后仍然可以对画布编辑，恢复网络后自动提交数据（IndexedDB）\n\n\n各模块的技术文档补充中此文档最后编辑于 2025.11.27项目开发中，欢迎提 issue 和 pr\n\n","categories":["Github项目"],"tags":["excalidraw","github"]},{"title":"2025-11-29-JavaScript中的数组方法与栈（Stack）和队列（Queue）的实现","url":"/Arknight-notes/posts/28254.html","content":"JavaScript 中的数组方法完全可以用来实现栈（Stack）和队列（Queue）的基本功能\n这是因为栈和队列本质上是对“插入”和“删除”操作位置的限制，而数组的push、pop、unshift、shift这些方法正好提供了在两端高效操作的能力\n先简单回顾一下这四种数组方法\n\n\n\n\n方法\n操作位置\n操作类型\n返回值\n时间复杂度\n\n\n\n\npush()\n尾部\n添加\n新长度\nO(1)\n\n\npop()\n尾部\n删除\n被删除元素\nO(1)\n\n\nunshift()\n头部\n添加\n新长度\nO(n)\n\n\nshift()\n头部\n删除\n被删除元素\nO(n)\n\n\n\n\n1. 实现栈（Stack）——后进先出（LIFO，Last In First Out）主要使用数组的末尾操作实现：\n\n\n\n\n操作\n数组方法\n示例代码\n时间复杂度\n\n\n\n\n入栈（push）\narray.push(item)\nstack.push(1)\nO(1)\n\n\n出栈（pop）\narray.pop()\nconst item = stack.pop()\nO(1)\n\n\n\n\n示例：\nconst stack = [];stack.push(1);    // [1]stack.push(2);    // [1, 2]stack.push(3);    // [1, 2, 3]console.log(stack.pop());  // 3console.log(stack.pop());  // 2console.log(stack);        // [1]\n2. 实现队列（Queue）——先进先出（FIFO，First In First Out）方式一：头部删除 + 尾部插入\n\n\n\n操作\n数组方法\n示例代码\n时间复杂度\n\n\n\n\n入队（enqueue）\narray.push(item)\nqueue.push(1)\nO(1)\n\n\n出队（dequeue）\narray.shift()\nconst item = queue.shift()\nO(n)\n\n\n\n\n问题：shift() 会导致数组所有元素向前移动，时间复杂度为 O(n)，频繁操作时性能很差\n方式二：尾部插入 + 头部删除\n\n\n\n操作\n数组方法\n示例代码\n时间复杂度\n\n\n\n\n入队\narray.unshift(item)\nqueue.unshift(1)\nO(n)\n\n\n出队\narray.pop()\nconst item = queue.pop()\nO(1)\n\n\n\n\n同样存在 O(n) 操作\n如果需要高效队列，可以使用双端队列实现或第三方库，有几种方式\n\n使用两个数组模拟（常见面试实现）：\n一个栈用于入队，一个栈用于出队，需要时倒腾\n\n\n使用 JavaScript 的 Deque（双端队列）库：\n如 js-deque 或其他库，支持 O(1) 的头尾操作\n\n\nES6+ 原生替代：虽然没有内置 Queue，但可以用 Array + 手动索引模拟环形队列（较复杂）\n\n","categories":["归档"]},{"title":"2025-12-15-杂谈-系统问题","url":"/Arknight-notes/posts/48096.html","content":"\n      \n        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\n      \n      \n        \n          \n          \n            联系站长以查看密码\n          \n        \n        \n      \n    \n    ","categories":["归档"]},{"title":"2025-12-25-ES6-关于JavaScript的Set 方法","url":"/Arknight-notes/posts/27040.html","content":"JavaScript Set 方法详解1. Set 是什么？Set​ 是 ES6 引入的一种新的数据结构，它类似于数组，但成员的值都是唯一的，没有重复的值。\n// 创建一个 Setconst mySet = new Set();// 或者从数组创建const setFromArray = new Set([1, 2, 3, 3, 4]); // 会自动去重console.log(setFromArray); // Set(4) {1, 2, 3, 4}\n2. Set 的基本方法2.1 添加元素：add()const set = new Set();// 添加单个元素set.add(1);set.add(2);set.add(2); // 重复添加，不会被添加进去// 链式调用set.add(3).add(4).add(5);// 可以添加任意类型的值set.add(\"hello\");set.add({ name: \"John\" });set.add([1, 2, 3]);set.add(NaN); // NaN 在 Set 中也是唯一的set.add(NaN); // 不会添加第二个 NaNconsole.log(set.size); // 查看大小\n2.2 删除元素：delete()const set = new Set([1, 2, 3, 4, 5]);// 删除指定值set.delete(3); // 删除 3console.log(set); // Set(4) {1, 2, 4, 5}// 删除不存在的值返回 falseconsole.log(set.delete(10)); // false// 删除对象引用需要相同的引用const obj = { name: \"John\" };set.add(obj);console.log(set.delete({ name: \"John\" })); // false，因为不是同一个引用console.log(set.delete(obj)); // true，删除成功\n2.3 检查存在：has()const set = new Set([1, 2, 3, 4, 5]);console.log(set.has(2)); // trueconsole.log(set.has(10)); // false// 对于 NaN，Set 能正确处理set.add(NaN);console.log(set.has(NaN)); // true\n2.4 清空 Set：clear()const set = new Set([1, 2, 3, 4, 5]);console.log(set.size); // 5set.clear();console.log(set.size); // 0console.log(set); // Set(0) {}\n3. Set 的遍历方法3.1 forEach()const set = new Set([\"apple\", \"banana\", \"orange\"]);// 遍历每个元素set.forEach((value, key, set) =&gt; {  // Set 的 key 和 value 相同  console.log(`${key}: ${value}`);});// 输出：// apple: apple// banana: banana// orange: orange\n3.2 keys()、values()、entries()const set = new Set([\"a\", \"b\", \"c\"]);// keys() - 返回键名的遍历器for (let key of set.keys()) {  console.log(key); // a, b, c}// values() - 返回键值的遍历器（Set 的键和值相同）for (let value of set.values()) {  console.log(value); // a, b, c}// entries() - 返回键值对的遍历器for (let entry of set.entries()) {  console.log(entry); // ['a', 'a'], ['b', 'b'], ['c', 'c']}\n4. Set 的特性4.1 唯一性// 自动去重const arr = [1, 2, 2, 3, 3, 3, 4, 5];const uniqueSet = new Set(arr);console.log([...uniqueSet]); // [1, 2, 3, 4, 5]// 对象引用不同，不算重复const obj1 = { id: 1 };const obj2 = { id: 1 };const objSet = new Set([obj1, obj2, obj1]);console.log(objSet.size); // 2，obj1 和 obj2 被认为是不同的\n4.2 与数组的对比// 查找元素const arr = [1, 2, 3, 4, 5];const set = new Set(arr);// 数组查找是 O(n)console.log(arr.includes(3)); // true，需要遍历// Set 查找是 O(1)console.log(set.has(3)); // true，哈希查找，更快// 判断是否重复const hasDuplicates = (array) =&gt; {  return new Set(array).size !== array.length;};console.log(hasDuplicates([1, 2, 3, 3])); // trueconsole.log(hasDuplicates([1, 2, 3, 4])); // false\n4.3 迭代顺序// Set 的遍历顺序就是插入顺序const set = new Set();set.add(3);set.add(1);set.add(2);for (let item of set) {  console.log(item); // 3, 1, 2（插入顺序）}// 与对象不同，对象的键顺序不保证const obj = { 3: \"a\", 1: \"b\", 2: \"c\" };console.log(Object.keys(obj)); // ['1', '2', '3']（数字键会排序）\n5. 实际应用场景5.1 数组去重（最常用）// 传统方法function uniqueArray(arr) {  return [...new Set(arr)];}// 使用const numbers = [1, 2, 3, 3, 4, 4, 5];console.log(uniqueArray(numbers)); // [1, 2, 3, 4, 5]// 字符串去重const str = \"hello world\";const uniqueChars = [...new Set(str)].join(\"\");console.log(uniqueChars); // 'helo wrd'\n5.2 求交集、并集、差集const setA = new Set([1, 2, 3, 4]);const setB = new Set([3, 4, 5, 6]);// 并集const union = new Set([...setA, ...setB]);console.log([...union]); // [1, 2, 3, 4, 5, 6]// 交集const intersection = new Set([...setA].filter((x) =&gt; setB.has(x)));console.log([...intersection]); // [3, 4]// 差集（A 有 B 没有）const difference = new Set([...setA].filter((x) =&gt; !setB.has(x)));console.log([...difference]); // [1, 2]\n5.3 数据筛选// 从数组中过滤出唯一的元素const data = [  { id: 1, name: \"Alice\" },  { id: 2, name: \"Bob\" },  { id: 1, name: \"Alice\" }, // 重复  { id: 3, name: \"Charlie\" },];// 基于 id 去重const seen = new Set();const uniqueData = data.filter((item) =&gt; {  if (seen.has(item.id)) {    return false;  } else {    seen.add(item.id);    return true;  }});console.log(uniqueData);// [//     { id: 1, name: 'Alice' },//     { id: 2, name: 'Bob' },//     { id: 3, name: 'Charlie' }// ]\n5.4 标签/分类系统class TagSystem {  constructor() {    this.tags = new Set();  }  addTag(tag) {    this.tags.add(tag.toLowerCase());    return this;  }  removeTag(tag) {    this.tags.delete(tag.toLowerCase());    return this;  }  hasTag(tag) {    return this.tags.has(tag.toLowerCase());  }  getAllTags() {    return [...this.tags];  }  merge(otherTagSystem) {    otherTagSystem.tags.forEach((tag) =&gt; this.tags.add(tag));    return this;  }}// 使用const articleTags = new TagSystem();articleTags.addTag(\"JavaScript\").addTag(\"Tutorial\").addTag(\"JavaScript\"); // 不会重复添加console.log(articleTags.getAllTags()); // ['javascript', 'tutorial']\n6. Set 性能优势// 测试查找性能const largeArray = Array.from({ length: 1000000 }, (_, i) =&gt; i);const largeSet = new Set(largeArray);console.time(\"Array查找\");largeArray.includes(999999);console.timeEnd(\"Array查找\"); // 约 0.5-1msconsole.time(\"Set查找\");largeSet.has(999999);console.timeEnd(\"Set查找\"); // 约 0.01ms// 测试重复检查性能const checkDuplicatesArray = (arr) =&gt; {  for (let i = 0; i &lt; arr.length; i++) {    for (let j = i + 1; j &lt; arr.length; j++) {      if (arr[i] === arr[j]) return true;    }  }  return false;};const checkDuplicatesSet = (arr) =&gt; {  return new Set(arr).size !== arr.length;};const testArray = Array.from({ length: 10000 }, () =&gt;  Math.floor(Math.random() * 1000));console.time(\"数组检查重复\");checkDuplicatesArray(testArray);console.timeEnd(\"数组检查重复\"); // 慢console.time(\"Set检查重复\");checkDuplicatesSet(testArray);console.timeEnd(\"Set检查重复\"); // 快\n7. WeakSet7.1 与 Set 的区别// Set 可以存储任何类型的值const set = new Set();let obj = { name: \"John\" };set.add(obj);console.log(set.size); // 1// WeakSet 只能存储对象引用const weakSet = new WeakSet();weakSet.add(obj); // OK// weakSet.add(1); // TypeError: Invalid value used in weak set// WeakSet 的引用是弱引用，不会阻止垃圾回收obj = null; // 清除引用// 等待垃圾回收后，weakSet 中的对应项会自动被移除\n7.2 WeakSet 的方法const weakSet = new WeakSet();const obj1 = {};const obj2 = {};weakSet.add(obj1);weakSet.add(obj2);console.log(weakSet.has(obj1)); // trueweakSet.delete(obj1);console.log(weakSet.has(obj1)); // false// WeakSet 没有 size 属性，不能遍历// console.log(weakSet.size); // undefined// weakSet.forEach(...) // 没有 forEach 方法\n7.3 WeakSet 的应用场景// 1. 存储 DOM 节点，避免内存泄漏const weakSet = new WeakSet();document.querySelectorAll(\"button\").forEach((button) =&gt; {  weakSet.add(button);  button.addEventListener(\"click\", () =&gt; {    if (weakSet.has(button)) {      console.log(\"按钮在集合中\");    }  });});// 当按钮从 DOM 中移除时，会被自动垃圾回收// weakSet 中的引用也会自动移除// 2. 私有属性模拟const privateData = new WeakSet();class User {  constructor(name) {    this.name = name;    privateData.add(this); // 标记为\"初始化\"  }  isInitialized() {    return privateData.has(this);  }}const user = new User(\"Alice\");console.log(user.isInitialized()); // true\n8. 常见的一些陷阱和注意事项8.1 NaN 的处理const set = new Set();set.add(NaN);console.log(set.has(NaN)); // true// 注意：NaN === NaN 为 false，但 Set 认为 NaN 等于自身\n8.2 对象引用const set = new Set();const obj1 = { id: 1 };const obj2 = { id: 1 };set.add(obj1);set.add(obj2);console.log(set.size); // 2，因为 obj1 和 obj2 是不同的对象引用console.log(set.has({ id: 1 })); // false，新对象不是同一个引用\n8.3 类型转换const set = new Set();set.add(1);set.add(\"1\");console.log(set.size); // 2，1 和 '1' 类型不同，不会去重console.log(set.has(1)); // trueconsole.log(set.has(\"1\")); // true\n8.4 遍历时修改const set = new Set([1, 2, 3]);// 在遍历时删除元素for (let item of set) {  if (item === 2) {    set.delete(item); // 当前正在遍历的元素可以安全删除  }  console.log(item); // 1, 2, 3（会正常遍历完）}// 在遍历时添加元素可能有问题for (let item of set) {  if (item === 1) {    set.add(4); // 添加的元素在本次遍历中可能不会被访问  }}\n9. 与其它数据结构的转换9.1 Set 与 Array// Set → Arrayconst set = new Set([1, 2, 3]);const arr1 = Array.from(set);const arr2 = [...set];console.log(arr1, arr2); // [1, 2, 3]// Array → Setconst array = [1, 2, 2, 3, 3, 3];const newSet = new Set(array);console.log([...newSet]); // [1, 2, 3]\n9.2 Set 与 String// 字符串去重并排序const str = \"javascript\";const uniqueSorted = [...new Set(str)].sort().join(\"\");console.log(uniqueSorted); // 'aijprstv'\n9.3 Set 与 Map// 使用 Set 存储 Map 的键const map = new Map([  [\"a\", 1],  [\"b\", 2],  [\"c\", 3],]);const keysSet = new Set(map.keys());console.log([...keysSet]); // ['a', 'b', 'c']\n10. 综合示例// 实现一个简单的权限系统class PermissionSystem {  constructor() {    this.permissions = new Set();  }  // 添加权限  addPermission(permission) {    this.permissions.add(permission);    return this;  }  // 批量添加权限  addPermissions(permissionsArray) {    permissionsArray.forEach((p) =&gt; this.permissions.add(p));    return this;  }  // 检查是否有某个权限  hasPermission(permission) {    return this.permissions.has(permission);  }  // 检查是否有所有指定权限  hasAllPermissions(requiredPermissions) {    return requiredPermissions.every((p) =&gt; this.permissions.has(p));  }  // 检查是否有任一指定权限  hasAnyPermission(permissions) {    return permissions.some((p) =&gt; this.permissions.has(p));  }  // 获取所有权限  getAllPermissions() {    return [...this.permissions];  }  // 移除权限  removePermission(permission) {    this.permissions.delete(permission);    return this;  }  // 清空所有权限  clearPermissions() {    this.permissions.clear();    return this;  }}// 使用示例const userPermissions = new PermissionSystem();userPermissions  .addPermissions([\"read\", \"write\", \"delete\"])  .addPermission(\"execute\");console.log(userPermissions.hasPermission(\"write\")); // trueconsole.log(userPermissions.hasAllPermissions([\"read\", \"write\"])); // trueconsole.log(userPermissions.getAllPermissions()); // ['read', 'write', 'delete', 'execute']\n\n总之\n\n高效查找：has()方法的时间复杂度是 O(1)\n遍历时按插入顺序输出\n需要去重时，优先考虑 Set\n需要快速查找元素是否存在时，用 Set 代替数组\n存储唯一值集合时，Set 是最佳选择\n需要存储对象引用并自动清理时，考虑 WeakSet\n\n","categories":["归档"]},{"title":"2025-11-17-关于动态规划(背包问题为例)","url":"/Arknight-notes/posts/24254.html","content":"动态规划介绍动态规划（Dynamic Programming，简称 DP）是一种算法设计范式，用于解决具有重叠子问题和最优子结构性质的优化问题。它通过将原问题分解为若干子问题，先解决子问题并保存结果（通常使用表格或数组），从而避免重复计算，最终构建出原问题的解。\n动态规划的核心思想源于数学中的贝尔曼最优性原理：最优策略的子策略总是最优的。与分治法不同，动态规划适用于子问题重叠的情况，能将指数级时间复杂度优化至多项式级。\n\n\n动态规划的适用条件\n最优子结构：原问题的最优解可由子问题的最优解组合得出。\n重叠子问题：子问题在递归求解中会被多次计算。\n\n实现方式\n自底向上（表格填充）：使用循环从小型子问题开始填充 DP 表格，直至原问题（常见于背包问题）。\n自顶向下（记忆化递归）：递归求解并使用备忘录存储已计算子问题结果。\n\n以 0/1 背包问题为例0/1 背包问题（0/1 Knapsack Problem）是动态规划的经典应用：给定 n 个物品，每个物品有重量 w_i 和价值 v_i，以及一个容量为 W 的背包。每个物品只能选择取或不取（0/1），求背包中物品的最大总价值。\n\n\n问题分析\n子问题：考虑前 i 个物品和容量为 j 的背包的最大价值。\n状态定义：dp[i][j] 表示前 i 个物品在容量 j 下的最大价值。\n状态转移方程：\n不取第 i 个物品：dp[i][j] = dp[i-1][j]\n取第 i 个物品（若 j ≥ w_i）：dp[i][j] = dp[i-1][j - w_i] + v_i\ndp[i][j] = max(以上两种情况)\n\n\n边界：dp[0][j] = 0（无物品），dp[i][0] = 0（容量为 0）\n\n示例假设物品：重量[1, 3, 4]，价值[15, 20, 30]，背包容量 W = 4。DP 表格填充过程如下所示：\n初始状态（i=0，无物品）容量 w:   0    1    2    3    4物品 i0        [0]  [0]  [0]  [0]  [0]\n考虑第 1 个物品（重量 1，价值 15）\n对于 w &lt; 1：无法放入，只能取上一行值（0）。\n对于 w ≥ 1：max(不放入: 0, 放入: 0 + 15) = 15。\n\n容量 w:   0    1    2    3    4物品 i0        [0]  [0]  [0]  [0]  [0]1        [0] [15] [15] [15] [15]\n考虑第 2 个物品（重量 3，价值 20）\n对于每个 w：\n如果 w &lt; 3：无法放入，取上一行值。\n如果 w ≥ 3：max(不放入: dp[1][w], 放入: dp[1][w-3] + 20)。\n\n\n\n计算示例：\n\nw=3：max(15, 15 + 20) = 35\nw=4：max(15, 15 + 20) = 35\n\n容量 w:   0    1    2    3    4物品 i0        [0]  [0]  [0]  [0]  [0]1        [0] [15] [15] [15] [15]2        [0] [15] [15] [35] [35]\n考虑第 3 个物品（重量 4，价值 30）\n对于每个 w：\n如果 w &lt; 4：无法放入，取上一行值。\n如果 w ≥ 4：max(不放入: dp[2][w], 放入: dp[2][w-4] + 30)。\n\n\n\n计算示例：\n\nw=4：max(35, 0 + 30) = 35（不放入更好）\n\n容量 w:   0    1    2    3    4物品 i0        [0]  [0]  [0]  [0]  [0]1        [0] [15] [15] [15] [15]2        [0] [15] [15] [35] [35]3        [0] [15] [15] [35] [35]\n最终结果：dp[3][4] = 35（选择第 1 和第 2 个物品：重量 1+3=4，价值 15+20=35）。\n一维 DP 优化过程简要文本模拟一维数组从后向前更新（避免覆盖）：\n初始 dp: [0, 0, 0, 0, 0]（容量 0 到 4）\n第 1 个物品后： [0, 15, 15, 15, 15]\n第 2 个物品后： [0, 15, 15, 35, 35]\n第 3 个物品后： [0, 15, 15, 35, 35]\n复杂度分析\n时间复杂度：O(n × capacity)\n空间复杂度：二维 O(n × capacity)，一维 O(capacity)\n\n伪代码（自底向上）dp = 二维数组 (n+1) x (W+1)，初始化为 0for i = 1 to n:    for j = 1 to W:        if w[i-1] &gt; j:            dp[i][j] = dp[i-1][j]        else:            dp[i][j] = max(dp[i-1][j], dp[i-1][j - w[i-1]] + v[i-1])返回 dp[n][W]\n时间复杂度 O(nW)，空间复杂度 O(nW)（可优化至 O(W) 使用一维数组）\n动态规划通过系统地记录子问题解，避免了暴力递归的冗余计算，在组合优化、序列问题等领域广泛应用。理解背包问题有助于掌握 DP 的状态设计与转移核心。\n0/1 背包问题的 TypeScript 实现详解0/1 背包问题（0/1 Knapsack Problem）是动态规划的经典示例。给定 n 个物品，每个物品具有重量 weights[i] 和价值 values[i]，以及一个背包容量 capacity。每个物品只能选择放入或不放入（不可重复），目标是求背包内物品的最大总价值。\n动态规划状态定义与转移\n状态：dp[i][w] 表示考虑前 i 个物品（索引 0 到 i-1），背包容量为 w 时的最大价值。\n转移方程：\n如果不放入第 i 个物品：dp[i][w] = dp[i-1][w]\n如果放入第 i 个物品（前提 w ≥ weights[i-1]）：dp[i][w] = dp[i-1][w - weights[i-1]] + values[i-1]\ndp[i][w] = Math.max(不放入, 放入)\n\n\n初始条件：dp[0][w] = 0（无物品），dp[i][0] = 0（容量为 0）。\n结果：dp[n][capacity]\n\nTypeScript 实现以下提供两种实现：标准二维 DP 和空间优化的一维 DP（推荐，后者空间复杂度 O(capacity)）\n1. 二维 DP 实现function knapsack01(weights: number[], values: number[], capacity: number): number {    const n = weights.length;    // 创建 (n+1) x (capacity+1) 的二维数组，初始化为 0    const dp: number[][] = Array.from({ length: n + 1 }, () =&gt; Array(capacity + 1).fill(0));    for (let i = 1; i &lt;= n; i++) {        for (let w = 1; w &lt;= capacity; w++) {            if (weights[i - 1] &gt; w) {                // 重量超出，无法放入                dp[i][w] = dp[i - 1][w];            } else {                // 取最大值                dp[i][w] = Math.max(                    dp[i - 1][w],                              // 不放入                    dp[i - 1][w - weights[i - 1]] + values[i - 1]  // 放入                );            }        }    }    return dp[n][capacity];}\n2. 一维 DP 实现（空间优化，使用滚动数组）function knapsack01Optimized(weights: number[], values: number[], capacity: number): number {    const n = weights.length;    // 一维数组，dp[w] 表示容量 w 时的最大价值    const dp: number[] = Array(capacity + 1).fill(0);    for (let i = 0; i &lt; n; i++) {        // 从后向前遍历（防止覆盖前状态）        for (let w = capacity; w &gt;= weights[i]; w--) {            dp[w] = Math.max(dp[w], dp[w - weights[i]] + values[i]);        }    }    return dp[capacity];}\n示例const weights = [1, 3, 4];const values = [15, 20, 30];const capacity = 4;console.log(knapsack01Optimized(weights, values, capacity));  // 输出 35（放入重量 1 和 3 的物品）\n\n物品数量 n = 3\n重量 weights = [1, 3, 4]\n价值 values = [15, 20, 30]\n背包容量 capacity = 4\n\n","categories":["归档"]},{"title":"2024-12-25-JavaScript / TypeScript 语法速记","url":"/Arknight-notes/posts/23505.html","content":"JavaScript / TypeScript 语法速记表变量声明// ES5var x = 10; // 函数作用域// ES6+let y = 20; // 块级作用域，可重新赋值const z = 30; // 块级作用域，不可重新赋值\n数据类型// 基本类型let str: string = \"Hello\";let num: number = 42;let bool: boolean = true;let undef: undefined = undefined;let nul: null = null;let sym: symbol = Symbol(\"id\");// 引用类型let obj: object = { key: \"value\" };let arr: number[] = [1, 2, 3];let func: Function = () =&gt; {};// TS特有类型let anyType: any = \"anything\"; // 任意类型let tuple: [string, number] = [\"a\", 1]; // 元组enum Color {  Red,  Green,  Blue,} // 枚举let unknownType: unknown; // 未知类型let neverType: never; // 永不存在的值let voidType: void; // 无返回值\n运算符// 算术运算符+ - * / % ** ++ --// 比较运算符==  ===  !=  !==  &gt;  &lt;  &gt;=  &lt;=// 逻辑运算符&amp;&amp;  ||  !// 赋值运算符=  +=  -=  *=  /=  %=// ES6新增??    // 空值合并?.    // 可选链...   // 展开/剩余运算符\n函数// 函数声明function add(a: number, b: number): number {  return a + b;}// 函数表达式const multiply = function (a, b) {  return a * b;};// 箭头函数const divide = (a, b) =&gt; a / b;const sayHi = () =&gt; console.log(\"Hi\");// 参数默认值function greet(name = \"Guest\") {}// 剩余参数function sum(...numbers) {}// TS函数类型type AddFunc = (a: number, b: number) =&gt; number;\n类与面向对象// 类定义class Animal {  // 属性  name: string;  private age: number;  protected species: string;  static count: number = 0;  // 构造函数  constructor(name: string) {    this.name = name;  }  // 方法  speak(): void {    console.log(\"Sound\");  }  // Getter/Setter  get getAge(): number { return this.age; }  set setAge(value: number) { this.age = value; }}// 继承class Dog extends Animal {  bark(): void {    console.log(\"Woof!\");  }  // 方法重写  override speak(): void {    console.log(\"Woof!\");  }}// 抽象类 (TS)abstract class Shape {  abstract area(): number;}// 接口 (TS)interface Person {  name: string;  age: number;  greet(): void;}// 实现接口class Student implements Person {  name: string;  age: number;  greet() { console.log(\"Hello\"); }}\n数组操作// 数组方法arr.push(), arr.pop(), arr.shift(), arr.unshift();arr.map(), arr.filter(), arr.reduce(), arr.forEach();arr.find(), arr.findIndex(), arr.some(), arr.every();arr.slice(), arr.splice(), arr.concat(), arr.join();arr.sort(), arr.reverse();// 解构赋值const [first, ...rest] = [1, 2, 3];const { name, age } = person;// 扩展运算符const newArr = [...oldArr, 4];const newObj = { ...oldObj, key: \"value\" };\n对象操作// 对象字面量增强const name = \"John\";const person = { name, age: 30 }; // 属性简写const obj = { [\"key\" + 1]: \"value\" }; // 计算属性名// 方法简写const obj = {  method() {    return this;  },};// 对象方法Object.keys(obj), Object.values(obj), Object.entries(obj);Object.assign(target, source);Object.freeze(obj);Object.seal(obj);\n异步编程// Promiseconst promise = new Promise((resolve, reject) =&gt; {  setTimeout(() =&gt; resolve(\"Done\"), 1000);});promise  .then((result) =&gt; console.log(result))  .catch((error) =&gt; console.error(error))  .finally(() =&gt; console.log(\"Complete\"));// Async/Awaitasync function fetchData() {  try {    const data = await fetch(url);    const result = await data.json();    return result;  } catch (error) {    console.error(error);  }}// Promise方法Promise.all([p1, p2]);Promise.race([p1, p2]);Promise.allSettled([p1, p2]);Promise.any([p1, p2]);\n模块系统// 导出export const PI = 3.14;export function add() {}export default class MyClass {}export { var1, var2 as alias };// 导入import MyClass from \"./module\";import { var1, var2 as alias } from \"./module\";import * as Module from \"./module\";import(\"./module\").then((module) =&gt; {}); // 动态导入\n字符串// 模板字符串const greeting = `Hello ${name}, you are ${age} years old`;// 字符串方法str.includes(), str.startsWith(), str.endsWith();str.repeat(), str.padStart(), str.padEnd();str.trim(), str.trimStart(), str.trimEnd();str.replace(), str.replaceAll();str.slice(), str.substring(), str.substr();\n类型操作 (TypeScript)// 类型注解let x: number = 5;// 类型别名type ID = string | number;type User = { id: ID; name: string };// 联合类型let value: string | number;// 交叉类型type Combined = TypeA &amp; TypeB;// 类型断言let str = value as string;let len = (&lt;string&gt;value).length;// 泛型function identity&lt;T&gt;(arg: T): T {  return arg;}interface Generic&lt;T&gt; {  value: T;}// 条件类型type IsString&lt;T&gt; = T extends string ? true : false;// 映射类型type Readonly&lt;T&gt; = { readonly [K in keyof T]: T[K] };type Partial&lt;T&gt; = { [K in keyof T]?: T[K] };\n错误处理// Try-Catchtry {  // 可能出错的代码  throw new Error(\"Something went wrong\");} catch (error) {  console.error(error);} finally {  // 始终执行}\nES6+ 新特性// 解构赋值const { a, b } = obj;const [x, y] = arr;// 默认参数function f(x = 1, y = 2) {}// 剩余参数function f(...args) {}// 可选链const value = obj?.prop?.nested;// 空值合并const result = input ?? \"default\";// BigIntconst big = 9007199254740991n;// 动态导入import(\"./module.js\").then((module) =&gt; {});\n常用数组/对象方法链// 常见处理模式array  .filter((item) =&gt; item.active)  .map((item) =&gt; ({ ...item, processed: true }))  .sort((a, b) =&gt; a.id - b.id)  .reduce((acc, curr) =&gt; acc + curr.value, 0);\n实用代码片段// 深拷贝const deepCopy = JSON.parse(JSON.stringify(obj));// 或const deepCopy = structuredClone(obj);// 去重const unique = [...new Set(array)];// 对象合并const merged = Object.assign({}, obj1, obj2);// 或const merged = { ...obj1, ...obj2 };// 检查空对象const isEmpty = Object.keys(obj).length === 0;// 延迟执行const delay = (ms) =&gt; new Promise((resolve) =&gt; setTimeout(resolve, ms));// 节流防抖const debounce = (func, wait) =&gt; {  let timeout;  return (...args) =&gt; {    clearTimeout(timeout);    timeout = setTimeout(() =&gt; func(...args), wait);  };};\n\nconstructor 关键字constructor 是类（class）中用于定义构造函数的关键字。构造函数是一种特殊的方法，在使用 new 创建类实例时自动调用，用于初始化对象的属性和状态。\n\n作用：\n初始化新创建的对象。\n可接受参数，用于设置实例的初始值。\n如果类中未显式定义 constructor，JavaScript 会提供一个默认的空构造函数。\n\n\n语法示例（TypeScript/JavaScript）：\nclass Person {    name: string;    age: number;    // 构造函数    constructor(name: string, age: number) {        this.name = name;  // 初始化实例属性        this.age = age;    }    greet() {        console.log(`Hello, my name is ${this.name}`);    }}\n\n特点：\n\n一个类中只能有一个名为 constructor 的方法，否则会抛出语法错误。\n在继承中，可通过 super() 调用父类的构造函数。\n\n\n\nnew 关键字new 是用于创建对象实例的操作符关键字。它与构造函数结合使用，执行类的实例化过程。\n\n作用：\n创建一个新对象。\n将构造函数的 this 绑定到新对象。\n执行构造函数代码。\n如果构造函数未显式返回对象，则返回新创建的对象。\n\n\n执行步骤（内部机制）：\n创建一个空对象 {}。\n将该对象的原型（proto）设置为构造函数的 prototype。\n将 this 绑定到新对象并调用构造函数。\n返回该对象（除非构造函数返回其他对象）。\n\n\n语法示例：const person = new Person('Alice', 30);  // 使用 new 调用构造函数创建实例person.greet();  // 输出: Hello, my name is Alice\n常见错误：\n直接调用构造函数而不使用 new（如 Person(‘Alice’, 30)），会导致 this 指向全局对象（严格模式下为 undefined），可能造成意外行为。\n\n\n\n两者关系\nnew 操作符触发类的 constructor 方法执行。\n它们共同实现了 JavaScript 的类实例化机制，支持原型继承和面向对象编程范式。\n\n在 TypeScript 中，这些关键字的行为与 JavaScript 完全一致，但 TypeScript 通过类型注解提供了更强的静态类型检查，提升了代码的安全性和可维护性。\n\nDST:\nconst &gt; let &gt; var​  优先使用 const\n=== 代替 ==  严格相等判断\n箭头函数保持 this 绑定\n模板字符串代替拼接\n解构简化代码\nPromise 处理异步，async/await 更可读\n可选链和空值合并处理 null/undefined\n\n","categories":["前端"],"tags":["前端开发","JavaScript"]},{"title":"2025-11-20-关于滑动窗口","url":"/Arknight-notes/posts/25943.html","content":"滑动窗口（Sliding Window）是一种经典的算法设计技巧，主要用于处理线性数据结构（如数组、字符串、链表）上的连续子序列（子数组或子串）问题。它通过维护一个“窗口”在数据上滑动，避免重复计算，从而将暴力枚举的 O(n²) 或更高复杂度优化至 O(n)\n\n\n窗口：数据中一段连续的区间 [left, right]（左闭右开）或 [left, right]。\n左指针（left）：窗口左侧边界。\n右指针（right）：窗口右侧边界。\n滑动过程：\n先扩展右指针（right++），扩大窗口。\n当窗口状态不满足条件时，收缩左指针（left++），缩小窗口。\n每次窗口合法时，记录或更新答案。\n\n\n\n算法设计通用模板（以数组为例）function slidingWindow(arr: number[], target: number): number {    let left = 0;    let maxResult = 0;  // 或 minResult、count 等，根据题目    let windowState = 0;  // 维护窗口内的某种状态（如和、元素个数、唯一字符等）    for (let right = 0; right &lt; arr.length; right++) {        // 1. 扩展右边界：加入 arr[right]        windowState = updateWhenAdd(windowState, arr[right]);        // 2. 当窗口不合法时，收缩左边界        while (windowInvalid(windowState, target) &amp;&amp; left &lt;= right) {            windowState = updateWhenRemove(windowState, arr[left]);            left++;        }        // 3. 此时窗口合法，更新答案        maxResult = Math.max(maxResult, right - left + 1);  // 例如求最大长度    }    return maxResult;}\n常见滑动窗口类型\n固定窗口大小（窗口长度固定为 k）\n典型问题：求长度为 k 的子数组的最大/最小和、最大平均值等。\n方法：右指针移动 k 步后开始记录，左指针始终与右指针保持距离 k。\n示例：LeetCode 209（最小长度子数组和 ≥ target）可变形为固定窗口。\n\n\n可变窗口大小（窗口长度动态变化）\n最大/最小长度：求满足条件的最长或最短子数组。\n计数类：统计满足条件的子数组个数。\n典型问题：\nLeetCode 3：无重复字符的最长子串（窗口内字符唯一）。\nLeetCode 76：最小覆盖子串（窗口包含所有目标字符）。\nLeetCode 424：最多替换 k 个字符后的最长重复字符子串。\n\n\n\n\n\n设计滑动窗口的关键步骤\n明确窗口代表什么：窗口内维护的是一段连续子数组/子串。\n定义窗口的合法状态：例如，和 ≤ target、无重复字符、包含所有所需元素等。\n维护窗口状态：\n使用变量（如 sum、count）、哈希表（Map/Set 统计频率或位置）、双指针等。\n高效更新：添加右元素 O(1)，移除左元素 O(1)。\n\n\n决定何时移动左/右指针：\n右指针通常在外层 for 循环中单向移动（保证总时间 O(n)）。\n左指针在内层 while 循环中移动，直到窗口重新合法。\n\n\n记录答案：在窗口合法时更新全局最优解。\n\n适用问题特征：\n\n要求连续子数组/子串的极值（最大、最小、个数）。\n数据具有线性顺序。\n条件具有单调性（扩大窗口使条件更严格，缩小则更宽松）。\n\n","categories":["归档"]},{"title":"2025-11-25 关于链表(Javascript)","url":"/Arknight-notes/posts/33314.html","content":"关于链表(Javascript)链表是一种常见的数据结构，由一系列节点组成，每个节点包含数据和指向下一个节点的引用，在 JavaScript 中广泛应用于算法问题和实际开发\n链表的基本操作1. 单向链表的实现下面是一个简单的单向链表的实现，包括节点定义和基本操作：\n// 定义节点类class ListNode {  constructor(value) {    this.value = value; // 节点的值    this.next = null; // 指向下一个节点的指针，初始为 null  }}// 定义单向链表类class LinkedList {  constructor() {    this.head = null; // 链表头节点，初始为 null  }  // 在链表末尾添加节点  append(value) {    const newNode = new ListNode(value); // 创建一个新的节点    if (this.head === null) {      // 如果链表为空，新的节点作为头节点      this.head = newNode;    } else {      let current = this.head;      while (current.next !== null) {        // 遍历链表找到最后一个节点        current = current.next;      }      current.next = newNode; // 将新的节点添加到最后一个节点的 next    }  }  // 在链表头部添加节点  prepend(value) {    const newNode = new ListNode(value); // 创建一个新的节点    newNode.next = this.head; // 新节点的 next 指向当前的头节点    this.head = newNode; // 新节点作为头节点  }  // 删除指定值的节点  delete(value) {    if (this.head === null) return; // 如果链表为空，直接返回    // 如果头节点就是要删除的节点    if (this.head.value === value) {      this.head = this.head.next;      return;    }    let current = this.head;    while (current.next !== null) {      if (current.next.value === value) {        // 找到要删除的节点        current.next = current.next.next; // 将要删除的节点移出链表        return;      }      current = current.next;    }  }  // 打印链表  print() {    let current = this.head;    while (current !== null) {      process.stdout.write(`${current.value} -&gt; `); // 输出当前节点的值      current = current.next;    }    console.log(\"null\"); // 表示链表结束  }}// 示例：使用单向链表const list = new LinkedList();list.append(1);list.append(2);list.append(3);list.prepend(0);list.print(); // 输出 0 -&gt; 1 -&gt; 2 -&gt; 3 -&gt; nulllist.delete(2);list.print(); // 输出 0 -&gt; 1 -&gt; 3 -&gt; null\n2. 双向链表的实现下面是一个简单的双向链表的实现，包括节点定义和基本操作：\n// 定义双向节点类class DoublyListNode {  constructor(value) {    this.value = value; // 节点的值    this.next = null; // 指向下一个节点的指针，初始为 null    this.prev = null; // 指向前一个节点的指针，初始为 null  }}// 定义双向链表类class DoublyLinkedList {  constructor() {    this.head = null; // 链表头节点，初始为 null    this.tail = null; // 链表尾节点，初始为 null  }  // 在链表末尾添加节点  append(value) {    const newNode = new DoublyListNode(value); // 创建一个新的节点    if (this.tail === null) {      // 如果链表为空，新的节点作为头和尾节点      this.head = newNode;      this.tail = newNode;    } else {      this.tail.next = newNode; // 将新的节点添加到尾节点的 next      newNode.prev = this.tail; // 新节点的 prev 指向当前的尾节点      this.tail = newNode; // 新节点作为新的尾节点    }  }  // 在链表头部添加节点  prepend(value) {    const newNode = new DoublyListNode(value); // 创建一个新的节点    if (this.head === null) {      // 如果链表为空，新的节点作为头和尾节点      this.head = newNode;      this.tail = newNode;    } else {      this.head.prev = newNode; // 头节点的 prev 指向新的节点      newNode.next = this.head; // 新节点的 next 指向当前的头节点      this.head = newNode; // 新节点作为新的头节点    }  }  // 删除指定值的节点  delete(value) {    if (this.head === null) return; // 如果链表为空，直接返回    // 如果头节点就是要删除的节点    if (this.head.value === value) {      this.head = this.head.next;      if (this.head !== null) {        this.head.prev = null;      } else {        this.tail = null; // 如果链表为空，更新尾节点      }      return;    }    let current = this.head;    while (current !== null) {      if (current.value === value) {        // 找到要删除的节点        if (current.next !== null) {          current.next.prev = current.prev;        } else {          this.tail = current.prev; // 更新尾节点        }        current.prev.next = current.next;        return;      }      current = current.next;    }  }  // 打印链表  print() {    let current = this.head;    while (current !== null) {      process.stdout.write(`${current.value} &lt;-&gt; `); // 输出当前节点的值      current = current.next;    }    console.log(\"null\"); // 表示链表结束  }}// 示例：使用双向链表const dList = new DoublyLinkedList();dList.append(1);dList.append(2);dList.append(3);dList.prepend(0);dList.print(); // 输出 0 &lt;-&gt; 1 &lt;-&gt; 2 &lt;-&gt; 3 &lt;-&gt; nulldList.delete(2);dList.print(); // 输出 0 &lt;-&gt; 1 &lt;-&gt; 3 &lt;-&gt; null\n查找某个元素问题描述：在链表中查找指定值的节点，并返回其位置索引。\n/** * 查找指定值的节点 * @param {LinkedList} list - 单向链表 * @param {any} value - 要查找的值 * @returns {number} - 节点的位置索引，如果未找到返回-1 */function findElement(list, value) {  let current = list.head;  let index = 0;  while (current !== null) {    if (current.value === value) {      return index; // 找到值，返回索引    }    current = current.next;    index++;  }  return -1; // 未找到，返回-1}// 示例：查找元素const searchList = new LinkedList();searchList.append(1);searchList.append(2);searchList.append(3);searchList.append(4);console.log(findElement(searchList, 3)); // 输出 2console.log(findElement(searchList, 5)); // 输出 -1\n2. 在指定位置插入元素问题描述：在链表的指定位置插入新节点。\n/** * 在指定位置插入节点 * @param {LinkedList} list - 单向链表 * @param {number} position - 插入位置（从0开始） * @param {any} value - 要插入的值 * @returns {boolean} - 插入成功返回true，否则返回false */function insertAtPosition(list, position, value) {  if (position &lt; 0) {    return false; // 位置无效  }  if (position === 0) {    // 在头部插入    const newNode = new ListNode(value);    newNode.next = list.head;    list.head = newNode;    return true;  }  let current = list.head;  let index = 0;  // 找到指定位置的前一个节点  while (current !== null &amp;&amp; index &lt; position - 1) {    current = current.next;    index++;  }  // 如果位置超出链表长度  if (index !== position - 1 &amp;&amp; current === null) {    return false;  }  // 插入新节点  const newNode = new ListNode(value);  newNode.next = current.next;  current.next = newNode;  return true;}// 示例：在指定位置插入元素const insertList = new LinkedList();insertList.append(1);insertList.append(2);insertList.append(4);insertList.print(); // 输出 1 -&gt; 2 -&gt; 4 -&gt; nullinsertAtPosition(insertList, 2, 3); // 在索引2的位置插入3insertList.print(); // 输出 1 -&gt; 2 -&gt; 3 -&gt; 4 -&gt; nullinsertAtPosition(insertList, 0, 0); // 在开头插入0insertList.print(); // 输出 0 -&gt; 1 -&gt; 2 -&gt; 3 -&gt; 4 -&gt; null\n3. 查找指定位置的元素问题描述：获取链表中指定位置的元素值。\n/** * 获取指定位置的元素 * @param {LinkedList} list - 单向链表 * @param {number} position - 位置索引（从0开始） * @returns {any|undefined} - 位置上的值，如果位置无效返回undefined */function getElementAtPosition(list, position) {  if (position &lt; 0 || list.head === null) {    return undefined; // 位置无效或链表为空  }  let current = list.head;  let index = 0;  while (current !== null &amp;&amp; index &lt; position) {    current = current.next;    index++;  }  if (index === position &amp;&amp; current !== null) {    return current.value;  }  return undefined; // 位置超出链表长度}// 示例：获取指定位置的元素const positionList = new LinkedList();positionList.append(10);positionList.append(20);positionList.append(30);console.log(getElementAtPosition(positionList, 0)); // 输出 10console.log(getElementAtPosition(positionList, 2)); // 输出 30console.log(getElementAtPosition(positionList, 5)); // 输出 undefined\n4. 删除指定位置的元素问题描述：删除链表中指定位置的节点。\n/** * 删除指定位置的节点 * @param {LinkedList} list - 单向链表 * @param {number} position - 要删除的位置（从0开始） * @returns {boolean} - 删除成功返回true，否则返回false */function deleteAtPosition(list, position) {  if (position &lt; 0 || list.head === null) {    return false; // 位置无效或链表为空  }  if (position === 0) {    // 删除头节点    list.head = list.head.next;    return true;  }  let current = list.head;  let index = 0;  // 找到指定位置的前一个节点  while (current !== null &amp;&amp; index &lt; position - 1) {    current = current.next;    index++;  }  // 如果位置超出链表长度  if (index !== position - 1 || current.next === null) {    return false;  }  // 删除节点  current.next = current.next.next;  return true;}// 示例：删除指定位置的元素const deleteList = new LinkedList();deleteList.append(1);deleteList.append(2);deleteList.append(3);deleteList.append(4);deleteList.print(); // 输出 1 -&gt; 2 -&gt; 3 -&gt; 4 -&gt; nulldeleteAtPosition(deleteList, 2); // 删除索引2的位置（值为3）deleteList.print(); // 输出 1 -&gt; 2 -&gt; 4 -&gt; nulldeleteAtPosition(deleteList, 0); // 删除索引0的位置（值为1）deleteList.print(); // 输出 2 -&gt; 4 -&gt; null\n5. 获取链表长度问题描述：计算链表中节点的数量。\n/** * 获取链表长度 * @param {LinkedList} list - 单向链表 * @returns {number} - 链表长度 */function getListLength(list) {  let current = list.head;  let length = 0;  while (current !== null) {    length++;    current = current.next;  }  return length;}// 示例：获取链表长度const lengthList = new LinkedList();lengthList.append(1);lengthList.append(2);lengthList.append(3);console.log(getListLength(lengthList)); // 输出 3lengthList.append(4);console.log(getListLength(lengthList)); // 输出 4\n\n其他操作\n查找元素：根据值查找节点位置\n指定位置插入：在特定位置插入新节点\n指定位置获取：获取特定位置的节点值\n指定位置删除：删除特定位置的节点\n递归反转：使用递归方式反转链表\n获取长度：统计链表中节点的数量反转链表\n\n问题描述：反转一个单向链表\n\n初始化 prev 为 null（新链表的尾部）。\ncurrent 从链表头节点开始。\n在循环中：\n暂存 next = current.next（避免指针丢失）。\n将 current.next 指向 prev（反转当前指针）。\n更新 prev = current（前移 prev）。\n更新 current = next（前移 current）。\n\n\n循环结束后，prev 指向原链表的尾节点（新头节点），更新 list.head = prev。\n\n其实就是三指针原地反转\n\n/** * 反转单向链表 * @param {LinkedList} list - 单向链表 * @returns {LinkedList} - 反转后的链表 */function reverseLinkedList(list) {  let prev = null;  let current = list.head;  while (current !== null) {    let next = current.next; // 暂存下一个节点    current.next = prev; // 将当前节点的 next 指向前一个节点    prev = current; // 更新前一个节点为当前节点    current = next; // 继续遍历下一个节点  }  list.head = prev; // 更新头节点为最后一个非空节点  return list;}// 示例：反转链表const rList = new LinkedList();rList.append(1);rList.append(2);rList.append(3);rList.print(); // 输出 1 -&gt; 2 -&gt; 3 -&gt; nullreverseLinkedList(rList);rList.print(); // 输出 3 -&gt; 2 -&gt; 1 -&gt; null\n合并两个有序链表问题描述：合并两个有序链表，使结果链表仍然有序。\n/** * 合并两个有序链表 * @param {LinkedList} l1 - 第一个有序链表 * @param {LinkedList} l2 - 第二个有序链表 * @returns {LinkedList} - 合并后的有序链表 */function mergeTwoLists(l1, l2) {  let dummy = new ListNode(0); // 创建一个哨兵节点  let current = dummy;  let p1 = l1.head;  let p2 = l2.head;  // 遍历两个链表  while (p1 !== null &amp;&amp; p2 !== null) {    if (p1.value &lt; p2.value) {      current.next = p1; // 将较小值的节点添加到结果链表中      p1 = p1.next;    } else {      current.next = p2;      p2 = p2.next;    }    current = current.next;  }  // 将剩余的节点连接到结果链表中  if (p1 !== null) {    current.next = p1;  }  if (p2 !== null) {    current.next = p2;  }  let mergedList = new LinkedList();  mergedList.head = dummy.next; // 哨兵节点的 next 为合并后的头节点  return mergedList;}// 示例：合并两个有序链表const list1 = new LinkedList();list1.append(1);list1.append(3);list1.append(5);const list2 = new LinkedList();list2.append(2);list2.append(4);list2.append(6);const mergedList = mergeTwoLists(list1, list2);mergedList.print(); // 输出 1 -&gt; 2 -&gt; 3 -&gt; 4 -&gt; 5 -&gt; 6 -&gt; null\n\n更新中\n","categories":["数据结构"],"tags":["数据结构","JavaScript","链表"]},{"title":"2025-12-07-杂谈-复杂异构系统监控与可视化项目设计","url":"/Arknight-notes/posts/51477.html","content":"复杂异构系统监控与可视化项目设计问题背景：现在需要设计一个系统，使用 py 的 fastapi 作为后端\n目前有一个使用 Docker Compose 编排的复杂容器化环境，基于 SeedEmu（SEED Internet Emulator）框架构建。该框架专用于模拟大规模互联网基础设施，常用于网络安全研究、教育和实验，特别是区块链网络的安全性测试。此 docker-compose.yml 定义了一个模拟的互联网环境，其中部署了一个完整的 Ethereum Proof-of-Stake (PoS) 区块链网络，分布在多个自治系统（Autonomous Systems, AS）中，并通过互联网交换点（Internet Exchange Points, IXP）和路由器实现互联。该环境的主要目的是模拟真实互联网拓扑下的区块链网络行为，支持研究区块链在复杂网络环境下的安全性、性能、攻击与防御（如 Eclipse 攻击、分区攻击、路由攻击等），并提供可视化监控、数据采集和分析工具。\n主要组件与功能有：数据库与辅助服务，包括用于存储区块链监控数据的 postgresql（数据库名为 ethereum_monitor），作为缓存或消息队列的 redis，以及用于存储和分析网络拓扑、区块链节点关系等复杂关系数据的图数据库 neo4j。\nEthereum 区块链网络在 AS 101–112（共 12 个自治系统）中部署了大量 Ethereum PoS 节点。每个 AS 内部包含 3 个本地网络（inet0、inet1、inet2），每个网络内有 3 个 Ethereum 节点（共 9 个节点/AS）。总计约 108 个 Ethereum validator/miner 节点（节点 ID 从 2 到 108），加上一个 BootNode 和 BeaconSetup 节点。所有节点运行在自定义的链上（chain_id: 1337, chain_name: posCurrentEnhancedNet）。部分节点（如 AS101 的 host0）暴露了 JSON-RPC (8545)、WebSocket (8546) 和 Web 界面 (8000) 端口，便于外部交互。\n网络路由基础设施基于 SeedEmu，AS 2 作为一个骨干/中转 AS，包含四个边界路由器（r51–r54），通过点对点链路（net_2_net_51_52 等）连接。IXP（互联网交换点）包括四个全球 IXP（ix51–ix54），每个有 Route Server（路由服务器），用于多边对等互联。AS 21–24 作为 IXP 的参与者（peering AS），每个连接一个 IXP。AS 101–112 每个 AS 有一个边界路由器连接到对应的 IXP（例如 AS101 连接 ix51），实现与外部互联网的连通。所有路由器运行真实路由协议（如 BGP），支持模拟路由攻击、劫持等。\n可视化与监控工具包括运行 SeedEmu 的互联网拓扑可视化界面的 seedemu-internet-client，映射端口 8080，提供整个网络拓扑的图形化视图，以及运行 Ethereum 网络专用可视化界面的 seedemu-ether-client，映射端口 5000，用于查看区块链节点状态、同步情况、交易等。eth_node_cleaner 是自定义服务，暴露端口 8888，可能用于中央数据收集、节点状态清理或监控指标聚合，连接 PostgreSQL、Redis 和 Neo4j。\n其他特性包括大量自定义网络（local 和 global 类型），精确分配 IP 地址段，节点标签丰富（org.seedsecuritylabs.seedemu.meta.*），便于 SeedEmu 工具识别和渲染，部分服务使用 privileged 模式和 cap_add: ALL，以支持模拟路由所需的网络权限。\n现在需要实现一系列功能，提供基于 FastAPI 框架的 RESTful API 路由模块（topology_router），专用于提供区块链仿真环境（特别是结合 SeedEmu 和 Ethereum PoS 网络）的完整拓扑数据访问接口如下：GET /overview 获取整个仿真环境的拓扑概览信息（如节点总数、层级结构等）；GET /statistics 获取拓扑统计数据（如节点、链路数量等汇总指标）；GET /health 检查拓扑服务的健康状态，返回组件运行状况。\nGET /ethereum 获取完整的以太坊网络拓扑数据（节点与 P2P 连接）；GET /ethereum/nodes 获取所有以太坊节点列表，支持按层级过滤（execution 或 consensus）；GET /ethereum/nodes/{node_id}获取指定以太坊节点（执行层或共识层）的详细信息；GET /ethereum/validators/{validator_id}根据验证者公钥获取单个验证者节点的详细状态和信息。\nGET /physical 获取纯物理拓扑结构（不包含容器运行时监控数据）；GET /physical/devices 获取物理设备列表（路由器、主机等），支持按设备类型过滤；GET /physical/links 获取物理链路（网络连接）列表，支持按连接类型过滤；GET /physical/networks 获取所有物理网络的配置信息（网络 ID、名称、子网、网关等）。\nGET /contract 获取智能合约相关的拓扑视图（合约部署、调用关系等）；GET /contract/statistics 获取合约层面的统计信息（如合约数量、调用频率等）。\nGET /transaction 获取交易拓扑数据，支持通过时间范围（start_time 和 end_time）过滤；GET /transaction/statistics 获取交易层面的统计信息；GET /transaction/address/{address}/analysis 分析特定以太坊地址的资金/交易流向（流入流出关系图）。\nGET /layer/{layer}根据指定拓扑层（枚举值，如 ethereum、physical 等）获取对应层级的完整拓扑数据；POST /combined 支持组合多个拓扑层（如以太坊层+物理层）生成统一的拓扑视图，可指定渲染格式。\nPOST /render 接收任意拓扑数据和渲染请求（格式如 cytoscape、graphviz 等），返回经过布局算法处理的可直接用于前端可视化的数据。\nGET /nodes/{node_id}获取任意节点（跨层级）的详细信息，支持指定层级；GET /analysis/{layer}对指定层级进行网络分析（如连通性、中心性、社区检测等指标）。\nPOST /cache/clear 清空服务内部所有缓存（用于强制刷新数据）；GET /debug/info 获取详细的调试信息，包括服务组件状态、各处理器缓存大小、支持的层级与渲染格式等，便于开发与运维排查。\n\n针对该环境和需求的系统设计方案需要设计一个 FastAPI 后端，它充当一个”中间层（Middleware）”或”聚合层（Aggregator）”，将底层分散的基础设施（Docker）、网络拓扑（SeedEmu/Neo4j）和应用状态（Ethereum/PostgreSQL）整合成统一的 API 暴露给前端\n1. 系统架构概览由于涉及 140+ 容器和多种数据源，系统的核心挑战在于数据聚合和性能优化。建议采用分层架构，包括前端/可视化大屏与 FastAPI 网关的交互，以及 FastAPI 后端应用内的 Redis 缓存层、业务逻辑层 TopologyService，和各种适配器（Docker Adapter、Neo4j Adapter、Ethereum Adapter Web3.py、DB Adapter SQLAlchemy）的协作，最终与基础设施 Docker Compose 中的 Docker Socket、Neo4j 图数据库、JSON-RPC AS101 Host0 和 PostgreSQL ethereum_monitor 进行交互。\n2. 核心模块设计我们需要将代码组织为清晰的模块，以应对你列出的 9 大类接口。\n2.1 数据模型层 (Models/Schemas)使用 Pydantic 定义统一的拓扑数据结构，这是所有接口返回的基础。网络拓扑系统采用了分层架构设计，主要包括以下几个层级：API 层 - topology_api.py 提供 RESTful 接口，服务层 - topology_service.py 协调各种拓扑功能，数据层 - real_topology_service.py 处理真实数据获取，专门处理器层 - 处理合约、交易等特定类型的拓扑，管理与渲染层 - 负责生命周期管理和数据渲染。\n用户通过 API 请求拓扑数据（如 /topology/ethereum），API 调用 TopologyService 的 get_ethereum_topology() 方法，TopologyService 委托给 _real_data_service（即 RealTopologyService），RealTopologyService 从 Neo4j 数据库获取真实的以太坊 P2P 网络拓扑数据，数据经过处理和格式化后返回给用户。\n对于以太坊拓扑，从 Neo4j 数据库查询执行层和共识层节点及其连接关系，查询验证者节点并与共识节点关联，将原始数据转换为前端友好的拓扑格式，通过 Docker 客户端获取容器信息，建立 IP 地址与容器名称的映射。对于物理拓扑，通过 Docker 客户端获取所有容器的详细信息，根据容器名称识别设备类型（路由器、主机等），根据容器连接的网络建立设备间连接关系，使用共享网络原则确定设备连接。\n在 topology_interfaces.py 中定义了核心抽象类：TopologyNode 作为拓扑节点基类，包含 id（节点唯一标识）、name（节点名称）、node_type（节点类型，执行层、共识层、验证者等）、ip_address（IP 地址）、layer（所属层级）、status（状态）、metadata（元数据）等属性；TopologyLink 作为拓扑连接基类，包含 source（源节点 ID）、target（目标节点 ID）、link_type（连接类型）、layer（所属层级）、direction（连接方向）、metadata（元数据）等属性。\n不同类型的拓扑节点包括以太坊节点（执行层节点、共识层节点、验证者节点）和物理节点（路由器、主机、交换机）。拓扑数据最终以 nodes（节点列表，每个节点包含 id、name、type、ip_address、status 等属性）、links（连接列表，每个连接包含 source、target、type 等属性）、元数据（时间戳、数据源、统计信息等）的格式组织。\n这是与底层交互的关键。InfrastructureAdapter (Docker &amp; SeedEmu) 作用是获取物理拓扑，实现方式是使用 docker Python 库读取容器列表，解析 com.docker.compose.service 和 org.seedsecuritylabs.seedemu.meta. 标签来识别节点角色（AS、路由器、主机）；对应接口是 /physical/。\nGraphDBAdapter (Neo4j) 作用是获取网络静态拓扑和关联关系，实现方式是使用 neo4j Python 驱动，SeedEmu 通常会将生成的拓扑导入 Neo4j，查询 Cypher 语句来获取节点间的连接；对应接口是 /overview, /analysis/{layer}。\nBlockchainAdapter (Web3.py &amp; Postgres) 作用是获取链上实时状态，实现方式是使用 web3.py (AsyncHTTPProvider) 连接开放 RPC 端口的节点（如 AS101 的 8545）获取 Block Height, Peer Count，以及连接 PostgreSQL (ethereummonitor) 查询交易历史、合约调用统计；对应接口是 /ethereum/, /contract/_, /transaction/*。\n2.3 业务服务层 (Services)这是实现 RealTopologyService 的地方，负责组装数据。TopologyService 能够根据请求的 layer (physical, ethereum) 调用不同的 Adapter，实现 /combined 接口，将 Docker 的运行状态（Up/Down）注入到 Neo4j 查出的静态拓扑中，并将 Ethereum 节点的逻辑 ID（Validator ID）映射到物理容器 IP。非常重要的是使用 Redis 缓存完整的拓扑 JSON，并设置后台定时任务（FastAPI lifespan 或 APScheduler）每 5-10 秒刷新一次缓存。\nAnalysisService 将拓扑数据加载到 Python 的 networkx 库中，计算中心性（Centrality）、最短路径（用于分析攻击传播）、社区发现等算法；对应接口是 /analysis/*。\n3. 具体接口实现策略针对你提供的文档，以下是具体实现建议：\n物理层 (Physical Layer) 的挑战是如何知道哪个容器连接哪个。方案是 SeedEmu 通常会在生成容器时将连接信息写入 Neo4j 或生成的 metadata 文件。优先从 Neo4j 读取链路关系，从 Docker API 读取节点存活状态（Status: Running/Exited）。\n以太坊层 (Ethereum Layer) 的挑战是 108 个节点，如何获取所有节点状态。方案是使用信标链数据 (Consensus)，连接 Beacon Node API (如果环境中有) 获取验证者状态 (Active/Slashed)；使用 P2P 拓扑，使用 admin_peers RPC 方法（需要节点开启该 API）查询节点的连接对象。由于无法轮询所有 108 个节点，可以只轮询几个关键 Bootnode 和 AS 网关节点，构建局部图；使用 Postgres 补充，从数据库中读取已知的节点列表和 Validator ID 映射。\n交易与合约 (Transaction &amp; Contract) 的挑战是实时分析交易流向。方案是不要直接扫描链，而是利用环境中的 postgresql (ethereum_monitor)。SeedEmu 的监控器应该已经将区块和交易写入库中。接口 /transaction/address/{address}/analysis 直接执行 SQL 聚合查询（Group by to/from），返回资金流向图。\n可视化渲染 (Rendering) 的接口是 POST /render，逻辑是前端可能只需传递原始数据，后端使用 networkx 计算布局（如 ForceAtlas2 或层级布局），计算出每个节点的 (x, y) 坐标，返回给前端直接绘制。这能减轻前端浏览器处理 140+ 节点布局的压力。\n4. 代码结构示例# app/routers/topology.pyfrom fastapi import APIRouter, Depends, HTTPExceptionfrom app.services.topology_service import TopologyServicefrom app.schemas.topology import TopologyGraphrouter = APIRouter(prefix=\"/topology\", tags=[\"Topology\"])@router.get(\"/overview\")async def get_overview(service: TopologyService = Depends(get_topology_service)):    # 从缓存获取，如果无则计算    return await service.get_system_overview()@router.get(\"/ethereum/nodes/{node_id}\")async def get_eth_node_detail(node_id: str, service: TopologyService = Depends()):    # 1. 查 Neo4j 获取节点基础信息    # 2. 查 Docker 确认容器是否在线    # 3. 查 Web3/DB 获取链上余额和状态    data = await service.get_node_composite_info(node_id, layer=\"ethereum\")    if not data:        raise HTTPException(status_code=404, detail=\"Node not found\")    return data@router.post(\"/combined\")async def get_combined_view(layers: list[str], service: TopologyService = Depends()):    # 融合物理层和区块链层    # 例如：展示 区块链P2P连线 覆盖在 物理AS拓扑 上    return await service.generate_combined_topology(layers)\n5. 关键技术难点与解决方案Docker 网络访问方面，FastAPI 容器需要挂载 /var/run/docker.sock 才能查询兄弟容器的状态。docker-compose.yml 配置中需要添加 volumes: - /var/run/docker.sock:/var/run/docker.sock。\n跨容器数据库连接方面，连接 Neo4j 和 Postgres 时，Host 应使用 Docker Compose 服务名（如 neo4j, postgresql），而不是 localhost。\n性能瓶颈方面，问题在于/ethereum 接口如果实时调用 100+ 次 RPC 会超时。解决方法是使用”后台采集 + 前端读取”模式，编写一个后台 Task (使用 asyncio 或 Celery) 每 10 秒扫描一次网络状态存入 Redis。API 接口只读 Redis。\nIP 地址管理方面，SeedEmu 的自定义网络（inet0, net_2_net_51_52）非常复杂。在返回 /physical 拓扑时，务必解析 Docker inspect 结果中的 NetworkSettings，将特定网段 IP 映射给前端，否则前端无法理解路由关系。\n6. 总结建议设计这个系统时，请遵循以下步骤：首先打通 Neo4j，它是拓扑的真理来源（Source of Truth），确保能查询出 AS、Router 和 Host 的关系；其次实现缓存机制，复杂的 Docker 集群状态获取很慢，不要让 API 直接穿透到 Docker Daemon；定义清晰的 ID 映射，最大的坑在于关联 “Docker Container Name” (e.g., as101_host0) 和 “Ethereum Node ID” (e.g., Validator-3)，需要在服务启动时建立这个映射表；按层开发，先做 Physical（最简单，只读 Docker），再做 Ethereum（读 DB），最后做高级的 Contract/Transaction 分析。\n实现”实时更新”并”高亮变化”的核心在于结合 FastAPI 的 WebSocket 推送机制与 D3.js 的 General Update Pattern（通用更新模式）。这里有三个关键点：后端推送，只推送最新的全量/增量状态；前端数据绑定，D3 必须通过 Key Function 识别哪些是新节点、哪些是旧节点，而不是每次清空画布重绘；视觉反馈，利用 CSS 动画或 D3 Transition 让变化的节点产生”闪烁”或”颜色渐变”。\n1. 整体架构设计后端 (FastAPI) 运行一个后台任务（Background Task），每隔几秒扫描一次 Docker/Ethereum 状态，通过 WebSocket 广播给前端；前端 (D3.js) 维护一个长连接，收到数据后，执行 updateGraph(newData)。\n2. 后端：FastAPI WebSocket 实现我们需要一个 ConnectionManager 来管理前端连接，并推送拓扑数据。\n# app/routers/ws_topology.pyfrom fastapi import APIRouter, WebSocket, WebSocketDisconnectfrom app.services.topology_service import TopologyServiceimport asyncioimport jsonrouter = APIRouter()class ConnectionManager:    def __init__(self):        self.active_connections: list[WebSocket] = []    async def connect(self, websocket: WebSocket):        await websocket.accept()        self.active_connections.append(websocket)    def disconnect(self, websocket: WebSocket):        self.active_connections.remove(websocket)    async def broadcast(self, message: dict):        for connection in self.active_connections:            await connection.send_json(message)manager = ConnectionManager()# 模拟后台数据推送任务async def topology_broadcaster(service: TopologyService):    \"\"\"    这个函数需要在 main.py 的 @app.on_event(\"startup\") 中启动    \"\"\"    while True:        # 获取最新拓扑（包含 Docker 状态 + Geth 连接）        topology_data = await service.get_full_topology_snapshot()        # 广播数据        if manager.active_connections:            await manager.broadcast(topology_data)        # 每 5 秒推送一次，避免前端渲染压力过大        await asyncio.sleep(5)@router.websocket(\"/ws/topology\")async def websocket_endpoint(websocket: WebSocket):    await manager.connect(websocket)    try:        while True:            # 保持连接活跃，也可以接收前端的控制指令（比如点击了某个节点）            data = await websocket.receive_text()    except WebSocketDisconnect:        manager.disconnect(websocket)\n3. 前端：D3.js 实时更新与高亮逻辑这是最关键的部分。不要清空 SVG！使用 D3 的 Enter (新增), Update (更新), Exit (删除) 模式。\n核心策略包括 ID 绑定，告诉 D3 如何通过 ID（如 enode_id 或 container_name）区分节点，而不是数组索引；平滑模拟，数据更新时，不要将 alpha 重置为 1（会导致整个图剧烈爆炸），而是重置为 0.3 左右（轻微调整）；样式 Diff，比对新旧数据，如果状态变化（如 IP 变了，Peer 数变了），添加 CSS 类名触发动画。\n","categories":["归档"]},{"title":"2025-12-25-力扣百题速练（Javascript/TypeScript）Vol.1","url":"/Arknight-notes/posts/39687.html","content":"简单刷个力扣百题，完球了这玩意从大二下开坑以来就没刷完，现在后端转前端也要那前端那一套来过一趟，还有几天字节面试了都\n\n1.两数之和给定一个整数数组 nums 和一个整数目标值 target在该数组中找出 和为目标值 target 的那 两个 整数，并返回它们的数组下标你可以假设每种输入只会对应一个答案，并且同一个元素不能重复使用\n示例：输入：nums = [2,7,11,15], target = 9输出：[0,1] 解释：因为 nums[0] + nums[1] = 2 + 7 = 9。\n直接用双重循环解，优化的话其实可以上哈希表\nfunction twoSum(nums: number[], target: number): number[] {    for (let i = 0; i &lt; nums.length; i++) {        for (let j = i + 1; j &lt; nums.length; j++) {            if (nums[i] + nums[j] === target) {                return [i, j];            }        }    }    return [];}\n\n2.两数相加给定两个非空单向链表，表示两个非负整数每个节点存储一位数字，数字以逆序存储（个位在头部），要求返回一个新链表表示它们的和（同样逆序存储）不允许修改原链表\n示例：输入：l1 = 2 → 4 → 3（表示 342），l2 = 5 → 6 → 4（表示 465）输出：7 → 0 → 8（表示 807）\n本质上是模拟竖式加法，从低位到高位逐位相加。由于链表逆序存储，正好从个位开始遍历\n\n逐位相加并处理进位：\n同时遍历两个链表的节点，取当前节点值相加，加上上一位的进位（初始进位为 0）。\n当前位结果 = (val1 + val2 + carry) % 10\n新进位 carry = Math.floor((val1 + val2 + carry) / 10)\n\n\n使用哑节点（dummy head）简化代码：\n创建一个哑节点，尾指针指向它，便于统一处理头部节点，避免单独处理第一个节点。\n\n\n处理链表长度不等和最终进位：\n当一个链表遍历完时，将另一个链表的剩余节点视为 val = 0 继续相加。\n遍历结束后，若仍有进位（carry = 1），需添加一个新节点值为 1。\n\n\n\n提供以下 ListNode 类型定义：\nclass ListNode {  val: number;  next: ListNode | null;  constructor(val?: number, next?: ListNode | null) {    this.val = val === undefined ? 0 : val;    this.next = next === undefined ? null : next;  }}\n题解\nfunction addTwoNumbers(l1: ListNode | null, l2: ListNode | null): ListNode | null {  const dummy: ListNode = new ListNode(0);  // 哑节点，没有 dummy，直接从第一个节点开始构建，结果链表的头节点会在循环中不断变化  //需要额外判断是否是第一个节点  let tail: ListNode = dummy;  //始终指向结果链表的“当前最后一个节点”。  //每次计算出一位新数字后，直接在 tail 后面添加新节点  let carry: number = 0;  // 进位，当前这一位加完后，是否需要给下一位（更高位）额外加 1  while (l1 !== null || l2 !== null || carry !== 0) {    const val1: number = l1 ? l1.val : 0;    const val2: number = l2 ? l2.val : 0;    const sum: number = val1 + val2 + carry;    const digit: number = sum % 10;    carry = Math.floor(sum / 10);    tail.next = new ListNode(digit);    tail = tail.next;    if (l1) l1 = l1.next;    if (l2) l2 = l2.next;  }  return dummy.next;}\n3.无重复字符的最长子串要求给定一个字符串 s，找出其中不含有重复字符的最长子串的长度（而非子序列）\n示例：\n\n输入：”abcabcbb” → 输出：3（子串 “abc”）\n输入：”bbbbb” → 输出：1\n输入：”pwwkew” → 输出：3（子串 “wke”）\n\n\n直接上滑动窗口，结合哈希集合（Set）或映射\n\n使用左指针 left 和右指针 right 维护一个窗口 (left, right)\n扩展右指针，若遇到重复字符，则收缩左指针直到无重复\n每次更新最大长度 maxLength = Math.max(maxLength, right - left)\n\n\nfunction lengthOfLongestSubstring(s: string): number {    const charSet = new Set&lt;string&gt;();  // 记录窗口内字符    let left = 0;                       // 左指针    let maxLength = 0;                  // 最大长度    for (let right = 0; right &lt; s.length; right++) {        // 若当前字符已存在，收缩左指针        while (charSet.has(s[right])) {            charSet.delete(s[left]);            left++;        }        charSet.add(s[right]);        maxLength = Math.max(maxLength, right - left + 1);    }    return maxLength;}\n\n4.寻找两个正序数组的中位数要求在两个已排序数组 nums1 和 nums2 中找到合并后的中位数，且时间复杂度必须为 O(log(m + n))，其中 m 和 n 分别为数组长度\n示例：\n输入：nums1 = [1,3], nums2 = [2]输出：2.00000解释：合并数组 = [1,2,3] ，中位数 2\n输入：nums1 = [1,2], nums2 = [3,4]输出：2.50000解释：合并数组 = [1,2,3,4] ，中位数 (2 + 3) / 2 = 2.5\n最初思路最开始打算做双指针合并，使用两个指针 i 和 j 分别指向 nums1 和 nums2 的当前待比较位置（初始为 0），每次比较 nums1[i] 和 nums2[j]，将较小的元素放入结果数组 merged，并将对应指针后移，当某个数组遍历完后，将另一个数组剩余元素全部追加到 merged，合并完成后，merged 就是一个完整有序数组\n然后就可以根据总长度奇偶性计算中位数：奇数直接取第 (total+1)/2 个元素（索引 mid）偶数取第 total/2 和第 total/2 + 1 个元素的平均（索引 mid-1 和 mid）\n想了 40 分钟，但是复杂度 m * n，直接寄了\nfunction findMedianSortedArrays(nums1: number[], nums2: number[]): number {    const merged: number[] = [];    for (let i = 0; i &lt; nums1.length; i++) {        for (let j = 0; j &lt; nums2.length; j++) {        while(nums2[j] &lt;= nums1[i]);            merged.push(nums2[j]);        }        merged.push(nums1[i]);    }    for (let k = 0; k &lt; nums2.length; k++) {        merged.push(nums2[k]);    }    const total = merged.length;    const mid = Math.floor(total / 2);    return total % 2 === 1 ? merged[mid] : (merged[mid - 1] + merged[mid]) / 2;}\n改进\n外层 for：遍历 nums1 的每一个元素 nums1[i]。\n内层 while（代替 for，避免重复遍历）：在放入 nums1[i] 之前，先检查 nums2 的头部元素（nums2[0]）。\n只要 nums2[0] &lt;= nums1[i]，就说明这个元素应该排在 nums1[i] 前面，先放入 merged，并从 nums2 中移除（使用 shift()）。\n这样保证了顺序正确。\n\n\n放入当前 nums1[i]。\n外层循环结束后，如果 nums2 还有剩余元素（说明它们都大于 nums1 所有元素），直接全部追加。\n\nfunction findMedianSortedArrays(nums1: number[], nums2: number[]): number {  const merged: number[] = [];  // 外层循环遍历 nums1 的每个元素  for (let i = 0; i &lt; nums1.length; i++) {    // 在放入 nums1[i] 之前，先把 nums2 中所有小于等于 nums1[i] 的元素放入    while (nums2.length &gt; 0 &amp;&amp; nums2[0] &lt;= nums1[i]) {      merged.push(nums2.shift()!); // 取出 nums2 头部元素    }    // 放入当前 nums1[i]    merged.push(nums1[i]);  }  // 处理 nums2 中剩余的所有元素（如果 nums2 还有）  while (nums2.length &gt; 0) {    merged.push(nums2.shift()!);  }  const total = merged.length;  const mid = Math.floor(total / 2);  if (total % 2 === 1) {    return merged[mid];  } else {    return (merged[mid - 1] + merged[mid]) / 2;  }}\n二分法暴力合并为 O(m + n)，但题目要求对数复杂度，因此需避免完整合并。核心思路是将问题转化为在较短数组上二分查找一个分区点，使左右部分满足中位数条件：\n\n总元素数 total = m + n。\n中位数位置：若 total 奇数，为第 (total + 1)/2 个元素；若偶数，为第 total/2 和第 total/2 + 1 个元素的平均。\n我们需要在合并数组的“左侧”选取 total/2 个元素（使用 (total + 1)/2 以统一奇偶处理）。\n在较短数组 A 上二分查找左侧元素个数 i（0 ≤ i ≤ m），则较长数组 B 左侧元素个数 j = (total + 1)/2 - i。\n分区条件：\n左侧最大值 ≤ 右侧最小值：max(A[i-1], B[j-1]) ≤ min(A[i], B[j])。\n\n\n处理边界：使用 -∞ 和 +∞ 填充空侧。\n\n算法步骤\n确保 nums1 为较短数组（若不是，交换）。\n二分范围：low = 0, high = nums1.length。\n计算分区：i = (low + high) / 2, j = (m + n + 1) / 2 - i。\n检查分区：\n若 A[i-1] &gt; B[j]，则 i 太大，high = i - 1。\n若 B[j-1] &gt; A[i]，则 i 太小，low = i + 1。\n否则，分区正确。\n\n\n计算中位数：\n左侧最大：max(A[i-1], B[j-1])。\n右侧最小：min(A[i], B[j])。\n若 total 奇数，返回左侧最大；偶数，返回平均。\n\n\n\nfunction findMedianSortedArrays(nums1: number[], nums2: number[]): number {    const merged: number[] = [];    // 外层循环遍历 nums1 的每个元素    for (let i = 0; i &lt; nums1.length; i++) {        // 在放入 nums1[i] 之前，先把 nums2 中所有小于等于 nums1[i] 的元素放入 merged        while (nums2.length &gt; 0 &amp;&amp; nums2[0] &lt;= nums1[i]) {            merged.push(nums2.shift()!);  // 取出 nums2 头部元素        }        // 放入当前 nums1[i]        merged.push(nums1[i]);    }    // 处理 nums2 中剩余的所有元素（如果 nums2 还有）    while (nums2.length &gt; 0) {        merged.push(nums2.shift()!);    }    const total = merged.length;    const mid = Math.floor(total / 2);    if (total % 2 === 1) {        return merged[mid];    } else {        return (merged[mid - 1] + merged[mid]) / 2;    }}\n\n5.最长的回文子串要求给定一个字符串 s，返回其中最长的回文子串（回文指正读反读相同的连续子串）示例：\n\n输入：”babad” → 输出：”bab” 或 “aba”（长度 3）\n输入：”cbbd” → 输出：”bb”（长度 2）\n\n\n中心扩展法（Expand Around Center）时间复杂度 O(n²)，空间复杂度 O(1)\n思路回文串以中心对称。中心可能为单个字符（奇数长度回文）或两个相同字符间（偶数长度回文）。 对于字符串每个可能中心（共 2n-1 个），向两侧扩展比较字符，直至不对称。记录扩展中最长回文。\n步骤：\n\n遍历字符串索引 i 从 0 到 n-1。\n以 i 为中心扩展奇数长度回文。\n以 i 和 i+1 为中心扩展偶数长度回文。\n每次扩展更新最长回文起点和长度。\n返回对应子串。\n\n\nTypeScript 实现function longestPalindrome(s: string): string {    if (s.length &lt; 2) return s;    let start = 0;      // 最长回文起点    let maxLength = 1;  // 最长回文长度（初始至少 1）    function expandAroundCenter(left: number, right: number) {        while (left &gt;= 0 &amp;&amp; right &lt; s.length &amp;&amp; s[left] === s[right]) {            const currentLength = right - left + 1;            if (currentLength &gt; maxLength) {                start = left;                maxLength = currentLength;            }            left--;            right++;        }    }    for (let i = 0; i &lt; s.length; i++) {        // 奇数长度回文（中心为 i）        expandAroundCenter(i, i);        // 偶数长度回文（中心为 i 和 i+1）        expandAroundCenter(i, i + 1);    }    return s.substring(start, start + maxLength);}\n\n6. Z 字变换将一个给定字符串  s  根据给定的行数  numRows ，以从上往下、从左到右进行 Z 字形排列比如输入字符串为  \"PAYPALISHIRING\"  行数为  3  时，排列如下：\nP A H NA P L S I I GY I R\n之后输出需要从左往右逐行读取，产生出一个新的字符串，比如：\"PAHNAPLSIIGYIR\"\n实现这个将字符串进行指定行数变换的函数：\nstring convert(string s, int numRows);\n示例 1：\n输入：s = “PAYPALISHIRING”, numRows = 3输出：”PAHNAPLSIIGYIR”\n示例 2：\n输入：s = “PAYPALISHIRING”, numRows = 4输出：”PINALSIGYAHRPI”解释：P I NA L S I GY A H RP I\nTypeScript 实现直接计算位置\nfunction convert(s: string, numRows: number): string {  if (numRows === 1) return s;  let result = \"\";  const cycle = 2 * numRows - 2;  for (let row = 0; row &lt; numRows; row++) {    for (let i = 0; i + row &lt; s.length; i += cycle) {      result += s[i + row];      if (row !== 0 &amp;&amp; row !== numRows - 1 &amp;&amp; i + cycle - row &lt; s.length) {        result += s[i + cycle - row];      }    }  }  return result;}\n\n7. 整数反转给你一个 32 位的有符号整数  x ，返回将  x  中的数字部分反转后的结果如果反转后整数超过 32 位的有符号整数的范围  [−231, 231 − 1] ，就返回 0假设环境不允许存储 64 位整数（有符号或无符号\n示例 1：输入：x = 123输出：321\n示例 2：输入：x = -123输出：-321\n没啥好讲的，转字符串反转再转回去，处理一下负号和边界情况就成\n反转字符串\nconst reverseString = (str: string): string =&gt; str.split(\"\").reverse().join(\"\");\nfunction reverse(x: number): number {  if (x === 0) {    return x;  }  const MAX = 2 ** 31 - 1;  const MIN = -(2 ** 31);  let mid = x.toString();  let LI: boolean = true;  if (mid[0] === \"-\") {    LI = false;  }  const reverseString = mid.split(\"\").reverse().join(\"\");  if (LI === true) {    if (parseInt(reverseString) &lt; MIN || parseInt(reverseString) &gt; MAX) {      return 0;    }    return parseInt(reverseString);  }  if (LI === false) {    let fin = reverseString.slice(0, reverseString.length - 1);    let fin2 = -parseInt(fin);    if (fin2 &lt; MIN || fin2 &gt; MAX) {      return 0;    }    return fin2;  }}\n\n8.字符串转换整数实现一个  myAtoi(string s)  函数，使其能将字符串转换成一个 32 位有符号整数。\n函数  myAtoi(string s)  的算法如下：\n\n空格：读入字符串并丢弃无用的前导空格（\" \"）\n符号：检查下一个字符（假设还未到字符末尾）为  '-'  还是  '+'如果两者都不存在，则假定结果为正\n转换：通过跳过前置零来读取该整数，直到遇到非数字字符或到达字符串的结尾，如果没有读取数字，则结果为 0\n舍入：如果整数数超过 32 位有符号整数范围  [−231, 231 − 1] ，需要截断这个整数，使其保持在这个范围内。具体来说，小于  −231  的整数应该被舍入为  −231 ，大于  231 − 1  的整数应该被舍入为  231 − 1\n\nfunction myAtoi(s: string): number {  let max = 2 ** 31 - 1;  let min = -(2 ** 31);  let i: number = 0;  let sign: number = 1;  let fin = \"\";  let clac = 0;  if (i &lt;= s.length) {    while (s[i] === \" \") {      i++;    }    while (s[i] === \"-\" || s[i] === \"+\") {      if (s[i] === \"-\") {        sign = -1;      }      if (s[i] === \"+\") {        sign = 1;      }      if (clac === 1) {        return 0;      }      clac = 1;      i++;    }    while (s[i] &lt;= \"9\" &amp;&amp; s[i] &gt;= \"0\") {      fin = fin + s[i];      i++;    }    if (fin === \"\") return 0;    if (sign === 1) {      if (parseInt(fin) &gt;= max) {        return max;      }      if (parseInt(fin) &lt;= min) {        return min;      }      return parseInt(fin);    }    if (sign === -1) {      if (-parseInt(fin) &gt;= max) {        return max;      }      if (-parseInt(fin) &lt;= min) {        return min;      }      return -fin;    }  }}\n没啥好说的，处理一下转换和条件判断的事情\n\n9.回文数给一个整数  x ，如果  x  是一个回文整数，返回  true ；否则，返回  false回文数是指正序（从左向右）和倒序（从右向左）读都是一样的整数例如，121  是回文，而  123  不是\n智斗程度堪比两数之和，转字符串逆序比较秒了\nfunction isPalindrome(x: number): boolean {  let arr = x.toString();  let brr = arr.split(\"\").reverse().join(\"\");  if (arr === brr) {    return true;  }  if (arr !== brr) {    return false;  }}\n\n10.正则表达式匹配给你一个字符串  s  和一个字符规律  p，请你来实现一个支持  '.'  和  '*'  的正则表达式匹配。\n\n'.'  匹配任意单个字符\n'*'  匹配零个或多个前面的那一个元素\n\n匹配是要涵盖  整个  字符串  s  的，而不是部分字符串。\n示例 1：\n输入：s = “aa”, p = “a”输出：false解释：”a” 无法匹配 “aa” 整个字符串。\n示例 2:\n输入：s = “aa”, p = “a“输出：true解释：因为 ‘‘ 代表可以匹配零个或多个前面的那一个元素, 在这里前面的元素就是 ‘a’。因此，字符串 “aa” 可被视为 ‘a’ 重复了一次。\n示例 3：\n输入：s = “ab”, p = “.“输出：true解释：”.“ 表示可匹配零个或多个（’*‘）任意字符（’.’）\n这道题最开始是想要用纯同步双指针来解，没解出来\nfunction isMatch(s: string, p: string): boolean {  if (s == p) {    return true;  }  let sindex = 0;  let pindex = 0;  while (sindex &lt; s.length &amp;&amp; pindex &lt; p.length) {    if (s[sindex] === p[pindex] || p[pindex] === \".\") {      sindex++;      pindex++;    }    if (p[pindex] === \"*\") {      while (s[sindex] === s[sindex + 1]) {        sindex++;      }      pindex++;    }    if (s[sindex] !== p[pindex]) {      if (p[pindex] !== \"*\" &amp;&amp; p[pindex] !== \".\") {        return false;      }    }    return true;  }}\n↑ 错误答案\n主要是该问题具有非确定性：同一个 “x*“ 可以有多种匹配方式（0 次、1 次、多次），需要尝试不同分支。纯同步双指针（单路径贪婪）无法处理回溯需求，会在某些案例中错误消耗字符，导致后续失败。\n比如说在 s = “aaa”, p = “aba” 里贪婪匹配可能错误使用 “b“，而实际应跳过 “b*“（匹配 0 次）\n因此不能用简单 while 循环同步双指针线性解决，必须引入分支或状态记录\n然后题解就是使用 dp 解决：\n定义二维布尔数组 dp[i][j] 表示：s 的前 i 个字符（s[0..i-1]）是否能被 p 的前 j 个字符（p[0..j-1]）匹配，最终答案为 dp[m][n]，其中 m = s.length，n = p.length\nfunction isMatch(s: string, p: string): boolean {  const m = s.length,    n = p.length;  const dp = Array(m + 1)    .fill(null)    .map(() =&gt; Array(n + 1).fill(false));  dp[0][0] = true;  for (let j = 2; j &lt;= n; j++) {    if (p[j - 1] === \"*\") {      dp[0][j] = dp[0][j - 2];    }  }  for (let i = 1; i &lt;= m; i++) {    for (let j = 1; j &lt;= n; j++) {      if (p[j - 1] === \"*\") {        dp[i][j] =          dp[i][j - 2] ||          ((s[i - 1] === p[j - 2] || p[j - 2] === \".\") &amp;&amp; dp[i - 1][j]);      } else {        dp[i][j] =          (s[i - 1] === p[j - 1] || p[j - 1] === \".\") &amp;&amp; dp[i - 1][j - 1];      }    }  }  return dp[m][n];}\n初始化:空串与空模式dp[0][0] = true：空字符串可以被空模式匹配。空字符串与非空模式 只有当模式中某些 “x*” 可以匹配 0 次字符时，才可能匹配空字符串。 因此从左向右扫描模式：\nfor (let j = 2; j &lt;= n; j++) {    if (p[j-1] === '*') {        dp[0][j] = dp[0][j-2];  // 直接继承“跳过当前 x*”的状态    }}\n示例：p = “abc*“ 可以匹配空字符串，故 dp[0][2]、dp[0][4]、dp[0][6] 均为 true。\n状态转移方程遍历 i = 1..m 和 j = 1..n，根据 p[j-1] 的类型分为两种情况：\n\n当前模式字符不是 ‘*‘（普通字符或 ‘.’） 只能进行单字符匹配：\ndp[i][j] = (s[i-1] === p[j-1] || p[j-1] === '.') &amp;&amp; dp[i-1][j-1];\n含义：当前字符匹配且前一个子问题也匹配，则当前子问题成立。\n\n当前模式字符是 ‘*‘（与前一个字符组成 “x”） ‘‘ 提供了两种选择：\n\n匹配 0 次：直接跳过整个 “x*”，状态等同于 dp[i][j-2]。\n匹配 1 次或多次：前提是当前 s[i-1] 能与 “x” 匹配（s[i-1] === p[j-2] 或 p[j-2] === '.'），且在上一个字符已匹配的基础上继续使用 “x*” 匹配当前字符，即 dp[i-1][j]\n\n两者任一成立即可：\ndp[i][j] = dp[i][j-2] ||          ((s[i-1] === p[j-2] || p[j-2] === '.') &amp;&amp; dp[i-1][j]);\n\n\n时间与空间复杂度\n时间复杂度：O(mn)，每个状态只计算一次。\n空间复杂度：O(mn)，可进一步优化为 O(n)（仅使用两行或一行滚动数组）。\n\n","categories":["力扣"],"tags":["前端开发","JavaScript"]},{"title":"2025-11-27-前端学习-关于JavaScript 实现哈希表","url":"/Arknight-notes/posts/39960.html","content":"JavaScript 实现哈希表哈希表（Hash Table，散列表）是一种通过键（Key）直接访问值（Value）的数据结构，通过哈希函数将键映射到表中的位置\n哈希函数// 简单的哈希函数示例function hashString(key, tableSize) {  let hash = 17;  for (let i = 0; i &lt; key.length; i++) {    hash = (13 * hash * key.charCodeAt(i)) % tableSize;  }  return hash;}\n用 JavaScript 实现哈希表class HashTable {  constructor(size = 53) {    this.keyMap = new Array(size);  }  // 哈希函数  _hash(key) {    let total = 0;    const PRIME = 31;    const MAX_LENGTH = 100;        for (let i = 0; i &lt; Math.min(key.length, MAX_LENGTH); i++) {      const char = key[i];      const value = char.charCodeAt(0) - 96; // a=1, b=2...      total = (total * PRIME + value) % this.keyMap.length;    }    return total;  }  // 插入键值对  set(key, value) {    const index = this._hash(key);        if (!this.keyMap[index]) {      this.keyMap[index] = [];    }        // 检查键是否已存在，存在则更新    for (let i = 0; i &lt; this.keyMap[index].length; i++) {      if (this.keyMap[index][i][0] === key) {        this.keyMap[index][i][1] = value;        return;      }    }        this.keyMap[index].push([key, value]);  }  // 获取值  get(key) {    const index = this._hash(key);        if (this.keyMap[index]) {      for (let i = 0; i &lt; this.keyMap[index].length; i++) {        if (this.keyMap[index][i][0] === key) {          return this.keyMap[index][i][1];        }      }    }    return undefined;  }  // 删除键值对  delete(key) {    const index = this._hash(key);        if (!this.keyMap[index]) return false;        for (let i = 0; i &lt; this.keyMap[index].length; i++) {      if (this.keyMap[index][i][0] === key) {        this.keyMap[index].splice(i, 1);        if (this.keyMap[index].length === 0) {          delete this.keyMap[index];        }        return true;      }    }    return false;  }  // 获取所有键  keys() {    const keysArr = [];    for (let i = 0; i &lt; this.keyMap.length; i++) {      if (this.keyMap[i]) {        for (let j = 0; j &lt; this.keyMap[i].length; j++) {          if (!keysArr.includes(this.keyMap[i][j][0])) {            keysArr.push(this.keyMap[i][j][0]);          }        }      }    }    return keysArr;  }  // 获取所有值  values() {    const valuesArr = [];    for (let i = 0; i &lt; this.keyMap.length; i++) {      if (this.keyMap[i]) {        for (let j = 0; j &lt; this.keyMap[i].length; j++) {          if (!valuesArr.includes(this.keyMap[i][j][1])) {            valuesArr.push(this.keyMap[i][j][1]);          }        }      }    }    return valuesArr;  }}\n自动扩容class EnhancedHashTable {  constructor(initialCapacity = 8, loadFactor = 0.75) {    this.capacity = initialCapacity;    this.loadFactor = loadFactor;    this.size = 0;    this.buckets = new Array(this.capacity);  }  _hash(key) {    let hashCode = 0;    const PRIME = 31;        // 处理不同类型的键    const keyStr = typeof key === 'string' ? key : JSON.stringify(key);        for (let i = 0; i &lt; keyStr.length; i++) {      hashCode = (PRIME * hashCode + keyStr.charCodeAt(i)) % this.capacity;    }    return hashCode;  }  _resize() {    const oldBuckets = this.buckets;    this.capacity *= 2;    this.buckets = new Array(this.capacity);    this.size = 0;    for (const bucket of oldBuckets) {      if (bucket) {        for (const [key, value] of bucket) {          this.set(key, value);        }      }    }  }  set(key, value) {    // 检查是否需要扩容    if (this.size / this.capacity &gt;= this.loadFactor) {      this._resize();    }    const index = this._hash(key);        if (!this.buckets[index]) {      this.buckets[index] = [];    }    // 更新或添加    for (let i = 0; i &lt; this.buckets[index].length; i++) {      if (this.buckets[index][i][0] === key) {        this.buckets[index][i][1] = value;        return;      }    }    this.buckets[index].push([key, value]);    this.size++;  }  get(key) {    const index = this._hash(key);    const bucket = this.buckets[index];        if (bucket) {      for (const [k, v] of bucket) {        if (k === key) return v;      }    }    return undefined;  }  has(key) {    return this.get(key) !== undefined;  }  clear() {    this.buckets = new Array(this.capacity);    this.size = 0;  }  // 获取负载因子  getLoadFactor() {    return this.size / this.capacity;  }}\n支持任何类型键的通用哈希表class UniversalHashTable {  constructor(size = 53) {    this.table = new Array(size);  }  // 通用哈希函数，支持多种类型  _hash(key) {    if (typeof key === 'number') {      return key % this.table.length;    }        if (typeof key === 'string') {      let hash = 0;      for (let i = 0; i &lt; key.length; i++) {        hash = (hash &lt;&lt; 5) - hash + key.charCodeAt(i);        hash = hash &amp; hash; // 转为32位整数      }      return Math.abs(hash) % this.table.length;    }        if (typeof key === 'object' &amp;&amp; key !== null) {      // 对象使用JSON字符串化      return this._hash(JSON.stringify(key));    }        return 0;  }  // 双重哈希解决冲突  _hash2(key) {    return 7 - (this._hash(key) % 7);  }  // 使用线性探测开放寻址  _findSlot(key, forInsert = false) {    let index = this._hash(key);    let step = 1;        while (this.table[index] !== undefined) {      if (this.table[index] !== null &amp;&amp; this.table[index].key === key) {        return index; // 找到键      }            if (forInsert &amp;&amp; (this.table[index] === null || this.table[index] === undefined)) {        return index; // 找到可插入的空槽      }            // 线性探测      index = (index + 1) % this.table.length;      step++;            if (step &gt; this.table.length) {        throw new Error('Hash table is full');      }    }        return forInsert ? index : -1;  }  set(key, value) {    const index = this._findSlot(key, true);    this.table[index] = { key, value };  }  get(key) {    const index = this._findSlot(key, false);    return index !== -1 ? this.table[index].value : undefined;  }  delete(key) {    const index = this._findSlot(key, false);    if (index !== -1) {      this.table[index] = null; // 标记为删除      return true;    }    return false;  }}\n使用 JavaScript 内置结构使用 Object\n// 最简单的哈希表实现const hashTable = {};hashTable['key1'] = 'value1';hashTable['key2'] = 'value2';// 获取const value = hashTable['key1'];// 删除delete hashTable['key1'];\n使用 Map\n// ES6 Map 是更好的哈希表实现const map = new Map();// 设置键值对map.set('name', 'Alice');map.set(42, 'The Answer');map.set({ id: 1 }, 'Object Key');// 获取console.log(map.get('name')); // Alice// 检查是否存在console.log(map.has(42)); // true// 删除map.delete(42);// 大小console.log(map.size);// 遍历map.forEach((value, key) =&gt; {  console.log(key, value);});// 清空map.clear();\n使用 Set（类似哈希集合）\n// 用于存储唯一值const set = new Set();set.add(1);set.add(2);set.add(2); // 重复，不会被添加console.log(set.has(1)); // trueconsole.log(set.size);   // 2set.delete(1);\n性能优化选择合适的哈希函数\n// 更好的字符串哈希函数（djb2算法）function hashDJB2(str, tableSize) {  let hash = 5381;  for (let i = 0; i &lt; str.length; i++) {    hash = (hash * 33) ^ str.charCodeAt(i);  }  return Math.abs(hash) % tableSize;}\n优化冲突处理\nclass OptimizedHashTable {  constructor(size = 53) {    this.table = new Array(size);    this.deleted = Symbol('deleted'); // 特殊标记删除  }  // 二次探测  _probe(index, i, tableSize) {    return (index + i * i) % tableSize;  }  // 双重哈希  _doubleHash(index, i, tableSize, key) {    const hash2 = 1 + (this._hash2(key) % (tableSize - 1));    return (index + i * hash2) % tableSize;  }}\n实际应用频率计数器\nfunction frequencyCounter(arr) {  const frequency = new Map();    for (const item of arr) {    frequency.set(item, (frequency.get(item) || 0) + 1);  }    return frequency;}// 使用const arr = ['apple', 'banana', 'apple', 'orange', 'banana', 'banana'];const freq = frequencyCounter(arr);console.log(freq.get('banana')); // 3\n缓存实现（LRU Cache）\nclass LRUCache {  constructor(capacity) {    this.capacity = capacity;    this.cache = new Map(); // 哈希表 + 维护顺序  }  get(key) {    if (!this.cache.has(key)) return -1;        const value = this.cache.get(key);    this.cache.delete(key);    this.cache.set(key, value); // 更新为最近使用        return value;  }  put(key, value) {    if (this.cache.has(key)) {      this.cache.delete(key);    } else if (this.cache.size &gt;= this.capacity) {      // 删除最久未使用的      const oldestKey = this.cache.keys().next().value;      this.cache.delete(oldestKey);    }        this.cache.set(key, value);  }}\n分组算法\nfunction groupBy(array, keyFn) {  const groups = new Map();    for (const item of array) {    const key = typeof keyFn === 'function'       ? keyFn(item)       : item[keyFn];        if (!groups.has(key)) {      groups.set(key, []);    }        groups.get(key).push(item);  }    return groups;}// 使用const people = [  { name: 'Alice', age: 25 },  { name: 'Bob', age: 30 },  { name: 'Charlie', age: 25 }];const groupedByAge = groupBy(people, 'age');console.log(groupedByAge.get(25));// [{ name: 'Alice', age: 25 }, { name: 'Charlie', age: 25 }]\n复杂度\n\n\n\n操作\nObject\nMap\n自定义哈希表\n\n\n\n\n插入\nO(1)\nO(1)\nO(1)-O(n)\n\n\n查找\nO(1)\nO(1)\nO(1)-O(n)\n\n\n删除\nO(1)\nO(1)\nO(1)-O(n)\n\n\n遍历键\nO(n)\nO(n)\nO(n)\n\n\n\n\n最坏情况（所有键冲突）会退化为 O(n)\n","categories":["数据结构"],"tags":["前端开发"]},{"title":"2025-12-25-面试算法ACM模式构建构建输入输出模板（Javascript）","url":"/Arknight-notes/posts/31996.html","content":"我觉得就应该像力扣那样搞关键函数模式，至少前端岗可以这么搞上 ACM 感觉除了 cpp 和 py 其他处理输入输出要麻烦死，遂在这里记录 js 的处理模板\n一、基础模板我们先来看一个基础模板\nconst rl = require(\"readline\").createInterface({ input: process.stdin });var iter = rl[Symbol.asyncIterator]();const readline = async () =&gt; (await iter.next()).value;void (async function () {  // 直接输出需要的字符串，不需要处理输入  console.log(\"Hello Nowcoder!\");})();\n我们接下来逐行解析下每行代码的作用\n1. 引入 readline 模块并创建接口const rl = require(\"readline\").createInterface({ input: process.stdin });\n\nrequire(\"readline\")：引入 Node.js 内置的readline模块，这个模块用于从命令行（标准输入）读取一行一行的输入。\ncreateInterface({ input: process.stdin })：创建一个输入接口，指定输入源为process.stdin（标准输入，也就是用户在控制台输入的内容）。\n变量rl就是这个输入接口的实例，后续通过它来控制输入的读取。\n\n2. 创建异步迭代器var iter = rl[Symbol.asyncIterator]();\n\nSymbol.asyncIterator是 Javascript 的一个内置符号，用于定义对象的异步迭代器\n这里通过rl[Symbol.asyncIterator]()获取 rl 接口的异步迭代器，赋值给iter。\n异步迭代器的作用是：可以通过next()方法异步地获取下一行输入（因为输入是用户手动输入的，属于异步操作）。\n\n3. 定义读取一行输入的函数const readline = async () =&gt; (await iter.next()).value;\n\n这是一个异步函数（async标记），作用是读取一行输入。\n调用iter.next()会返回一个 Promise，await会等待这个 Promise 完成，获取下一行输入的结果。\n结果的value属性就是读取到的一行字符串（如果没有更多输入，value会是undefined）。\n简单说：调用readline()就可以得到一行输入的内容（字符串类型）\n\n4. 立即执行的异步函数（核心逻辑区）void (async function () {  // Write your code here 👉 你的核心代码写在这里  // 直接输出需要的字符串，不需要处理输入 console.log(\"Hello Nowcoder!\");})();\n这是整个代码的执行入口，也就是你需要编写核心逻辑的地方，我们拆解一下：\n\nvoid async function (){...}():这是一个立即执行的异步函数表达式 (IIFE)。\nasync标记：允许函数内部使用 await 关键字（因为读取输入输出是异步操作）。\nvoid：避免函数执行后返回值可能导致的语法问题，单纯让函数执行。\n最后的()：表示定义后立即执行这个函数。\n\n\n\n核心代码写在哪里？答案是：写在void async function () { ... }这个函数内部（也就是注释// Write your code here的位置）。根据题目的输入格式不同，你需要修改这个区域的代码。具体常见的输入格式见我第二部分详细讲解。\n总结这个模板的作用是标准化输入读取流程：\n\n准备好读取输入的工具（rl接口，iter迭代器，readline函数）。\n在立即执行的异步函数中，通过await readline()获取输入。\n在函数内部编写你的核心逻辑（处理输入、计算、输出结果）。\n\n二、常见出题形式1.单组 A+B描述给定两个整数a和b，请你求出a + b的值。\n输入描述：第一行有两个整数a和b\n输出描述：输入一个整数，代表a + b的值。\n示例输入：1 2输出：3\nconst rl = require(\"readline\").createInterface({ input: process.stdin });var iter = rl[Symbol.asyncIterator]();const readline = async () =&gt; (await iter.next()).value;void (async function () {  // Write your code here  while ((line = await readline())) {    let tokens = line.split(\" \");    let a = parseInt(tokens[0]);    let b = parseInt(tokens[1]);    console.log(a + b);  }})();\n核心逻辑解析函数内部的while循环：\nwhile(line = await readline()) { ... }\n\n作用：持续读取每一行输入 ，直到没有更多输入(readline()返回undefined，循环终止)。\nline = await readline()：先调用readline()读取每一行输入，赋值给line。\n当没有输入时，readline()先返回undefined，循环条件为false，退出循环。\n\n循环内部的代码\nlet tokens = line.split(\" \"); // 将一行输入按空格分割成数组（比如输入\"1 2\"，得到[\"1\", \"2\"]）let a = parseInt(tokens[0]); // 将第一个元素转为整数let b = parseInt(tokens[1]); // 将第二个元素转为整数 console.log(a + b); // 输出结果\n2.多组_A+B_EOF 形式描述给定若干组测试数据，读取至文件末尾为止，每组数据有两个整数 a 和 b，请你求出 a + b 的值。\n输入描述每行有两个整数 a 和 b，读取至文件末尾为止\n输出描述输出若干行，每行一个整数，代表 a + b 的值。\n示例输入：1 2114 5142024 727输出：36282751\nconst rl = require(\"readline\").createInterface({ input: process.stdin });var iter = rl[Symbol.asyncIterator]();const readline = async () =&gt; (await iter.next()).value;void (async function () {  // 循环读取每一行输入，直到没有更多输入（EOF）  while ((line = await readline())) {    // 将一行输入按空格分割成数组（例如\"1 2\"分割为[\"1\", \"2\"]）    let tokens = line.split(\" \");    // 将分割后的字符串转为整数    let a = parseInt(tokens[0]);    let b = parseInt(tokens[1]);    // 输出两数之和    console.log(a + b);  }})();\n3.多组_A+B_T 组形式描述给定 t 组测试数据。每组数据有两个整数 a 和 b，请你求出 a + b 的值。\n输入描述第一行有一个整数 t，每行有两个整数 a 和 b\n输出描述输出 t 行，每行一个整数，代表 a + b 的值。\n示例输入：31 2114 5142024 727输出：36282751\nconst rl = require(\"readline\").createInterface({ input: process.stdin });var iter = rl[Symbol.asyncIterator]();const readline = async () =&gt; (await iter.next()).value;void (async function () {  // 第一步：读取第一行，获取测试用例数量T  let T = parseInt(await readline());  // 第二步：循环T次，处理每组数据  for (let i = 0; i &lt; T; i++) {    // 读取一行输入    let line = await readline();    // 分割成两个数字    let tokens = line.split(\" \");    let a = parseInt(tokens[0]);    let b = parseInt(tokens[1]);    // 输出结果    console.log(a + b);  }})();\n4.多组A+B零尾模式描述给定若干组测试数据，最后一组数据为 0 0，作为输入的结尾。每组数据有两个整数 a 和 b，请你求出 a + b 的值。\n输入描述每行有两个整数 a 和 b，最后一组数据为 0 0，作为输入的结尾。\n输出描述输出若干行，每行一个整数，代表 a + b 的值。\n示例输入：1 2114 5142024 7270 0输出：36282751\nconst rl = require(\"readline\").createInterface({ input: process.stdin });var iter = rl[Symbol.asyncIterator]();const readline = async () =&gt; (await iter.next()).value;void (async function () {  // 循环读取每一行输入  while ((line = await readline())) {    // 分割并转换为数字    let tokens = line.split(\" \");    let a = parseInt(tokens[0]);    let b = parseInt(tokens[1]);    // 关键：判断是否为0 0，是则终止循环    if (a === 0 &amp;&amp; b === 0) {      break; // 退出循环，不再处理后续输入    }    // 不是终止条件则输出结果    console.log(a + b);  }})();\n5.单组_一维数组示例输入：31 4 7输出：12\nconst rl = require(\"readline\").createInterface({ input: process.stdin });var iter = rl[Symbol.asyncIterator]();const readline = async () =&gt; (await iter.next()).value;void (async function () {  // 第一步：读取第一行，获取数字的个数n  let n = parseInt(await readline());  // 第二步：读取第二行，获取包含n个数字的字符串  let line = await readline();  // 第三步：对字符串进行处理，转化为数字数组  let nums = line    .split(\" \")    .filter((x) =&gt; x)    .map(Number); // 用空格分割，过滤空值  // 第四步：计算数组中所有数字的总和  let sum = nums.reduce((acc, curr) =&gt; acc + curr, 0);  // 第五步：输出总和  console.log(sum);})();\n6.多组_一维数组_T 组形式示例输入：331 4 71100021 2输出：1210003\nconst rl = require(\"readline\").createInterface({ input: process.stdin });var iter = rl[Symbol.asyncIterator]();const readline = async () =&gt; (await iter.next()).value;void (async function () {  // 读取测试用例总数T  const T = parseInt(await readline());  // 循环处理每组数据  for (let i = 0; i &lt; T; i++) {    // 读取当前组的元素个数n    const n = parseInt(await readline());    // 读取当前组的数组元素行    const arrayLine = await readline();    // 将字符串分割为数字数组    const numbers = arrayLine      .split(\" \")      .filter((x) =&gt; x)      .map(Number);    // 计算数组总和（使用reduce累加，初始值为0）    const sum = numbers.reduce((acc, current) =&gt; acc + current, 0);    // 输出当前组的总和    console.log(sum);  }})();\n7.单组_二维数组示例输入：3 41 2 3 45 6 7 89 10 11 12输出：78\nconst rl = require(\"readline\").createInterface({ input: process.stdin });var iter = rl[Symbol.asyncIterator]();const readline = async () =&gt; (await iter.next()).value;void (async function () {  // 1. 读取第一行，获取二维数组的行数m和列数n  let firstLine = await readline();  let [m, n] = firstLine.split(\" \").map(Number); // m=3, n=4（对应示例输入）  let totalSum = 0; // 存储总和  // 2. 循环读取m行数据（二维数组的每一行）  for (let i = 0; i &lt; m; i++) {    let row = await readline(); // 读取一行数据（如\"1 2 3 4\"）    let nums = row      .split(\" \")      .filter((x) =&gt; x)      .map(Number); // 转为数字数组（如[1,2,3,4]）    // 3. 累加当前行的所有元素到总和    let rowSum = nums.reduce((acc, curr) =&gt; acc + curr, 0);    totalSum += rowSum;  }  // 4. 输出二维数组所有元素的总和  console.log(totalSum);})();\n8.多组_二维数组_T 组形式示例输入：33 41 2 3 45 6 7 89 10 11 121 120243 21 14 51 4输出：78202416\nconst rl = require(\"readline\").createInterface({ input: process.stdin });var iter = rl[Symbol.asyncIterator]();const readline = async () =&gt; (await iter.next()).value;void (async function () {  // 1. 读取测试用例总数T  const T = parseInt(await readline());  // 2. 循环处理每组二维数组  for (let t = 0; t &lt; T; t++) {    // 2.1 读取当前组的行数m和列数n    const [m, n] = (await readline())      .split(\" \")      .filter((x) =&gt; x)      .map(Number);    let totalSum = 0; // 存储当前组的总和    // 2.2 读取m行数据（二维数组的每一行）    for (let i = 0; i &lt; m; i++) {      const row = (await readline())        .split(\" \")        .filter((x) =&gt; x)        .map(Number);      // 累加当前行的所有元素      const rowSum = row.reduce((acc, curr) =&gt; acc + curr, 0);      totalSum += rowSum;    }    // 2.3 输出当前组的总和    console.log(totalSum);  }})();\n9.单组_字符串描述给定一个长度为n的字符串s,请你将其倒置，然后输出。\n输入描述第一行有一个整数n，第二行有一个字符串s，仅包含小写英文字符。\n输出描述输出一个字符串，代表倒置后的字符串s。\n示例输入：5abcde输出：edcba\nconst rl = require(\"readline\").createInterface({ input: process.stdin });var iter = rl[Symbol.asyncIterator]();const readline = async () =&gt; (await iter.next()).value;void (async function () {  // 1. 读取第一行：字符串的长度n（本题中可忽略具体值，仅用于匹配输入格式）  const n = parseInt(await readline());  // 2. 读取第二行：需要反转的字符串  const str = await readline();  // 3. 反转字符串：  //    - split('') 将字符串转为字符数组（如\"abcde\" → ['a','b','c','d','e']）  //    - reverse() 反转数组（→ ['e','d','c','b','a']）  //    - join('') 将数组转回字符串（→ \"edcba\"）  const reversedStr = str.split(\"\").reverse().join(\"\");  // 4. 输出反转后的字符串  console.log(reversedStr);})();\n10.多组_字符串_T 组形式描述给定t组询问，每次只给出一个长度为n的字符串s,请你将其倒置，然后输出。\n输入描述第一行有一个整数t，随后t组数据。每组的第一行有一个整数n,每组的第二行有一个字符串s，仅包含小写英文字符。\n输出描述输出t行，每行一个字符串，代表倒置后的字符串s。\n示例输入：35abcde8redocwon9tfarcenim输出：edcbanowcoderminecraft\nconst rl = require(\"readline\").createInterface({ input: process.stdin });var iter = rl[Symbol.asyncIterator]();const readline = async () =&gt; (await iter.next()).value;void (async function () {  // 1. 读取测试用例总数T  const T = parseInt(await readline());  // 2. 循环处理每组字符串  for (let t = 0; t &lt; T; t++) {    // 2.1 读取当前组的字符串长度n（仅用于匹配输入格式，反转逻辑不依赖此值）    const n = parseInt(await readline());    // 2.2 读取当前组需要反转的字符串    const str = await readline();    // 2.3 反转字符串：拆分为字符数组 → 反转数组 → 拼接为字符串    const reversedStr = str.split(\"\").reverse().join(\"\");    // 2.4 输出反转后的字符串    console.log(reversedStr);  }})();\n11.单组_二维字符数组输入描述第一行有两个整数n和m，随后n行，每行有m个字符，仅包含小写英文字符。\n输出描述输出一个二维字符数组。\n示例输入：3 4abcdefghijkl输出：lkjihgfedcba\nconst rl = require(\"readline\").createInterface({ input: process.stdin });var iter = rl[Symbol.asyncIterator]();const readline = async () =&gt; (await iter.next()).value;void (async function () {  // 1. 读取第一行，获取二维数组的行数m和列数n  const [m, n] = (await readline())    .split(\" \")    .filter((x) =&gt; x)    .map(Number);  // 2. 读取m行字符串，存储到数组中  const rows = [];  for (let i = 0; i &lt; m; i++) {    rows.push(await readline());  }  // 3. 处理逻辑：  //    a. 先将每行字符串反转（如\"abcd\" → \"dcba\"）  //    b. 再将所有行的顺序反转（如[行1, 行2, 行3] → [行3, 行2, 行1]）  const reversedRows = rows    .map((row) =&gt; row.split(\"\").reverse().join(\"\")) // 每行字符反转    .reverse(); // 行顺序反转  // 4. 逐行输出处理后的结果  reversedRows.forEach((row) =&gt; console.log(row));})();\n12.多组_带空格的字符串_T 组形式描述给定t组询问，每次给出一个长度为n的带空格的字符串s，请你去掉空格之后，将其倒置，然后输出。\n输入描述第一行有一个整数t，随后有t组数据。每组的第一行有一个整数n，每组的第二行有一个字符串s，仅包含小写英文字符和空格，保证字符串首尾都不是空格。\n输出描述输出 t 行，每行一个字符串，代表倒置后的字符串s。\n示例输入：39one space11two  spaces14three   spaces输出：ecapsenosecapsowtsecapseerht\nconst rl = require(\"readline\").createInterface({ input: process.stdin });var iter = rl[Symbol.asyncIterator]();const readline = async () =&gt; (await iter.next()).value;void (async function () {  // 1. 读取测试用例总数T  const T = parseInt(await readline());  // 2. 循环处理每组字符串  for (let t = 0; t &lt; T; t++) {    // 2.1 读取当前组的字符串总长度n（用于匹配输入格式）    const n = parseInt(await readline());    // 2.2 读取带空格的字符串    const str = await readline();    // 2.3 处理逻辑：    //    a. 先将字符串所有字符（包括空格）反转    //    b. 再去除反转后字符串中的所有空格    const processed = str      .split(\"\") // 拆分为字符数组（含空格）      .reverse() // 反转所有字符（包括空格）      .join(\"\") // 拼接回字符串      .replace(/\\s+/g, \"\"); // 去除所有空格（\\s+匹配任意空白字符）    // 2.4 输出处理结果    console.log(processed);  }})();\n13.单组_保留小数位数描述给定一个小数 n ，请你保留 3 位小数后输出。\n如果原来的小数位数少于 3 ，需要补充 0 。\n如果原来的小数位数多于 3 ，需要四舍五入到 3 位。\n输出描述输出一个小数，保留 3 位。\n示例输入：1.23输出：1.230输入：114.514输出：114.514输入：123输出：123.000\nconst rl = require(\"readline\").createInterface({ input: process.stdin });var iter = rl[Symbol.asyncIterator]();const readline = async () =&gt; (await iter.next()).value;void (async function () {  // 1. 读取输入的小数（单组输入，只需读一次）  const numStr = await readline();  // 2. 将字符串转换为浮点数  const num = parseFloat(numStr);  // 3. 保留3位小数：toFixed(3)会自动补零，确保结果是3位小数  const result = num.toFixed(3);  // 4. 输出格式化后的结果  console.log(result);})();\n14.单组_补充前导零描述给定一个正整数 n ，请你保留 9 个数位，然后输出。\n如果数位少于 9 个，那么需要补充前导零。\n输出描述输出一个小数，保留 3 位。\n示例输入：123输出：000000123输入：123456789输出：123456789\nconst rl = require(\"readline\").createInterface({ input: process.stdin });var iter = rl[Symbol.asyncIterator]();const readline = async () =&gt; (await iter.next()).value;void (async function () {  // 1. 读取输入的数字（单组输入，读取一行即可）  const numStr = await readline();  // 2. 补充前导零至9位：  //    - padStart(9, '0') 表示如果字符串长度不足9位，在前面补'0'直到长度为9  const result = numStr.padStart(9, \"0\");  // 3. 输出处理后的结果  console.log(result);})();\n常用方法\nparseInt()：将字符串转化为整数。\nparseFloat()：将字符串转化为浮点数。\nsplit()：将字符串按指定分隔符分割成数组。\nreverse()：反转数组。\njoin()：将数组元素按指定分隔符拼接成字符串。\npadStart()：在字符串前面补充指定字符，直到字符串长度达到指定长度。\n\nline = await readline()：要注意 await readline()获取的是一段字符串，后面我们还要自己将它分割或者转化为其他数据类型。\n\nlet tokens = line.split(' ')：这段代码作用是，将一行输入按空格分割成数组（例如”1 2”分割为[“1”, “2”]）。\nlet a = parseInt(tokens[0])：这段代码的作用是，将分割的字符转化为数字。\n\n再配合while和for语句差不多可以应对各种题型了\n","categories":["算法"],"tags":["算法"]},{"title":"2025-12-26-关于Javascript/TypeScript 的顺序表，链表","url":"/Arknight-notes/posts/46758.html","content":"JavaScript 原生提供了 Array 作为高效的动态顺序表实现，但为了理解底层原理，通常需要手动实现。链表则需要完全手动实现，因为 JavaScript 无内置链表结构。\n以下分别提供两种数据结构的完整实现，包括基本操作（插入、删除、查找、遍历等），并附带说明。\n1. 顺序表（基于数组的动态顺序表）顺序表的核心是连续存储，使用数组实现\n// 创建顺序表const seqList = [];// 添加元素seqList.push(10);seqList.push(20);seqList.push(30);// 在索引 1 处插入 15seqList.splice(1, 0, 15);  // [10, 15, 20, 30]// 修改索引 2 处的元素seqList[2] = 25;           // [10, 15, 25, 30]// 删除索引 0 处的元素seqList.splice(0, 1);      // [15, 25, 30]// 输出长度和内容console.log('长度:', seqList.length);  // 3console.log('内容:', seqList);         // [15, 25, 30]\n手动实现如下：\nclass SequentialList {    constructor(capacity = 10) {        this.data = new Array(capacity);  // 存储元素        this.size = 0;                    // 当前元素个数        this.capacity = capacity;         // 当前容量    }    // 获取长度    getSize() {        return this.size;    }    // 判断是否为空    isEmpty() {        return this.size === 0;    }    // 扩容（当 size === capacity 时）    resize(newCapacity) {        const newData = new Array(newCapacity);        for (let i = 0; i &lt; this.size; i++) {            newData[i] = this.data[i];        }        this.data = newData;        this.capacity = newCapacity;    }    // 在索引 index 处插入元素    add(index, element) {        if (index &lt; 0 || index &gt; this.size) {            throw new Error('索引越界');        }        if (this.size === this.capacity) {            this.resize(this.capacity * 2);  // 扩容为两倍        }        // 从后向前移动元素        for (let i = this.size - 1; i &gt;= index; i--) {            this.data[i + 1] = this.data[i];        }        this.data[index] = element;        this.size++;    }    // 在末尾添加元素    append(element) {        this.add(this.size, element);    }    // 删除索引 index 处的元素并返回    remove(index) {        if (index &lt; 0 || index &gt;= this.size) {            throw new Error('索引越界');        }        const removed = this.data[index];        // 从前向后移动元素        for (let i = index + 1; i &lt; this.size; i++) {            this.data[i - 1] = this.data[i];        }        this.size--;        // 可选：缩容（避免频繁缩容，通常当 size == capacity / 4 时缩为一半）        if (this.size &gt; 0 &amp;&amp; this.size === Math.floor(this.capacity / 4)) {            this.resize(Math.floor(this.capacity / 2));        }        return removed;    }    // 获取索引处元素    get(index) {        if (index &lt; 0 || index &gt;= this.size) {            throw new Error('索引越界');        }        return this.data[index];    }    // 设置索引处元素    set(index, element) {        if (index &lt; 0 || index &gt;= this.size) {            throw new Error('索引越界');        }        this.data[index] = element;    }    // 遍历打印    print() {        let str = 'SequentialList: [';        for (let i = 0; i &lt; this.size; i++) {            str += this.data[i];            if (i !== this.size - 1) str += ', ';        }        str += ']';        console.log(str);    }}// 使用示例const seqList = new SequentialList();seqList.append(1);seqList.append(2);seqList.add(1, 3);seqList.print();  // SequentialList: [1, 3, 2]\n2. 链表（单向链表）链表使用节点分散存储，支持高效的插入和删除（O(1)），但随机访问较慢（O(n)）\n// 节点类class ListNode {    constructor(val = null, next = null) {        this.val = val;        this.next = next;    }}class LinkedList {    constructor() {        this.head = new ListNode();  // 虚拟头结点，便于操作        this.size = 0;    }    getSize() {        return this.size;    }    isEmpty() {        return this.size === 0;    }    // 在索引 index 处插入元素    add(index, element) {        if (index &lt; 0 || index &gt; this.size) {            throw new Error('索引越界');        }        let prev = this.head;        for (let i = 0; i &lt; index; i++) {            prev = prev.next;        }        const node = new ListNode(element);        node.next = prev.next;        prev.next = node;        this.size++;    }    // 在链表头部添加元素    addFirst(element) {        this.add(0, element);    }    // 在链表末尾添加元素    addLast(element) {        this.add(this.size, element);    }    // 获取索引处元素    get(index) {        if (index &lt; 0 || index &gt;= this.size) {            throw new Error('索引越界');        }        let cur = this.head.next;        for (let i = 0; i &lt; index; i++) {            cur = cur.next;        }        return cur.val;    }    // 设置索引处元素    set(index, element) {        if (index &lt; 0 || index &gt;= this.size) {            throw new Error('索引越界');        }        let cur = this.head.next;        for (let i = 0; i &lt; index; i++) {            cur = cur.next;        }        cur.val = element;    }    // 删除索引处元素并返回    remove(index) {        if (index &lt; 0 || index &gt;= this.size) {            throw new Error('索引越界');        }        let prev = this.head;        for (let i = 0; i &lt; index; i++) {            prev = prev.next;        }        const removedNode = prev.next;        prev.next = removedNode.next;        removedNode.next = null;        this.size--;        return removedNode.val;    }    // 遍历打印    print() {        let str = 'LinkedList: [';        let cur = this.head.next;        while (cur) {            str += cur.val;            if (cur.next) str += ' -&gt; ';            cur = cur.next;        }        str += ']';        console.log(str);    }}// 使用示例const linkedList = new LinkedList();linkedList.addLast(1);linkedList.addLast(2);linkedList.add(1, 3);linkedList.print();  // LinkedList: [1 -&gt; 3 -&gt; 2]\n\nLRU 缓存的实现（使用双向链表 + HashMap）LRU（Least Recently Used）缓存是一种常见的数据结构，用于实现固定容量缓存，当容量满时淘汰最近最少使用的元素。在 JavaScript 中，最高效的实现方式是结合双向链表（控制访问顺序）和Map（或对象）作为哈希表（实现 O(1) 访问）\nJS实现：class LRUCache {    /**     * 构造函数     * @param {number} capacity - 缓存的最大容量     */    constructor(capacity) {        this.capacity = capacity;        // 缓存容量        this.cache = new Map();          // 使用 Map 作为哈希表，保持插入顺序并支持 O(1) 操作        this.head = {};                  // 双向链表的虚拟头节点        this.tail = {};                  // 双向链表的虚拟尾节点        this.head.next = this.tail;      // 初始化链表：head &lt;-&gt; tail        this.tail.prev = this.head;    }    /**     * 将节点移动到链表头部（表示最近使用）     * @private     * @param {Object} node - 要移动的节点     */    _moveToHead(node) {        // 先从当前位置移除        node.prev.next = node.next;        node.next.prev = node.prev;        // 插入到头部        node.next = this.head.next;        node.prev = this.head;        this.head.next.prev = node;        this.head.next = node;    }    /**     * 从链表尾部移除节点（淘汰最久未使用的）     * @private     * @returns {Object} 被移除的节点     */    _removeTail() {        const lastNode = this.tail.prev;        lastNode.prev.next = this.tail;        this.tail.prev = lastNode.prev;        return lastNode;    }    /**     * 获取缓存值     * @param {any} key - 键     * @returns {any} 值，如果不存在返回 -1     */    get(key) {        const node = this.cache.get(key);        if (!node) {            return -1;  // 未找到        }        // 刷新访问顺序：将节点移到头部        this._moveToHead(node);        return node.value;    }    /**     * 放入缓存     * @param {any} key - 键     * @param {any} value - 值     */    put(key, value) {        const existingNode = this.cache.get(key);        if (existingNode) {            // 已存在：更新值并移到头部            existingNode.value = value;            this._moveToHead(existingNode);        } else {            // 不存在：创建新节点            const newNode = { key, value, prev: null, next: null };            this.cache.set(key, newNode);            // 插入到头部            newNode.next = this.head.next;            newNode.prev = this.head;            this.head.next.prev = newNode;            this.head.next = newNode;            // 检查容量是否超出            if (this.cache.size &gt; this.capacity) {                const tailNode = this._removeTail();  // 移除尾部节点                this.cache.delete(tailNode.key);      // 从哈希表中删除            }        }    }    // 可选：打印当前缓存顺序（用于调试）    printCache() {        const result = [];        let current = this.head.next;        while (current !== this.tail) {            result.push(`${current.key}:${current.value}`);            current = current.next;        }        console.log('LRU Cache (most recent -&gt; least recent):', result.join(' -&gt; '));    }}// 使用示例const cache = new LRUCache(3);cache.put(1, 1);cache.put(2, 2);cache.put(3, 3);cache.printCache();  // 3:3 -&gt; 2:2 -&gt; 1:1console.log(cache.get(2));  // 2（刷新顺序）cache.printCache();         // 2:2 -&gt; 3:3 -&gt; 1:1cache.put(4, 4);            // 容量满，淘汰最久未使用的 1cache.printCache();         // 4:4 -&gt; 2:2 -&gt; 3:3\nTS实现使用双向链表结合 Map（Map 在 TypeScript 中天然支持泛型）实现 O(1) 时间复杂度的 get 和 put 操作\n// 双向链表节点接口interface Node&lt;K, V&gt; {    key: K;    value: V;    prev: Node&lt;K, V&gt; | null;    next: Node&lt;K, V&gt; | null;}class LRUCache&lt;K = number, V = number&gt; {    private capacity: number;                // 缓存容量    private cache: Map&lt;K, Node&lt;K, V&gt;&gt;;        // 哈希表：键到节点的映射    private head: Node&lt;K, V&gt;;                // 虚拟头节点    private tail: Node&lt;K, V&gt;;                // 虚拟尾节点    constructor(capacity: number) {        this.capacity = capacity;        this.cache = new Map&lt;K, Node&lt;K, V&gt;&gt;();        this.head = { key: null as any, value: null as any, prev: null, next: null };        this.tail = { key: null as any, value: null as any, prev: null, next: null };        this.head.next = this.tail;        this.tail.prev = this.head;    }    // 将节点移动到头部（最近使用）    private moveToHead(node: Node&lt;K, V&gt;): void {        // 从当前位置移除        node.prev!.next = node.next;        node.next!.prev = node.prev!;        // 插入头部        node.next = this.head.next;        node.prev = this.head;        this.head.next!.prev = node;        this.head.next = node;    }    // 移除尾部节点（最久未使用）    private removeTail(): Node&lt;K, V&gt; {        const lastNode = this.tail.prev!;        lastNode.prev!.next = this.tail;        this.tail.prev = lastNode.prev;        return lastNode;    }    // 获取值    get(key: K): V | -1 {        const node = this.cache.get(key);        if (!node) {            return -1;        }        this.moveToHead(node);  // 刷新访问顺序        return node.value;    }    // 放入键值对    put(key: K, value: V): void {        const existingNode = this.cache.get(key);        if (existingNode) {            existingNode.value = value;  // 更新值            this.moveToHead(existingNode);        } else {            const newNode: Node&lt;K, V&gt; = { key, value, prev: null, next: null };            this.cache.set(key, newNode);            // 插入头部            newNode.next = this.head.next;            newNode.prev = this.head;            this.head.next!.prev = newNode;            this.head.next = newNode;            // 超出容量时淘汰            if (this.cache.size &gt; this.capacity) {                const tailNode = this.removeTail();                this.cache.delete(tailNode.key);            }        }    }    // 调试：打印缓存顺序（最近 -&gt; 最久）    printCache(): void {        const result: string[] = [];        let current = this.head.next;        while (current !== this.tail) {            result.push(`${current!.key}:${current!.value}`);            current = current!.next;        }        console.log('LRU Cache:', result.join(' -&gt; '));    }}// 使用示例const cache = new LRUCache&lt;number, number&gt;(3);cache.put(1, 1);cache.put(2, 2);cache.put(3, 3);cache.printCache();  // 3:3 -&gt; 2:2 -&gt; 1:1console.log(cache.get(2));  // 2cache.printCache();         // 2:2 -&gt; 3:3 -&gt; 1:1\n链表反转的实现单向链表的反转实现，包括迭代和递归两种方式\nJS实现// 单向链表节点定义class ListNode {    constructor(val = null, next = null) {        this.val = val;        this.next = next;    }}// 创建链表的辅助函数function createLinkedList(arr) {    if (arr.length === 0) return null;    let head = new ListNode(arr[0]);    let current = head;    for (let i = 1; i &lt; arr.length; i++) {        current.next = new ListNode(arr[i]);        current = current.next;    }    return head;}// 打印链表的辅助函数function printLinkedList(head) {    const result = [];    let current = head;    while (current) {        result.push(current.val);        current = current.next;    }    console.log('LinkedList:', result.join(' -&gt; '));}// 方法一：迭代反转（推荐，空间复杂度 O(1)）function reverseListIterative(head) {    let prev = null;         // 前驱指针    let current = head;      // 当前指针    let next = null;         // 临时存储下一节点    while (current !== null) {        next = current.next; // 保存下一节点        current.next = prev; // 反转指针        prev = current;      // 前驱前进        current = next;      // 当前前进    }    return prev;  // prev 成为新头节点}// 方法二：递归反转function reverseListRecursive(head) {    // 递归终止条件：空链表或只有一个节点    if (head === null || head.next === null) {        return head;    }    // 递归反转后续链表    const newHead = reverseListRecursive(head.next);    // 反转当前节点与下一节点的指向    head.next.next = head;    head.next = null;    return newHead;  // 新头节点始终是原链表的尾节点}// 使用示例const list = createLinkedList([1, 2, 3, 4, 5]);printLinkedList(list);  // 1 -&gt; 2 -&gt; 3 -&gt; 4 -&gt; 5const reversedIterative = reverseListIterative(list);printLinkedList(reversedIterative);  // 5 -&gt; 4 -&gt; 3 -&gt; 2 -&gt; 1const list2 = createLinkedList([6, 7, 8]);printLinkedList(list2);  // 6 -&gt; 7 -&gt; 8const reversedRecursive = reverseListRecursive(list2);printLinkedList(reversedRecursive);  // 8 -&gt; 7 -&gt; 6\nTS实现// 单向链表节点类型class ListNode {    val: number;    next: ListNode | null;    constructor(val?: number, next?: ListNode) {        this.val = val ?? 0;        this.next = next ?? null;    }}// 创建链表辅助函数function createLinkedList(arr: number[]): ListNode | null {    if (arr.length === 0) return null;    const head = new ListNode(arr[0]);    let current = head;    for (let i = 1; i &lt; arr.length; i++) {        current.next = new ListNode(arr[i]);        current = current.next;    }    return head;}// 打印链表辅助函数function printLinkedList(head: ListNode | null): void {    const result: number[] = [];    let current = head;    while (current) {        result.push(current.val);        current = current.next;    }    console.log('LinkedList:', result.join(' -&gt; '));}// 迭代反转（推荐，空间 O(1)）function reverseListIterative(head: ListNode | null): ListNode | null {    let prev: ListNode | null = null;    let current: ListNode | null = head;    while (current !== null) {        const next = current.next;  // 保存下一节点        current.next = prev;        // 反转指针        prev = current;             // 前驱前进        current = next;             // 当前前进    }    return prev;  // 新头节点}// 递归反转function reverseListRecursive(head: ListNode | null): ListNode | null {    if (head === null || head.next === null) {        return head;    }    const newHead = reverseListRecursive(head.next);    head.next.next = head;    head.next = null;    return newHead;}// 使用示例const list = createLinkedList([1, 2, 3, 4, 5]);printLinkedList(list);  // 1 -&gt; 2 -&gt; 3 -&gt; 4 -&gt; 5const reversedIter = reverseListIterative(list);printLinkedList(reversedIter);  // 5 -&gt; 4 -&gt; 3 -&gt; 2 -&gt; 1const list2 = createLinkedList([6, 7, 8]);const reversedRec = reverseListRecursive(list2);printLinkedList(reversedRec);  // 8 -&gt; 7 -&gt; 6\nDFA:\n\n顺序表：适合随机访问（O(1)），插入/删除较慢（O(n)），实现简单，内存连续\n链表：适合频繁插入/删除（O(1)），随机访问慢（O(n)），内存分散，支持动态扩展, 链表常用于特定算法（如 LRU 缓存、链表反转等）\n\n","categories":["数据结构"],"tags":["数据结构","前端开发","算法"]},{"title":"2025-12-26-力扣百题速练（Javascript、TypeScript）Vol.2","url":"/Arknight-notes/posts/39620.html","content":"这里是力扣速刷第二期awa说是速刷其实卡了挺久\n\n11. 盛最多水的容器给定一个长度为  n  的整数数组  height 。有  n  条垂线，第  i  条线的两个端点是  (i, 0)  和  (i, height[i])找出其中的两条线，使得它们与  x  轴共同构成的容器可以容纳最多的水返回容器可以储存的最大水量\n输入：[1,8,6,2,5,4,8,3,7]输出：49解释：图中垂直线代表输入数组 [1,8,6,2,5,4,8,3,7]。在此情况下，容器能够容纳水（表示为蓝色部分）的最大值为 49\n最开始直接暴力解\nfunction maxArea(height: number[]): number {  let res = 0;  let i = 0;  let j = 1;  for (i = 0; i &lt; height.length - 1; i++) {    for (j = 1; j &lt; height.length; j++) {      let xin = (j - i) * Math.min(height[i], height[j]);      if (xin &gt; res) {        res = xin;      }    }  }  return res;}\n后面想了一下，做了些改进\nfunction maxArea(height: number[]): number {  let res = 0;  let i = 0;  let j = height.length - 1;  while (i &lt; j) {    let fin = Math.min(height[i], height[j]) * (j - i);    if (fin &gt; res) {      res = fin;    }    if (height[i] &lt; height[j]) {      i++;    } else {      j--;    }  }  return res;}\n初始时宽度最大，若当前面积不是最大，则必须通过增加高度来补偿宽度损失移动较短指针是因为：保持较短边不动，宽度只会变小，面积不可能增大；只有移动较短边才可能遇到更高的高度，从而提升面积\n经典双指针加贪心的题\n\n12.整数转罗马数字七个不同的符号代表罗马数字，其值如下：\n\n\n\n\n符号\n值\n\n\n\n\nI\n1\n\n\nV\n5\n\n\nX\n10\n\n\nL\n50\n\n\nC\n100\n\n\nD\n500\n\n\nM\n1000\n\n\n\n\n罗马数字是通过添加从最高到最低的小数位值的转换而形成的。将小数位值转换为罗马数字有以下规则：\n\n如果该值不是以 4 或 9 开头，请选择可以从输入中减去的最大值的符号，将该符号附加到结果，减去其值，然后将其余部分转换为罗马数字。\n如果该值以 4 或 9 开头，使用  减法形式，表示从以下符号中减去一个符号，例如 4 是 5 (V) 减 1 (I): IV ，9 是 10 (X) 减 1 (I)：IX。仅使用以下减法形式：4 (IV)，9 (IX)，40 (XL)，90 (XC)，400 (CD) 和 900 (CM)。\n只有 10 的次方（I, X, C, M）最多可以连续附加 3 次以代表 10 的倍数。你不能多次附加 5 (V)，50 (L) 或 500 (D)。如果需要将符号附加 4 次，请使用  减法形式。\n\n给定一个整数，将其转换为罗马数字。\n示例 1：\n**输入：num = 3749\n输出： “MMMDCCXLIX”\n解释：\n3000 = MMM 由于 1000 (M) + 1000 (M) + 1000 (M)700 = DCC 由于 500 (D) + 100 (C) + 100 (C)40 = XL 由于 50 (L) 减 10 (X)9 = IX 由于 10 (X) 减 1 (I)注意：49 不是 50 (L) 减 1 (I) 因为转换是基于小数位\n示例 2：\n**输入：num = 58\n输出：“LVIII”\n解释：\n50 = L8 = VIII\n示例 3：\n**输入：num = 1994\n输出：“MCMXCIV”\n解释：\n1000 = M900 = CM90 = XC4 = IV\n最初想法是尝试通过逐位处理数字的方式将整数转换为罗马数字：\n\n将数字转换为字符串并反转： 使用 reverseString(num.toString()) 将数字从高位到低位变为低位到高位（例如 1994 → “4991”）,从个位开始依次处理每个数位（个位、十位、百位、千位）\n为每个数位定义对应的罗马符号：\n个位（i===0）：1→\"I\", 5→\"V\", 10→\"X\"\n十位（i===1）：1→\"X\", 5→\"L\", 10→\"C\"\n百位（i===2）：1→\"C\", 5→\"D\", 10→\"M\"\n千位（i===3）：直接用 \"M\" 重复\n\n\n根据当前位上的数字（0-9）生成对应罗马表示：\n1-3：重复添加 “1” 的符号（curr1）\n4：curr1 + curr2（如 “IV”）\n5：curr2（如 “V”）\n6-8：curr2 + 重复 (digit-5) 次 curr1\n9：curr1 + curr3（如 “IX”）\n\n\n使用数组 + unshift 收集符号： 因为已反转数字，低位先处理，使用 unshift（从数组头部插入）试图让高位符号最终出现在前面\n最后 join 成字符串返回\n\nfunction intToRoman(num: number): string {  let curr1 = \"\";  let curr2 = \"\";  let curr3 = \"\";  const reverseString = (str: string): string =&gt;    str.split(\"\").reverse().join(\"\");  let top = reverseString(num.toString());  let l = top.length;  let finalstr: string[] = [];  let i = 0;  function nums(pos: number) {    const di = Number(top[pos]);    if (di === 0) return;    if (di &lt;= 3) {      for (let j = 0; j &lt; di; j++) {        finalstr.unshift(curr1);      }    } else if (di === 4) {      finalstr.unshift(curr1 + curr2);    } else if (di === 5) {      finalstr.unshift(curr2);    } else if (di &lt;= 8) {      for (let j = 0; j &lt; di - 5; j++) {        finalstr.unshift(curr1);      }      finalstr.unshift(curr2);    } else if (di === 9) {      finalstr.unshift(curr1 + curr3);    }  }  while (i &lt; l) {    if (i === 0) {      curr1 = \"I\";      curr2 = \"V\";      curr3 = \"X\";      nums(i);      i++;    }    if (i === 1) {      curr1 = \"X\";      curr2 = \"L\";      curr3 = \"C\";      nums(i);      i++;    }    if (i === 2) {      curr1 = \"C\";      curr2 = \"D\";      curr3 = \"M\";      nums(i);      i++;    }    if (i === 3) {      const vas = Number(top[i]);      for (let j = 0; j &lt; vas; j++) {        finalstr.unshift(\"M\");      }      i++;    }  }  return finalstr.join(\"\");}\n题目标准解法是贪心算法 + 值-符号映射表，从高位到低位匹配最大可能值，这个写法确实没有想出来：\nfunction intToRoman(num: number): string {    const valueSymbols: [number, string][] = [        [1000, \"M\"], [900, \"CM\"], [500, \"D\"], [400, \"CD\"],        [100,  \"C\"], [90,  \"XC\"], [50,  \"L\"], [40,  \"XL\"],        [10,   \"X\"], [9,   \"IX\"], [5,   \"V\"], [4,   \"IV\"],        [1,    \"I\"]    ];    let result = '';    for (const [value, symbol] of valueSymbols) {        while (num &gt;= value) {            result += symbol;            num -= value;        }    }    return result;}\n\n13. 罗马数字转整数罗马数字包含以下七种字符: I， V， X， L，C，D  和  M。\n字符 数值I 1V 5X 10L 50C 100D 500M 1000\n例如， 罗马数字  2  写做  II ，即为两个并列的 1 。12  写做  XII ，即为  X + II 。 27  写做  XXVII, 即为  XX + V + II 。\n通常情况下，罗马数字中小的数字在大的数字的右边。但也存在特例，例如 4 不写做  IIII，而是  IV。数字 1 在数字 5 的左边，所表示的数等于大数 5 减小数 1 得到的数值 4 。同样地，数字 9 表示为  IX。这个特殊的规则只适用于以下六种情况：\n\nI  可以放在  V (5) 和  X (10) 的左边，来表示 4 和 9。\nX  可以放在  L (50) 和  C (100) 的左边，来表示 40 和 90。\nC  可以放在  D (500) 和  M (1000) 的左边，来表示 400 和 900。\n\n给定一个罗马数字，将其转换成整数。\n示例 1:\n输入: s = “III”输出: 3\n示例 2:\n输入: s = “IV”输出: 4\n示例 3:\n输入: s = “IX”输出: 9\n示例 4:\n输入: s = “LVIII”输出: 58解释: L = 50, V= 5, III = 3.\n示例 5:\n输入: s = “MCMXCIV”输出: 1994解释: M = 1000, CM = 900, XC = 90, IV = 4.\n直接从左到右遍历字符串，比较当前符号与下一个符号的值：\n\n如果当前值 &lt; 下一个值，则减去当前值（形成减法组合）。\n否则加上当前值\n\nfunction romanToInt(s: string): number {  const map = {    I: 1,    V: 5,    X: 10,    L: 50,    C: 100,    D: 500,    M: 1000,  };  let res = 0;  for (let i = 0; i &lt; s.length; i++) {    const current = map[s[i]];    const next = map[s[i + 1]];    if (next &amp;&amp; current &lt; next) {      res += next - current;      i++;    } else {      res += current;    }  }  return res;}\n\n14. 最长公共前缀编写一个函数来查找字符串数组中的最长公共前缀\n如果不存在公共前缀，返回空字符串  \"\"\n示例 1：\n输入：strs = [“flower”,”flow”,”flight”]输出：”fl”\n示例 2：\n输入：strs = [“dog”,”racecar”,”car”]输出：””解释：输入不存在公共前缀\n题解比较简单，如下\nfunction longestCommonPrefix(strs: string[]): string {  if (strs.length === 0) return \"\";  for (let i = 0; i &lt; strs[0].length; i++) {    const char = strs[0][i];    for (let j = 1; j &lt; strs.length; j++) {      if (i === strs[j].length || strs[j][i] !== char) {        return strs[0].substring(0, i);      }    }  }  return strs[0];}\n主要就是注意一个写法，在 JavaScript（以及 TypeScript）中，strs[0][i] 是一种链式索引访问（chained indexing）的写法，用于访问二维结构或嵌套可索引对象中的元素\n假设 strs = [\"flower\", \"flow\", \"flight\"]，循环变量 i = 2 时：\n\nstrs[0] → \"flower\"\nstrs[0][2] → \"flower\" 的第 2 个字符 → 'o'\n\n同理：\n\nstrs[1][2] → \"flow\"[2] → 'o'\nstrs[2][2] → \"flight\"[2] → 'i'\n\n通过比较 strs[0][i]与其他字符串的 strs[j][i] 是否相等，来判断第 i 位置是否仍属于公共前缀\n等价的写法const firstStr = strs[0];firstStr[i];// 使用 charAt 方法strs[0].charAt(i);// 使用 at 方法 ES2022+strs[0].at(i);\n\n15. 三数之和一个整数数组  nums ，判断是否存在三元组  [nums[i], nums[j], nums[k]]  满足  i != j、i != k  且  j != k ，同时还满足  nums[i] + nums[j] + nums[k] == 0 ，返回所有和为  0  且不重复的三元组，且答案中不可以包含重复的三元组\n示例 1：输入：nums = [-1,0,1,2,-1,-4]输出：[[-1,-1,2],[-1,0,1]]解释：nums[0] + nums[1] + nums[2] = (-1) + 0 + 1 = 0nums[1] + nums[2] + nums[4] = 0 + 1 + (-1) = 0nums[0] + nums[3] + nums[4] = (-1) + 2 + (-1) = 0不同的三元组是 [-1,0,1]和 [-1,-1,2]\n示例 2：输入：nums = [0,1,1]输出：[]解释：唯一可能的三元组和不为 0\n示例 3：输入：nums = [0,0,0]输出：[[0,0,0]]解释：唯一可能的三元组和为 0\n最开始是想直接 n^3 暴力解，然后用 Set 去重\nfunction threeSum(nums: number[]): number[][] {  nums.sort((a, b) =&gt; a - b);  const result: number[][] = [];  const seen = new Set&lt;string&gt;();  for (let i = 0; i &lt; nums.length - 2; i++) {    for (let j = i + 1; j &lt; nums.length - 1; j++) {      for (let k = j + 1; k &lt; nums.length; k++) {        if (nums[i] + nums[j] + nums[k] === 0) {          const triplet = [nums[i], nums[j], nums[k]];          const key = triplet.join(\",\");          if (!seen.has(key)) {            seen.add(key);            result.push(triplet);          }        }      }    }  }  return result;}\n很明显，时间复杂度特别高，直接爆了\n解法的话依旧双指针降维\n第一步：排序排序后可以：利用有序数组的特性，通过指针移动快速缩小范围\n比如原数组是 [-1,0,1,2,-1,-4]，排序后变成 [-4,-1,-1,0,1,2]。这时候，相同的元素（比如两个 -1）会挨在一起，方便后续去重（重复元素会相邻，容易跳过）\n第二步：固定一个数，双指针找另外两个数排序后，我们固定第一个数 nums[i]，然后用左指针 left 指向 i+1，右指针 right 指向数组末尾。三个数的和 sum = nums[i] + nums[left] + nums[right]：\n\n如果 sum &lt; 0：说明需要更大的数，左指针右移（left++）；\n如果 sum &gt; 0：说明需要更小的数，右指针左移（right--）；\n如果 sum = 0：找到一个有效三元组，记录结果。\n\n第三步：去重具体分三种情况：\n1. 固定数 nums[i] 重复比如排序后的数组是 [-4,-1,-1,0,1,2]，当 i=1（nums[i]=-1）时，和 i=2（nums[i]=-1）时的情况是一样的。这时候需要跳过重复的 nums[i]。\n判断条件：如果 i &gt; 0 且 nums[i] === nums[i-1]，说明当前 nums[i] 和前一个数重复，直接跳过。\n2. 左指针 nums[left] 重复假设已经找到 i=0（nums[i]=-4），left=1（nums[left]=-1），right=5（nums[right]=2），此时和为 -4 + (-1) + 2 = -3，不满足条件。左指针右移到 left=2（nums[left]=-1），这时候 nums[left] 和前一个 left 位置的数重复，需要跳过。\n判断条件：当找到和为 0 的三元组后，需要循环判断 nums[left] === nums[left+1]，如果是，左指针右移，直到遇到不同的数。\n3. 右指针 nums[right] 重复同样，找到和为 0 的三元组后，如果 nums[right] 和前一个 right 位置的数重复（比如 nums[right]=1 和 nums[right-1]=1），需要跳过。\n判断条件：循环判断 nums[right] === nums[right-1]，如果是，右指针左移，直到遇到不同的数。\n\n先排序：nums.sort((a, b) =&gt; a - b)，使得相同元素相邻，便于跳过重复。\n外层循环跳过重复的 i：如果当前 nums[i] 与前一个相同，则跳过（避免同一值的 i 产生重复三元组）。\n内层双指针移动时跳过重复的 left 和 right：找到一个有效三元组后，跳过所有相同的 left 和 right 值。\n\nfunction threeSum(nums: number[]): number[][] {  nums.sort((a, b) =&gt; a - b); // 先排序，关键一步  const result: number[][] = [];  for (let i = 0; i &lt; nums.length - 2; i++) {    // 跳过重复的 nums[i]    if (i &gt; 0 &amp;&amp; nums[i] === nums[i - 1]) {      continue;    }    let left = i + 1;    let right = nums.length - 1;    while (left &lt; right) {      const sum = nums[i] + nums[left] + nums[right];      if (sum === 0) {        result.push([nums[i], nums[left], nums[right]]); //加入结果        // 跳过重复的 left        while (left &lt; right &amp;&amp; nums[left] === nums[left + 1]) {          left++;        }        // 跳过重复的 right        while (left &lt; right &amp;&amp; nums[right] === nums[right - 1]) {          right--;        }        left++;        right--;      } else if (sum &lt; 0) {        left++;      } else {        right--;      }    }  }  return result;}\n16. 最接近的三数之和给你一个长度为  n  的整数数组  nums  和 一个目标值  target。请你从  nums  中选出三个整数，使它们的和与  target  最接近，返回这三个数的和假定每组输入只存在恰好一个解\n示例：输入：nums = [-1,2,1,-4] , target = 1输出：2解释：与 target 最接近的和是 2 (-1 + 2 + 1 = 2)\n解法和三数之和一样都是双指针解题多一些判断而已\nfunction threeSumClosest(nums: number[], target: number): number {  nums.sort((a, b) =&gt; a - b);  let closestSum = nums[0] + nums[1] + nums[2];  let minDiff = Math.abs(closestSum - target);  for (let i = 0; i &lt; nums.length - 2; i++) {    let left = i + 1;    let right = nums.length - 1;    while (left &lt; right) {      const sum = nums[i] + nums[left] + nums[right];      const diff = Math.abs(sum - target);      if (diff &lt; minDiff) {        minDiff = diff;        closestSum = sum;      }      if (sum &lt; target) {        left++;      } else if (sum &gt; target) {        right--;      } else {        return sum;      }    }  }  return closestSum;}\n\n17.电话号码的的数字组合给定一个仅包含数字  2-9  的字符串，返回所有它能表示的字母组合。答案可以按  任意顺序  返回。\n给出数字到字母的映射如下（与电话按键相同）。注意 1 不对应任何字母。\n\n示例 1：输入：digits = “23”输出：[“ad”,”ae”,”af”,”bd”,”be”,”bf”,”cd”,”ce”,”cf”]\n示例 2：输入：digits = “2”输出：[“a”,”b”,”c”]\n练度不够，还得继续练\n主要解法是迭代法：\n\n外层循环遍历 digits 中的每一个数字（从左到右）。\n对于当前数字 digit：\n获取其对应的所有可能字母 letters（如 ‘2’ → ‘abc’）。\n创建一个临时数组 temp，用于存储“加入当前数字字母后的新组合”。\n遍历当前 result 中的每一个已有组合 prev（这些是处理前几个数字得到的所有组合）。\n对 letters 中的每一个 letter，将其追加到 prev 后面，形成新字符串 prev + letter，并加入 temp。\n\n\n一轮结束后，将 temp 赋值给 result，成为下一轮的“已有组合”。\n\nfunction letterCombinations(digits: string): string[] {  if (digits.length === 0) return [];  const map: { [key: string]: string } = {    \"2\": \"abc\",    \"3\": \"def\",    \"4\": \"ghi\",    \"5\": \"jkl\",    \"6\": \"mno\",    \"7\": \"pqrs\",    \"8\": \"tuv\",    \"9\": \"wxyz\",  };  let result: string[] = [\"\"];  for (const digit of digits) {    const letters = map[digit];    const temp: string[] = [];    for (const prev of result) {      for (const letter of letters) {        temp.push(prev + letter);      }    }    result = temp;  }  return result;}\n从“空组合”开始，依次将每个新数字的字母可能性“横向扩展”到所有已有组合上，最终得到所有完整组合\n\n18.四数之和给你一个由  n  个整数组成的数组  nums ，和一个目标值  target 。请你找出并返回满足下述全部条件且不重复的四元组  [nums[a], nums[b], nums[c], nums[d]] （若两个四元组元素一一对应，则认为两个四元组重复）：\n\n0 &lt;= a, b, c, d &lt; n\na、b、c  和  d  互不相同\nnums[a] + nums[b] + nums[c] + nums[d] == target\n\n输入：nums = [1,0,-1,0,-2,2], target = 0输出：[[-2,-1,1,2] , [-2,0,0,2] , [-1,0,0,1]]\n输入：nums = [2,2,2,2,2], target = 8输出：[[2,2,2,2]]\n就是三数之和的基础上再套上一层 for 循环\n题解\n/** * @param {number[]} nums * @param {number} target * @return {number[][]} */function(nums, target) {    nums.sort((a, b) =&gt; a - b);  // 先排序    const n = nums.length;    const result = [];    if (n &lt; 4) return result;    for (let i = 0; i &lt; n - 3; i++) {        // 去重 i        if (i &gt; 0 &amp;&amp; nums[i] === nums[i - 1]) continue;        // 剪枝：当前四个最小值之和已大于 target，直接终止        if (nums[i] + nums[i + 1] + nums[i + 2] + nums[i + 3] &gt; target) break;        // 剪枝：当前 i 与后面三个最大值之和小于 target，跳过本次 i        if (nums[i] + nums[n - 3] + nums[n - 2] + nums[n - 1] &lt; target) continue;        for (let j = i + 1; j &lt; n - 2; j++) {            // 去重 j            if (j &gt; i + 1 &amp;&amp; nums[j] === nums[j - 1]) continue;            // 剪枝            if (nums[i] + nums[j] + nums[j + 1] + nums[j + 2] &gt; target) break;            if (nums[i] + nums[j] + nums[n - 2] + nums[n - 1] &lt; target) continue;            let left = j + 1;            let right = n - 1;            while (left &lt; right) {                const sum = nums[i] + nums[j] + nums[left] + nums[right];                if (sum === target) {                    result.push([nums[i], nums[j], nums[left], nums[right]]);                    // 去重 left                    while (left &lt; right &amp;&amp; nums[left] === nums[left + 1]) left++;                    // 去重 right                    while (left &lt; right &amp;&amp; nums[right] === nums[right - 1]) right--;                    left++;                    right--;                } else if (sum &lt; target) {                    left++;                } else {                    right--;                }            }        }    }    return result;};\n\n19. 删除链表的第 n 个节点给你一个链表，删除链表的倒数第  n  个结点，并且返回链表的头结点\n输入：head = [1,2,3,4,5], n = 2输出：[1,2,3,5]\n输入：head = [1], n = 1输出：[]\n自己写的一版，思路主要是遍历一趟链表搞到 length，再用 n 确定 index 来定位要删的位置，最后再删掉该节点\nfunction removeNthFromEnd(head: ListNode | null, n: number): ListNode | null {  let len = 0;  let curr = head;  while (curr !== null) {    len++;    curr = curr.next;  }  if (len === n) {    return head?.next ?? null;  }  let index = len - n - 1;  let delindex = 0;  let del = head;  let prev = new ListNode(0);  prev.next = head;  while (del !== null) {    prev = prev.next;    del = del.next;    if (delindex === index) {      prev.next = del.next;    }    delindex++;  }  return head;}\n题解的话主要是用快慢指针,这个思路挺不错的其实\n\n引入虚拟头结点 dummy\n让 fast 指针先走 n 步\n然后 slow 与 fast 同步移动，当 fast 到达末尾时，slow 指向的就是倒数第 n 个节点的前一个节点\n执行 slow.next = slow.next.next 删除目标节点\n\nfunction removeNthFromEnd(head: ListNode | null, n: number): ListNode | null {  // 边界：空链表或 n 无效直接返回  if (head === null) return null;  const dummy = new ListNode(0);  dummy.next = head;  let fast: ListNode | null = dummy;  let slow: ListNode | null = dummy;  // fast 先走 n 步  for (let i = 0; i &lt; n; i++) {    fast = fast!.next; // n 合法时不会为 null  }  // fast 和 slow 同步移动，直到 fast 到达末尾  while (fast!.next !== null) {    fast = fast!.next;    slow = slow!.next;  }  // 此时 slow 指向倒数第 n 个节点的前一个节点  if (slow!.next !== null) {    slow!.next = slow!.next.next;  }  return dummy.next;}\n\n20.有效的括号给定一个只包括  '('，')'，'{'，'}'，'['，']'  的字符串  s ，判断字符串是否有效\n有效字符串需满足：\n\n左括号必须用相同类型的右括号闭合。\n左括号必须以正确的顺序闭合。\n每个右括号都有一个对应的相同类型的左括号。\n\n示例 1：输入：s = \"()\"输出：true\n示例 2：输入：s = \"()[]{}\"输出：true\n示例 3：输入：s = \"(]\"输出：false\n示例 4：输入：s = \"([])\"输出：true\n示例 5：输入：s = \"([)]\"输出：false\n提示：\n\n1 &lt;= s.length &lt;= 104\ns  仅由括号  '()[]{}'  组成\n\n思路不难，主要就是栈匹配问题\n\n开括号 → 入栈 stk.push(s[i])\n闭括号 → 元素出栈 stk.pop() 进行匹配  \n若栈空或栈顶不匹配 → 立即返回 false；否则弹出栈顶\n遍历结束 → 栈空返回 true，否则 false\n\nfunction isValid(s: string): boolean {  let stk: string[] = [];  for (let i = 0; i &lt; s.length; i++) {    if (s[i] === \"(\" || s[i] === \"[\" || s[i] === \"{\") {      stk.push(s[i]);    } else if (s[i] === \")\" || s[i] === \"]\" || s[i] === \"}\") {      if (stk.length === 0) {        return false;      }      let curr = stk.pop()!;      if (curr === \"(\" &amp;&amp; s[i] === \")\") {      } else if (curr === \"[\" &amp;&amp; s[i] === \"]\") {      } else if (curr === \"{\" &amp;&amp; s[i] === \"}\") {      } else {        return false;      }    }  }  return stk.length === 0;}\n","categories":["力扣"],"tags":["前端开发","JavaScript","算法"]},{"title":"2025-12-17-前端画布设计Vol.1 实现基础元素渲染和状态控制","url":"/Arknight-notes/posts/43445.html","content":"PixiJS 实现基础元素渲染和状态控制PixiJS 是一个强大的 2D 渲染引擎，它使用 WebGL 和 Canvas 技术来高效地渲染图形，主要通过  ElementRenderer  类实现。\n基本图形渲染实现设计的画布中，基本图形是通过 PixiJS 的 Graphics 类绘制的，支持以下基本图形类型：\n\n矩形 (rect):\ng.rect(0, 0, data.width, data.height);g.fill({ color: fillColor, alpha });g.stroke({ width: strokeWidth, color: strokeColor });\n\n圆角矩形 (rounded rectangle):\ng.roundRect(0, 0, data.width, data.height, data.radius);g.fill({ color: fillColor, alpha });g.stroke({ width: strokeWidth, color: strokeColor });\n\n圆形 (circle):\ng.ellipse(data.width / 2, data.height / 2, data.width / 2, data.height / 2);g.fill({ color: fillColor, alpha });g.stroke({ width: strokeWidth, color: strokeColor });\n\n菱形 (diamond):\ng.poly([  data.width / 2,  0,  data.width,  data.height / 2,  data.width / 2,  data.height,  0,  data.height / 2,]);g.fill({ color: fillColor, alpha });g.stroke({ width: strokeWidth, color: strokeColor });\n\n\n图形属性实现每个图形元素都由  CanvasElement  接口定义，支持以下属性：\n\n背景色 (background):\n\n通过  fill  属性实现\n例如：g.fill({ color: fillColor, alpha })\n使用 PIXI.Color 类处理颜色值\n\n\n边框宽度 (border-width):\n\n通过  strokeWidth  属性实现\n例如：g.stroke({ width: strokeWidth, color: strokeColor })\n\n\n边框颜色 (border-color):\n\n通过  stroke  属性实现\n例如：g.stroke({ width: strokeWidth, color: strokeColor })\n同样使用 PIXI.Color 类处理颜色值\n\n\n透明度 (alpha):\n\n通过 alpha 属性实现\n例如：g.fill({ color: fillColor, alpha })\n\n\n\n在  ElementRenderer  类中，图形渲染的过程包括以下步骤：\n\n首先清空之前的图形绘制：g.clear()\n设置绘制样式（边框宽度、边框颜色、填充颜色、透明度）：\nconst strokeWidth = data.strokeWidth ?? 2;const strokeColor = new PIXI.Color(data.stroke);const fillColor = new PIXI.Color(data.fill);const alpha = data.alpha ?? 1;\n\n根据图形类型绘制对应的形状\n\n设置图形的位置和旋转：\ng.pivot.set(data.width / 2, data.height / 2);g.position.set(data.x + data.width / 2, data.y + data.height / 2);g.rotation = data.rotation;\n\n\n特殊功能\n旋转功能: 通过设置  pivot  点和  rotation  属性实现\n圆角矩形: 使用  g.roundRect(x, y, width, height, radius)  方法\n纹理缓存: 对图像元素使用纹理缓存以提高性能\n动态加载: 图像元素支持异步加载纹理\n\n状态管理机制在您的项目中，状态管理由  zustand  库实现，通过  CanvasStore  集中管理所有画布元素的状态。状态管理包含以下几个核心部分：\n1. 状态结构\nelements: 一个记录对象，包含所有画布元素\nselectedIds: 当前选中的元素 ID 数组\ntool: 当前使用的工具类型\ncurrentStyle: 当前绘制样式（填充色、边框色、边框宽度等）\n\n2. 状态更新机制状态更新通过以下方法实现：\n\naddElement: 添加元素\nupdateElement: 更新元素属性\nremoveElements: 删除元素\nsetSelected: 设置选中的元素\nbatchUpdateElements: 批量更新元素（用于提高性能）\n\n元素渲染机制元素渲染通过  ElementRenderer  类实现，它与状态管理紧密结合：\n1. 状态-渲染同步在  Core_StageManager.ts  中，有一个关键的订阅机制：\nuseStore.subscribe(   (state) =&gt; ({ elements: state.elements, selectedIds: state.selectedIds, tool: state.tool }),   (state) =&gt; {     if (!this.state.destroyed) {       this.elementRenderer.renderElements(state.elements, this.elementLayer, this.state.destroyed)       this.transformerRenderer.renderTransformer(         state.elements,         state.selectedIds,         this.elementRenderer.getSpriteMap(),         this.onHandleDown,         this.viewport.scale.x,       )       // ...//} },   { equalityFn: stateEqualityFn }, )\n每当状态发生变化时，就会触发渲染更新。\n2. 渲染过程ElementRenderer.renderElements  方法遍历所有元素并执行以下操作：\n\n元素映射管理：使用  spriteMap  记录已渲染的元素\n类型处理：根据元素类型（矩形、圆形、文本、图像等）进行相应渲染\n属性应用：将状态中的属性（位置、大小、颜色等）应用到渲染对象\n\n3. 状态与渲染的实时同步当状态变化时，例如：\n\n用户拖动元素时，updateElement  更新元素的  x  和  y  坐标\n用户改变填充颜色时，updateElement  更新  fill  属性\n选择元素时，setSelected  更新  selectedIds\n\n这些状态变更会立即触发渲染更新，确保 UI 与状态保持同步。\n状态控制机制1. 撤销/重做项目集成了撤销/重做功能，通过  UndoRedoManager  和命令模式实现：\n\n每个操作（添加、删除、更新）都创建一个命令对象\n命令对象包含执行和撤销操作的逻辑\nundo  和  redo  方法控制历史记录栈\n\n2. 选择状态管理\nselectedIds  数组跟踪当前选中的元素\n选择变化会触发渲染更新，显示选择框和控制点\nTransformerRenderer 负责渲染选择框和调整手柄\n\n3. 工具状态管理\ntool  属性跟踪当前使用的工具\n工具变化会影响交互行为和光标样式\n不同工具对相同的用户输入（如鼠标点击）会有不同的响应\n\n4. 实时协作项目使用 Yjs 实现实时协作功能：\n\n状态变化通过 Yjs 同步到其他用户\nYjs 的 observe 机制确保本地状态与共享状态同步\n使用事务（transact）保证操作的原子性\n\n性能优化\n状态比较优化：使用  stateEqualityFn  减少不必要的重渲染\n批量更新：batchUpdateElements  方法用于批量更新元素，减少渲染次数\n精灵映射：ElementRenderer  保留精灵映射以避免重复创建/销毁\n防抖机制：虽然代码中注释掉了防抖，但设计中考虑了性能优化\n\n这种架构确保了状态与渲染之间的紧密同步，同时保持了良好的性能和可扩展性。\n","categories":["前端"],"tags":["前端开发"]},{"title":"2025-12-26-关于JavaScript面试算法：字符串，数组，数字反转和转换","url":"/Arknight-notes/posts/47427.html","content":"字符串，数组，数字的转换数字（Number）、字符串（String） 和 数组（Array） 之间的相互转换算是常见操作了，常见转换方向、推荐方法、示例代码及说明如下：\n\n\n\n\n从 → 到\n方法\n示例代码\n说明\n\n\n\n\nNumber → String\nString(num) 或 num.toString()\nlet str = String(123); // “123” let str = (123).toString(); // “123”\n最可靠方式。toString() 可指定进制，如 (10).toString(2) // “1010”。\n\n\nNumber → Array\nString(num).split(‘’)\nlet arr = String(123).split(‘’); // [“1”, “2”, “3”]\n先转为字符串，再按字符拆分成数组（适用于单个数字的位拆分）。\n\n\nString → Number\nNumber(str) 或 +str 或 parseInt(str, 10)\nlet num = Number(“123”); // 123 let num = +”123”; // 123 let num = parseInt(“123”, 10); // 123\n+str 最简洁；parseInt 适合提取整数部分（忽略后缀非数字）。\n\n\nString → Array\nstr.split(separator)\nlet arr = “1,2,3”.split(‘,’); // [“1”, “2”, “3”] let arr = “123”.split(‘’); // [“1”, “2”, “3”]\nsplit(‘’) 按单个字符拆分；split(‘,’) 按逗号等分隔符拆分。\n\n\nArray → String\narr.toString() 或 arr.join(separator)\nlet str = [1,2,3].toString(); // “1,2,3” let str = [1,2,3].join(‘’); // “123” let str = [1,2,3].join(‘-‘); // “1-2-3”\njoin() 更灵活，可自定义分隔符（默认逗号）。\n\n\nArray → Number\n先转为字符串，再转为数字（如 Number(arr.join(‘’))）\nlet num = Number([1,2,3].join(‘’)); // 123\n适用于纯数字数组；若数组含非数字，返回 NaN。\n\n\nArray(Number) → Array(String)\narr.map(String) 或 arr.map(num =&gt; num.toString())\nlet strArr = [1,2,3].map(String); // [“1”, “2”, “3”]\n逐元素转换为字符串，最常用方法。\n\n\nArray(String) → Array(Number)\narr.map(Number) 或 arr.map(str =&gt; parseInt(str, 10))\nlet numArr = [“1”,”2”,”3”].map(Number); // [1, 2, 3]\n逐元素转换为数字；parseInt 更安全处理可能含非纯数字字符串。\n\n\n\n\n数组转数字本质是拼接字符串\nconst arr = ['2', '1', '22', '23'];// 步骤1: 使用 join('') 无分隔符拼接成字符串 const str = arr.join(''); // \"212223\"// 步骤2: 转换为数字 const num = Number(str); // 212223 // 或等价简写：const num = +arr.join('');console.log(num); // 212223（number 类型）\n数组转连续字符串本质也是拼接字符串\nconst arr: string[] = ['X', 'W', 'W'];// 使用 join('')（最常用） const str: string = arr.join(''); // \"XWW\"// 使用 join() 无参数（默认逗号，但空字符串等价） const str2: string = arr.join(); // 注意：默认会得到 \"X,W,W\"，必须传空字符串\n字符串反转：ES6:\nconst reverseString = (str: string): string =&gt; str.split('').reverse().join('');// 使用示例 console.log(reverseString('hello')); // 'olleh'\n手动循环（不依赖内置方法）：\nfunction reverseString(str) {  let reversed = '';  for (let i = str.length - 1; i &gt;= 0; i--) {    reversed += str[i];  }  return reversed;}\n数组反转（Array Reverse）:原地反转：\nconst arr = [1, 2, 3, 4];arr.reverse();  // arr 变为 [4, 3, 2, 1]\n手动实现：\nfunction reverseArray(arr) {  let left = 0, right = arr.length - 1;  while (left &lt; right) {    [arr[left], arr[right]] = [arr[right], arr[left]];    left++;    right--;  }  return arr;}\n数字反转（leetcode # 7）function reverseInt(x) {  const sign = x &lt; 0 ? -1 : 1;  const reversed = sign * parseInt(Math.abs(x).toString().split('').reverse().join(''), 10);  return reversed;}\n补充：数组排序\nnums.sort((a, b) =&gt; a - b);","categories":["算法"],"tags":["JavaScript","算法"]},{"title":"2025-12-27-前端画布设计Vol.3 实时协作（Yjs + Hocuspocus + 持久化）","url":"/Arknight-notes/posts/60421.html","content":"实时协作画布系统：Yjs + Hocuspocus + 持久化概述在设计工具、白板应用和文档编辑器中，多用户同时编辑同一文档的需求日益增长。传统的客户端-服务器模型在这种场景下存在诸多挑战，例如冲突解决、网络延迟和离线支持等。\n为了支持多用户同时编辑画布内容，并具备离线编辑能力，我们采用了 Yjs（一种 CRDT 实现）配合 IndexedDB 和 Hocuspocus 的架构方案。\n核心技术组件Yjs (Y.Map)Yjs 是一个用于创建实时协作应用程序的库，它实现了 Conflict-free Replicated Data Types (CRDTs) 算法。CRDTs 是一种特殊的数据结构，可以在多个副本之间同步，而不需要中央协调，从而保证最终一致性。\nY.Map 是 Yjs 提供的一种共享数据类型，类似于 JavaScript 中的 Map。它的关键特性包括：\n\n自动冲突解决：当多个用户同时修改数据时，Yjs 自动解决冲突\n分布式一致性：保证所有客户端看到相同的数据状态\n高效同步：只传输变更部分，减少网络流量\n\n持久化选项持久化是协作系统的关键组件，不仅需要在客户端存储数据以支持离线使用，还需要在服务端存储数据以实现长期保存和共享。本项目实际实现的持久化策略包括：\n1. IndexedDB（客户端）IndexedDB 是浏览器内置的数据库，用于存储大量结构化数据。在协作系统中，它用于：\n\n使用 y-indexeddb 库创建 IndexeddbPersistence 实例\n为每个房间创建独立的 IndexedDB 存储 (canvas-local-db-${roomId})\n提供 getYDocForRoom、getYElementsForRoom 和 getIndexedDBProviderForRoom 等函数来管理不同房间的数据\n\nimport * as Y from 'yjs';import { IndexeddbPersistence } from 'y-indexeddb';import { HocuspocusProvider } from '@hocuspocus/provider'; // 如需实时同步时导入// 使用 Map 存储不同房间的 Yjs 文档及相关提供者，确保单例管理和数据隔离const roomDocuments = new Map&lt;  string,  {    yDoc: Y.Doc;    yElements: Y.Map&lt;any&gt;;    indexeddbProvider: IndexeddbPersistence;    wsProvider: HocuspocusProvider | null;  }&gt;();/** * 获取或创建指定房间的 Yjs 文档实例 *  * @param roomId 协作房间的唯一标识符 * @returns 该房间对应的 Y.Doc 实例 */export const getYDocForRoom = (roomId: string): Y.Doc =&gt; {  // 若该房间的文档已存在，直接复用以避免重复创建  if (roomDocuments.has(roomId)) {    return roomDocuments.get(roomId)!.yDoc;  }  // 创建新的 Yjs 文档实例  const yDoc = new Y.Doc();  // 获取画布元素的核心数据结构（Y.Map，用于存储所有 CanvasElement）  const yElements = yDoc.getMap&lt;any&gt;('elements');  // 初始化 IndexedDB 持久化提供者  // 数据库名称动态包含 roomId，确保不同房间的数据互不干扰  const indexeddbProvider = new IndexeddbPersistence(`canvas-local-db-${roomId}`, yDoc);  // 将文档相关信息存入 Map，便于后续访问和管理  roomDocuments.set(roomId, {    yDoc,    yElements,    indexeddbProvider,    wsProvider: null, // 初始为空，后续可动态绑定 HocuspocusProvider 以实现实时协作  });  return yDoc;};\n\n离线数据存储：即使用户断网，数据也不会丢失\n快速本地访问：减少对服务器的依赖\n大容量存储：相比 localStorage，支持更大的数据量\n\n2. SQLite（服务端）SQLite 作为服务端数据库，用于持久化存储画布内容：\n\n关系型结构：提供 SQL 查询能力\n轻量级：无需单独的服务器进程\n跨平台：可在多种环境中运行\n服务端存储：确保数据在服务端持久化\n\n// 服务端数据库实现 (ALD_Backend/src/db.ts)import { Database } from \"bun:sqlite\";const db = new Database(\"collab.sqlite\");// 启用 WAL 模式以提高并发性能db.exec(\"PRAGMA journal_mode = WAL;\");// 房间表，包含 content BLOB 字段存储 Yjs 二进制数据db.run(`  CREATE TABLE IF NOT EXISTS rooms (    id TEXT PRIMARY KEY,    name TEXT NOT NULL,    creator_id TEXT NOT NULL,    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,    content BLOB, -- Yjs 二进制数据    FOREIGN KEY (creator_id) REFERENCES users(id)  )`);// Hocuspocus 数据库扩展实现 (ALD_Backend/src/collab.ts)const dbExtension = new HocuspocusDB({  fetch: async ({ documentName }) =&gt; {    const roomId = getRoomId(documentName);    console.log(      `[Yjs] Fetching data for RoomID: ${roomId}, Original documentName: ${documentName}`    );    const query = db.query(\"SELECT content FROM rooms WHERE id = $id\");    const row = query.get({ $id: roomId }) as {      content: Uint8Array | null;    } | null;    if (row &amp;&amp; row.content !== null &amp;&amp; row.content !== undefined) {      if (row.content.length &gt; 0) {        console.log(          `[Yjs] Returning data with size: ${row.content.length} bytes`        );        return new Uint8Array(row.content);      } else {        console.log(`[Yjs] content is empty, creating new Yjs document`);        const ydoc = new Y.Doc();        ydoc.getMap(\"elements\"); // 存储图形元素        return Y.encodeStateAsUpdate(ydoc);      }    }    console.log(`[Yjs] No valid data found, creating new Yjs document`);    const ydoc = new Y.Doc();    ydoc.getMap(\"elements\"); // 存储图形元素    return Y.encodeStateAsUpdate(ydoc);  },  store: async ({ documentName, state }) =&gt; {    const roomId = getRoomId(documentName);    try {      console.log(        `[Yjs] Saving data for RoomID: ${roomId}, State size: ${state.length} bytes, Original documentName: ${documentName}`      );      if (state.length &gt; 0) {        const roomCheck = db.query(\"SELECT id FROM rooms WHERE id = $id\");        const roomExists = roomCheck.get({ $id: roomId });        if (!roomExists) {          console.error(            `[Yjs] Room ${roomId} does not exist, cannot save data`          );          return;        }        const update = db.query(          \"UPDATE rooms SET content = $blob WHERE id = $id\"        );        update.run({ $blob: state, $id: roomId });        console.log(`[Yjs] Data saved successfully for RoomID: ${roomId}`);      } else {        console.log(          `[Yjs] Skipping save for RoomID: ${roomId} as state is empty`        );      }    } catch (error) {      console.error(`[Yjs] Save failed for ${roomId}:`, error);    }  },});\nHocuspocus ProviderHocuspocus 是一个协作编辑框架，提供了 Yjs 的服务器端实现。它负责：\n\n多客户端同步：协调多个客户端之间的数据同步\nWebSocket 连接管理：建立持久连接\n房间管理：隔离不同协作空间的数据\n与多种持久化后端集成：可连接到数据库、文件系统等\n\n系统架构设计graph TB    subgraph \"Frontend Application (React/Vue)\"        A[Canvas UI Components]        B[State Management&lt;br/&gt;Zustand/Pinia]        C[Yjs Document&lt;br/&gt;Shared Data]        D[IndexedDB&lt;br/&gt;Local Persistence]    end    subgraph \"Backend Services\"        E[Hono Server&lt;br/&gt;Port 3000]        F[RESTful API&lt;br/&gt;Auth/RM]        G[SQLite DB&lt;br/&gt;Persistence]    end    subgraph \"WebSocket Services\"        H[Hocuspocus Server&lt;br/&gt;Port 1234]        I[Yjs Extensions&lt;br/&gt;DB/Storage]    end    A &lt;--&gt; C    B &lt;--&gt; C    C &lt;--&gt; D    C &lt;--&gt; H    E &lt;--&gt; F    E &lt;--&gt; G    F &lt;--&gt; H    H &lt;--&gt; I    I &lt;--&gt; G    style A fill:#87CEEB    style B fill:#98FB98    style C fill:#FFD700    style D fill:#DDA0DD    style E fill:#F0E68C    style F fill:#FFA07A    style G fill:#BA55D3    style H fill:#20B2AA    style I fill:#FF69B4\ngraph LR    subgraph \"Client A\"        A[Y.Map&lt;br/&gt;Shared Data]        B[IndexedDB&lt;br/&gt;Local Persistence]    end    subgraph \"Server\"        C[Hocuspocus&lt;br/&gt;Server]        D[SQLite DB&lt;br/&gt;Persistence]    end    subgraph \"Client B\"        E[Y.Map&lt;br/&gt;Shared Data]        F[IndexedDB&lt;br/&gt;Local Persistence]    end    A &lt;--&gt; C    E &lt;--&gt; C    B &lt;--&gt; D    F &lt;--&gt; D    C &lt;--&gt; D    style A fill:#FFD700    style B fill:#DDA0DD    style C fill:#20B2AA    style D fill:#BA55D3    style E fill:#FFD700    style F fill:#DDA0DD\n数据流向\n用户操作更新本地 Y.Map\n变更自动同步到 IndexedDB（本地持久化）\n变更通过 Hocuspocus 同步到服务器和其他客户端\n服务器将变更存储到 SQLite 数据库\n其他客户端接收变更并更新本地 Y.Map\n\n实现细节1. 初始化协作环境import * as Y from \"yjs\";import { IndexeddbPersistence } from \"y-indexeddb\";import { HocuspocusProvider } from \"@hocuspocus/provider\";// 创建 Yjs 文档const ydoc = new Y.Doc();// 获取共享的 Y.Map 用于存储画布元素const yElements = ydoc.getMap(\"elements\");// 设置 IndexedDB 持久化const indexeddbProvider = new IndexeddbPersistence(\"canvas-room\", ydoc);// 设置 Hocuspocus 提供者export const initWsProvider = (roomId: string, token: string) =&gt; {  // 如果房间不存在，先创建  if (!roomDocuments.has(roomId)) {    getYDocForRoom(roomId);  }  const roomData = roomDocuments.get(roomId)!;  // 如果已存在 WebSocket 提供者，先销毁  if (roomData.wsProvider) {    roomData.wsProvider.destroy();  }  // 创建新的 WebSocket 提供者，并关联 Yjs 文档  console.log(    `[Room ${roomId}] Initializing WebSocket Provider with token: ${token}`  );  const wsProvider = new HocuspocusProvider({    // 确保 URL 结尾规范，方便拼接    url: `ws://localhost:3000/collaboration/${roomId}`,    name: roomId, // Hocuspocus 会将其拼接为 /collaboration/{roomId}    token: token,    // 明确指定要同步的文档    document: roomData.yDoc,  });  console.log(wsProvider);  // 监听 WebSocket 连接状态  wsProvider.on(\"status\", (event: any) =&gt; {    console.log(`[Room ${roomId}] WebSocket status:`, event.status); // 'connected' or 'disconnected'  });  // 更新房间数据中的 WebSocket 提供者  roomData.wsProvider = wsProvider;  return wsProvider;};\n2. 画布元素管理interface CanvasElement {  id: string;  type: string;  x: number;  y: number;  width: number;  height: number;  color: string;}// 添加元素yElements.set(elementId, {  id: elementId,  type: \"rectangle\",  x: 100,  y: 100,  width: 200,  height: 150,  color: \"#ff0000\",});// 监听元素变化yElements.observeDeep((events) =&gt; {  events.forEach((event) =&gt; {    // 处理添加、更新、删除事件  });});\n3. React 状态集成import { create } from \"zustand\";import { useEffect } from \"react\";interface CanvasStore {  ydoc: Y.Doc;  yElements: Y.Map&lt;CanvasElement&gt;;  elements: Map&lt;string, CanvasElement&gt;;  addElement: (element: CanvasElement) =&gt; void;  updateElement: (id: string, updates: Partial&lt;CanvasElement&gt;) =&gt; void;  deleteElement: (id: string) =&gt; void;}export const useCanvasStore = create&lt;CanvasStore&gt;((set, get) =&gt; ({  // ... store implementation}));\n4. 离线支持实现离线支持是通过 IndexedDB 实现的：\n\n当用户在线时，所有操作同步到服务器和其他客户端\n当用户离线时，操作仅保存在本地 IndexedDB 中\n当用户重新连接时，本地更改自动同步到服务器\n\n// 等待 IndexedDB 数据加载await indexeddbProvider.whenSynced;// 监听连接状态provider.on(\"synced\", () =&gt; {  console.log(\"Document synced with server\");});\n优化后续还可以实现批量更新，防抖，服务端数据验证等优化。\n","categories":["归档"]},{"title":"2025-12-18-前端画布设计Vol.2 实现富文本编辑","url":"/Arknight-notes/posts/10362.html","content":"画布项目中富文本编辑器的实现浅析0x00 概述该画布项目采用 wangEditor（v5 版本）的 React 封装组件 @wangeditor/editor-for-react 实现富文本编辑功能。主要通过两个组件协作完成：\n\nRichTextEditor.tsx：核心富文本编辑器封装，负责工具栏和编辑区的渲染与配置。\nBottomTextEditor.tsx：底部面板式编辑器，仅在选中单个文本元素时显示，将富文本编辑器集成到画布操作流程中，支持实时更新元素内容并记录撤销/重做操作。\n\n主要形式是一个底部面板，单击文本元素会出现\n0x01 RichTextEditor 组件实现RichTextEditor 是对 wangEditor 的二次封装，提供可复用的富文本编辑器\nimport \"@wangeditor/editor/dist/css/style.css\";import { useState, useEffect } from \"react\";import { Editor, Toolbar } from \"@wangeditor/editor-for-react\";const toolbarConfig: Partial&lt;IToolbarConfig&gt; = {  toolbarKeys: [    \"bold\",    \"italic\",    \"underline\",    \"through\",    \"|\",    \"fontSize\",    \"fontFamily\",    \"color\",    \"bgColor\",    \"|\",    \"justifyLeft\",    \"justifyCenter\",    \"justifyRight\",    \"|\",    \"undo\",    \"redo\",  ],};const editorConfig: Partial&lt;IEditorConfig&gt; = {  placeholder: \"请输入文本...\",  autoFocus: true,};useEffect(() =&gt; {  return () =&gt; {    if (editor == null) return;    editor.destroy();    setEditor(null);  };}, [editor]);return (  &lt;div className=\"...\"&gt;    &lt;Toolbar editor={editor} defaultConfig={toolbarConfig} mode=\"simple\" /&gt;    &lt;Editor      defaultConfig={editorConfig}      value={value}      onCreated={setEditor}      onChange={(editor) =&gt; onChange(editor.getHtml())}      mode=\"simple\"      style={{ height: \"200px\", overflowY: \"auto\" }}    /&gt;  &lt;/div&gt;);\n\n工具栏配置（toolbarConfig） 通过 toolbarKeys 指定显示的菜单键（加粗、斜体、下划线、删除线、字体大小/家族、颜色、背景色、对齐方式）以及撤销/重做。\n编辑器配置（editorConfig） 设置占位符和自动聚焦。wangEditor 支持更丰富的配置（如最大长度、自定义菜单等），此处保持最小化。\n生命周期管理 使用 useEffect 在组件卸载或 editor 实例变化时调用 editor.destroy()，防止内存泄漏。\n内容同步value props 控制初始 HTML，onChange 回调通过 editor.getHtml() 获取最新 HTML 内容并向上通知。\n\n0x02 BottomTextEditor 组件实现BottomTextEditor 将富文本编辑器集成到画布状态管理中，仅针对选中单个文本元素时激活。\nconst { selectedIds, elements, updateElement } = useStore();const selectedId = selectedIds.length === 1 ? selectedIds[0] : null;const element = selectedId ? elements[selectedId] : null;const [localHtml, setLocalHtml] = useState(\"\");useEffect(() =&gt; {  if (element &amp;&amp; element.type === \"text\") {    setLocalHtml(element.text || \"\");  }}, [element?.id, element?.text]);const handleChange = (html: string) =&gt; {  setLocalHtml(html);  const initialText = element.text || \"\";  updateElement(element.id, { text: html });  const updateCommand = new UpdateElementPropertyCommand(    { id: element.id, property: \"text\", oldValue: initialText, newValue: html },    \"修改文本内容\"  );  undoRedoManager.executeCommand(updateCommand);};return (  &lt;div className=\"fixed bottom-8 ... animate-slide-up\"&gt;    &lt;RichTextEditor value={localHtml} onChange={handleChange} /&gt;  &lt;/div&gt;);\n\n选中元素判断 从 Zustand store（canvasStore）获取选中 ID 和元素集合，仅当选中单个文本类型元素时渲染编辑器。\n本地状态（localHtml） 使用 useState 维护本地 HTML 副本，并在选中元素变化时通过 useEffect 同步 store 中的 element.text。 此设计主要解决中文输入法（IME）组成阶段的问题：在拼音输入过程中，wangEditor 的 onChange 会频繁触发，若直接更新全局 store，可能导致输入延迟、光标跳动或内容混乱。通过本地状态缓冲实时变化，避免不必要的 store 更新。\n内容变更处理（handleChange）\n更新本地状态。\n实时调用 updateElement 更新画布 store，驱动 canvas 重新渲染文本元素。\n创建 UpdateElementPropertyCommand 命令并执行，支持撤销/重做（undo/redo）。命令记录旧值和新值，处理历史操作\n\n\n\n0x03 关键问题解决与设计\n输入法兼容性 中文输入过程中，组成事件（composition）会多次触发编辑器变更。若直接在 onChange 中更新全局状态，可能导致性能问题或输入体验不佳。本实现通过本地状态缓冲 setLocalHtml(html) 缓解该问题\n实时渲染与历史管理 实时更新 store 确保画布文本即时反映变更；同时通过命令模式记录操作，实现完整的 undo/redo 支持。\n\n0x04 当前实现的风险与不足分析当前实现虽已满足基础富文本编辑需求，但是还是有一些问题\n\n输入法体验优化不彻底 虽通过本地状态缓冲缓解了 IME 组成阶段的频繁更新问题，但未监听 compositionstart/compositionend 事件。在某些极端输入场景（如快速切换输入法或长句输入）下，仍可能出现光标偏移或临时内容丢失的现象。\n内容净化与 XSS 防护不足 完全依赖 wangEditor 内置的有限转义机制，未引入 DOMPurify 等专用净化库。在用户插入外部链接、图片或自定义 HTML 时，存在潜在的存储型或 DOM 型 XSS 风险，尤其在内容后续导出或分享场景中。\n样式与对齐精度问题 wangEditor 生成的 HTML 结构（如多层 span/div 嵌套）与画布自定义文本渲染逻辑可能不完全匹配，导致编辑器中预览效果与画布最终渲染存在细微差异（如行高、字间距、对齐方式）。\n性能与内存管理 频繁的实时更新（onChange 触发 store 更新与命令记录）在长文本场景下可能导致轻微卡顿；此外，未对编辑器实例进行复用，当快速切换不同文本元素时会反复创建/销毁实例，增加内存开销。\n\n面对这些问题后续都可以做一些改进：\n\n引入 DOMPurify 进行内容净化来处理 XSS 问题 在内容存储前（提交到 store 或后端）及渲染时统一调用 DOMPurify.sanitize，对 HTML 进行严格过滤。自定义白名单以保留 wangEditor 支持的必要标签与属性，同时移除所有事件处理器及危险协议。\n完善输入法兼容性 在 RichTextEditor 中监听 composition 事件，在组成阶段暂不触发 handleChange，仅在 compositionend 后统一更新 store 与命令记录，进一步消除输入延迟与光标问题。\n性能优化 实现编辑器实例复用（单一全局实例，根据选中元素动态切换内容），并在长文本时增加防抖处理，减少不必要的 store 更新与命令执行。\n\n0x05 总结主要就是 wangEditor 的 React 封装，结合 Zustand 状态管理和命令模式，来适配画布类项目的文本编辑需求，实现了基础的文本编辑功能\n","categories":["前端"],"tags":["前端开发"]},{"title":"2025-12-27-算法刷题-关于链表操作","url":"/Arknight-notes/posts/40452.html","content":"后悔数据结构当初没有好好学的第n天现在恶补，知识学爆\n\n基础操作：\n\n查找元素：根据值查找节点位置\n指定位置插入：在特定位置插入新节点\n指定位置获取：获取特定位置的节点值\n指定位置删除：删除特定位置的节点\n获取长度：统计链表中节点的数量\n\n\n\n\n\n\n题目描述\n主要实现思路\n\n\n\n\nBM1\n反转链表\n使用三指针（prev、curr、next）迭代反转：保存下一个节点，反转当前指向，移动指针。返回prev作为新头。\n\n\nBM2\n链表内指定区间反转\n引入虚拟头结点定位第m-1个节点（pre）。然后在[m,n]区间执行(n-m)次头插法（逐个将下一个节点插入pre后）。\n\n\nBM3\n链表中的节点每k个一组翻转\n每k个节点为一组，使用反转链表方法局部反转。若剩余不足k个，则保持原序。递归或迭代均可，推荐迭代分段处理。\n\n\nBM4\n合并两个排序的链表\n双指针模拟归并排序：比较两个链表当前节点值，小者接入新链表，移动对应指针。处理剩余部分。\n\n\nBM5\n合并k个已排序的链表\n使用小根堆（优先队列）维护k个链表头结点，每次弹出最小值并接入结果链表，同时推入其下一个节点。\n\n\nBM6\n判断链表中是否有环\n快慢指针（Floyd判圈算法）：fast每次走2步，slow走1步。若相遇则有环，否则无环。\n\n\nBM7\n链表中环的入口结点\n先用快慢指针相遇于环内某点，再令一指针从头启动，与慢指针同步移动，相遇处即环入口。\n\n\nBM8\n链表中倒数最后k个结点\n快慢指针：fast先走k步，然后slow与fast同步移动，至fast到尾时slow即为倒数第k个节点。\n\n\nBM9\n删除链表的倒数第n个节点\n同BM8定位倒数第n+1个节点（pre），然后pre.next = pre.next.next删除目标节点。注意头节点特殊处理。\n\n\nBM10\n两个链表的第一个公共结点\n双指针同步走：先计算长度差，长者先走差值步；或让指针走完一链表后换另一链表，总路程相等时相遇即公共节点。\n\n\nBM11\n链表相加(二)\n模拟加法从低位到高位（需先反转链表或用栈），处理进位。结果可能需反转回原序。\n\n\nBM12\n单链表的排序\n归并排序（自底向上）：分段合并有序子链表，或快慢指针找中点递归归并。时间O(n log n)。\n\n\nBM13\n判断一个链表是否为回文结构\n快慢指针找中点，反转后半部分，与前半部分逐节点比较值是否相等。恢复链表可选。\n\n\nBM14\n链表的奇偶重排\n分离奇偶位节点成两个链表（odd、even），然后even接odd尾部。注意偶数长度处理。\n\n\nBM15\n删除有序链表中重复的元素-I\n单指针遍历：若当前节点与下一节点值相同，跳过下一节点（保留首次出现）。\n\n\nBM16\n删除有序链表中重复的元素-II\n引入虚拟头结点，双指针或单指针遍历：若连续重复，跳过整个重复段（一个不留）。\n\n\n\n\n\n一般会给出一个最基础的链表\nfunction ListNode(val, next) {    this.val = (val === undefined ? 0 : val);    this.next = (next === undefined ? null : next);}\n\n节点包含两个成员：\nval：存储节点的值，通常为整数（int），题目中 |val| ≤ 1000。\nnext：指向下一个节点的指针（引用），类型为同类 ListNode*（或 ListNode），初始可能为 NULL/null/None\n\n\n无哑头节点（dummy head）：输入的 head 就是真实头结点（有有效值），除非题目特别说明\n单向链表：只能从头到尾遍历，无前向指针\n输入形式：\n函数签名通常为 ListNode* head（或类似），可能额外传入其他参数（如 m、n、k 等）\n空链表：head = NULL / null / None\n\n\n输出形式：\n大多数题目要求返回新的头结点（ListNode*）\n操作通常要求原地修改，以满足空间复杂度 O(1)\n\n\n\n\n常见操作单链表常见操作的实现方法以下针对单链表（节点结构为 val 和 next）的几种常见操作，提供标准、高效的实现思路。所有操作均基于从头结点开始遍历，时间复杂度与空间复杂度分析清晰。假设节点定义如下（以 JavaScript 为例，其他语言类似）：\nfunction ListNode(val, next) {    this.val = val;    this.next = next || null;}\n1. 查找元素：根据值查找节点位置（返回位置或节点）思路：从头遍历，逐个比较节点值，直到找到匹配值或到达链表末尾。\n实现要点：\n\n返回第一个匹配节点的位置（从 1 开始）或节点本身。\n未找到返回 -1 或 null。\n\nfunction findNode(head, target) {    let pos = 1;    let curr = head;    while (curr !== null) {        if (curr.val === target) {            return pos;  // 或 return curr; 返回节点本身        }        curr = curr.next;        pos++;    }    return -1;  // 未找到}\n\n时间复杂度：O(n)\n空间复杂度：O(1)\n\n2. 指定位置插入：在第 i 个位置插入新节点（i 从 1 开始）思路：遍历到第 i-1 个节点，将新节点插入其后。特殊处理插入到头部（i=1）。\n实现要点：\n\n若 i=1，新节点成为新头。\n若 i &gt; 长度，插入失败或插入尾部（视题目要求）。\n\nfunction insertAtPosition(head, i, val) {    let newNode = new ListNode(val);    if (i === 1) {        newNode.next = head;        return newNode;  // 新头结点    }        let curr = head;    for (let pos = 1; pos &lt; i - 1 &amp;&amp; curr !== null; pos++) {        curr = curr.next;    }    if (curr === null) return head;  // i 超出范围，不插入        newNode.next = curr.next;    curr.next = newNode;    return head;}\n\n时间复杂度：O(i) → 最坏 O(n)\n空间复杂度：O(1)\n\n3. 指定位置获取：获取第 i 个节点的値（i 从 1 开始）思路：遍历 i-1 步，直接返回当前节点的值。\nfunction getAtPosition(head, i) {    let curr = head;    for (let pos = 1; pos &lt; i &amp;&amp; curr !== null; pos++) {        curr = curr.next;    }    return curr ? curr.val : null;  // 未找到返回 null}\n\n时间复杂度：O(i) → 最坏 O(n)\n空间复杂度：O(1)\n\n4. 指定位置删除：删除第 i 个节点（i 从 1 开始）思路：遍历到第 i-1 个节点，修改其 next 指向跳过第 i 个节点。特殊处理删除头结点。\nfunction deleteAtPosition(head, i) {    if (head === null) return null;    if (i === 1) return head.next;  // 删除头结点        let curr = head;    for (let pos = 1; pos &lt; i - 1 &amp;&amp; curr !== null; pos++) {        curr = curr.next;    }    if (curr === null || curr.next === null) return head;  // i 超出范围        curr.next = curr.next.next;  // 跳过第 i 个节点    return head;}\n\n时间复杂度：O(i) → 最坏 O(n)\n空间复杂度：O(1)\n\n5. 获取链表长度（节点数量）思路：遍历链表，累计计数。\nfunction getLength(head) {    let len = 0;    let curr = head;    while (curr !== null) {        len++;        curr = curr.next;    }    return len;}\n\n时间复杂度：O(n)\n空间复杂度：O(1)\n\n\n反转链表BM1  | 全量反转链表给定一个单链表的头结点pHead(该头节点是有值的，比如在下图，它的val是1)，长度为n，反转该链表后，返回新链表的表头。\n数据范围： 0≤n≤10000≤n≤1000\n要求：空间复杂度 O(1)O(1) ，时间复杂度 O(n)O(n) 。\n如当输入链表{1,2,3}时，\n经反转后，原链表变为{3,2,1}，所以对应的输出为{3,2,1}。\n以上转换过程如下图所示：\n\n\n解法：\n\n初始化 prev 为 null（新链表的尾部）。\ncurrent 从链表头节点开始。\n在循环中：\n暂存 next = current.next（避免指针丢失）。\n将 current.next 指向 prev（反转当前指针）。\n更新 prev = current（前移 prev）。\n更新 current = next（前移 current）。\n\n\n循环结束后，prev 指向原链表的尾节点（新头节点），更新 list.head = prev。\n\n其实就是三指针原地反转\n\nexport function ReverseList(head: ListNode): ListNode {    let prev = null;    let curr = head;    while (curr !== null) {            // 保存下一个节点，防止断链        let next = curr.next;        // 反转当前节点的指向        curr.next = prev;        // 指针向前移动        prev = curr;        curr = next;    }    // prev 指向反转后的新头结点    return prev;};\nBM2  | 反转链表部分区间给定一个单链表的头结点 head，长度为 n，反转该链表从位置 m 到 n 的部分，返回反转后的链表。\n数据范围： 0≤m≤n≤n≤1000 ，链表中任意节点的值满足 |val|≤1000\n例如：给出的链表为 1→2→3→4→5→NULL1→2→3→4→5→NULL, m=2,n=4m=2,n=4,返回 1→4→3→2→5→NULL1→4→3→2→5→NULL.  \n要实现原地反转指定区间，需要：\n\n找到反转区间的前一个节点（pre），即第 m-1 个节点。\n找到反转区间的最后一个节点（记为 end），即第 n 个节点。\n将 [m, n] 区间使用经典链表反转方法进行原地反转。\n正确连接反转后的区间与前后部分：\npre.next 指向反转后区间的新的头节点（原第 n 个节点）。\n反转后区间的尾节点（原第 m 个节点）指向 end.next。\n\n\n\n关键操作：\n\n先遍历定位到 pre 和反转区间的起始节点 start（第 m 个节点）。\n然后在 [start, end] 区间内使用三指针迭代反转。\n最后调整指针连接。\n\n\nexport function reverseBetween(head: ListNode | null, m: number, n: number): ListNode | null {    if (head === null || m === n) return head;    const dummy = new ListNode(0);    dummy.next = head;    let pre = dummy;    // 移动到第 m-1 个节点    for (let i = 0; i &lt; m - 1; i++) {        pre = pre.next!;    }    let start = pre.next!;   // 第 m 个节点（反转区间的原头部）    let then = start.next;   // 第 m+1 个节点（待头插的节点）    // 执行 (n - m) 次头插    for (let i = 0; i &lt; n - m; i++) {        start.next = then.next;   // 从原区间摘除 then        then.next = pre.next;     // then 插入 pre 之后（成为新头部）        pre.next = then;          // 更新 pre 的 next        then = start.next;        // 更新 then 为下一个待移动节点    }    return dummy.next;}\n\n","categories":["力扣"],"tags":["数据结构","链表","算法"]},{"title":"2025-10-28 前端学习-关于网络请求（Fetch、Axios、Ajax、XHR）","url":"/Arknight-notes/posts/61262.html","content":"XHR、Ajax、Fetch、Axios当涉及前端网络请求时，有许多工具/技术可供选择，包括 Fetch、Axios、Ajax 和 XHR 等。这些技术在发送和处理HTTP请求方面提供了不同的功能和方法。本文将深入探讨这些技术的特点、优势和用法，帮你更好地理解并选择最适合项目需求的技术。\n基本概念Fetch、Axios、Ajax 和XHR都是前端用于发送HTTP请求的工具或技术：\n\nXHR：一种在浏览器中用于与服务器进行异步通信的API，通过发送HTTP请求并处理服务器返回的数据，实现页面的无刷新更新和动态交互。\n\nAjax：通过在浏览器和服务器之间进行异步通信，实现部分页面更新和动态交互，提升用户体验；可以在不重新加载整个页面的情况下，通过JavaScript发送HTTP请求到服务器，并处理服务器返回的数据；减少带宽消耗，提高页面加载速度；提高用户交互性，实现更多的动态效果和实时更新。\n\nFetch：一种现代化的网络请求方法，通过使用 Promise 处理异步操作，简洁而直观地发送HTTP请求、处理响应，并支持各种功能和API，如设置请求头、传递参数、处理流数据、上传下载文件等。\n\nAxios：一个基于Promise的现代化HTTP客户端，是目前最流行的 HTTP 客户端，可以在浏览器和Node.js环境中发送HTTP请求，并具有拦截请求和响应、支持并发请求、提供丰富的API等功能。\n\n\n下面就来看看这些技术都是怎么用的，以及都有什么特点\n\nXHRXMLHttpRequest 是一个内置的 JavaScript 对象，XMLHttpRequest（XHR）对象用于与服务器交互。通过 XMLHttpRequest 可以在不刷新页面的情况下请求特定 URL，获取数据。这允许网页在不影响用户操作的情况下，更新页面的局部内容。\nXMLHttpRequest 在 AJAX 编程中被大量使用。尽管名称包含XML，XMLHttpRequest 也可以用于获取任何类型的数据，而不仅仅是 XML。它甚至支持 HTTP 以外的协议（包括 file:// 和 FTP）。\nXMLHttpRequest 存在一些缺点：\n\n语法复杂性：使用原始的 XMLHttpRequest 进行复杂的 AJAX 请求需要编写更多的代码，并手动处理状态管理、错误处理等方面的逻辑。相比之下，Axios 和 Fetch API 提供了更简单和直观的语法，使得发送和处理 HTTP 请求更加方便。\n\n功能限制：XHR 提供的功能相对较少，需要手动设置请求头、处理超时、取消请求等。而 Axios 和 Fetch API 提供了更丰富的功能，如拦截请求和响应、自动转换数据格式、请求取消等。\n\nXSRF（跨站请求伪造）保护：在 Axios 中，可以通过设置 withCredentials 选项来自动处理 XSRF 保护。然而，在 XMLHttpRequest 和 Fetch API 中，需要手动设置请求头来实现类似的保护。\n\n错误处理：XHR 的错误处理较为繁琐，需要在回调函数中进行错误判断。而 Axios 和 Fetch API 使用 Promise 和 async/await 语法，能够更便捷地处理请求和响应的错误。\n\n仅限于浏览器环境：XMLHttpRequest 是浏览器提供的 API，因此只能在浏览器环境中使用，无法在其他环境中（如服务器端）直接使用。\n\n\n请求步骤使用 XMLHttpRequest 发送请求的步骤如下：\n\n创建XMLHttpRequest对象：\n\nlet xhr = new XMLHttpRequest();\n\n设置请求参数：\n\nxhr.open('GET', 'https://example.com/api/data', true);\n\n设置请求头（可选）：\n\nxhr.setRequestHeader('Content-Type', 'application/json');\n\n监听状态变化：\n\nxhr.onreadystatechange = () =&gt; {    if (xhr.readyState === 4) {      if (xhr.status === 200) {        // 请求成功，处理响应        console.log(xhr.responseText);      } else {        // 请求失败        console.error('请求失败');      }    }  };\n\n发送请求：\n\nxhr.send();\n完整代码如下：\nvar xhr = new XMLHttpRequest();  xhr.open('GET', 'https://api.example.com/data', true);  xhr.onreadystatechange = () =&gt; {    if (xhr.readyState === 4) {      if (xhr.status === 200) {        // 请求成功，处理响应        console.log(xhr.responseText);      } else {        // 请求失败        console.error('请求失败');      }    }  };  xhr.send();\n这里创建了一个XMLHttpRequest对象，并使用open()方法设置了一个GET请求类型和URL。然后，通过监听onreadystatechange事件来判断请求的状态并处理响应。当readyState为4时，表示请求已完成，此时可以通过status属性判断请求是否成功（200表示成功）。如果成功，可以通过responseText属性获取服务器返回的数据进行处理。如果失败，将到控制台输出错误信息。\nopenXMLHttpRequest 的 open() 方法用于初始化一个请求。open() 方法接受三个必填参数和一个可选参数，它们是：\n\nmethod: 表示请求的 HTTP 方法，例如 GET、POST、PUT 等。\n\nxhr.open(\"GET\", \"https://example.com/api/data\", true);\n\nurl: 表示请求的 URL 地址。\n\nxhr.open(\"GET\", \"https://example.com/api/data\", true);\n\nasync: 表示请求是否异步执行，即是否使用异步模式。默认为 true，表示异步执行；false 表示同步执行。\n\nxhr.open(\"GET\", \"https://example.com/api/data\", true);\n\nusername (可选): 表示用于进行 HTTP 认证的用户名。\n\nxhr.open(\"GET\", \"https://example.com/api/data\", true, \"username\");\n\npassword (可选): 表示用于进行 HTTP 认证的密码。\n\nxhr.open(\"GET\", \"https://example.com/api/data\", true, \"username\", \"password\");\n综合起来，open() 方法的完整语法如下：\nxhr.open(method, url, async, username, password);\n请求头和响应头可以使用 setRequestHeader() 方法设置 XMLHttpRequest 的请求头。这个方法接受两个参数：头字段的名称和值。\nxhr.setRequestHeader(\"Content-Type\", \"application/json\");  xhr.setRequestHeader(\"Authorization\", \"Bearer token123\");\n这里使用 setRequestHeader() 方法设置了两个请求头：Content-Type 和 Authorization。第一个参数是头字段的名称，第二个参数是头字段的值。\n可以使用 getResponseHeader() 方法或者 getAllResponseHeaders() 方法来获取 XMLHttpRequest 的响应头。\n\ngetResponseHeader()：通过指定头字段的名称，可以获取指定的响应头字段的值。\n\nconst contentType = xhr.getResponseHeader(\"Content-Type\");\n这里使用 getResponseHeader() 方法获取了名为 Content-Type的响应头字段的值。\n\ngetAllResponseHeaders()：该方法返回一个包含所有响应头信息的字符串。\n\nconst headers = xhr.getAllResponseHeaders();\n这里使用 getAllResponseHeaders() 方法获取了所有响应头信息，并将其存储在名为 headers 的变量中。\n这里返回的 headers 是一个包含所有响应头信息的字符串。该字符串中每一行表示一个响应头字段，具有以下形式：\nHeaderName: HeaderValue\n例如，如果响应头中包含 Content-Type 和 Authorization 字段，那么返回的 headers 字符串可能如下所示：\nContent-Type: application/json  Authorization: Bearer token123\n可以使用适当的方法（如字符串解析）将这个字符串进行进一步处理，以获取特定的响应头字段的名称和值。\n注意，要在调用 open() 方法之后、发送请求之前使用 setRequestHeader() 方法来设置请求头，以确保设置能够生效。同样，要在接收到响应之后才能使用 getResponseHeader() 或 getAllResponseHeaders() 来获取响应头信息。\nreadyState上面示例中的 readyState 是 XMLHttpRequest 对象的一个属性，用于表示请求的状态。该属性有以下五种可能的取值：\n\n0 (未初始化): XMLHttpRequest 对象已创建，但尚未调用 open 方法。\n1 (载入中): open 方法已调用，但尚未调用 send 方法。\n2 (载入完成): send 方法已调用，并且响应头和响应状态已经可用。\n3 (交互中): 正在接收响应数据，此时部分响应内容可能已经可以访问了。\n4 (完成): 响应数据接收完成，整个请求过程已经完全结束。\n\n通常情况下，我们主要关注 readyState 为 4 的状态，即请求完成状态。在这个状态下，我们可以通过检查 status 属性来获取请求的结果（比如响应状态码），并通过 responseText 或 responseXML 属性来获取服务器返回的数据。\n注意，readyState 属性是只读的，我们不能直接修改它的值。它会在请求过程中自动更新，我们可以通过监听 readystatechange 事件来进行相应的处理。\nstatusstatus 是 XMLHttpRequest 对象的一个属性，用于表示 HTTP 状态码。\nHTTP 状态码是服务器对请求处理的结果进行响应的标准化数字代码。常见的一些 HTTP 状态码包括：\n\n200 OK：表示请求成功并返回所请求的数据。\n201 Created：表示请求成功并在服务器上创建了新资源。\n204 No Content：表示请求成功，但响应中无返回的内容。\n400 Bad Request：表示请求有语法错误或参数错误，服务器无法理解。\n401 Unauthorized：表示请求未经授权，需要用户进行身份验证。\n403 Forbidden：表示服务器拒绝请求，通常是因为请求的资源没有访问权限。\n404 Not Found：表示请求的资源不存在。\n500 Internal Server Error：表示服务器内部发生错误，无法完成请求。\n\n在使用 XMLHttpRequest 发送请求后，可以通过检查 status 属性来获取服务器对请求的响应状态码，并根据不同的状态码进行相应的处理。\n事件属性XMLHttpRequest (XHR) 对象具有以下常用的事件属性：\n\nonreadystatechange: 当 readyState 属性发生变化时触发该事件。可以使用 xhr.onreadystatechange 属性来指定处理状态变化的回调函数。在每次状态变化时都会触发该事件，可以通过检查 xhr.readyState 属性来确定当前的状态。\n\nxhr.onreadystatechange = () =&gt; {    if(xhr.readyState === 4) {      // 请求已完成      if(xhr.status === 200) {        // 请求成功      } else {        // 请求失败      }    } else {      // 请求进行中    }  };\n\nonload: 当请求成功完成并且响应数据完全加载时触发该事件。可以使用 xhr.onload 属性来指定处理成功加载的回调函数。通常在这个事件中获取和处理响应数据。\n\nxhr.onload = () =&gt; {    // 获取和处理响应数据    const responseData = JSON.parse(xhr.responseText);    // 其他操作...  };\n\nonerror: 当请求发生错误时触发该事件。可以使用 xhr.onerror 属性来指定处理错误的回调函数。常见的错误包括网络错误、无法完成请求等。\n\nxhr.onerror = () =&gt; {    // 处理错误逻辑  };\n\nonprogress: 在数据传输过程中持续触发，用于追踪请求的进度。可以使用 xhr.onprogress 属性来指定处理进度的回调函数。\n\nxhr.onprogress = (event) =&gt; {    // 处理进度逻辑  };\n\nontimeout： 当请求超时时触发该事件。可以使用 xhr.ontimeout 属性来指定处理超时的回调函数。\n\nxhr.ontimeout = () =&gt; {    // 处理超时逻辑  };\nresponseTyperesponseType 是 XMLHttpRequest 对象的属性，用于指定响应的数据类型。它决定了如何解析从服务器返回的响应数据。\n常见的 responseType 值包括：\n\n“” (默认值): 表示响应的数据类型是字符串。\n\nxhr.responseType = \"\";\n\n“text”: 表示响应的数据类型是字符串。\n\nxhr.responseType = \"text\";\n\n“json”: 表示响应的数据类型是 JSON 对象，会自动将响应数据解析为 JavaScript 对象。\n\nxhr.responseType = \"json\";\n\n“document”: 表示响应的数据类型是 XML 文档对象，会自动将响应数据解析为 XML 文档对象。\n\nxhr.responseType = \"document\";\n\n“arraybuffer”: 表示响应的数据类型是 ArrayBuffer 对象，适用于二进制数据的传输和处理。\n\nxhr.responseType = \"arraybuffer\";\n\n“blob”: 表示响应的数据类型是 Blob 对象，适用于文件下载等场景。\n\nxhr.responseType = \"blob\";\n通过设置不同的 responseType 值，可以根据需要获取不同类型的响应数据。注意，在设置 responseType 之前，最好在调用 open 方法之后、发送请求之前设置，以确保设置生效。\n\nAjaxAJAX（Asynchronous JavaScript and XML，异步 JavaScript 和 XML）是一种使用现有的网页技术来创建异步请求和更新页面内容的方法。Ajax 本身不是一种技术，而是一种将一些现有技术结合起来使用的方法，包括：HTML 或 XHTML、CSS、JavaScript、DOM、XML、XSLT、以及最重要的 XMLHttpRequest 对象。\n当使用结合了这些技术的 Ajax 模型以后，网页应用能够快速地将增量更新呈现在用户界面上，而不需要重载（刷新）整个页面。这使得程序能够更快地回应用户的操作。Ajax 最吸引人的特性是它的”异步”性质，这意味着它可以与服务器通信、交换数据并更新页面，而无需刷新页面。\nAjax 是一种使用浏览器提供的 XMLHttpRequest 对象实现的技术，用于在不刷新整个页面的情况下进行异步请求和更新页面内容。可以说 Ajax 是基于浏览器提供的 XMLHttpRequest 对象来实现的。\n以下是基于原生 JavaScript 的 AJAX 请求代码示例：\n// 创建 XMLHttpRequest 对象  const xhr = new XMLHttpRequest();  // 指定请求的方法和 URL  xhr.open('GET', 'api_url', true);  // 第三个参数 true 表示异步请求  // 设置请求头（如果需要）  xhr.setRequestHeader('Content-Type', 'application/json');  // 根据实际需求设置请求头  // 注册一个回调函数来处理响应  xhr.onreadystatechange = function() {    if (xhr.readyState === 4 &amp;&amp; xhr.status === 200) {      const response = JSON.parse(xhr.responseText);  // 处理响应数据      // 在这里执行相应的操作      console.log(response);    }  };  // 发送请求  xhr.send();\n虽然 AJAX 是一种强大的技术，但相对于 Axios 和 Fetch API，它有以下一些缺点：\n\n兼容性问题：AJAX 的兼容性相对较低，尤其在旧版本的浏览器中可能会出现问题。而 Axios 和 Fetch API 使用了更现代的 JavaScript 特性，具有更好的兼容性。\n\n代码冗余：使用原生的 AJAX 需要编写较多的代码来处理不同的状态码、错误处理以及请求的拼装等。而 Axios 和 Fetch API 提供了更简洁和易用的接口，减少了代码冗余。\n\n缺乏默认配置：AJAX 不提供默认的全局配置，如请求和响应拦截器、统一的错误处理等。而 Axios 和 Fetch API 支持全局配置，并且提供了更方便的拦截器机制。\n\n功能限制：AJAX 在处理跨域请求时需要注意添加额外的处理，比如设置 CORS 头部信息或者使用 JSONP。而 Axios 和 Fetch API 提供了更直接的方式来处理跨域请求。\n\n可读性较差：由于 AJAX 使用的是回调函数来处理异步请求，可能会导致代码逻辑比较复杂，可读性较差。而 Axios 和 Fetch API 使用的是 Promise 或 async/await，使代码结构更加清晰易读。\n\n\n\nFetchFetch 是一种用于进行网络请求的现代 JavaScript API。它提供了一种简单、灵活且功能强大的方式，用于从服务器获取资源并处理响应。\nFetch API 在浏览器中原生支持，并且以 Promise 为基础，使得异步请求更加直观和易用。使用 Fetch API，可以执行各种类型的请求（如 GET、POST、PUT、DELETE 等），发送请求时可以设置请求头、请求参数，以及处理响应数据。\n与传统的 AJAX 相比，Fetch API 具有以下优点：\n\nPromise 支持：Fetch API 使用 Promise 对象来处理异步操作，使得处理异步请求的流程更加清晰、易于阅读和编写。\n更简洁的 API：Fetch API 提供了一个简洁的 API，使发送请求变得更加直观和简单，同时提供了丰富的配置选项（如设置请求头、请求参数等）。\n内置的 JSON 解析：在处理响应时，Fetch API 内置了对 JSON 数据的解析，无需手动进行解析操作。\n更好的错误处理：Fetch API 使用了更全面的错误处理机制，允许通过检查响应状态码来确定请求是否成功，并以不同的方式处理错误。\n\nfetch()Fetch API 提供了一个全局的 fetch() 方法，该方法提供了一种简单、逻辑的方式来通过网络异步获取资源。\nfetch() 方法的语法如下：\nfetch(url, options)    .then(response =&gt; {      // 在这里处理响应    })    .catch(error =&gt; {      // 在这里处理错误    });  \n这里有两个参数：\n\nurl：请求的 URL 地址。\noptions（可选）：一个包含请求选项的对象，可以指定请求的方法（method）、请求头（headers）、请求体（body）等。\n\n注意，fetch()默认使用的是 GET 请求，如果需要使用其他方法（如 POST、PUT 等），需要通过 options 参数进行设置。\nfetch() 方法返回一个 Promise 对象，可以使用 .then() 方法来处理成功的响应，使用 .catch() 方法来处理错误的情况。\n\n在 .then() 中，可以访问到 response 对象，进一步处理响应的内容。\n在 .catch() 中，我们可以访问到 error 对象，用于处理请求过程中的任何错误。\n\noptions 对象包含的属性如下：\n{    method: 'POST', // *GET, POST, PUT, DELETE等    mode: 'cors', // no-cors, *cors, same-origin    cache: 'no-cache', // *default, no-cache, reload, force-cache, only-if-cached    credentials: 'same-origin', // include, *same-origin, omit    headers: {       'Content-Type': 'application/json'    },    redirect: 'follow', // manual, *follow, error    referrerPolicy: 'no-referrer', // no-referrer, *client    body: JSON.stringify(data)      // body 数据类型必须与 \"Content-Type\" 请求头匹配  }\n\nmethod：请求方法，例如 GET、POST、PUT、DELETE 等。\nmode：请求模式，可以是 no-cors、*cors、same-origin 等。\ncache：缓存模式，可以是 default、no-cache、reload、force-cache、only-if-cached 等。\ncredentials：请求的凭证模式，可以是 include、*same-origin、omit 等。\nheaders：请求头对象，用于设置请求头的键值对。\nredirect：重定向模式，可以是 manual、*follow、error 等。\nreferrerPolicy：引用页面隐私设置，可以是 no-referrer、*client 等。\nbody：请求体数据，必须与 “Content-Type” 请求头指定的数据类型匹配。在示例中，使用JSON.stringify()将数据转换为 JSON 字符串。\n\nresponse一旦获取到响应（Response），返回的对象包含以下属性：\n\nresponse.body：一个简单的 getter，提供了响应内容的可读流（ReadableStream）。\nresponse.bodyUsed：一个布尔值，用于记录响应体是否已经被使用过。\nresponse.headers：与响应相关联的头部信息对象。\nresponse.ok：一个布尔值，指示响应是否成功。\nresponse.redirected：指示响应是否是重定向结果的布尔值。\nresponse.status：响应的状态码。\nresponse.statusText：与状态码对应的状态消息。\nresponse.type：响应的类型。\nresponse.url：响应的 URL。\n\n我们可以使用 response.type 来确定响应的类型，并根据不同的类型采取相应的处理方法：\nfetch(url)    .then(response =&gt; {      // 检查响应状态码      if (!response.ok) {        throw new Error('Network response was not ok');      }      // 定义一个响应类型与解析方法的映射关系      const responseTypes = new Map([        ['json', () =&gt; response.json()],        ['text', () =&gt; response.text()],        ['formData', () =&gt; response.formData()],        ['blob', () =&gt; response.blob()],        ['arrayBuffer', () =&gt; response.arrayBuffer()]      ]);      // 根据响应类型选择相应的解析方法      const parser = responseTypes.get(response.type);      if (parser) {        return parser();      } else {        throw new Error('Unsupported response type');      }    })    .then(data =&gt; {      // 处理数据      console.log(data);    })    .catch(error =&gt; {      // 处理错误情况      console.error('Error:', error);    });\nResponse 对象提供了 5 个方法，用于从 HTTP 响应中获取不同类型的数据：\n\nresponse.json()：将响应体解析为 JSON 对象。如果响应的 Content-Type 是 application/json，则使用此方法。\nresponse.text()：将响应体解析为文本字符串。如果响应的 Content-Type 是纯文本类型，如 text/plain 或 text/html，则使用此方法。\nresponse.formData()：将响应体解析为 FormData 对象。如果响应的 Content-Type 是 multipart/form-data，则使用此方法。FormData 通常用于上传文件或提交表单数据。\nresponse.blob()：将响应体解析为 Blob 对象。Blob 对象表示二进制大对象，可以是图像、音频、视频等类型的数据。\nresponse.arrayBuffer()：将响应体解析为 ArrayBuffer 对象。ArrayBuffer 是一种表示二进制数据的固定长度缓冲区。\n\n这些方法返回一个 Promise，当解析完成时，Promise 将被解析为相应的数据类型。\n请求头和响应头fetch 函数的请求头包含在发起 HTTP 请求时发送给服务器的信息，用于传递额外的参数和配置。可以使用 headers 对象来设置和操作请求头。常见的请求头字段包括：\n\nContent-Type：指定请求体的格式类型，如 application/json、application/x-www-form-urlencoded 等。\nAuthorization：用于身份验证，通常与 Token 或用户名密码一起使用。\nAccept：指定客户端所能接受的响应数据类型。\nUser-Agent：标识发起请求的用户代理（浏览器或应用程序）的信息。\n\n在 fetch 函数中可以通过第二个参数进行配置，其中可以指定请求头：\nfetch(url, {    method: 'GET',    headers: {      'Content-Type': 'application/json',      'Authorization': 'Bearer token123'    }  })    .then(response =&gt; {      // 处理响应    })    .catch(error =&gt; {      // 处理错误    });\n响应头是服务器在响应 HTTP 请求时发送给客户端的头部信息。可以通过 Response 对象的 headers 属性访问响应头。常见的响应头字段包括：\n\nContent-Type：指定响应体的格式类型。\nSet-Cookie：设置或修改客户端的 Cookie。\nCache-Control：控制缓存的行为，如 no-cache、max-age 等。\nContent-Disposition：指定响应的内容该如何展示（如文件的下载）。\n\n在处理 fetch 返回的 Response 对象时，可以通过调用 response.headers.get('Header-Name') 方法来获取特定的响应头字段的值。\nfetch(url)    .then(response =&gt; {      const contentType = response.headers.get('Content-Type');      // 其他处理逻辑    })    .catch(error =&gt; {      // 处理错误    });\n错误处理除了可以使用 catch() 来处理错误之外，与使用其他异步操作一样，我们也可以使用 async/await 来处理异步请求，使代码更加简洁和易读：\nasync function fetchData() {    try {      const response = await fetch('https://api.example.com/data');      if (response.ok) {        const data = await response.json();        console.log(data); // 处理解析后的数据      } else {        throw new Error('请求失败');      }    } catch (error) {      console.log(error); // 处理错误    }  }  fetchData();\n取消请求在标准的 Fetch API 中，没有提供直接取消 Fetch 请求的内置方法。但是，可以使用以下方法来模拟或实现取消 Fetch 请求的效果。\n使用 AbortController 和 AbortSignal：这是一种较新的浏览器特性，用于生成可以取消请求的信号。可以创建一个 AbortController对象，然后将其关联到 Fetch 请求中，当需要取消请求时，调用 AbortController 的 abort()方法：\n// 创建 AbortController 和关联的 signal  const abortController = new AbortController();  const signal = abortController.signal;  // 发起 Fetch 请求，并将 signal 传递给 fetch 函数  fetch(url, { signal })    .then(response =&gt; {      // 处理响应    })    .catch(error =&gt; {      if (error.name === 'AbortError') {        // 请求已被取消      } else {        // 处理其他错误      }    });  // 当需要取消请求时，调用 abort() 方法  abortController.abort();\n\nAxiosAxios 是一个基于 Promise 网络请求库，用于在浏览器和 Node.js 中进行 HTTP 请求。在服务端它使用原生 node.js http 模块, 而在客户端 (浏览端) 则使用 XMLHttpRequests。Axios 是目前最流行的 HTTP 请求库，其 npm 每周下载量达到了 4500w+。\nAxios 库具有以下特点：\n\n浏览器和 Node.js：Axios 可在浏览器和 Node.js 环境中使用，可以在不同的平台上执行 HTTP 请求。\nPromise API：Axios 使用 Promise API 进行异步操作，能够更轻松地处理异步请求和响应。\n请求拦截和响应拦截：可以通过拦截器，在请求发送之前或响应返回之后对请求进行全局性或个性化的变换和处理。可以在请求或响应的不同阶段添加公共的请求头、验证身份、处理错误等。\n取消请求：Axios 允许取消未完成的请求，以避免无效的请求，并减轻服务器的负担。取消请求可以通过创建取消令牌、使用取消令牌进行请求配置或者在拦截器中中断请求来实现。\n并发请求：Axios 提供了执行多个并发请求的能力，可以同时发起多个请求，并在所有请求完成后进行处理。\n自动转换数据：Axios 可以自动将请求和响应的数据进行格式转换，包括 JSON、URL 编码等。无需手动处理数据转换的过程。\n错误处理机制：当请求过程中出现错误时，Axios 会返回详细的错误信息，包括 HTTP 错误状态码、错误描述等。可以根据需要对这些错误进行处理和显示。\n简洁的 API：Axios 的 API 设计简洁易用，具有直观的方法命名和参数配置。可以轻松地使用 Axios 进行 GET、POST、PUT、DELETE 等常见的 HTTP 请求。\n\n可以通过以下命令来安装 Axios：\n// 使用 npm 安装  npm install axios  // 使用 yarn 安装  yarn add axios\n下面来进行一个简单的 get 请求：\naxios.get('https://api.example.com/data')    .then(response =&gt; {      // 处理成功响应      console.log(response.data);    })    .catch(error =&gt; {      // 处理错误      console.error(error);    });\n这里使用 axios.get 方法发起了一个 GET 请求，并将请求的 URL 作为参数传递给该方法。然后使用 Promise 的 .then 方法处理成功响应，并通过 response.data 获取响应数据。如果请求失败，可以通过 Promise 的 .catch 方法捕获错误。\n请求方法axios 支持通过简写方式来执行不同类型的请求：\n\naxios.request(config)\naxios.get(url[, config])\naxios.delete(url[, config])\naxios.head(url[, config])\naxios.options(url[, config])\naxios.post(url[, data[, config]])\naxios.put(url[, data[, config]])\naxios.patch(url[, data[, config]])\n\n对于这些方法，第一个参数是请求的 URL，config 和 data 分别是请求的配置项和请求参数，这两个参数都是可选的。例如，下面是一个 post 请求：\nconst options = {    headers: {'X-Custom-Header': 'value'}  };  axios.post('/save', { a: 10 }, options)    .then(response =&gt; {      // 处理成功响应      console.log(response.data);    })    .catch(error =&gt; {      // 处理错误      console.error(error);    });\n当作为第二个参数传递给 axios.post 函数时，Axios 会自动将 JavaScript 对象序列化为 JSON。 这样就无需将 POST 正文序列化为 JSON。Axios 还会自动将 Content-Type 请求头设置为 application/json\n多个请求在 Axios 中，可以使用 axios.all 和 axios.spread 来处理多个并发的请求：\nconst axios = require('axios');  // 创建多个请求  const request1 = axios.get('https://api.example.com/data1');  const request2 = axios.get('https://api.example.com/data2');  // 并发发送多个请求  axios.all([request1, request2])    .then(axios.spread((response1, response2) =&gt; {      // 处理各个请求的响应      console.log(response1.data);      console.log(response2.data);    }))    .catch(error =&gt; {      // 处理错误      console.error(error);    });\n可以看到，在 .then 方法中使用了 axios.spread 函数将多个请求的响应结果进行解构，通过多个参数分别接收各个请求的响应。可以根据实际情况命名这些参数，并通过 response1.data、response2.data 等方式获取各个请求的响应数据。\n请求拦截、响应拦截在 Axios 中，可以使用 transformRequest 方法在请求发送之前对请求数据进行转换和处理，它是一个请求拦截器，是一个可选的函数。\ntransformRequest 函数接收两个参数：requestData 和 requestHeaders。其中，requestData 是要发送的请求数据，requestHeaders 是要发送的请求头信息。可以在 transformRequest 函数内部对这些参数进行修改，并将修改后的值返回。返回的结果将作为实际发送请求的数据。\naxios({    url: 'https://api.example.com/data',    method: 'post',    data: {      id: 12345,      name: 'John Doe'    },    transformRequest: (data, headers) =&gt; {      // 对请求数据进行转换和处理      const modifiedData = { ...data }; // 复制原始数据      // 修改数据或添加额外字段      modifiedData.extraField = 'Extra Value';      // 修改请求头信息      headers['Content-Type'] = 'application/json';      return JSON.stringify(modifiedData); // 返回处理后的数据    }  })    .then(response =&gt; {      // 处理成功响应      console.log(response.data);    })    .catch(error =&gt; {      // 处理错误      console.error(error);    });  \n这里使用 Axios 发起了一个 POST 请求。通过传递包含 transformRequest 函数的配置对象来定义请求。在 transformRequest 函数内部，复制了原始的请求数据 data，并进行了一些修改和处理，如添加了额外的字段和修改了请求头信息。最终，将修改后的数据以 JSON 字符串的形式返回。Axios 将使用 transformRequest 函数返回的结果作为实际发送请求的数据。\n除了可以对请求进行拦截之外，Axios 还支持对响应进行拦截，对响应数据进行转换和处理。可以通过 transformResponse 响应拦截器来实现。该函数接收一个参数：responseData，它是从服务器接收到的原始响应数据。可以在 transformResponse 函数内部对这个参数进行修改，并将修改后的值返回。返回的结果将作为实际处理响应的数据。\naxios.get('https://api.example.com/data', {    transformResponse: (data) =&gt; {      // 对响应数据进行转换和处理      const parsedData = JSON.parse(data); // 解析 JSON 字符串      // 修改数据或添加额外字段      parsedData.extraField = 'Extra Value';      return parsedData; // 返回处理后的数据    }  })    .then(response =&gt; {      // 处理成功响应      console.log(response.data);    })    .catch(error =&gt; {      // 处理错误      console.error(error);    });  \n这里使用 Axios 发起了一个 GET 请求，并通过传递包含 transformResponse 函数的配置对象来定义请求。在 transformResponse 函数内部，对从服务器接收到的响应数据 data 进行了一些修改和处理，如解析 JSON 字符串，添加了额外的字段。最终将修改后的数据返回。\n拦截请求和响应Axios 中，可以使用拦截器来拦截请求和响应，并在其被发送或接收之前进行一些额外的处理，可以通过 axios.interceptors 对象来添加拦截器。\n// 添加请求拦截器  axios.interceptors.request.use(config =&gt; {    // 在发送请求之前做一些处理    console.log('请求拦截器');    // 修改请求配置    config.headers['Authorization'] = 'Bearer token';    return config;  }, error =&gt; {    // 处理请求错误    console.error('请求出错：', error);  });  // 添加响应拦截器  axios.interceptors.response.use(response =&gt; {    // 在接收到响应数据之前做一些处理    console.log('响应拦截器');    // 修改响应数据    response.data = { ...response.data, extraField: 'Extra Value' };    return response;  }, error =&gt; {    // 处理响应错误    console.error('响应出错：', error);  });  // 发送请求  axios.get('https://api.example.com/data')    .then(response =&gt; {      // 处理成功响应      console.log(response.data);    })    .catch(error =&gt; {      // 处理请求或响应错误      console.error(error);    });\n这里首先使用 axios.interceptors.request.use 方法添加了一个请求拦截器。该拦截器在发送请求之前被调用，并接收请求配置对象 config 作为参数。可以对请求配置进行修改，如添加请求头信息。最后，要确保返回修改后的配置对象。\n接下来，使用 axios.interceptors.response.use 方法添加了一个响应拦截器。该拦截器在接收到响应数据之前被调用，并接收响应对象 response 作为参数。可以对响应数据进行修改，如添加额外的字段。同样，要确保返回修改后的响应对象。\n客户端支持 XSRF 防护跨站请求伪造（简称 XSRF）是一种攻击 Web 应用的方法，其中攻击者将自己伪装成合法且受信任的用户，以影响应用程序与用户浏览器之间的交互。 有很多方法可以执行此类攻击，包括 XMLHttpRequest。\n幸运的是，Axios 通过允许在发出请求时嵌入额外的身份验证数据来防止 XSRF。 这使得服务器能够发现来自未经授权的位置的请求。以下是使用 Axios 完成此操作的方法：\nconst options = {    method: 'post',    url: '/login',    xsrfCookieName: 'XSRF-TOKEN',    xsrfHeaderName: 'X-XSRF-TOKEN',  };  axios(options)    .then(response =&gt; {      // 处理成功响应      console.log(response.data);    })    .catch(error =&gt; {      // 处理请求错误      console.error(error);    });\n这里有两个 xsrf 相关的属性：\n\nxsrfCookieName: 'XSRF-TOKEN'：用于跨站请求伪造(XSRF/CSRF)保护的配置选项之一。它指定了存储 XSRF 令牌的 cookie 的名称。XSRF 令牌用于防止恶意网站发起对已验证用户的请求。\n\nxsrfHeaderName: 'X-XSRF-TOKEN'：用于跨站请求伪造(XSRF/CSRF)保护的配置选项之一。它指定了包含 XSRF 令牌的请求头的名称。服务器端可以通过检查该请求头来验证请求的合法性。\n\n\n请求进度Axios 的另一个有趣的功能是能够监控请求的进度，这在下载或上传大文件时特别有用，可以使用 onUploadProgress 和 onDownloadProgress 两个配置选项来实现。\n对于上传进度，可以使用 onUploadProgress 配置选项。它会在上传数据时触发，并提供关于上传进度的信息。\naxios.post('/upload', data, {    onUploadProgress: progressEvent =&gt; {      const percentCompleted = Math.round((progressEvent.loaded * 100) / progressEvent.total);      console.log(`上传进度：${percentCompleted}%`);    },  })    .then(response =&gt; {      console.log(response.data);    })    .catch(error =&gt; {      console.error(error);    });\n这里发送了一个 POST 请求，在配置选项中使用了 onUploadProgress。当数据上传过程中触发进度事件时，回调函数会被执行。在回调函数中，我们计算出了已上传数据的百分比，并将其打印出来。\n对于下载进度，可以使用 onDownloadProgress 配置选项。它会在接收到响应数据时触发，并提供关于下载进度的信息。\naxios.get('/download', {    onDownloadProgress: progressEvent =&gt; {      const percentCompleted = Math.round((progressEvent.loaded * 100) / progressEvent.total);      console.log(`下载进度：${percentCompleted}%`);    },  })    .then(response =&gt; {      console.log(response.data);    })    .catch(error =&gt; {      console.error(error);    });\n这里发送了一个 GET 请求，在配置选项中使用了 onDownloadProgress。当数据下载过程中触发进度事件时，回调函数会被执行。在回调函数中，我们计算出了已下载数据的百分比，并将其打印出来。\n取消请求在 Axios 中，可以使用取消令牌（cancel token）来取消请求。取消令牌是一个对象，它表示一个具体的取消操作，并允许在需要时中止请求。\n// 创建一个取消令牌源  const CancelToken = axios.CancelToken;  const source = CancelToken.source();  // 发送请求  axios.get('/api/data', {    cancelToken: source.token  })    .then(response =&gt; {      console.log(response.data);    })    .catch(error =&gt; {      if (axios.isCancel(error)) {        console.log('请求已被取消：', error.message);      } else {        console.error(error);      }    });  // 取消请求  source.cancel('取消请求的原因');  \n这里，先创建了一个取消令牌源 source。然后，发送 GET 请求时将 cancelToken 配置选项设置为 source.token，即将取消令牌与该请求关联起来。当需要取消请求时，调用 source.cancel() 方法，并传入取消请求的原因作为参数。\n在请求的 .catch() 方法中，我们使用 axios.isCancel(error) 来判断捕获的错误是否是一个已取消的请求。如果是取消请求导致的错误，则会打印出 ‘请求已被取消’ 的提示信息。否则，将打印出其他类型的错误。\n请求超时可以使用 timeout 配置选项设置 Axios 请求的超时时间，这个选项指定了请求在多少毫秒后如果没有得到响应就会超时。\naxios.get('/api/data', {    timeout: 5000 // 设置超时时间为5秒  })    .then(response =&gt; {      console.log(response.data);    })    .catch(error =&gt; {      console.error(error);    });\n发送了一个 GET 请求，并在配置选项中设置了 timeout 为 5000 毫秒（即 5 秒）。如果请求在 5 秒内没有得到响应，就会触发超时错误。在超时错误的情况下，请求会被自动取消，并且进入 .catch() 分支。您可以根据需要进行错误处理。\n注意，如果不设置 timeout 选项，默认情况下 Axios 请求是没有超时限制的。\n\n相对于 Fetch、XMLHttpRequest 和 Ajax，我还是更喜欢 Axios。它提供了简洁易用的 API，统一的错误处理和拦截器支持，取消请求和超时处理功能，以及基于 Promise 的链式调用和跨浏览器兼容性。这些特性使得使用 Axios 更方便、高效，并提供更好的开发体验。\n\n更新: 2024-02-24 16:18:33 原文: https://www.yuque.com/cuggz/feplus/ouwmxw3uk0vdnz8p\n\n","categories":["前端"],"tags":["前端开发","JavaScript"]},{"title":"2025-12-28-前端学习-接口类型定义、Axios 封装与请求规范","url":"/Arknight-notes/posts/16956.html","content":"关于接口类型定义、Axios 封装与请求规范的常见问题使用 TypeScript 的 React 或 Vue 项目中，通常会高度重视网络层的工程化实践，通常会从实际项目经验入手，逐步深入到设计理念、类型安全和最佳实践\n关于接口类型定义、Axios 封装与请求规范的常见问题整理如下：\n基本经验与动机\n在项目中是否对 Axios 进行过二次封装？为什么需要封装，而不是直接使用原生 Axios？ 是的，在所有中大型项目中都会对 Axios 进行二次封装。主要原因是原生 Axios 配置分散、重复代码多（如每个请求都需手动设置 baseURL、headers 和错误处理）。封装后可以统一管理公共逻辑，减少冗余，提升代码一致性和可维护性，避免直接使用导致的配置不统一和后期修改困难。\n\nVue/React 项目中，你们是怎么管理 API 接口的？有统一的请求封装吗？ 我们采用统一的请求封装层。通常创建一个独立的 apiClient 实例作为基础，然后在 services 或 api 目录下按业务模块（如 auth、user、room）划分文件，每个模块导出具体的请求函数。所有接口调用都通过这些封装函数进行，确保风格一致、类型安全，并便于后期维护和 mock。\n\n说说 Axios 二次封装的主要目的和好处？ 主要目的是统一配置和公共逻辑处理，包括 baseURL、超时、Token 添加、错误统一处理等。好处包括：减少重复代码、提升可维护性、统一错误提示和加载状态、便于环境切换、支持类型安全（TS 项目），最终降低 bug 率并提高团队开发效率。\n\n\n实现细节与规范\n怎么封装 Axios 的？主要封装了哪些方面（如 baseURL、超时、请求/响应拦截器、错误处理）？ 首先使用 axios.create() 创建实例，设置 baseURL、timeout 和默认 headers。然后添加请求拦截器统一注入 Token 和加载状态；响应拦截器中提取 data、处理业务 code、统一错误提示（如 401 跳转登录），并支持 Token 刷新重试。\n\n在项目中，如何统一处理请求头（如添加 Token）、环境切换（开发/生产 baseURL）和错误提示？ 请求头通过请求拦截器或 setAuthToken 函数统一添加 Authorization；环境切换利用 Vite 或 Webpack 的环境变量动态设置 baseURL；错误提示在响应拦截器中根据 status 或业务 code 统一处理，使用 toast 组件显示消息，或触发全局错误处理逻辑。\n\n封装后，如何组织和管理具体的 API 接口？（如按模块分文件、统一导出） 按业务模块分文件（如 auth.ts、room.ts），每个文件定义相关接口函数并导出；再创建一个 index.ts 统一导出所有模块，便于在业务组件中按需导入（如 import { login } from ‘@/api’）。这样结构清晰，便于维护和权限控制。\n\n如何处理请求取消、重复请求防抖或加载状态？ 使用 Axios CancelToken 或 AbortController 实现请求取消，适用于组件卸载或搜索防抖场景；重复请求通过 URL + 方法 + 参数的 Map 缓存取消函数实现防重；加载状态可在拦截器中 dispatch 全局 loading action，或在单个请求中使用 async/await 结合状态管理。\n\n\n类型安全与工程化（TypeScript）\n在使用 TypeScript 的项目中，你是怎么结合接口类型定义来封装 Axios 的？如何实现响应数据的类型推导？ 先在 types/api.ts 中集中定义所有接口的请求参数和响应类型。然后在服务函数中使用 Axios 泛型，如 apiClient.get&lt;RoomListResponse&gt;(url)，这样返回值的类型自动推导为定义的接口类型，实现全程类型检查和编辑器提示。\n\n说说 Axios 泛型的使用，比如如何通过 &lt;T&gt; 指定返回类型，确保调用时有类型提示和检查？ 通过 apiClient.post&lt;T&gt;(url, data)的方式指定泛型 T 为具体响应类型（如 LoginResponse）。这样调用时 TypeScript 会自动推导返回值属性，提供属性提示和编译时错误检查（如访问不存在字段会报错），显著提升类型安全。\n\n怎么定义接口请求参数和响应类型的？有统一的响应包装类型（如 ApiResponse&lt;T&gt;）吗？ 定义通用包装类型 interface ApiResponse&lt;T&gt; { code: number; data: T; message?: string; } 所有接口响应类型继承此泛型（如 type LoginResponse = ApiResponse&lt;{ token: string }&gt;;），便于统一处理业务 code 和错误。\n\n在封装中，如何处理拦截器或自定义配置的 TypeScript 类型扩展（如扩展 AxiosRequestConfig）？ 通过模块声明扩展 AxiosRequestConfig 接口，添加自定义字段（如 _retry: boolean 用于 Token 刷新）。拦截器参数类型自然继承扩展后的配置，确保类型兼容和提示完整。\n\n如果后端返回结构不统一，怎么通过类型守卫或转型确保类型安全？\n\n\n\n类型守卫（Type Guard）是 TypeScript 中的一种机制，用于在运行时缩小变量的类型范围，从而让编译器在特定代码块中更精确地推断变量的类型。它本质上是一个返回布尔值的表达式或函数，当该表达式为 true 时，TypeScript 会自动将变量的类型收窄（narrow）为更具体的类型。\n\n//typeof 类型守卫 使用 JavaScript 的 typeof 操作符function print(value: string | number) {  if (typeof value === 'string') {    // 这里 value 被收窄为 string    console.log(value.toUpperCase());  } else {  // 这里 value 被收窄为 number    console.log(value.toFixed(2));  }}\n在响应拦截器中先转型为 any 或 unknown，然后使用类型守卫（如 if (‘code’ in res &amp;&amp; res.code === 0)）判断成功，再返回 res.data 并断言为具体类型。这样既兼容不统一结构，又保持业务层类型安全\n深度与实践相关\n封装后，在业务组件中调用接口的体验如何？相比直接用 Axios 有哪些改进？ 体验显著提升：调用简洁，自动获得类型提示和错误检查；无需关心 Token、baseURL 或错误处理。相比直接使用，减少了大量样板代码，降低了出错概率，并提高了代码可读性。\n\n有考虑过从 OpenAPI/Swagger 自动生成类型和接口函数吗？ 是的，在较大项目中会使用 openapi-typescript 或 swagger-typescript-api 从后端 OpenAPI 文档自动生成类型和请求函数。这样保持前后端类型一致，减少手动维护成本，并进一步提升工程化水平。\n\n如果项目规模很大，是怎么进一步优化网络层的（如模块化、服务层分离）？ 通过严格的服务层分离：apiClient 只负责基础请求，services 层按领域划分（如 userService、orderService），每个服务聚合相关接口并处理业务逻辑；结合代码生成和 mock 工具，实现高度模块化和可测试性。\n\n说说项目中网络请求的常见痛点，以及封装如何解决的。 常见痛点包括 Token 管理散乱、错误处理不统一、环境配置易错、类型不安全。二次封装通过拦截器统一 Token 和错误、环境变量管理配置、TS 泛型确保类型安全，有效解决了这些问题，显著降低了联调和维护成本。\n\n\n\nAxios 封装与接口管理具体实现基础的实现\n如何封装 Axios？ 一个典型的 Axios 封装结构如下：\n// api/utils/apiClient.tsimport axios, { type AxiosRequestConfig } from \"axios\";const apiClient = axios.create({  baseURL: import.meta.env.VITE_API_BASE_URL || \"/api\",  timeout: 10000,  headers: {    \"Content-Type\": \"application/json\",  },});// 请求拦截器apiClient.interceptors.request.use(  (config) =&gt; {    const token = localStorage.getItem(\"token\");    if (token) {      config.headers.Authorization = `Bearer ${token}`;    }    return config;  },  (error) =&gt; Promise.reject(error));// 响应拦截器apiClient.interceptors.response.use(  (response) =&gt; response.data,  (error) =&gt; {    if (error.response?.status === 401) {      localStorage.removeItem(\"token\");      window.location.href = \"/login\";    }    return Promise.reject(error);  });export default apiClient;\n\n如何统一处理请求头、环境切换和错误提示？\n\n环境切换：通过 Vite 或 Webpack 的环境变量（如 VITE_API_BASE_URL）动态配置 baseURL。\n请求头处理：在请求拦截器中统一注入 Authorization 等认证头。\n错误提示：在响应拦截器中根据状态码或业务码统一处理错误，例如 401 跳转登录、500 显示服务器错误提示。\n\n\n如何组织和管理具体的 API 接口？ 按业务模块划分文件，并统一导出，便于维护。\n// api/index.tsexport { default as userApi } from \"./user\";export { default as roomApi } from \"./room\";// api/room.tsimport apiClient from \"./utils/apiClient\";import type { RoomResponse, CreateRoomRequest } from \"./types\";const roomApi = {  getRooms: (params: { page: number; size: number }) =&gt;    apiClient.get&lt;RoomResponse&gt;(\"/rooms\", { params }),  createRoom: (data: CreateRoomRequest) =&gt; apiClient.post(\"/rooms\", data),  updateRoom: (id: string, data: Partial&lt;CreateRoomRequest&gt;) =&gt;    apiClient.put(`/rooms/${id}`, data),  deleteRoom: (id: string) =&gt; apiClient.delete(`/rooms/${id}`),};export default roomApi;\n\n如何处理请求取消、重复请求防抖或加载状态？ 使用 AbortController 实现请求取消和防重提交。\nconst pendingRequests = new Map&lt;string, AbortController&gt;();apiClient.interceptors.request.use((config) =&gt; {  const requestKey = `${config.method?.toUpperCase()}${config.url}`;  if (pendingRequests.has(requestKey)) {    pendingRequests.get(requestKey)?.abort();  }  const controller = new AbortController();  config.signal = controller.signal;  pendingRequests.set(requestKey, controller);  return config;});apiClient.interceptors.response.use(  (response) =&gt; {    const requestKey = `${response.config.method?.toUpperCase()}${      response.config.url    }`;    pendingRequests.delete(requestKey);    return response;  },  (error) =&gt; {    if (error.config) {      const requestKey = `${error.config.method?.toUpperCase()}${        error.config.url      }`;      pendingRequests.delete(requestKey);    }    return Promise.reject(error);  });\n\n\n类型安全与工程化（TypeScript）\n如何结合接口类型定义封装 Axios？\n// api/types/index.tsexport interface ApiResponse&lt;T&gt; {  code: number;  message: string;  data: T;}export interface Room {  id: string;  name: string;  description?: string;  createdAt: string;  updatedAt: string;}export interface RoomResponse extends ApiResponse&lt;Room[]&gt; {  pagination: { page: number; size: number; total: number };}export interface CreateRoomRequest {  name: string;  description?: string;}\n\nAxios 泛型的使用\n// apiService.tsimport type { AxiosRequestConfig, AxiosResponse } from \"axios\";import apiClient from \"./utils/apiClient\";import type { ApiResponse } from \"./types\";class ApiService {  async get&lt;T&gt;(    url: string,    config?: AxiosRequestConfig  ): Promise&lt;ApiResponse&lt;T&gt;&gt; {    const response: AxiosResponse&lt;ApiResponse&lt;T&gt;&gt; = await apiClient.get(      url,      config    );    return response.data;  }  async post&lt;T, D = any&gt;(    url: string,    data?: D,    config?: AxiosRequestConfig  ): Promise&lt;ApiResponse&lt;T&gt;&gt; {    const response: AxiosResponse&lt;ApiResponse&lt;T&gt;&gt; = await apiClient.post(      url,      data,      config    );    return response.data;  }  // put、delete 同理}export const apiService = new ApiService();// 使用示例const getRooms = async () =&gt; {  const response = await apiService.get&lt;Room[]&gt;(\"/rooms\", {    params: { page: 1, size: 10 },  });  return response.data; // 类型为 Room[]};\n\n定义统一的响应包装类型\nexport interface ApiResponse&lt;T&gt; {  code: number;  message: string;  data: T;}export interface ApiError {  code: number;  message: string;  details?: any;}\n\n拦截器的 TypeScript 类型扩展\n// 扩展 AxiosRequestConfigexport interface CustomAxiosRequestConfig extends AxiosRequestConfig {  showLoading?: boolean;  showError?: boolean;}// 在拦截器中使用apiClient.interceptors.request.use((config: CustomAxiosRequestConfig) =&gt; {  if (config.showLoading !== false) {    // 显示加载状态  }  return config;});\n\n处理不统一的后端返回结构 使用类型守卫确保类型安全。\nfunction isApiResponse&lt;T&gt;(data: any): data is ApiResponse&lt;T&gt; {  return (    data &amp;&amp; typeof data === \"object\" &amp;&amp; \"code\" in data &amp;&amp; \"data\" in data  );}apiClient.interceptors.response.use((response) =&gt; {  if (isApiResponse(response.data)) {    return response.data;  } else {    return { code: 200, message: \"success\", data: response.data };  }});\n\n\n应用及其后期实践\n封装后在业务组件中的使用 封装后调用更加简洁、安全，无需重复处理 Token、错误或类型。\n// 未封装前const fetchRooms = async () =&gt; {  try {    const response = await axios.get(\"/api/rooms\");    return response.data;  } catch (error) {    console.error(error);  }};// 封装后import { roomApi } from \"@/api\";const fetchRooms = async () =&gt; {  try {    const response = await roomApi.getRooms({ page: 1, size: 10 });    return response.data;  } catch (error) {    // 错误已统一处理  }};\n\nOpenAPI/Swagger 自动生成类型和接口函数 可使用 openapi-typescript-codegen 或 swagger-typescript-api 等工具从后端 OpenAPI 文档自动生成类型定义和请求函数，实现前后端类型完全一致，显著减少手动维护成本。\n\n\n","categories":["归档"]},{"title":"2025-11-15-配置 dnscrypt-proxy 实现加密 DNS 服务（Windows）","url":"/Arknight-notes/posts/32233.html","content":"简介随着互联网的飞速发展，网络安全问题日益成为公众关注的焦点。从个人用户到企业机构，如何保护网络通信的安全性成为了不可忽视的问题。而在这之中，域名系统（DNS）作为互联网的基础服务之一，其安全性直接影响着整个网络环境的安全性。\nDNS（Domain Name System），即域名系统，负责将人类易于记忆的域名转换为计算机可以识别的 IP 地址（如 192.168.1.1）。这一过程看似简单，但实际上 DNS 在互联网中扮演着至关重要的角色。然而，传统的 DNS 通信并不加密，这使得它成为了网络安全的一个薄弱环节。\n近年来，随着网络安全威胁的不断增加，尤其是中间人攻击、DNS 劫持和数据窃取等恶意行为的频发，传统的明文 DNS 通信方式已经无法满足现代网络的安全需求。为了应对这一挑战，加密 DNS 技术应运而生。加密 DNS 通过在客户端与 DNS 服务器之间建立加密通道，确保了 DNS 查询的安全性。\n一、传统 DNS 的安全性问题在深入了解加密 DNS 之前，我们需要先认识传统 DNS 通信中存在的安全漏洞，以及这些漏洞可能带来的风险。\n中间人攻击（ManintheMiddle, MitM）传统的 DNS 通信是通过明文进行的，这意味着在数据传输过程中，任何处于客户端与 DNS 服务器之间的中间人都可以轻松截获和篡改 DNS 查询内容。这种中间人攻击可能导致以下后果：\nDNS 劫持攻击者可以将原本正常的域名解析请求重定向到恶意网站。数据窃取：攻击者可以直接获取用户的网络使用信息，甚至窃取敏感数据。\nDNS 缓存投毒（Cache Poisoning）DNS 服务器通常会缓存查询结果以提高效率。然而，如果攻击者能够污染这一缓存，将导致后续的所有相关请求都被重定向到恶意地址。这种攻击方式不仅影响单个用户，还可能波及整个网络。\n数据泄露风险由于传统 DNS 通信缺乏加密保护，用户的每一次 DNS 查询都会暴露其访问的网站信息。这使得用户的上网行为可以被轻易监控，进而导致隐私泄露。\n缺乏身份验证机制传统的 DNS 协议中缺少有效的身份验证机制，攻击者可以伪造 DNS 响应，从而欺骗客户端或服务器，实施各类恶意活动。\n二、加密 DNS 的优势为了应对上述问题，加密 DNS 技术应运而生。通过在客户端与 DNS 服务器之间建立加密通道，加密 DNS 能够有效保护 DNS 通信的安全性，防止中间人攻击和其他恶意行为。\n数据传输加密加密 DNS（如 DNS over TLS  或  DNS over HTTPS）利用现代加密协议（如 TLS/SSL）对 DNS 查询和响应进行加密。这使得即使在中间人攻击的情况下，攻击者也无法窃取或篡改 DNS 通信内容。\n防止缓存投毒加密 DNS 通过严格的认证机制确保了 DNS 响应的真实性，从而有效防范 DNS 缓存投毒攻击。\n保护用户隐私加密 DNS 可以防止用户的 DNS 查询被第三方窃取或监控。这对于注重隐私的个人用户和企业用户来说尤为重要。\n增强网络安全性通过加密 DNS 通信，整个网络的安全性得到显著提升。这不仅保护了用户的上网行为，还为企业的内部网络提供了更高的安全防护。\n\n配置 dnscrypt-proxyDNS 加密方案有 DNS over HTTPS（DoH）以及 DNS over TLS（DoT）两种，dnsmasq 似乎是不支持这两种方式的。而 dnscrypt-proxy 是一个灵活的本地 DNS 代理工具，支持 DNSCrypt、DNS over HTTPS (DoH)、DNS over TLS (DoT) 等加密协议，可有效防止 DNS 查询被窃听、篡改或污染。\n1. 下载与解压\n访问 GitHub 发布页面：https://github.com/DNSCrypt/dnscrypt-proxy/releases/latest\n下载适用于 Windows 的压缩包（通常为 dnscrypt-proxy-win64-*.zip）。\n解压到任意目录，例如 C:\\dnscrypt-proxy。\n目录中将包含 dnscrypt-proxy.exe、example-dnscrypt-proxy.toml 等文件。\n\n2. 配置 dnscrypt-proxy.toml配置文件应该为 dnscrypt-proxy.toml修改 dnscrypt-proxy 监听的端口，因为 53 端口已经被 dnsmasq 占用，这里修改成 5353\nlisten_addresses = ['127.0.0.1:5353']\n来到 sources 这一块，把自带的远程源全部注释掉，不然每次启动都要到远程源下载可用服务器列表，影响启动速度，自带源又都放在 github 上，下不到就会启动失败，用自己配的自定义服务器就行，下面会写\n[sources]  ## An example of a remote source from https://github.com/DNSCrypt/dnscrypt-resolvers  # [sources.'public-resolvers']  #   urls = ['https://raw.githubusercontent.com/DNSCrypt/dnscrypt-resolvers/master/v3/public-resolvers.md', 'https://download.dnscrypt.info/resolvers-list/v3/public-resolvers.md', 'https://ipv6.download.dnscrypt.info/resolvers-list/v3/public-resolvers.md', 'https://download.dnscrypt.net/resolvers-list/v3/public-resolvers.md']  #   cache_file = '/var/cache/dnscrypt-proxy/public-resolvers.md'  #   minisign_key = 'RWQf6LRCGA9i53mlYecO4IzT51TGPpvWucNSCh1CBM0QTaLn73Y7GFO3'  #   refresh_delay = 72  #   prefix = ''  ## Anonymized DNS relays  # [sources.'relays']  #   urls = ['https://raw.githubusercontent.com/DNSCrypt/dnscrypt-resolvers/master/v3/relays.md', 'https://download.dnscrypt.info/resolvers-list/v3/relays.md', 'https://ipv6.download.dnscrypt.info/resolvers-list/v3/relays.md', 'https://download.dnscrypt.net/resolvers-list/v3/relays.md']  #   cache_file = '/var/cache/dnscrypt-proxy/relays.md'  #   minisign_key = 'RWQf6LRCGA9i53mlYecO4IzT51TGPpvWucNSCh1CBM0QTaLn73Y7GFO3'  #   refresh_delay = 72  #   prefix = ''\n来到最底下，加上自定义服务器，可用的服务器可以在这里找到https://dnscrypt.info/public-servers\n[static][static.'aliyun']stamp = 'sdns://AgAAAAAAAAAACTIyMy41LjUuNSCY49XlNq8pWM0vfxT3BO9KJ20l4zzWXy5l9eTycnwTMA5kbnMuYWxpZG5zLmNvbQovZG5zLXF1ZXJ5'[static.'txyun']stamp = 'sdns://AgAAAAAAAAAACjEuMTIuMTIuMTIgj0tzmXxLBOpQ_q-pGiQx1CvKa1TCO8-du_VyJJOU4QwHZG9oLnB1YgovZG5zLXF1ZXJ5'\n来到这一块，配置使用自定义服务器\n# server_names = ['scaleway-fr', 'google', 'yandex', 'cloudflare']server_names = ['aliyun', 'txyun']\n引导解析器（bootstrap_resolvers）：用于初始加载公共解析器列表。若默认解析器（Quad9 和 Google）被阻断或不可用，推荐修改为可靠组合：\nbootstrap_resolvers = ['1.1.1.1:53', '1.0.0.1:53', '8.8.8.8:53', '9.9.9.10:9953']\n（Cloudflare 高度可靠；Quad9 的 9953 端口可绕过端口 53 阻断。）修改检测网络是否连通的地址，可以是任意 ip 的任意端口，哪怕没有响应，只要端口是打开的，就认为网络连通\n# netprobe_address = '9.9.9.9:53'netprobe_address = '223.5.5.5:53'\n因为集群环境没有 ipv6，顺便禁用 ipv6 的 AAAA 查询\n# block_ipv6 = falseblock_ipv6 = true\n启用 dns 查询日志（可选）\n[query_log]  file = '/var/log/dnscrypt-proxy/query.log'\n3. 测试运行以管理员身份打开命令提示符，导航到解压目录：\ncd C:\\[dir]\\dnscrypt-proxy\n运行代理：\ndnscrypt-proxy.exe\n观察控制台输出，应出现 “Source [public-resolvers] loaded” 和 “dnscrypt-proxy is ready”。\n测试解析：\nnslookup example.com 127.0.0.1\n若成功，返回正常 IP 地址。按 Ctrl+C 停止测试。\n4. 安装为 Windows 服务（开机自动运行）在同一管理员命令提示符中执行：\ndnscrypt-proxy.exe -service install\n启动服务：\ndnscrypt-proxy.exe -service start\n设置自动启动（可选，默认已自动）：使用 services.msc（Win + R 输入）找到 “dnscrypt-proxy” 服务，属性中设为 “自动” 或 “自动（延迟启动）”。或命令：\nsc config dnscrypt-proxy start= delayed-auto\n5. 配置系统 DNS打开网络设置：右键网络图标 &gt; “打开网络和 Internet 设置” &gt; “更改适配器选项”。右键当前网络适配器 &gt; 属性 &gt; Internet 协议版本 4 (TCP/IPv4) &gt; 属性。\n\n选择 “使用下面的 DNS 服务器地址”：首选 DNS 服务器：127.0.0.1，备选 DNS 服务器：可留空或设为公共非加密（如 1.1.1.1）然后确认并应用\n若要清空 DNS 缓存：\nipconfig /flushdns\n6. 管理服务管理：\n\n启动/停止/重启：dnscrypt-proxy.exe -service start/stop/restart\n状态查询：sc query dnscrypt-proxy（显示 RUNNING 或 STOPPED）\n图形化：services.msc 中管理 “dnscrypt-proxy”。\n卸载：dnscrypt-proxy.exe -service uninstall\n更新时：停止服务，替换可执行文件，重启服务。\n\n此配置后所有 DNS 查询将通过本地 127.0.0.1 代理转发至上游加密服务器实现隐私保护\n","categories":["笔记"],"tags":["校园网","计网","DNS"]},{"title":"2025-12-28-力扣百题速练（Javascript、TypeScript）Vol.3","url":"/Arknight-notes/posts/42325.html","content":"依旧刷题中\n21.合并两个有序链表将两个升序链表合并为一个新的 升序 链表并返回。新链表是通过拼接给定的两个链表的所有节点组成的。\n示例 1：\n\n输入：l1 = [1,2,4], l2 = [1,3,4]输出：[1,1,2,3,4,4]\n示例 2：\n输入：l1 = [], l2 = []输出：[]\n示例 3：\n输入：l1 = [], l2 = [0]输出：[0]\n提示：\n\n两个链表的节点数目范围是 [0, 50]\n-100 &lt;= Node.val &lt;= 100\nl1 和 l2 均按 非递减顺序 排列\n\nRelated Topics\n\n递归\n链表\n\n解法很简单，假设输入两个有序链表：\nlist1: 1 → 2 → 4 list2: 1 → 3 → 4\n合并过程逐步展示指针变化（→ 表示 next 指针，cur 为当前构建指针）：\n初始状态 dummy → null cur = dummy list1: 1 → 2 → 4 list2: 1 → 3 → 4\n步骤 1：比较 list1.val(1) ≤ list2.val(1) cur.next = list1 的 1 cur 前进 → 指向 1 list1 前进 → 2 → 4 当前新链表：dummy → 1\n步骤 2：比较 list1.val(2) &gt; list2.val(1) cur.next = list2 的 1 cur 前进 → 指向 1 list2 前进 → 3 → 4 当前新链表：dummy → 1 → 1\n步骤 3：比较 list1.val(2) ≤ list2.val(3) cur.next = list1 的 2 cur 前进 → 指向 2 list1 前进 → 4 当前新链表：dummy → 1 → 1 → 2\n步骤 4：比较 list1.val(4) &gt; list2.val(3) cur.next = list2 的 3 cur 前进 → 指向 3 list2 前进 → 4 当前新链表：dummy → 1 → 1 → 2 → 3\n步骤 5：比较 list1.val(4) ≤ list2.val(4) cur.next = list1 的 4 cur 前进 → 指向 4 list1 前进 → null 当前新链表：dummy → 1 → 1 → 2 → 3 → 4\n步骤 6：list1 已空，剩余 list2(4) 直接接上 cur.next = list2 的 4 当前新链表：dummy → 1 → 1 → 2 → 3 → 4 → 4\n最终返回：dummy.next 结果链表：1 → 1 → 2 → 3 → 4 → 4\n该过程通过不断比较两个链表的当前节点，将较小节点直接拼接至新链表尾部（cur 后），并前进对应指针，直至处理完所有节点\nfunction mergeTwoLists(list1: ListNode | null, list2: ListNode | null): ListNode | null {      let index = 0      let dum = new ListNode(1)        let cur = dum        while (list1 &amp;&amp; list2) {          if (list1.val &lt;= list2.val) {              cur.next = list1;        // 将较小节点接到 cur 后              list1 = list1.next;      // list1 前进          } else {              cur.next = list2;              list2 = list2.next;          }          cur = cur.next;              // cur 前进      }        cur.next = list1 || list2      return dum.next    };\n","categories":["力扣"],"tags":["前端开发","JavaScript","算法"]},{"title":"2025-11-23-前端学习-身份验证管理-基于 JWT Token 的实现","url":"/Arknight-notes/posts/42304.html","content":"前端身份验证管理-基于 JWT Token 的实现0x01 JWT 简介与工作原理JSON Web Token（JWT）是一种开放标准（RFC 7519），用于在网络应用环境中安全传输声明。它是一种紧凑、自包含的令牌格式，由三部分组成：Header（头部）、Payload（载荷）和 Signature（签名），以点（.）分隔，形成 Base64Url 编码的字符串。\n\nHeader：包含令牌类型（”typ”: “JWT”）和签名算法（如 “alg”: “HS256” 或 “RS256”）。\nPayload：承载声明信息，包括注册声明（iss、exp、sub 等）和自定义声明（用户 ID、角色等）。注意，Payload 未加密，仅编码，不应存放敏感数据。\nSignature：使用密钥对 Header 和 Payload 进行签名，确保令牌完整性和真实性。\n\nJWT 的典型认证流程：\n\n用户提交用户名和密码登录。\n服务器验证凭证成功后，生成 JWT 并返回给客户端。\n客户端存储 JWT（通常在 localStorage 或 HttpOnly Cookie 中）。\n后续请求中，客户端在 Authorization 头携带 JWT（Bearer &lt;token&gt;）。\n服务器验证 JWT 的签名、过期时间和声明，若有效则授权访问。\n\n相比传统 Session 认证，JWT 无状态，便于分布式系统扩展，但需注意令牌不可主动撤销（依赖短过期时间和刷新机制）。\n0x02 前端 Token 存储与管理前端管理 JWT 的核心是通过 setAuthToken 和 clearAuthToken 函数统一处理认证状态，通常结合 Axios 实例实现。\n\n存储方式：\n优先使用 HttpOnly + Secure + SameSite Cookie：防止 XSS 攻击（JavaScript 无法访问），并通过 SameSite 属性缓解 CSRF。\n避免 localStorage/sessionStorage：易受 XSS 窃取。\n若必须使用 JavaScript 存储，结合短过期时间和刷新令牌。\n\n\nAxios 封装示例（apiClient.ts）：\nimport axios from 'axios';const apiClient = axios.create({ baseURL: '/api' });export const setAuthToken = (token: string) =&gt; {  if (token) {    apiClient.defaults.headers.common['Authorization'] = `Bearer ${token}`;  }};export const clearAuthToken = () =&gt; {  delete apiClient.defaults.headers.common['Authorization'];};// 请求拦截器：可选统一添加其他逻辑apiClient.interceptors.request.use(config =&gt; {  // 可从 Cookie 或存储中读取 token  return config;});export default apiClient;\n\n\n登录成功后：\n// 登录接口调用后const response = await login(username, password);localStorage.setItem('token', response.data.token); // 或依赖 CookiesetAuthToken(response.data.token);\n登出时：\nclearAuthToken();localStorage.removeItem('token'); // 或清除 Cookie\n0x03 通过钩子或守卫验证用户权限在前端框架中，使用路由守卫或钩子（如 Vue Router 的 beforeEach 或 React 的自定义钩子）验证权限，确保未认证用户无法访问受保护路由。\n\nVue 示例（router/index.ts）：\nimport router from '@/router';import { getToken } from '@/utils/auth'; // 从存储获取 tokenrouter.beforeEach((to, from, next) =&gt; {  if (to.meta.requiresAuth) { // 路由元信息标记需认证    const token = getToken();    if (token) {      // 可选：调用后端验证 token 有效性      next();    } else {      next('/login'); // 重定向登录    }  } else {    next();  }});\n\nReact 示例（ProtectedRoute 组件）： 使用 Context 或 Redux 管理认证状态，在路由组件中检查：\nimport { Navigate } from \"react-router-dom\";const ProtectedRoute = ({ children }) =&gt; {  const token = localStorage.getItem(\"token\");  return token ? children : &lt;Navigate to=\"/login\" /&gt;;};\n\n\n此外，可结合角色声明（Payload 中的 roles）实现细粒度权限控制，如按钮级隐藏。\n0x04 Token 刷新与过期处理为提升用户体验，实施刷新令牌机制：\n\nAccess Token：短过期（15-60 分钟）。\nRefresh Token：长过期，存储在 HttpOnly Cookie。\n在 Axios 响应拦截器中捕获 401 错误，调用刷新接口获取新 Access Token。\n\n示例：\napiClient.interceptors.response.use(  response =&gt; response,  async error =&gt; {    if (error.response.status === 401) {      // 调用刷新接口，更新 token      const newToken = await refreshToken();      setAuthToken(newToken);      // 重试原请求      return apiClient(error.config);    }    return Promise.reject(error);  });\n0x05 安全实践\n使用 HTTPS\n严格验证服务器端签名、exp、iss 和 aud\n避免 Payload 中存放敏感信息\n实施 CSRF 防护（SameSite Cookie 或 token）\n定期轮换密钥，支持刷新令牌旋转\n监控异常登录，实施黑名单（短期令牌下可选）\n\n0x06 参考资料\nRFC 7519: JSON Web Token\nOWASP JWT Cheat Sheet\nAuth0 JWT Best Practices\nCurity JWT Security Guide\n\n","categories":["归档"]},{"title":"2026-01-02-关于机器学习实训论文相关工作","url":"/Arknight-notes/posts/52226.html","content":"我真的服了为什么实训论文要把ddl放在期末考试之前…\n一、完成科研论文一篇，具体要求如下：\n1、科研论文主题：传统机器学习在保险领域的前沿研究课题\n涵盖风险评估、欺诈检测、客户细分等多个方面，以下是一些具体的课题方向：\n(1)基于传统机器学习的精准风险评估模型研究。多特征融合的风险评估：利用传统机器学习算法，如逻辑回归、决策树等，融合客户的人口统计学信息、健康状况、信用记录、消费行为等多维度特征，构建更精准的风险评估模型，为保险定价提供更可靠的依据。\n(2)动态风险评估模型。通过集成实时数据流，如车辆行驶数据、设备运行状态数据等，运用传统机器学习模型动态评估保险标的风险状况，实现保险产品的动态定价和风险监控。\n(3)传统机器学习在保险欺诈检测中的应用。基于特征工程的欺诈检测：对保险理赔数据进行深入的特征工程，提取有效的欺诈特征，如索赔时间间隔、索赔金额分布、客户行为模式等，然后利用随机森林、支持向量机等传统机器学习模型进行欺诈行为的识别和预测。\n(4)异常检测算法在欺诈检测中的应用。采用孤立森林、One-Class SVM等异常检测算法，识别保险数据中的异常点和潜在的\n欺诈行为，提高欺诈检测的效率和准确性。\n(5)基于传统机器学习的保险客户细分研究。聚类分析在客户细分中的应用：运用K-Means、层次聚类等聚类算法，根据客户的风险偏好、消费习惯、保险需求等特征，将客户划分为不同的细分群体，为保险公司制定个性化的营销策略和产品设计提供依据。\n(6)客户生命周期价值评估。利用传统机器学习算法建立客户生命周期价值评估模型，通过分析客户的历史购买行为、保费缴纳情况、理赔记录等数据，预测客户在未来一段时间内的价值贡献，帮助保险公司优化客户关系管理策略。\n(7)传统机器学习在保险产品定价中的应用。针对保险产品定价中的非线性问题，采用支持向量机、神经网络等传统机器学习算法，构建非线性定价模型，更好地拟合保险风险与保费之间的关系，提高定价的合理性和准确性。\n2、个人基于网络、统计年鉴、参考文献寻找相关数据；\n3、提出比较新颖的机器学习方法；\n4、提出的方法要与至少三个已有比较经典的预测方法对比；\n5、研究论文格式规范，要素齐全；\n6、附录包括各种方法实现的源代码及数据文件；\n7、截止提交论文时间：2026年1月6日。\n二、打分标准\n1、有较好的创新，提交论文各方面要素完成质量高，分数在95分以上；\n2、有一定创新，提交论文各方面要素完成质量较高，分数在90分左右；\n3、提交论文工作量饱满，论文完成质量较高，分数在85分左右；\n4、提交论文质量一般，分数在70分左右；\n5、独立完成，杜绝抄袭，也不能将其他项目成果拿来作为本次实训成果。\n\n开坑现在有多个GitHub上的开源机器学习项目与保险领域的传统机器学习应用高度相关，特别是欺诈检测、风险评估和客户细分。这些项目通常使用scikit-learn库实现随机森林、逻辑回归、支持向量机、K-Means聚类等传统算法，并包含完整代码、数据处理和模型比较流程。您可以直接参考、运行或修改这些项目，以支持您的实训论文写作（例如比较多个模型的性能）。\n保险欺诈检测\nsaritmaitra/Fraud-detection—Insurancehttps://github.com/saritmaitra/Fraud-detection—Insurance 使用随机森林算法构建保险索赔欺诈检测模型，包括数据清洗、特征工程、模型训练和评估。代码以Jupyter Notebook形式呈现，便于理解和复现。数据集为常见汽车保险索赔数据。\n\n\n添加模型对比：课程要求至少三个传统机器学习方法。在 Notebook 中新增逻辑回归（LogisticRegression）和支持向量机（SVC），使用相同数据进行训练和评估对比（表格展示指标，如 AUC、F1）。\n处理不平衡：添加 SMOTE 过采样（from imblearn.over_sampling import SMOTE）。\n实验严谨性：引入交叉验证（cross_val_score）和网格搜索（GridSearchCV）调参。\n可视化：添加 ROC 曲线、混淆矩阵和特征重要性图（RandomForestClassifier.featureimportances）。\n论文整合：运行结果后，截取图表和指标，用于实训论文的实验部分。强调您的修改（如模型融合）作为创新点。\n\n这些Notebook主要涉及的方法概述提供的两个Jupyter Notebook（”Insurance Claims - Fraud Detection.ipynb” 和 “Fraud Detection _xtended.ipynb”）均聚焦于汽车保险理赔欺诈检测的二元分类任务（fraud_reported: Y/N）。它们采用传统机器学习流程，以随机森林为核心算法，同时进行多模型对比。方法整体框架为端到端预测管道，包括数据预处理、特征工程、模型训练、评估与比较。以下按流程阶段总结主要方法：\n1. 数据加载与探索（EDA）\n使用pandas加载CSV数据集（汽车保险理赔记录，包含客户信息、事故细节、理赔金额等39个特征）。\n基本统计描述（df.describe()、df.head()）和可视化（matplotlib/seaborn绘制分布图、相关热力图）。\n识别关键问题：类不平衡（欺诈样本占比低）、类别特征多、数值特征需标准化。\n\n2. 数据预处理与特征工程\n清洗与编码：LabelEncoder处理类别变量（e.g., insured_sex, auto_make）；处理缺失值（未显式，但隐含填充或删除）。\n特征构建与选择：计算新特征（如车辆年龄vehicle_age = current_year - auto_year）；使用ExtraTreesRegressor评估特征重要性（隐含筛选）；在扩展版中显式删除低重要性或共线性特征（e.g., vehicle_claim, age, certain dummies）。\n标准化：StandardScaler对数值特征缩放（fit_transform训练集，transform测试集）。\n分割：train_test_split（80/20或类似比例，random_state固定以复现）。\n\n3. 模型构建与训练\n核心模型：RandomForestClassifier（n_estimators=100，默认参数为主）。\n扩展模型：在扩展版中引入XGBoost (XGBClassifier)作为备选最终模型。\n不平衡处理：未显式使用SMOTE等高级重采样，仅通过交叉验证隐含缓解（实际中依赖模型鲁棒性）。\n\n4. 模型比较与评估\n多算法对比：同时评估7种传统机器学习模型：\nLogisticRegressionCV（带交叉验证的逻辑回归）。\nXGBClassifier（极端梯度提升）。\nKNeighborsClassifier（K近邻）。\nDecisionTreeClassifier（决策树）。\nSVC（支持向量机，gamma=’auto’）。\nRandomForestClassifier（随机森林）。\nAdaBoostClassifier（自适应提升）。\n\n\n交叉验证：10折KFold（n_splits=10），评估指标主要为accuracy（均值与标准差）。\n可视化：箱线图（boxplot）比较各模型准确率分布。\n结论导向：随机森林或XGBoost通常表现最佳（准确率约0.82-0.95，视特征子集而定），强调集成学习在非参数场景下的优势。\n\n5. 整体特点与局限\n重点：非参数集成学习（随机森林/XGBoost）的鲁棒性，适用于高维、混合类型数据。\n未涉及高级方法：无深度学习、异常检测专用算法（如Isolation Forest或One-Class SVM）；不平衡处理较简单；无AUC/Recall等欺诈专用指标（仅accuracy，可能因不平衡导致偏差）。\n扩展版改进：特征删减后重新评估，仅保留LR与XGB对比，性能无显著变化，最终选XGB。\n\n这些方法体现了典型监督分类流程，适合保险欺诈这类不平衡二元任务。实际应用中，可进一步优化不平衡处理与指标选择，以提升对少数欺诈类的召回率。\n\n项目提供的核心方法与思路总结该GitHub仓库（saritmaitra/Fraud-detection—Insurance）聚焦于利用机器学习技术检测汽车保险理赔欺诈，属于典型的二元分类任务（欺诈/非欺诈）。项目以随机森林算法为核心，提供了一个完整的端到端实践框架，适合作为实训论文的基础。以下基于仓库README、文件结构及Notebook内容（包括您先前提供的代码细节）总结其主要方法与思路：\n1. 总体思路\n问题定位：保险欺诈导致行业巨额损失，传统规则系统难以应对复杂模式。项目通过历史理赔数据提取行为特征，构建预测模型，实现自动化欺诈识别。\n核心路径：数据驱动的监督学习流程——从数据预处理到特征工程，再到多模型对比，最终选优（随机森林为主，扩展中考虑XGBoost）。\n创新点：强调比较研究（multi-model comparison），通过实证验证算法适用性；注重行为特征提取，以捕捉欺诈模式。\n适用性：适用于类不平衡、高维混合数据的保险场景，思路实用、可复现，强调集成学习的鲁棒性。\n\n2. 主要方法\n数据来源与探索：\n数据：汽车保险历史交易记录（data文件夹，包含客户信息、事故细节、理赔金额等约39个特征）。\n探索：pandas加载、描述统计、可视化（seaborn/matplotlib绘制分布、相关图），识别不平衡（欺诈样本稀少）。\n\n\n预处理与特征工程：\n清洗：处理缺失值、异常。\n编码：LabelEncoder处理类别变量（e.g., 性别、车型、事故类型）。\n标准化：StandardScaler缩放数值特征。\n特征构建/选择：计算新特征（如车辆年龄）；使用ExtraTreesRegressor评估重要性；扩展版删除低相关特征（e.g., injury_claim, age）。\n分割：train_test_split（80/20）。\n\n\n模型构建与对比：\n核心模型：RandomForestClassifier（n_estimators=100），集成决策树，处理非线性与噪声。\n多算法对比（关键亮点）：10折KFold交叉验证评估7种传统模型：\nLogisticRegressionCV（逻辑回归，带CV）。\nXGBClassifier（极端梯度提升）。\nKNeighborsClassifier（K近邻）。\nDecisionTreeClassifier（决策树）。\nSVC（支持向量机，gamma=’auto’）。\nRandomForestClassifier（随机森林）。\nAdaBoostClassifier（自适应提升）。\n\n\n扩展版：特征优化后聚焦LR与XGB对比，验证稳定性。\n\n\n评估与可视化：\n指标：accuracy（均值/标准差），扩展可补充AUC/Recall（欺诈任务关键）。\n可视化：箱线图比较模型分布，方差小、均值高的模型（如RF/XGB）优选。\n结论导向：集成模型（RF/XGB）通常最佳，鲁棒性强。\n\n\n\n项目思路强调实证比较与实用性：先广义筛选模型，再优化特征，确保选出最适算法。适合实训扩展：添加不平衡处理（SMOTE）、更多指标（Recall/F1），或解释性分析（特征重要性）。\n文献综述的写作建议文献综述需客观梳理领域进展、突出空白，为您的项目（随机森林+多模型对比）定位创新。长度1500-2500字，引用20-30篇（中外平衡，2015年后为主）。避免抄袭Khalil论文（您提供的PDF），改用类似主题不同引用。\n推荐结构（第2章）\n保险欺诈背景（300-500字）：经济影响、监管挑战。\n方法演进（500-800字）：从规则到ML，集成学习优势。\n传统ML实证应用（600-800字）：随机森林等在欺诈检测的表现，多模型对比研究。\n数据挑战与预处理（400-600字）：不平衡、特征工程策略。\n研究空白与本文定位（200-400字）：缺乏系统对比，您的项目填补。\n\n写作要点\n引用来源：Google Scholar/CNKI搜索“insurance fraud detection machine learning”“汽车保险欺诈 随机森林”。\n关键文献示例（可替换）：\nNgai et al. (2011)：欺诈检测综述。\nItri et al. (2019)：随机森林优于多算法。\nHanafy &amp; Ming (2021)：SMOTE不平衡处理。\nXia et al. (2023)：集成学习优势。\n\n\n本文定位：您的项目通过7模型交叉验证对比，验证随机森林在汽车保险数据集的优越性，扩展预处理，提供实证参考。\n\n示例段落（2.3节片段）传统机器学习算法在汽车保险欺诈检测中的应用已取得显著进展。多项研究证实随机森林在多算法对比中表现突出，例如Itri et al. (2019)测试10种模型，结果显示随机森林准确率最高。该优势源于其集成机制，能有效处理高维特征与非线性关系（Xia et al., 2023）。类似地，Nordin et al. (2024)比较树基模型，发现增强型算法在敏感性上领先。极端梯度提升（XGBoost）作为补充，亦在不平衡场景中展现竞争力（Jovanovic et al., 2022）。这些实证工作为本文的多模型对比实验提供了理论基础。\n\n建议的章节结构与详细写作要点第3章 研究方法（预计8-12页，是论文最重的章节）3.1 数据集描述\n\n数据来源：说明数据集为公开的汽车保险理赔数据集（1000条记录，40个原始特征）。\n目标变量：fraud_reported（Y/N，二分类，欺诈比例约25%）。\n特征分类：数值特征（如months_as_customer、age、policy_annual_premium、total_claim_amount等）、类别特征（如policy_state、incident_type、auto_make等）、时间特征（如policy_bind_date、incident_date）。\n数据基本统计：插入表格展示主要特征的描述性统计（均值、标准差、缺失率等）。\n类不平衡问题：明确指出欺诈样本仅占25%，这正是需要特别关注的点。\n\n3.2 数据预处理\n\n缺失值处理：说明“？”被视为缺失，collision_type、property_damage、police_report_available等字段用“UNKNOWN”或模式填充。\n类别变量编码：采用LabelEncoder或One-Hot Encoding（说明两种方式的取舍，Notebook中主要用了LabelEncoder）。\n数值变量标准化：StandardScaler。\n时间特征提取：从policy_bind_date和incident_date计算“保单持有时长”（months_as_customer已存在，可补充事故发生距离保单绑定时间等）。\n其他清洗：删除无用列（如_c39、policy_number等）。\n\n3.3 特征工程与特征选择\n\n新特征构造：可补充（如总赔付金额占比、是否高额理赔、事故时间段划分等）。\n特征重要性分析：展示ExtraTreesRegressor得出的特征重要性排名图（Notebook中有）。\n特征选择：描述在“Fraud Detection _xtended.ipynb”中删除了10个低重要性或高相关性特征（如vehicle_claim、injury_claim、age等），并说明此举旨在降低维度、减少噪声。\n强调这一步对应贡献1（系统性框架）和贡献2（公平对比前提）。\n\n3.4 类不平衡处理（关键补充点）\n\n说明原始实验未显式处理不平衡，因此准确率可能高估。\n引入多种策略进行对比实验： （1）不处理（baseline） （2）随机欠采样 （3）SMOTE过采样 （4）类权重调整（class_weight=’balanced’）\n说明这些策略将在第4章中与不同分类器组合进行评估（这是回应文献不足的重要创新点）。\n\n3.5 分类算法\n\n列出七种算法：Logistic Regression (LR)、K-Nearest Neighbors (KNN)、Decision Tree (DT)、Support Vector Machine (SVM)、Random Forest (RF)、AdaBoost、XGBoost。\n简述每种算法原理与适用性（1-2句），特别强调RF的bagging机制和对不平衡数据的天然鲁棒性。\n\n3.6 实验设计与评估指标\n\n数据划分：80%训练、20%测试，随机种子固定。\n交叉验证：10折CV（Notebook中已使用）。\n评估指标： – Accuracy（整体准确率） – Precision、Recall、F1-score（特别关注Recall，因为漏掉欺诈成本高） – AUC-ROC（对不平衡数据更稳健）\n超参数设置：说明使用了默认或简单网格搜索（如RF n_estimators=100）。\n\n第4章 实验结果与分析（预计10-15页，核心实证章节）4.1 数据探索性分析\n\n插入特征分布图、欺诈与非欺诈在关键特征上的差异（如total_claim_amount、incident_severity等）。\n相关性热力图。\n\n4.2 特征选择效果\n\n对比删除10个特征前后模型性能变化（Notebook中显示LR和XGB略有提升或持平）。\n展示最终保留特征的重要程度排序。\n\n4.3 算法性能对比（无不平衡处理）\n\n插入Notebook中的算法比较箱线图。\n表格列出10折CV的均值±标准差（Accuracy）。\n分析：LR和XGB表现最佳，RF紧随其后；解释RF标准差较小（更稳定）。\n\n4.4 类不平衡处理策略的影响（关键创新部分）\n\n新增实验结果表格：不同不平衡处理策略下，各算法在Recall、F1、AUC上的表现。\n重点分析： – SMOTE通常显著提升少数类Recall，但可能降低Precision。 – RF在多种策略下稳定性最好。 – 最终选择SMOTE + RF（或实际表现最好的组合）作为最优方案。\n插入ROC曲线对比图、混淆矩阵。\n\n4.5 最优模型解释\n\n展示RF的特征重要性图。\n解释前几名特征的业务含义（如total_claim_amount高、incident_severity严重、police_report_available=NO等更可能欺诈）。\n这部分增强模型可解释性，回应保险行业实际需求。\n\n4.6 讨论\n\n与文献对比：本研究RF表现与Itri(2019)、Sahin(2013)等一致或更优。\n解释为何RF综合最优：对噪声和不平衡鲁棒、特征重要性直观、训练快。\n局限性前置：数据集规模小（仅1000条）、欺诈比例较高（现实中更低）、未使用深度学习等。\n\n第5章 结论与展望5.1 研究结论\n\n逐条对应第1章四个贡献点总结：\n成功构建了完整端到端框架。\n多模型公平对比显示RF综合性能最优。\n实证了SMOTE等不平衡处理策略的有效性。\n提供了可复现的代码和方法路径。\n\n\n\n5.2 实践意义\n\n为保险公司提供了一个低成本、高可解释性的欺诈检测方案，可直接嵌入现有理赔审核流程。\n\n5.3 研究局限\n\n数据集规模较小、来源单一。\n未进行深度超参数调优。\n未引入更新的集成方法（如LightGBM、CatBoost）或深度学习。\n\n5.4 未来研究方向\n\n在更大规模真实数据集上验证。\n结合无监督异常检测（隔离森林等）构建混合模型。\n探索可解释AI技术（如SHAP值）进一步提升模型透明度。\n研究在线学习以适应欺诈模式漂移。\n\n—-\n\\cabstract{\n汽车保险领域正面临日益严峻的欺诈风险，导致行业经济损失巨大。为有效应对此类问题，本研究运用传统机器学习技术构建欺诈识别系统，提供了数据处理、特征提取以及模型构建的完整流程，采用汽车保险理赔数据集，进行相关实验，重点考察随机森林算法与其他分类器的性能对比，包括数据清洗、特征选择和不平衡处理。通过交叉验证和指标评估，结果显示优化后的随机森林模型在AUC和召回率方面表现出色。该研究验证了传统算法在实际场景中的可靠性，并为保险企业风险管理提供实用建议。\n}\n% 中文关键词(每个关键词之间用”；”分开,最后一个关键词不打标点符号。)\n\\ckeywords{汽车保险欺诈；随机森林算法；传统机器学习；数据不平衡；特征提取；性能评估}\n\n1保险业通过风险聚合与转移机制为社会经济活动提供安全保障，在全球经济运行中扮演着至关重要的角色。其庞大的资金池更是资本市场长期资本的重要来源之一（Barry &amp; Charpentier, 2020）。在财产保险领域，汽车保险覆盖面最为广泛并与日常生活紧密联系，构成了该领域的核心业务板块。其核心功能在于补偿车辆事故造成的经济损失，保障被保险人与第三方的权益，其稳健运营直接关系到千万家庭的财务安全与社会的稳定（Ngai et al., 2011）。保险公司、投保人、监管机构是这一生态的主要参与者，共同维系着市场的平衡。然而，这一平衡正受到日益猖獗的保险欺诈行为的严峻挑战。\n汽车保险欺诈已成为一个全球性的顽疾，对行业的财务健康和社会的诚信体系造成持续性的损害。欺诈行为导致保险公司支付了本不应承担的赔款，这些巨大的“渗漏”最终会通过提高保费的形式转嫁给所有诚实投保人，破坏了保险的公平性原则（Viaene &amp; Dedene, 2004）。据美国反保险欺诈联盟（Coalition Against Insurance Fraud）的报告，保险欺诈每年给美国造成的损失高达数百亿美元，其中车险领域是重灾区。欺诈的成因复杂，一方面，信息不对称使得保险公司难以在承保和理赔环节完全掌握投保人的真实风险与行为；另一方面，技术的进步，特别是数字化理赔流程的普及，在提升效率的同时，也为新型、更隐蔽的欺诈手段提供了可乘之机（Brazel &amp; Webb, 2022）。这不仅侵蚀了保险公司的承保利润，还可能导致定价模型失真，扭曲风险信号，长期而言将削弱保险的风险分担功能和社会效益。\n从广义上讲，保险欺诈是指任何以非法获取保险金为目的的故意行为。根据欺诈主体的不同，可分为保单持有人欺诈、第三方欺诈以及内部人员欺诈等。鉴于数据的可获得性与研究的可操作性，本文的研究焦点将集中于汽车理赔欺诈，即保单持有人或相关方在理赔环节，通过故意制造事故、夸大损失、伪造单据等手段骗取保险赔偿金的行为。这类欺诈是车险欺诈中最常见的形式，拥有相对丰富的公开研究数据基础，是应用数据驱动方法进行自动化检测的主要战场。\n为应对欺诈威胁，保险公司正从依赖专家规则和人工审核，转向基于数据挖掘与机器学习（ML）的自动化检测系统。传统的规则引擎虽然解释性强，但难以捕捉复杂的非线性关系和新型欺诈模式。机器学习，特别是监督学习算法，能够从历史理赔数据中自动学习欺诈模式，展现出巨大潜力。在众多机器学习方法中，集成学习因其卓越的预测性能和鲁棒性而备受关注。以随机森林（Random Forest）为代表的集成算法，通过构建多棵决策树并综合其结果，能有效缓解单棵树的过拟合问题，对高维特征和非线性关系有良好的处理能力（Polikar, 2012）。更重要的是，保险欺诈数据天然具有高度不平衡性（正常理赔远多于欺诈理赔），而随机森林通过自助采样（Bootstrap sampling）和随机特征子空间选择，能在不均衡数据上构建多样化的基分类器，从而在一定程度上提升对少数类（欺诈）样本的识别能力（Xia et al., 2023; Phua et al., 2010）。\n尽管机器学习在欺诈检测中的应用已取得丰硕成果，但现有研究仍存在一些有待深化之处。许多研究侧重于单一高级分类器（如XGBoost、深度神经网络）的性能比拼，而相对忽视了数据预处理阶段与分类模型的系统性整合与优化。特征工程、处理类别不平衡的重采样技术（如SMOTE、ADASYN）以及特征选择，对于最终模型性能的影响至关重要，有时甚至不亚于分类器本身的选择（Wang et al., 2021）。此外，在真实的汽车保险公开数据集上，对包含预处理流程在内的多种传统机器学习算法（如逻辑回归、支持向量机、决策树、随机森林、梯度提升树）进行端到端的、公平的对比实验研究相对有限，特别是深入探讨不同预处理技术如何与不同算法交互以提升欺诈检测性能的研究尚不充分。\n鉴于此，本文旨在系统性地探索并验证一套结合了先进预处理技术与经典机器学习算法的汽车保险欺诈检测框架。具体而言，本研究将在公开的汽车保险理赔数据集上，以随机森林算法为核心检测模型，系统性地集成多种特征编码、不平衡数据处理（如过采样与欠采样）及特征选择方法，构建一个完整的分析管道。通过设计详尽的对比实验，本文将评估该集成框架相对于单一模型及其他主流机器学习算法（如逻辑回归、支持向量机、XGBoost）在欺诈检测准确率、召回率、F1分数等关键指标上的性能表现，从而为构建高效、实用的车险欺诈检测系统提供实证依据。\n本文的主要贡献如下：\n\n提出了一个系统性的欺诈检测分析框架：将数据处理、特征工程、不平衡学习、特征选择与随机森林分类器进行有机整合，形成了一个可复现、可评估的完整机器学习工作流，强调了预处理环节在模型构建中的基础性地位。\n\n进行了全面、公平的算法对比实验：在公开基准数据集上，对包括随机森林在内的多种传统机器学习算法，在统一的预处理标准和评估指标下进行了性能对比与分析，为算法选择提供了实证参考。\n\n深入探讨了不平衡数据处理策略的有效性：实证检验了多种重采样技术在缓解保险欺诈数据类不平衡问题上的作用，并分析了其与不同分类器结合时的性能变化规律。\n\n提供了结构化的方法学实现：研究过程注重方法论的清晰描述与代码的结构化，确保了实验的可复现性，为后续研究者提供了可直接借鉴的技术路径和比较基线。\n\n\n本文余下部分的结构安排如下：第2章将对保险欺诈检测，特别是基于机器学习的检测方法的相关文献进行综述；第3章将详细阐述本文所采用的研究方法，包括数据集描述、预处理技术、特征工程、使用的机器学习算法以及实验设计；第4章将展示并分析实验结果，对不同模型和策略的性能进行对比与讨论；第5章将总结全文，概括主要研究发现，指出本研究的局限性，并对未来研究方向提出展望。\n2第2章 文献综述\n本章旨在回顾保险欺诈检测方法的技术演进，梳理传统机器学习算法在该领域的应用现状、优势与挑战，明确本研究的理论背景与创新点。\n保险欺诈，特别是汽车保险理赔欺诈，是全球保险业面临的一项持续性重大挑战，其导致的直接财务损失高达年度保费的5%-10%，并通过提高保费的形式将成本转嫁给全体消费者，最终侵蚀保险的风险分摊机制与社会公信力（Viaene et al., 2005; Coalition Against Insurance Fraud, 2022）。传统的欺诈检测主要依赖于专家制定的规则引擎和人工审核，这些方法虽具可解释性，但规则僵化、更新滞后，难以应对日益复杂、动态演变的欺诈模式（Ngai et al., 2011）。随着保险业务的全面数字化，海量的理赔数据得以积累，为应用数据驱动的方法进行自动化、智能化欺诈检测提供了坚实基础。\n2.1 欺诈检测方法的演进\n保险欺诈检测方法的演进与信息技术发展紧密相连。最早的检测工作完全依赖具有领域经验的核保员和理赔调查员，效率低下且主观性强。随后，基于规则的专家系统（Rule-Based Systems）成为主流，通过将专家的反欺诈知识编码为“IF-THEN”规则，实现了初步的自动化（Bentley, 2000）。然而，规则系统存在明显局限：规则创建和维护成本高，难以覆盖所有欺诈场景；对新型、协同欺诈模式不敏感；且容易产生大量误报（false positives）。为克服这些缺点，研究人员自20世纪90年代末开始探索统计方法与数据挖掘技术的应用，标志着该领域向数据驱动范式的转变。\n统计方法，如回归分析（逻辑斯蒂回归）、聚类分析（如K-Means）和异常检测，率先被引入。逻辑斯蒂回归能够量化各风险因素对欺诈概率的影响，提供了优于规则引擎的量化判别能力（Brockett et al., 2002）。聚类分析则用于识别理赔中的异常群体，而无需预先标记欺诈样本（Phua et al., 2010）。这些方法虽然比简单规则更灵活，但在处理高维、非线性、存在复杂交互关系的数据时，其表达能力仍显不足。21世纪初以来，机器学习，尤其是监督学习算法，凭借其强大的模式识别与预测能力，迅速成为欺诈检测研究的核心（West &amp; Bhattacharya, 2016）。监督学习通过从历史已标记（欺诈/非欺诈）的理赔数据中学习判别模式，构建预测模型，从而实现对新的未知理赔进行自动分类。这一范式成为当前学术研究与实际应用探索的主要方向。\n2.2 传统机器学习算法在保险欺诈检测中的应用\n在众多机器学习算法中，传统（或经典）机器学习算法因其模型相对简单、可解释性较好、计算效率较高，且在中小规模数据集上表现稳健，而在保险欺诈检测中得到了广泛研究和应用。\n单一分类器，如决策树（Decision Tree, DT）、支持向量机（Support Vector Machine, SVM）、K最近邻（K-Nearest Neighbors, KNN）和朴素贝叶斯（Naive Bayes），在早期研究中被频繁使用。决策树因其类似规则系统的树状结构、易于理解而受到青睐，但单棵树容易过拟合且稳定性差（Baesens et al., 2015）。SVM通过寻找最优分类超平面，在高维空间中表现出色，但其性能对核函数和参数选择敏感，且训练复杂度高。为了克服单一模型的局限性，集成学习（Ensemble Learning）方法被引入并证明具有显著优势。集成方法通过构建并结合多个基学习器来完成学习任务，能够有效提升模型的泛化能力、稳定性和准确性（Polikar, 2012）。\n随机森林（Random Forest, RF）和梯度提升决策树（Gradient Boosting Decision Tree, 如XGBoost、LightGBM）是两类最成功的集成算法。随机森林通过自助采样（Bootstrap）构建多棵决策树，并引入随机特征子空间，通过投票机制集成结果。研究表明，RF在保险欺诈检测任务中通常表现出优异的性能，其优势在于能有效处理高维特征、自动评估特征重要性、对缺失值和噪声不敏感，且不太容易过拟合（Sahin et al., 2013）。例如，Itri等人（2019）在汽车保险数据上比较了10种分类器，发现随机森林在准确率和AUC（曲线下面积）指标上均位列前茅。类似地，Xia等人（2023）的综述指出，基于树的集成模型在多种金融欺诈检测场景中 consistently 展现出鲁棒性。\n梯度提升树（如XGBoost）则采用串行、加法模型的方式，通过迭代地修正前一轮模型的错误，通常能达到比随机森林更高的预测精度，但其计算成本更高，且更易过拟合，需要精细的参数调优（Chen &amp; Guestrin, 2016）。Jovanovic等人（2022）的研究表明，在精心调参和处理类不平衡后，XGBoost能在欺诈检测的召回率上取得领先。此外，逻辑回归因其模型简单、可解释性强，常被用作性能比较的基线模型（Bhattacharya et al., 2011）。\n2.3 多模型比较研究与算法选择策略\n鉴于保险数据的多样性（不同地区、不同产品线）和欺诈模式的差异性，没有一种算法能被完全的通用。因此，在特定数据集上进行多模型对比实验，以实证方式选择最优算法，成为该领域研究的一个关键环节和实用策略（Lessmann et al., 2015）。这类研究不仅提供了特定场景下的最优解，也增进了对不同算法特性与数据模式之间匹配关系的理解。\n多数对比研究证实，集成方法（RF, XGBoost）通常优于单一模型（LR, DT, SVM）。例如，Nordin等人（2024）在比较多种树基模型后发现，随机森林在整体性能与稳定性上取得了最佳平衡。此类比较研究通常采用交叉验证来确保评估的可靠性，并综合考量准确率、精确率、召回率、F1分数和AUC等多个指标，因为欺诈检测任务对少数类（欺诈）的识别（高召回率）和控制误报（高精确率）往往需要权衡（Dal Pozzolo et al., 2015）。然而，现有研究在对比的广度与深度上仍存在差异。一些研究仅对比少数几种算法，或未对比较的算法进行系统的超参数优化，导致结论的普适性受限。此外，许多研究侧重于最终分类器的性能比拼，而将数据预处理和特征工程视为固定前置步骤，未深入探究不同预处理策略与不同分类器组合所产生的交互效应。\n2.4 数据不平衡与特征工程\n保险欺诈检测本质是一个极端类别不平衡的分类问题，欺诈案例通常仅占全部理赔的1%-10%。这种不平衡性导致分类器会倾向于预测多数类，从而使欺诈样本的识别率（召回率）极低（He &amp; Garcia, 2009）。\n应对此挑战主要从数据和算法两个层面着手。\n数据层面，重采样技术被广泛应用，包括随机过采样（复制少数类）、随机欠采样（删除多数类）以及合成少数类过采样技术（Synthetic Minority Over-sampling Technique, SMOTE）及其变体（如Borderline-SMOTE, ADASYN）（Chawla et al., 2002; Han et al., 2022）。算法层面，则可通过代价敏感学习（为误分类欺诈样本设置更高的惩罚权重）或使用本身对不平衡不敏感的算法（如随机森林）来应对。\n特征工程是提高模型性能的关键。原始保险数据包含大量类别型变量（如事故类型、车辆品牌）和数值型变量，常用特征包括：\n\n客户信息：年龄、教育水平、职业、爱好等\n保单信息：保单类型、赔偿限额、年费等\n事故详情：事故类型、严重程度、时间、地点等\n理赔信息：理赔金额、受伤人数、车辆损坏情况等\n时间特征：客户入会时长、事故时间等\n\n从原始数据中构造有判别力的新特征（如从投保日期和事故日期计算“保单持有期”），以及通过特征选择（如基于模型的特征重要性排序、过滤法）去除冗余或无关特征，以降低模型复杂度并可能提升性能（Zheng &amp; Casari, 2018）。然而，现有文献中，系统性地评估不同特征工程策略（特别是与特定分类器结合时）对最终欺诈检测性能影响的研究相对较少。\n2.5 可进一步探索的空间\n综上所述，尽管基于传统机器学习的保险欺诈检测研究已取得丰硕成果，尤其是以随机森林为代表的集成学习方法被证明有效，但仍存在一些探索空间：\n许多研究虽然进行了多模型对比，但往往侧重于最终分类器的性能排名，缺乏一个从数据预处理、特征工程到模型训练与评估的完整、透明、可复现的端到端分析框架的详细展示，也需要在统一的数据处理流程、相同的交叉验证设置和全面的评估指标下，对一系列有代表性的传统机器学习算法进行广泛比较。再次，对于数据预处理策略（特别是处理类不平衡的方法）与分类器性能之间的交互影响，缺乏深入的实证分析。\n本文将以一个公开的汽车保险理赔数据集为基础，构建一个系统化的分析流程，核心内容包括：（1）实施一套完整的预处理与特征工程方案；（2）在公平的实验设置下，系统对比包括逻辑回归、支持向量机、K近邻、决策树、随机森林、AdaBoost和XGBoost在内的七种传统机器学习算法的性能；（3）深入探讨随机森林算法在该任务中的优势及其原因；（4）实证分析不同的类不平衡处理策略对关键分类器性能的影响。本研究期望通过这些工作，为汽车保险欺诈检测的模型选择与工程实践提供一份实证参考与方法论范例。\n\n3本章详细阐述本研究的实验框架，包括数据集来源、数据预处理、特征工程、类不平衡处理、分类算法选择以及实验设计。\n3.1 数据采集3.1 数据集描述本研究采用公开的汽车保险理赔数据集，该数据集源于Kaggle平台上的“Vehicle Insurance Claim Fraud Detection”，该数据集包含车辆数据集（属性、型号、事故详情等）以及保单详情（保单类型、期限等），目标是检测理赔申请是否存在欺诈行为。数据集包含1000条理赔记录，每条记录对应一笔完整的汽车保险理赔申请，共计40个原始特征变量。\nhttps://www.kaggle.com/datasets/shivamb/vehicle-claim-fraud-detection/data\n目标变量为“fraud_reported”，取值为“Y”（欺诈）或“N”（非欺诈），属于典型的二分类任务。\n其中，欺诈样本占比约为25%（247条欺诈记录，753条非欺诈记录）\n\n数据集特征可分为以下几类：\n\n客户个人信息：months_as_customer（客户时长）、age（年龄）、insured_sex（性别）、insured_education_level（教育水平）、insured_occupation（职业）、insured_hobbies（爱好）、insured_relationship（家庭关系）等。\n保单信息：policy_state（投保州）、policy_csl（赔偿限额）、policy_deductable（免赔额）、policy_annual_premium（年保费）、umbrella_limit（伞状保险限额）等。\n事故信息：incident_type（事故类型）、collision_type（碰撞类型）、incident_severity（事故严重程度）、incident_state（事故发生州）、incident_city（事故城市）、incident_hour_of_the_day（事故发生小时）、number_of_vehicles_involved（涉事车辆数）等。\n理赔信息：total_claim_amount（总赔付金额）、injury_claim（人伤赔付）、property_claim（财产赔付）、vehicle_claim（车辆赔付）、bodily_injuries（受伤人数）、witnesses（目击证人数）等。\n车辆信息：auto_make（车辆品牌）、auto_model（车型）、auto_year（车辆生产年份）等。\n\n描述性统计分析表明，数值型特征如total_claim_amount和vehicle_claim在欺诈与非欺诈样本间存在显著差异；类别型特征如incident_severity（尤其是“Major Damage”级别）以及police_report_available与欺诈标签的相关性较高。这些初步观察为后续特征工程提供了重要依据。\n3.2 数据预处理 (Data Preprocessing)在应用分类算法之前，必须对原始数据进行清洗和转换，以纠正错误并提高特征质量。本研究的预处理流程如图 1 所示，包括缺失值处理、特征衍生、编码转换及数据标准化。\n3.2.1 数据清洗与缺失值处理 (Data Cleaning and Imputation)为了提高模型效率，本研究实施了以下清洗步骤：\n\n标签转换：将目标变量 fraud_reported 转换为数值格式（“Y”映射为 1，“N”映射为 0）。\n\n噪声剔除：删除了对预测无统计意义的列，包括唯一标识符（policy_number, insured_zip）、高基数类别特征（incident_location）以及全空列（_c39）。\n\n隐性缺失值处理：识别出数据中以“?”标识的缺失值，主要分布在 collision_type、property_damage 和 police_report_available 中。对于类别变量，采用众数填充或将其视作独立类别；对于数值变量，结合业务逻辑将缺失标记映射为 0（如警察报告不可用）。\n\n\n3.2.2 特征工程与衍生变量 (Feature Engineering)本研究通过特征挖掘构造了更具预测能力的变量：\n\n车辆标龄 (Vehicle Age)：利用数据基准年份（2018）减去制造年份 auto_year 得到。车辆的物理折旧程度通常与保险欺诈风险具有更强的非线性相关。\n\n事故时段分箱 (Incident Discretization)：采用区间分箱法，将 0-23 小时的连续变量 incident_hour_of_the_day 转化为七个离散时段（如凌晨、清晨、晚间等）。通过这种离散化处理，模型能够更好地识别特定高风险时间段内的欺诈模式。\n\n\n3.2.3 特征编码与标准化 (Encoding and Standardization)由于大多数机器学习模型无法处理非数值型数据，本研究采用了以下编码策略：\n\n独热编码 (One-Hot Encoding)：针对 policy_state、insured_occupation 等无序类别特征，将其转化为哑变量。\n\n标签编码 (Label Encoding)：针对具有潜在顺序或二元属性的特征应用标签编码。\n\n特征标准化：在进行多模型性能对比实验前，采用 StandardScaler 对连续型数值特征进行标准化处理，使各特征服从均值为 0、标准差为 1 的分布，消除量纲差异对逻辑回归（LR）、支持向量机（SVM）等模型的影响。\n\n\n3.2.4 数据划分 (Data Splitting)预处理完成后，数据集按 80% 训练集和 20% 测试集的比例进行随机划分。训练集用于模型学习和超参数调整，而独立的测试集则用于通过准确率、召回率（Recall）及 AUC 等指标评估系统的鲁棒性。\n\n第4章 实验结果与分析本章呈现实验结果，并对模型性能、不平衡处理效果及特征贡献进行深入分析。\n4.1 数据探索性分析4.2 特征选择效果4.3 算法性能对比4.4 XXX策略的影响4.5 最优模型解释4.6 讨论第5章 结论与展望5.1 研究结论5.2 实践意义5.3 研究局限5.4 未来方向\ninfrence\n\n通过集成机器学习和统计方法提升保险欺诈检测准确性摘要保险业在全球风险管理和提供金融安全方面发挥着关键作用。然而，该行业面临诸多挑战，特别是欺诈活动日益复杂化。为应对这些挑战，本研究旨在通过集成特征离散化、特征选择、数据重采样和二元分类等方法构建合适的决策模型，以创建用于识别保险欺诈的预测系统。本研究探讨了各种场景，包括不同分类器、特征选择方法、特征离散化技术和数据重采样策略的组合，并使用已建立的指标评估预测系统的性能。实验结果表明，在数据预处理阶段集成多种方法显著提升了分类模型的性能。采用KBD+RFE+Over+RF场景的模型实现了最高的AUC和F1分数，表明其在检测保险欺诈方面表现出色。本研究证明，通过利用重采样方法，提出的模型预测保险欺诈的能力得到显著增强，并强调了这些技术在提升所用集成人工智能技术效率方面的作用。此外，本文得出结论，保险业可以通过现代预测方法极大地受益，从而做出明智决策。\n关键词 分类 · 数据挖掘 · 特征离散化 · 保险欺诈 · 不平衡数据 · 机器学习 · 预测系统\n1 引言保险业是全球金融环境中不可或缺的组成部分，在风险管理和提供金融安全方面发挥着关键作用。保险业的基本原则是减轻金融损失或风险的可能性。保险部门由多个重要参与者组成，包括保险公司、被保险人、中介机构和监管当局（Khalil et al., 2022a）。\n保险公司面临着由动态经济、技术和监管因素塑造的复杂环境中的重大挑战。其中最关键的挑战之一是欺诈活动的增加，由先进技术和全球通信网络驱动，导致全球每年金融损失达数十亿美元（Akhtar et al., 2023）。这些欺诈活动不仅影响保险公司的盈利能力，还影响其定价策略以及提供的整体社会经济效益（Wang &amp; Xu, 2018）。\n为应对这些挑战，保险公司必须实施强有力的欺诈检测和预防措施，因为保险欺诈占其运营成本的很大一部分。除了与欺诈相关的挑战外，保险公司还面临运营困难，由于内部程序和系统的日益复杂性，这可能阻碍效率提升并阻碍数据分析和人工智能（AI）在风险评估和理赔处理中的集成（Hassan &amp; Abraham, 2013; Singh &amp; Chivukula, 2020）。因此，采用主动和灵活的方法对于确保在不确定性和变化面前的韧性、金融稳定性和创新至关重要（Khalil et al., 2024b）。《牛津英语词典》（Pearsall, 1999）将欺诈定义为“故意欺骗他人以获得金融或个人利益的行为”。保单持有人欺诈是保险欺诈的四种不同类别之一，由于其他类型欺诈的可用数据有限，本文将重点关注此类别。\n数据挖掘在保险业中广泛应用，用于欺诈检测、理赔分析、承保处理、风险评估和销售预测，因为它经常用于从海量数据中提取和揭示隐藏的洞察（Turban, 2011）。数据挖掘涉及从数据中发现统计上可靠的、以前未知的且可操作的洞察。数据必须具备可访问性、相关性、充分性和完整性。在理赔分析中使用集成算法有助于保险公司提升对理赔备案的理解并识别欺诈实例（Prasasti et al., 2020）。\n集成学习方法被广泛认可为一个突出的研究领域，它适应性强并适用于各种机器学习（ML）应用，如分类、回归，甚至无监督学习（Alsuwaillem et al., 2023）。它们的出色性能源于其提升模型泛化能力、减轻过拟合以及在单个模型可能挣扎的情况下改善性能的能力。集成学习方法可以大大提升预测准确性，但也带来了计算复杂性和模型可解释性的挑战（Khalil et al., 2022b; Piovezan et al., 2023）。集成学习是一种基本技术，旨在改善ML模型的性能。它为解决各种领域的复杂问题提供了一种强大且灵活的方法（Das et al., 2021）。\n预测系统通常由不同的数据挖掘方法支持，如数据重采样、特征离散化和特征选择，在识别风险方面发挥关键作用。通过选择相关特征子集，计算成本降低，模型的效率和可理解性大大提升（Gupta et al., 2022）。此外，数据集不平衡（即正负实例分布不均）可能影响预测算法的精度。在这种情况下，通过数据重采样可以提升模型的整体性能（Baesens et al., 2021; Subudhi &amp; Panigrahi, 2018）。回顾保险欺诈文献显示，缺乏将上述数据挖掘策略与AI分类器（如集成和经典ML方法）集成到一个统一处理程序中来开发保险欺诈分类模型的研究。\n本研究旨在通过创建多样化的检测场景来开发一个鲁棒的预测系统，使用数据重采样、特征离散化、特征选择以及不同分类器的组合。该预测系统的重点是识别保险欺诈，使用从保险公司获得的真实数据集进行验证。本研究通过利用两个不同的数据集（保险欺诈数据集和保险理赔数据集）评估预测准确性。根据对文献的批判性回顾，保险领域存在一个当前研究尚未填补的重大差距。\n因此，本研究的主要贡献如下：首先，本研究介绍了主要进展，其特征是通过引入不同的场景，使用不同的分类器，特别是采用两种不同的特征选择方法、特征离散化和三种不同的数据重采样策略。总体目标是开发一个精确且鲁棒的保险欺诈检测预测系统。其次，调查了在二元分类结果上应用离散化后跟特征选择的影响。第三，评估重采样技术对二元分类结果的影响。第四，在两个不同的数据集上实际实施提出的预测系统以确认其有效性，并公开提供代码。最后，使用四个公认的指标（准确性、敏感性（召回率）、F1分数、精度和AUC）对各种检测场景的性能差异进行彻底评估和比较。除了这些评估指标，还使用统计分析来确定所提出数据集的最有利场景。\n本文的其余部分概述如下：第2节简要介绍先前研究。第3节详细说明研究方法，包括研究设计、数据收集方法、描述本研究中用于检测保险欺诈的具体技术和方法，以及评估指标。第4节呈现和分析发现。最后，在第5节中呈现结论。\n2 文献综述长期以来，保险公司发现有充分理由在其运营中采用主动和灵活的方法，以实现其长期和短期目标，并有效应对风险预测、欺诈检测、理赔分析和定价策略等复杂挑战，以维持金融稳定并在不断变化的环境中取得成功（Barry &amp; Charpentier, 2020）。Turban（2011）将数据挖掘定义为通过应用数学、统计、人工智能和ML技术从大型数据库中提取有价值洞察的方法。\n保险欺诈仍然是一个普遍挑战，每年导致行业损失数十亿美元，需要强大的监管框架、跨市场合作和先进分析工具。学术和行业研究强调国家保险专员协会（NAIC）作为标准化反欺诈措施的关键机构，通过模型法，如其特别调查单位（SIU）指南，该指南要求保险公司遵守和数据共享协议（NAIC, 2022; Saylor, 2023）。例如，Hoyt et al.（2006）分析了汽车保险欺诈数据，发现反欺诈法律的结果喜忧参半。强制SIU和重罪分类减少了欺诈，但强制向执法部门报告增加了欺诈，表明在取代私人努力时效率低下。每年850亿美元的欺诈问题也受到立法以外的市场特定因素的显著影响。这些发现突出了针对性反欺诈措施的必要性。\n此外，Saylor（2023）的研讨会论文考察了机会主义汽车保险欺诈，强调其普遍性、经济影响和检测挑战。该研究强调机会主义欺诈占保险欺诈的很大一部分，但往往被忽视，转而关注高调的“硬”欺诈案例。使用中和理论，Saylor分析了犯罪者如何证明欺诈（例如，否认责任或受害者身份），并提出威慑策略，包括公众意识运动、增强理赔处理程序和机构间合作。主要建议重点激活内部道德控制并改善行业工具，如ISO数据库。（Aivaz et al., 2024）通过文献计量分析经济欺诈研究趋势，确定美国和中国为主要贡献者。主要发现突出对数字检测工具（AI、区块链）和社会经济影响的日益关注。该研究揭示了出版物增加但引用影响下降，表明需要更具影响力的研究。\n保险公司和数据挖掘研究人员在保险数据中遇到各种障碍，包括数据可用性、数据质量和缺失值问题。此外，他们还面临不平衡数据集和模型选择的可解释性问题（Cappiello, 2020）。因此，在保险领域进行了众多研究，使用各种方法。例如，Bhowmik（2011）提出了一种使用基于决策树（DT）和朴素贝叶斯分类的算法检测汽车保险欺诈的策略，并使用规则基于分类、决策树可视化和贝叶斯朴素可视化等程序分析预测。结果显示这些方法在识别汽车保险欺诈方面的表现良好。Dhieb et al.（2019, 2020）利用ML技术自主检测和分类机动车保险欺诈理赔，并包括识别可疑理赔的警报机制。\n进一步，Kowshalya和Nandhini（2018）使用数据挖掘技术预测保险费和欺诈理赔，减少了理赔分析的时间。他们基于汽车保险欺诈研究生成合成数据集，以开发用于检测虚假理赔的分类算法。Itri et al.（2019）开发了一种新方法，通过测试（10）ML算法来改善欺诈预测准确性，以确定哪些最有效和可靠。使用汽车保险理赔数据，该研究显示随机森林在预测欺诈方面优于所有其他算法。Subudhi和Panigrahi（2020）引入了一种基于GA的模糊C均值（FCM）聚类与监督分类器相结合的方法，用于检测汽车保险理赔欺诈，在真实数据上证明了其效率。Nordin et al.（2024）比较了传统和ML模型用于预测汽车保险欺诈，发现树增强朴素贝叶斯（TAN）模型在准确性和敏感性方面优于其他。该研究强调了ML在检测欺诈方面的有效性，并建议改善数据准备和模型设置以获得更好结果。\n另一方面，研究人员努力通过解决数据质量问题（如不平衡数据和缺失值）以及优化机器学习模型参数来改善不同领域的欺诈预测，以获得更好的性能。各种方法已被建议并用于文献中，以解决不平衡和缺失值分类挑战，当涉及到为保险欺诈检测建模获取高质量数据时。例如，Sundarkumar et al.（2015）采用随机欠采样重采样方法结合概率神经网络（PNN）、DT、SVM、逻辑回归（LR）和数据处理组方法（GMDH）。研究发现DT模型在欺诈检测中具有最高效能。同样，Hassan和Abraham（2016b）采用随机欠采样结合DT、NN和SVM模型。他们的发现表明DT模型表现出最高性能。Wang和Chen（2020）提出了一种三向集成方法，用于处理缺失数据，通过分组没有缺失值的对象并用每个组的平均属性填充空白。尽管从UCI ML存储库的实验证明了其有效性，但该方法缺乏处理缺失值的全面策略。\nHanafy和Ming（2021）研究了九种SMOTE家族方法，以解决预测保险费违约的不平衡数据。他们使用13个机器学习分类器评估这些技术，结果显示在应用SMOTE技术后分类器性能显著改善。Jovanovic et al.（2022）使用ML和组搜索萤火虫算法改进信用卡欺诈检测。使用欧洲信用卡交易的真实、不平衡数据集来调整极端梯度提升的SVM。在合成少数过采样扩展数据集后，该研究发现调整模型在准确性、召回率、精度和曲线下面积方面优于其他领先方法。Tayebi和Kafhali（2024）使用元启发式算法如遗传算法、粒子群优化和人工蜂群来优化信用卡欺诈检测中ML模型的超参数。这些方法在准确性、召回率和计算经济方面优于网格搜索，特别是对于不平衡数据集。\n基于对可用研究的全面分析，本研究旨在填补现有文献中的空白，通过进行彻底分析一个统一的框架来处理数据集并开发用于检测保险欺诈的分类模型。鉴于这一研究空白，不清楚在数据集处理期间集成推荐的方法和技术是否能改善分类模型。本研究还优先考虑积极结果，并开发方法来解释特定预测以改善模型可解释性。\n3 提出的计算方法在本节中，我们呈现了构建鲁棒保险欺诈检测系统的计算方法。我们的方法旨在通过集成不同的AI分类器与数据挖掘技术（如特征离散化、特征选择和重采样）来呈现不同的欺诈检测系统，以解决特征重要性和不平衡数据等挑战。通过概述要采用的具体步骤和技术，我们旨在实现鲁棒且可重复的结果，从而贡献于保险领域的进步。\n提出的方法结构化以确保计算任务的系统性和高效处理。我们从预处理阶段开始，如数据收集或预处理。随后，我们详细说明连续变量的离散化、SelectKbest（Kbest）和递归特征消除（RFE）技术用于特征选择、三种不同的数据重采样策略以及不同的分类器。然后，我们使用四个公认的评估指标（准确性、敏感性（召回率）、F1分数、精度和AUC）评估提出的系统的性能。这些阶段中的每一个都被视为对提出的系统整体有效性的必需。\n此外，我们强调了我们方法的适应性，它允许可扩展性和适用于一系列数据集或保险领域内的场景。这种灵活性使我们能够有效地应对数据特征和研究要求的变化，从而提升我们发现的泛化能力。系统涉及的程序的视觉表示描绘在图1中，它作为本研究上下文中保险欺诈检测的框架。\n3.1 数据收集在本分析中，使用两个不同的数据集来评估提出的系统的准确性。本研究的数据集从Kaggle.com获得。数据集中的目标变量不同。在第一个数据集中，我们实施提出的系统来检测汽车保险部门的保险欺诈，因此目标特征是“欺诈报告”列。在第二个数据集中，我们为汽车保险部门的理赔分析实施提出的系统，因此目标特征是“理赔标志”列，该列指示是否提交了理赔。图2显示两个数据集中的目标变量是分类的。因此，使用分类系统进行分析。图3显示数据集中的目标变量分布。在欺诈数据集中，非欺诈和欺诈理赔的比例为94–6%。\n数据集在欺诈汽车保险理赔上有15,419个实例，其中923个被分类为欺诈，显示数据分布中显著的类不平衡。数据集中的每个理赔由32个不同的属性定义，如表1中所列。保险理赔数据集包含10,302个汽车保险理赔，其中2,746个被分类为理赔提交，突出了显著的类不平衡。数据集中的每个理赔由26个唯一属性定义，如表2中所概述。\n本研究使用的两个数据集在大小、标签分布和缺失数据程度方面存在显著差异。第一个数据集专注于汽车保险部门中的欺诈理赔，更大，有15,419条记录，并表现出高度不平衡，其中只有6%的理赔被标记为欺诈，剩余94%为非欺诈。相比之下，第二个数据集分析是否提交了理赔，包含10,302条记录，不平衡程度较轻，有26.7%的理赔标记为提交，73.3%为非提交。此外，缺失数据在两个数据集之间显著不同。在第一个数据集中，单个特征中缺失值的最高百分比达到45.7%（补充数量），最低为0.35%（事故政策天数）。相反，第二个数据集的缺失数据范围较低，职业特征的最大值为6.45%，年龄特征的最小值为0.07%。这些差异突出了需要定制数据处理方法来解决每个数据集的独特类分布和数据完整性问题。\n3.2 数据预处理分类方法应用的最重要步骤之一是数据预处理，这也在图1的初始阶段中说明。因为数据可能包含多个错误，所以必须在任何未来操作之前处理数据。因此，此阶段涉及基本的数据处理任务，如填充缺失值、数据评分、特征编码、数据离散化和将数据分为训练和测试数据集。\n3.2.1 数据清洗和编码为了提升数据集的效率和质量，使用数据清洗来查找和修复错误、损坏和缺失信息。这使得分析和分类模型更有效（Cerda &amp; Varoquaux, 2022; Li et al., 2021）。首先，根据数据集，特征缺失值要么完全删除，要么更改其缺失值。在我们的研究中，我们从第一个数据集删除了两个特征（X21, X27），因为它们具有高百分比的缺失值，如表3所示。对于两个数据集中的剩余特征，对于二元和类别变量中的缺失值，使用列值的模式填充。相反，对于所有连续变量中的缺失值，使用列值的均值填充。\n对于目标变量，为了找到与它高度多重共线性的特征，我们检查了相关矩阵和方差膨胀因子（VIF）分析。此策略减少了多重共线性。在数据集（2）中，由于X23特征与目标变量的相关性显著，此策略很重要，以改善模型的预测准确性并保证剩余变量提供清晰且可解释的洞察与目标变量的关系。\n数据编码是预处理的重要部分，它是将原始数据转换为可以被算法和统计模型使用的数值表示。例如，我们将类别特征转换为数值格式，如将被保险人的性别分配为“1”表示“男性”和“0”表示“女性”。\n3.2.2 离散化方法离散化算法是机器学习、数据挖掘和统计分析中数据预处理的基本组成部分。将连续变量转换为离散变量简化了分析和算法应用。离散化有几个原因。首先，许多机器学习方法需要离散输入，因此必须转换连续数据。通过分组相似值，离散化简化了解释。连续变量的不同离散化方法有优缺点。使用无监督和监督方法。无监督方法如等宽和频率分箱按分布分离数据。然而，监督方法如基于决策树的离散化和基于熵的分箱使用类标签或目标变量来指导离散化。\n在本研究中，我们采用了KBinsDiscretizer（KBD）方法。KBD方法使用分箱技术将连续变量转换为离散箱，从而使需要分类输入的模型中使用连续数据。此方法可以改善清晰度、减少计算复杂性，并潜在地提升机器学习算法的效率，特别是那些受输入数据特性影响的算法。\n3.3 特征选择技术特征选择（FS），也称为属性选择或变量子集选择，是一个广泛用于减少特征空间维度的技术，同时保持给定方法的性能。特征选择呈现了一个复杂挑战，因为需要互补特征来处理交互和冗余。FS的目标是识别和消除与学习过程无关或冗余的特征。FS的主要目标是通过提升准确性和方法的效率和可理解性来改善学习性能（A. Singh &amp; Jain, 2019）。因此，需要更有效的全局搜索技术来有效解决特征选择。在本研究中，我们采用了两种不同的特征选择技术。\n3.3.1 Select K BestSelectKBest与ANOVA F值是一种单变量选择方法。在此方法中，通过消除无关特征来对特征进行排名。排名由每个特征与目标变量之间的关联计算的统计分数确定（Visalakshi &amp; Radha, 2014）。它通过计算每个特征与目标变量之间的ANOVA F值来选择K个最佳特征。具有更高F值的特征被认为与目标变量更相关。此方法在处理许多特征时特别有用，并且计算效率高。然而，它不考虑特征之间的交互，并且K的选择需要仔细确定以平衡模型性能和维度减少。K是用于特征选择的顶级特征数量（Srivatsan &amp; Santhanam, 2021）。\n3.3.2 递归特征消除（RFE）与随机森林分类器递归特征消除（RFE）是一种通过迭代从数据集中移除特征的选择特征的方法。RFE在此场景中与随机森林分类器作为估计器一起使用。该技术最初使用所有特征训练模型，然后评估每个特征的重要性（Lakshmanarao et al., 2022; Visalakshi &amp; Radha, 2014）。算法消除最不重要的特征并迭代此过程，直到达到所需特征数量。利用随机森林分类器与递归特征消除（RFE）对于通过随机森林模型生成的重要性分数来确定最重要特征是有效的。所用的分类器可以影响所选特征，并且要选择的特征数量必须仔细调整以提升模型性能（Visalakshi &amp; Radha, 2014）。\n3.4 重采样方法不平衡数据问题在许多数据集中普遍存在，导致偏差分类器模型无法对少数类做出准确预测（Kotsiantis et al., 2006）。因此，解决不平衡数据问题是必不可少的。已开发了各种方法来解决此问题，其中一种最成功的涉及使用基于采样的技术，如随机过采样和随机欠采样（Basit et al., 2022; Zhang et al., 2024）。表4显示了每个重采样方法的基本属性。\n3.5 分类器模型在提出的工作中，我们采用了不同的经典ML和集成学习分类器模型，即决策树（DT）、随机森林（RF）、AdaBoost、梯度提升（GB）和Bagging。认识到任何ML模型的性能取决于分配给其参数的具体值。\n3.5.1 决策树（DT）DT是一种灵活且可解释的分类技术，它通过递归划分数据，选择最佳分离特征到同质子集，最大化类标签纯度，直到达到停止标准，形成用于新预测的模型（Bansal et al., 2022）。它的优势在于捕捉复杂、非线性关系并处理各种数据类型，使其在许多分析场景中有用。然而，决策树容易过拟合，因为它们可以记忆训练数据，这会导致对新数据的泛化能力差，而不进行正则化。它们也对训练集的细微变化敏感，这会影响它们的预测，因此仔细的参数调整和集成方法对于最佳性能至关重要（Bansal et al., 2022）。\n3.5.2 随机森林（RF）RF是一种集成学习技术，通过训练多个决策树并结合它们的预测来提升机器学习任务中的准确性和泛化能力。对于回归任务，它取单个树预测的平均值，而对于分类任务，它使用类预测的模式（Roy &amp; George, 2017）。RF高度准确且鲁棒，通常避免过拟合，即使在缺失数据的情况下也能表现良好，这使其在各种应用中可靠。然而，RF需要大量处理能力用于大型数据集，并且缺乏单个决策树的可解释性，尽管其在多样任务中的高性能使其成为机器学习中的宝贵工具（Roy &amp; George, 2017）。\n3.5.3 自适应提升（AdaBoost）AdaBoost通过结合多个弱学习器并在每次迭代中调整误分类实例的权重来构建强分类器，这更关注困难案例，并允许后续学习器纠正先前错误，从而产生准确模型（Hassan &amp; Abraham, 2016a）。AdaBoost的优势在于其通过集成基分类器来改善弱学习器的能力，使其灵活且适应各种数据类型和问题领域。然而，AdaBoost的性能在噪声数据下可能受损，因为如果基分类器过于复杂或不稳定，它可能过拟合，这会影响其泛化。因此，其有效性取决于数据质量和分类器的简单性（Ben Jabeur et al., 2023）。\n3.5.4 梯度提升（GB）GB是一种集成学习技术，通过顺序添加弱学习器（通常决策树）来构建强大预测模型，以减少先前模型的错误。此过程通过梯度下降优化损失函数，并创建高度准确的模型（Dhieb et al., 2019）。GB模型以其强性能、对异常值的鲁棒性和处理数值和分类数据的能力而闻名，这使它们在各种分类和回归任务中高度通用。然而，尽管有这些优势，GB可能过拟合，特别是如果正则化不足或学习率太高，其迭代且复杂的模型构建过程在大型数据集上可能计算密集（Liu et al., 2019）。\n3.5.5 BaggingBagging是一种集成学习方法，通过在训练数据的随机子集上独立训练多个模型来减少方差，从而改善模型性能。通过捕捉模型间的数据变异性并通过平均（用于回归）或投票（用于分类）结合它们的预测，Bagging提升了准确性和泛化，并有效最小化过拟合并增加模型稳定性（Park &amp; Kwon, 2024）。其优势在于利用多样模型预测，这使其特别适用于复杂模型和大型数据集，通过优化性能和可扩展性。然而，Bagging可能无法改善低方差的稳定模型的结果，并且如果基模型或数据集本身有偏差，可能引入偏差。因此，评估模型稳定性和数据集特征对于使用Bagging实现最佳结果至关重要。\n3.6 分类准确性评估指标评估指标是查找和比较最佳模型的关键组成部分，它评估分类器的效率。一个受欢迎的指标是准确性，它显示正确预测的百分比。更高的准确值表明分类器整体表现更好。虽然准确性很重要，但它可能不足以解决分类困难，特别是处理不平衡数据时（Hossin &amp; Sulaiman, 2015; Khalil et al., 2024a）。针对这一挑战，使用各种分类评估标准来评估分类器的性能。\n\n\\text{Accuracy (AC)} = \\frac{TP + TN}{TP + FP + TN + FN}, \\quad (1)\n\\text{Recall (RC)} = \\frac{TP}{TP + FN}, \\quad (2)\n\\text{Precision (PR)} = \\frac{TP}{TP + FP}, \\quad (3)\nF1 - \\text{Score F} = \\frac{2 \\times TP}{2 \\times TP + FP + FN}, \\quad (4)其中TP表示真阳性，TN表示真阴性，FP是假阳性，FN是假阴性。\n4 预测分析和模型可解释性在本节中，我们呈现了为解决前述部分概述的研究问题而进行的实验和结果，即在数据集处理期间集成推荐的方法和技术是否能改善分类模型。我们的研究旨在构建一个鲁棒的分类模型来检测保险欺诈。为实现这一目标，我们通过创建多样化的检测场景设计并实施了一系列实验，使用数据重采样、特征离散化、特征选择以及不同分类器的组合。\n4.1 实验设置实验在一台配备2.60 GHz Intel(R) Core (TM) i7-12700F CPU和32 GB RAM的机器上运行。我们使用64位Windows 11。Python用于实现框架。Pandas数据帧加载数据集。Scikit Learn（Pedregosa et al., 2011）库实现ML和集成模型。为确保实验模型、参数配置和报告结果的可再现性，我们在作者的GitHub网站³上公开提供了所提出工作的源代码、可视化和数据。\n4.2 实验设计在我们的研究中，我们旨在探索在统一框架中结合各种技术如何改善预测模型的构建，导致开发一个可靠的系统，用于准确检测保险欺诈。我们希望通过彻底的研究和实验确定这一集成策略在提升预测模型以及提升保险欺诈检测准确性和可靠性的有效性。\n因此，我们的研究包括六个实验，每个实验都采用特定方法组合的不同场景，如图4所示。我们\n³https://github.com/AhmedKhalil91/classification-model.git.\n在每个实验中分析了各种条件，以理解它们的个别影响。六个实验的基础可以总结如下：\n(a) 在第一个实验中，数据直接使用而不进行离散化、特征选择或不平衡问题处理，直接输入分类模型，然后使用准确性、F1分数和AUC-ROC等指标评估模型的性能。此基线评估作为比较各种预处理技术影响的参考点，在后续实验中。\n(b) 第二个实验考察了在连续特征上应用KBD离散化方法的影响，然后修改的数据直接输入分类模型，然后评估模型的性能，以确定离散化如何影响模型学习，特别是相对于基线更有效地处理连续数据。\n(c) 第三个实验探索了特征选择（Kbest和RFE）技术的使用，以减少特征空间并潜在提升模型性能。在应用特征选择后，数据直接输入分类模型，然后使用标准指标评估模型性能，以了解关注相关特征是否能提升准确性和减少过拟合。\n(d) 第四个实验评估了KBD离散化后跟KBest和RFE特征选择的组合对分类性能的影响。在应用离散化和特征选择后的数据直接输入分类模型，然后评估模型的性能。此实验调查了离散化和特征选择之间的潜在协同作用在提升预测准确性和模型鲁棒性方面的作用。\n(e) 在第五个实验中，分析了重采样（Under, Over和SMOTE）技术对分类器性能的影响，以处理数据集中的类不平衡。每个重采样方法单独应用以平衡训练集，模型使用重采样数据训练，然后重点识别哪个重采样方法最佳提升不平衡类情况下的结果。\n(f) 最终实验涉及全面预处理方法，应用KBD离散化，后跟特征选择和重采样（欠采样、过采样和SMOTE）以解决类不平衡。然后使用处理后的数据训练分类模型，并使用指标评估其性能。此实验旨在展示集成多个预处理技术的累积益处及其对分类性能的整体影响。\n4.3 实验结果和讨论在本节中，我们提供对实验结果的全面检查，强调各种数据预处理技术对分类器性能的关键影响。实验遵循系统方法，从数据集预处理开始，将其分成80–20比例的训练和测试集，然后测试分类器在不同预处理场景下的表现。包括准确性、F1分数、召回率、精度和AUC在内的性能指标被记录，并在表5中详细说明。值得注意的是，对于不平衡数据集，AUC和F1分数优先于准确性，因为这些指标更好地解决类分布，并减少当一个类过度表示时的偏差。\n实验1 在没有数据变换的基线场景中，每个分类器被测试原始预测能力。结果显示决策树（DT）分类器以68.15%的AUC领先，其次是RF模型以52.14%的AUC分数在第一个数据集，而梯度提升（GB）在第二个数据集表现更好，实现了68.08%的AUC。这些分数反映了每个模型的基本效能，而没有来自数据变换的增强。\n实验2 该研究接下来调查了数据离散化对分类性能的影响，通过应用KBD技术于连续特征。KBD+DT的组合在第一个数据集上展示了显著改善，以69.89%的AUC，而KBD+GB在第二个数据集上以68.43%的AUC领先。这一AUC的增加表明数据离散化可以锐化分类器处理类区分的能力。\n实验3 为评估特征选择的影响，我们应用了两个方法，KBest和RFE。此实验使用减少特征集评估分类器分为两个场景。在第一个数据集，组合KBest+DT达到了最高的75.35%的AUC，超过基线，而KBest+GB在第二个数据集上以67.57%的AUC表现最佳。这些结果突出关注相关特征可以提升分类准确性通过减少噪声并聚焦于最信息丰富的属性。\n实验4 此实验集成了离散化和特征选择，在两个数据集上展示了增强的结果。具体来说，（KBD+KBest+DT）组合在第一个数据集达到了最高的77.34%的AUC，而（KBD+KBest+GB）在第二个数据集得分为67.89%。这些发现表明离散化和特征选择的组合通过同时减少维度并强调基本特征来加强模型。\n实验5 我们考察了三种重采样技术（欠采样、过采样和SMOTE）对分类器性能的影响在此实验中分为三个场景，旨在解决类不平衡。结果显示（Oversampler+RF）组合在分类器中展示了最高性能，以95.5%的AUC在第一个数据集和88.17%在第二个数据集。这些结果确认重采样方法，特别是过采样，可以通过平衡类分布并使模型从少数类学习更有效地显著改善模型性能。\n实验6 此最终实验评估了离散化、特征选择和重采样的组合影响于分类器效能。六个场景被测试，揭示（KBD+RFE+Over +RF）组合实现了最高的99.26%的AUC分数在第一个数据集和89.29%在第二个数据集。这一结果标志着对其他场景的实质改善，表明集成所有三种预处理技术是最大化分类器准确性和可靠性在类区分中的强大策略。\n为了提供清晰和简洁的概述，表6和7总结了这一比较，聚焦于AUC分数和F1分数作为选择每个实验中顶级表现场景的主要指标。此指标量化了模型区分类的能力，使能够有效识别展示在类不平衡情况下优越区分力的模型。\n结果显示每个预处理步骤如何影响模型有效分类数据的能力，特定技术导致两个数据集性能指标的显著改善。重采样技术，特别是过采样和SMOTE倾向于显示模型性能的显著增加，并突出它们在解决类不平衡方面的有效性。\n表5的详细分析揭示那些特定预处理技术组合一致提升了实验中的模型准确性。例如，决策树在与KBD离散化、RFE特征选择和SMOTE重采样配对时展示了最佳性能。该协同作用为每个数据集提供了优越的准确性和泛化。\n模式在模型中保持。对于随机森林，结合KBD离散化、RFE特征选择和过采样一致产生了数据集上的最高分数，肯定这些预处理策略提升性能，特别是对于树基模型。对于像AdaBoost和梯度提升这样的集成方法，最好结果也通过配对KBD离散化、RFE或KBest特征选择和SMOTE重采样获得，表明这些技术为集成模型提供相当益处，在保持准确性和防止过拟合方面。\n4.4 统计测试分析不同场景源于各种重采样和特征选择程序，这些变异直接影响分类器的性能。识别最佳策略变得挑战，因为不同数据集拥有独特特征，并且变化的数据预处理选项可以影响分类器准确性和鲁棒性。由于这一复杂性，确定评估和比较分类器在不同数据预处理情况下的最佳方法组合需要系统方法。\n统计显著性测试包括ANOVA和Friedman测试有助于客观和仔细评估这些差异。如表8所示，我们使用了两个测试来考察分类器在给定不同重采样和特征选择组合时的表现。我们特别感兴趣于每个方法在每个数据集内的AUC值。我们能够拒绝零假设，因为p值小于0.05阈值，这表明有统计上显著的差异。结果确认替代假设，即不同数据集内的场景表现显著不同。\n确认不同方法在每个数据集内表现显著不同使用ANOVA和Friedman测试后，进一步分析需要识别每个数据集的最佳场景。表9和10提供各种预测模型和预处理策略的全面评估，系统分析多个实验场景以识别基于中位性能值、排名总和和Friedman测试排名的最有效组合。中位指标反映模型性能的中心趋势，而排名总和和排名列提供每个场景相对性能的洞察基于Friedman测试。\n如表9所示，对于数据集（1）的顶级表现场景是KBD + RFE + Over + ML，它实现了最高排名（Rank 1）以0.9584的中位AUC和75的排名总和。这密切跟随KBD + RFE + SMOTE + ML，它获得第二排名（Rank 2）以0.9456的中位AUC，和Under + ML，它实现第三排名（Rank 3）以0.8936的中位AUC。显着地，纳入递归特征消除（RFE）和过采样技术的场景一致优于其他方法，表明特征选择和数据平衡的组合显著改善模型性能。相比之下，简单方法如Raw data + ML和KBD + ML排名相当低（Ranks 13和14），强调高级预处理技术的作用。\n表10中呈现的结果对于数据集（2）揭示KBD + RFE + Over + ML场景提供了最高性能，实现顶级排名（Rank 1）以0.8510的中位值和69的排名总和。这密切跟随KBD + Kbest + SMOTE + ML，它获得第二排名（Rank 2）以0.8299的AUC中位，和KBD + RFE + ML，它实现第三排名（Rank 3）以0.8530的中位AUC。相比之下，简单方法如Raw data + ML（Rank 12，中位=0.6287）和SMOTE + ML（Rank 15，中位=0.6172）表现差，强调高级预处理策略的作用。\n总之，此分析证明结合各种预处理技术可以显著改善分类模型性能。最佳组合，特别是对于区分任务如保险欺诈检测，发现于实验6中（KBD + RFE + Over + RF）场景，它展示了两个数据集上最高的AUC分数。这一组合有效平衡精度和召回，突出使用集成预处理方法来优化分类器准确性和鲁棒性的价值。这些发现提供有价值的洞察于数据预处理在优化分类器性能方面的关键作用，并可以指导未来研究在特定模型家族中选择适当的预处理策略。\n4.5 使用SHAP分析解释预测模型预测模型结果的解释是理解其行为并确保其在真实世界应用中可靠性的关键步骤（de Souza et al., 2024）。作为最先进的解释性框架，SHAP（SHapley Additive exPlanations）分析测量每个特征对模型预测的贡献，这有助于我们理解变量基础上的更高性能。通过检查SHAP值，我们可以识别影响模型发现的关键特征，验证所选特征的重要性，并从数据集基础模式中衍生实际洞察（Lundberg &amp; Lee, 2017）。这一可解释性步骤不仅提升了对模型的信任，还为精炼预处理策略和改善未来预测性能提供了宝贵指导。正如表6对于数据集（1）所示，通过全面评估识别的最佳表现场景是KBD + RFE + Over + RF。\n结果通过SHAP值说明在图7中，它确定特征对模型最终结果的影响。SHAP值范围大约-0.4到0.4，表明每个特征强度和方向的影响。正值（向右）提升模型输出，而负值（向左）减少它。这澄清了各种特征的重要性及其对结果的影响。图7说明了特征的垂直排名，最重要的位于顶部，最不重要的位于底部。主要特征如X31、X13和X16具有最大的SHAP值，表明它们对模型预测的重大影响。\n根据结果，变量X31（表示保险覆盖类型）、X13（显示事故责任人）和X16（指示汽车定价类别）具有最显著影响，SHAP值范围从0.2到0.4。这些特征很可能作为模型性能的主要驱动因素，并与最佳表现场景（KBD+RFE+Over+RF）一致，该场景结合了特征选择和领域特定知识。另一方面，像X12、X22和X7这样的特征具有较低的SHAP值，做出小贡献，表明它们要么不必要，要么相关性小。\n4.6 研究局限性虽然本研究通过统计和机器学习方法的集成开发了用于保险欺诈检测的鲁棒预测系统，但应承认几个重要局限性。最值得注意的是，我们当前的分析受限于公开可用数据集缺乏详细经济变量，这排除了全面经济影响评估，如成本效益矩阵、ROI分析或保险特定现象如道德风险和逆向选择的量化建模。这些分析需要访问专有金融指标（例如，理赔特定成本结构、保单持有人保费历史和损失比率），这超出了我们数据的范围。我们因此优先考虑核心检测算法的开发和验证，在可用数据的约束内。\n然而，我们认识到这些经济维度对于展示真实世界实施价值至关重要，并提出未来研究应：（1）建立行业伙伴关系以访问敏感金融数据进行全面经济建模；（2）开发集成框架，将欺诈预测与成本相结合；（3）调查保险欺诈的行为经济学方面，通过更丰富的保单持有人数据集。这些扩展将显著提升欺诈检测系统的实际效用，同时解决本研究已识别的技术预测能力和商业价值展示之间的重要交叉点。\n我们数据集的横截面性质阻止了全面时序验证，因为我们缺乏理赔时间戳、历史欺诈模式和方案演变的纵向记录。这一局限性限制了我们检查关键动态方面，包括季节性欺诈趋势、欺诈者行为适应模式和时序模型性能退化——所有这些对于在生产环境中维持检测准确性至关重要。我们强调，通过行业伙伴关系进行纵向数据收集来解决这些时序维度代表了一个关键的未来研究方向，以桥接实验验证和操作部署之间的差距。\n我们研究的另一个局限性是由于隐私约束缺乏敏感人口统计数据（例如，种族、性别），这阻止了使用像人口统计平价这样的指标进行公平性评估。虽然这保护了理赔人隐私，但它限制了我们评估潜在偏差的能力——鉴于保险部门的脆弱性对歧视性结果，这是一个关键担忧。未来具有适当数据的工作应严格审计人口统计组的预测并实施公平意识建模技术，以确保公平的欺诈检测系统。\n5 结论总之，本研究提供了对保险业欺诈检测的深入检查，通过利用多方面的途径集成多样数据预处理技术和分类算法。该分析调查了各种分类器、特征选择方法、数据离散化技术和重采样策略如何影响欺诈检测模型的性能。实证结果揭示了结合这些方法的显著优势，实验6组合（KBD+RFE+过采样+随机森林）展示了在检测欺诈理赔方面的最高效能，如通过优越指标如AUC和F1分数所证明。这种方法突出了欺诈检测中集成策略的重要性，这表明数据挖掘和机器学习技术的全面应用可以大大提升欺诈检测准确性，并帮助保险公司最小化金融损失。\n这一框架的含义对于行业从业者和政策制定者都是实质性的。通过采用这样的结构化和数据驱动方法，保险公司可以加强其欺诈检测系统，从而加强整体金融诚信和运营韧性。此外，这一框架不仅作为选择最佳预测模型的指南，还作为建立更鲁棒行业欺诈预防实践的基础。\n虽然我们的研究提供了有效的欺诈检测框架，但其横截面设计限制了时序验证，由于缺乏纵向数据（例如，理赔时间戳、欺诈模式演变）和详细经济变量的缺失（例如，成本结构、保单持有人成本历史）限制了成本效益分析、ROI量化以及保险特定现象如道德风险和逆向选择的建模。未来研究应扩展这一工作，通过：（1）纳入时序分析以评估季节趋势、欺诈者适应和模型衰退；（2）开发集成/混合分类器与高级特征离散化和重采样策略以改善鲁棒性；（3）建立行业伙伴关系以实现纵向数据集的真实世界验证；以及（4）未来经济建模需要保险公司合作以访问金融数据（理赔成本、支付历史）进行成本效益分析、ROI量化以及道德风险/逆向选择研究。此外，测试新型特征选择技术和自适应学习方法对于应对演变的欺诈策略至关重要。这些进步将桥接实验验证和操作部署之间的差距，最终提升保险部门的韧性和可持续性。我们的发现为这些努力奠定了基础，为从业者提供可扩展工具，同时为更安全和可信的欺诈检测生态系统铺平道路。\n资助 开放访问资助由科技与创新资助局（STDF）在埃及知识银行（EKB）的合作下提供。作者声明在准备本手稿期间未收到任何资金、赠款或其他支持。\n数据可用性 支持本研究发现的数据可在以下链接获得（https://github.com/AhmedKhalil91/classification-model.git）。\n声明\n利益冲突 作者声明没有相关的金融或非金融利益披露。\n开放访问 本文根据Creative Commons Attribution 4.0国际许可授权，该许可允许在任何媒介或格式中使用、共享、改编、分发和复制，只要您给予原作者和来源适当信用，提供Creative Commons许可链接，并指示是否进行了更改。本文中的图像或其他第三方材料包含在文章的Creative Commons许可中，除非在信用线中另有说明。如果材料未包含在文章的Creative Commons许可中，且您的预期用途不符合法定规定或超过允许用途，您将需要直接从版权持有人获得许可。要查看此许可的副本，请访问http://creativecommons.org/licenses/by/4.0/。\n参考文献Aivaz, K. A., Florea, I. O., &amp; Munteanu, I. (2024). 经济欺诈及其相关风险：一种集成文献计量分析方法. 风险, 12(5), 74.Akhtar, P., Ghouri, A. M., Khan, H. U. R., Amin ul Haq, M., Awan, U., Zahoor, N., Khan, Z., &amp; Ashraf, A. (2023). 使用人工智能和机器学习检测假新闻和虚假信息以避免供应链中断. 运筹学年鉴, 327(2), 633–657. https://doi.org/10.1007/s10479-022-05015-5Alsuwaillem, A. A. S., Salem, E., &amp; Saudagar, A. K. J. (2023). 不同机器学习算法在检测金融欺诈方面的性能. 计算经济学, 62(4), 1631–1667. https://doi.org/10.1007/s10614-022-10314-xAmirruddin, A. D., Muharam, F. M., Ismail, M. H., Tan, N. P., &amp; Ismail, M. F. (2022). 合成少数过采样技术（SMOTE）和逻辑模型树（LMT）-自适应提升算法用于分类油棕（Elaeis guineensis）营养和叶绿素充足水平的失衡数据集. 农业计算机与电子, 193, 106646. https://doi.org/10.1016/j.compag.2021.106646Baesens, B., Höppner, S., Ortner, I., &amp; Verdonck, T. (2021). RobROSE：处理欺诈检测中不平衡数据的鲁棒方法. 统计方法与应用, 30(3), 841–861. https://doi.org/10.1007/s10260-021-00573-7Bansal, M., Goyal, A., &amp; Choudhary, A. (2022). K-最近邻、遗传、支持向量机、决策树和长短期记忆算法在机器学习中的比较分析. 决策分析杂志, 3, 100071.Barry, L., &amp; Charpentier, A. (2020). 个性化作为承诺：大数据能否改变保险实践？ 大数据与社会, 7(1), 文章 2053951720935143. https://doi.org/10.1177/2053951720935143Basit, M. S., Khan, A., Farooq, O., Khan, Y. U., &amp; Shameem, M. (2022). 处理不平衡医疗数据集的因果：大数据中的基于集成和划分的特征选择. 2022 第5届多媒体、信号处理和通信技术国际会议 (IMPACT), 1–7. https://doi.org/10.1109/IMPACT55510.2022.10029111Ben Jabeur, S., Stef, N., &amp; Carmona, P. (2023). 使用XGBoost算法和变量重要性特征工程预测破产. 计算经济学, 61(2), 715–741. https://doi.org/10.1007/s10614-021-10227-1Bhowmik, R. (2011). 使用数据挖掘技术检测汽车保险欺诈. 计算与信息科学新兴趋势杂志, 2(4), 156–162.Cappiello, A. (2020). 保险企业的风险与控制. 在 A. Cappiello (编), 欧洲保险业：法规、风险管理和内部控制 (pp. 7–29). Springer International Publishing. https://doi.org/10.1007/978-3-030-43142-6_2Cerda, P., &amp; Varoquaux, G. (2022). 编码高基数字符串分类变量. IEEE知识与数据工程汇刊, 34(3), 1164–1176. https://doi.org/10.1109/TKDE.2020.2992529Das, S., Datta, S., Zubaidi, H. A., &amp; Obaid, I. A. (2021). 使用可解释机器学习分类树木和公用杆相关碰撞伤害类型. IATSS研究, 45(3), 310–316. https://doi.org/10.1016/j.iatssr.2021.01.001de Souza, M., de Castro, J. G., Peng, D. T., &amp; Gartner, I. R. (2024). 基于机器学习分析银行业金融机构金融压力的因果关系. 计算经济学, 64(3), 1857–1890. https://doi.org/10.1007/s10614-023-10514-zDhieb, N., Ghazzai, H., Besbes, H., &amp; Massoud, Y. (2019). 极端梯度提升机器学习算法用于安全汽车保险运营. 2019 IEEE车辆电子与安全国际会议 (ICVES), 1–5.Dhieb, N., Ghazzai, H., Besbes, H., &amp; Massoud, Y. (2020). 用于自动保险系统的安全AI驱动架构：欺诈检测和风险测量. IEEE访问：实用创新、开放解决方案, 8, 58546–58558. https://doi.org/10.1109/ACCESS.2020.2983300Gupta, S., Modgil, S., Bhattacharyya, S., &amp; Bose, I. (2022). 人工智能用于运筹研究领域的决策支持系统：回顾和未来研究范围. 运筹学年鉴, 308(1), 215–274. https://doi.org/10.1007/s10479-020-03856-6Hanafy, M., &amp; Ming, R. (2021). 通过数据级别方法改善汽车保险中的不平衡数据分类. 先进计算机科学与应用国际杂志, 12(6), 493–499.Hassan, A. K. I., &amp; Abraham, A. (2013). 计算智能模型用于保险欺诈检测：十年研究的回顾. 网络与创新计算杂志, 1(2013), 341–347.Hassan, A. K. I., &amp; Abraham, A. (2016a). 使用集成结合分类预测埃及市场保险公司破产. 计算机信息系统与工业管理应用国际杂志, 8, 257–265.Hassan, A. K. I., &amp; Abraham, A. (2016b). 使用不平衡数据分类建模保险欺诈检测. 在 N. Pillay, A. P. Engelbrecht, A. Abraham, du M. C. Plessis, V. Snášel, &amp; A. K. Muda (编), 自然和生物启发计算进展 (pp. 117–127). Springer International Publishing.Hossin, M., &amp; Sulaiman, M. N. (2015). 数据分类评估的评价指标回顾. 数据挖掘与知识管理过程国际杂志, 5(2), 1.Hoyt, R. E., Mustard, D. B., &amp; Powell, L. S. (2006). 州立法在减轻道德风险方面的有效性：来自汽车保险的证据. 法律与经济学杂志, 49(2), 427–450. https://doi.org/10.1086/501092Itri, B., Mohamed, Y., Mohammed, Q., &amp; Omar, B. (2019). 汽车保险欺诈检测的机器学习算法性能比较研究. 2019第三届智能计算与数据科学国际会议 (ICDS), 1–4. https://doi.org/10.1109/ICDS47004.2019.8942277Jovanovic, D., Antonijevic, M., Stankovic, M., Zivkovic, M., Tanaskovic, M., &amp; Bacanin, N. (2022). 使用组搜索萤火虫算法优化信用卡欺诈检测的机器学习模型. 数学, 10(13), 2272.Kafhali, E., S., &amp; Tayebi, M. (2024). 基于元启发式的超参数优化对欺诈交易检测性能分析. 进化智能, 17(2), 921–939.Khalil, A. A., Liu, Z., &amp; Ali, A. A. (2022a). 使用自适应网络基于模糊推理系统模型预测埃及石油保险的损失比率. 风险管理与保险评论, 25(1), 5–18. https://doi.org/10.1111/rmir.12200Khalil, A. A., Liu, Z., Salah, A., Fathalla, A., &amp; Ali, A. (2022b). 使用袋装和提升集成技术预测埃及市场保险公司破产. IEEE访问：实用创新、开放解决方案, 10, 117304–117314. https://doi.org/10.1109/ACCESS.2022.3210032Khalil, A. A., Liu, Z., Fathalla, A., Ali, A., &amp; Salah, A. (2024a). 基于机器学习的保险欺诈检测方法用于类不平衡数据集与缺失值. IEEE访问. https://doi.org/10.1109/ACCESS.2024.3468993Khalil, A. A., Liu, Z., Fathalla, A., Ali, A., &amp; Salah, A. (2024b). 使用自适应神经模糊推理系统的集成和组合模型提升埃及保险业的保险预测精度. 应用人工智能, 38(1), 2348413. https://doi.org/10.1080/08839514.2024.2348413Kotsiantis, S., Kanellopoulos, D., &amp; Pintelas, P. (2006). 处理不平衡数据集：回顾. GESTS计算机科学与工程国际交易, 30(1), 25–36.Kowshalya, G., &amp; Nandhini, M. (2018). 汽车保险中的欺诈理赔预测. 2018第二届发明通信与计算技术国际会议 (ICICCT), 1338–1343. https://doi.org/10.1109/ICICCT.2018.8473034Lakshmanarao, A., Srisaila, A., &amp; Kiran, T. S. R. (2022). 使用特征选择方法的自适应信用卡欺诈检测技术. 2022通信、计算与物联网国际会议 (IC3IoT), 1–5.Li, P., Rao, X., Blase, J., Zhang, Y., Chu, X., &amp; &amp; Zhang, C. (2021). CleanML：评估数据清洗对ML分类任务影响的研究. 2021 IEEE第37届数据工程国际会议 (ICDE), 13–24. https://doi.org/10.1109/ICDE51399.2021.00009Liu, J., Wu, C., &amp; Li, Y. (2019). 使用基于金融网络的信息和GA基于梯度提升方法改善财务困境预测. 计算经济学, 53(2), 851–872. https://doi.org/10.1007/s10614-017-9768-3Liu, T., Zhu, X., Pedrycz, W., &amp; Li, Z. (2020). 基于信息粒度的欠采样方法设计用于不平衡数据分类. 软计算, 24(22), 17333–17347. https://doi.org/10.1007/s00500-020-05023-2Lundberg, S. M., &amp; Lee, S. I. (2017). 解释模型预测的统一方法. 神经信息处理系统进展, 30, 1–10.NAIC (2022). 特别调查单位 (SIU) 指南.Nordin, S. Z. S., Wah, Y. B., Haur, N. K., Tan, K. P., Hashim, A., Rambeli, N., &amp; Jalil, N. A. (2024). 使用经典和机器学习模型预测汽车保险欺诈. 电气与计算机工程国际杂志 (IJECE), 14(1), 911–921.Park, Y., &amp; Kwon, T. Y. (2024). 使用划分袋装的大数据特征选择集成. 计算经济学. https://doi.org/10.1007/s10614-024-10741-yPearsall, J. (1999). 简明牛津词典第10版. Oxford UP.Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Prettenhofer, P., Weiss, R., &amp; Dubourg, V. (2011). Scikit-learn：Python中的机器学习. 机器学习研究杂志, 12, 2825–2830.Piovezan, R. P. B., de Andrade Junior, P. P., &amp; Ávila, S. L. (2023). 用于不完整数据的三向集成聚类. IEEE访问 : 实用创新, 开放解决方案, 8, 91855–91864.Prasasti, I. M. N., Dhini, A., &amp; Laoh, E. (2020). 使用监督分类器检测汽车保险欺诈. 2020大数据与信息安全国际研讨会 (IWBIS), 47–52. https://doi.org/10.1109/IWBIS50925.2020.9255426Roy, R., &amp; George, K. T. (2017). 使用机器学习技术检测保险理赔欺诈. 2017电路、功率和计算技术国际会议 (ICCPCT), 1–6. https://doi.org/10.1109/ICCPCT.2017.8074258Saylor, A. T. (2023). 增强机会主义汽车保险欺诈的威慑和检测的建议，用于保险专业人士和行业伙伴 [硕士论文, 威斯康星大学 – Platteville]. https://minds.wisconsin.edu/bitstream/handle/1793/84189/Saylor,%20Andrew.pdf?sequence=1Singh, S. K., &amp; Chivukula, M. (2020). 人工智能在保险业中的应用评论. 人工智能趋势, 4(1), 75–79.Singh, A., &amp; Jain, A. (2019). 基于特征选择方法的自适应信用卡欺诈检测技术. 在 S. K. Bhatia, S. Tiwari, K. K. Mishra, &amp; M. C. Trivedi (编), 计算机通信与计算科学进展 (pp. 167–178). Springer Singapore.Srivatsan, S., &amp; Santhanam, T. (2021). 使用特征选择和提升技术的早期糖尿病发作检测. 软计算ICTACT杂志, 12(1), 2474–2485.Subudhi, S., &amp; Panigrahi, S. (2018). 类不平衡在检测汽车保险欺诈中的影响. 2018第二届数据科学与商业分析国际会议 (ICDSBA), 528–531. https://doi.org/10.1109/ICDSBA.2018.00104Subudhi, S., &amp; Panigrahi, S. (2020). 使用优化的模糊c均值聚类和监督分类器检测汽车保险理赔欺诈. 金 Saud大学计算机与信息科学杂志, 32(5), 568–575. https://doi.org/10.1016/j.jksuci.2017.09.010Sundarkumar, G. G., Ravi, V., &amp; Siddeshwar, V. (2015). 基于单类支持向量机的欠采样：应用于流失预测和保险欺诈检测. 2015 IEEE计算智能与计算研究国际会议 (ICCIC), 1–7. https://doi.org/10.1109/ICCIC.2015.7435726Tayebi, M., &amp; Kafhali, E., S. (2024). 元启发式基于超参数优化对欺诈交易检测的性能分析. 进化智能, 17(2), 921–939.Turban, E. (2011). 决策支持与商业智能系统. Pearson Education India.Visalakshi, S., &amp; Radha, V. (2014). 特征选择技术及其应用文献回顾：数据挖掘中特征选择的回顾. 2014 IEEE计算智能与计算研究国际会议, 1–6.Wang, P., &amp; Chen, X. (2020). 用于不完整数据的三向集成聚类. IEEE访问 : 实用创新, 开放解决方案, 8, 91855–91864.Wang, Y., &amp; Xu, W. (2018). 使用深度学习和基于LDA的文本分析检测汽车保险欺诈. 决策支持系统, 105, 87–95. https://doi.org/10.1016/j.dss.2017.11.001Xiaolong, X., Wen, C., &amp; Yanfei, S. (2019). 用于不平衡数据分类的过采样算法. 系统工程与电子杂志, 30(6), 1182–1191. https://doi.org/10.21629/JSEE.2019.06.12Zhang, X., Yu, L., &amp; Yin, H. (2024). 基于集成重采样的迁移AdaBoost算法用于小样本信用分类与类不平衡. 计算经济学. https://doi.org/10.1007/s10614-024-10690-6  \n","categories":["归档"]},{"title":"2025-12-29-关于画布项目的相关考虑","url":"/Arknight-notes/posts/2357.html","content":"GitHub 仓库 https://github.com/Zhongye1/BDdraw_DEV\n该项目技术栈先进（React 18 + TypeScript + Vite + TailwindCSS + Zustand + PixiJS v8），涉及高性能渲染、无限画布、撤销/重做、实时协作等复杂功能，因此问题往往聚焦于性能优化、状态管理、图形渲染、架构设计以及实际工程实践。\n1. 项目整体介绍与架构设计项目的主要功能、目标用户以及它解决了哪些实际问题？\nBDdraw_DEV 是一个现代化的协同 2D 画布编辑器，采用 React + TypeScript + PixiJS 技术栈构建。该项目提供多种基本图形（矩形、圆形、菱形、线条、箭头、画笔等）元素的绘制，支持背景色、边框宽度、边框颜色等图形属性设置、富文本编辑、图片插入与滤镜处理，支持无限画布缩放、拖拽、提供 minimap，实现元素选择、分组、旋转、调整大小，支持撤销重做，快捷键，数据持久化，本地优先编辑，海量元素处理等交互功能。\n该项目作为一个集成协同编辑、离线编辑的无限画布，来解决团队协作协作效率和同步的问题\n\n项目架构是如何设计的？为什么选择将 React 用于 UI 层、Zustand 用于状态管理、PixiJS 用于渲染层分离？\n项目的核心在于其三层架构设计：React 负责 UI 层、Zustand 管理状态层、PixiJS 处理渲染层，实现数据驱动视图的模式。其便于实现撤销/重做、数据持久化和多人协同编辑等高级功能\n其优势在于：解耦设计：渲染层、状态管理层和逻辑层相互独立，便于维护和扩展便于协同：所有状态都集中管理在 Zustand Store 中，便于实现多人协同编辑易于撤销/重做：通过保存和恢复 Store 的快照实现完整的撤销/重做功能可持久化：状态数据可以轻松序列化/反序列化，便于保存和传输\n\n项目是如何组织目录结构的？这种模块化设计带来了哪些好处？前端部分主要是分为五个模块：\nsrc/api - API 客户端和类型定义（处理前后端通信）\ntypes - API 类型定义\nutils - API 工具函数\nAPI 服务封装和客户端工具\n\nsrc/components - React UI 组件（各种 UI 组件）\ncanvas_toolbar - 画布工具栏组件\ncollaboration - 协作功能组件\nheader - 页面头部组件\nproperty-panel - 属性面板组件\nrichtext_editor - 富文本编辑器组件\n\nsrc/hooks - 自定义 React Hooks\n状态管理（简单的本地存储，用于存储用户偏好、UI 状态等）\n快捷键处理\n\nsrc/lib - 工具库和核心功能模块\nAddElementCommand.ts、RemoveElementCommand.ts、UndoRedoManager.ts - 命令模式实现\nconstants.ts - 常量定义\nutils.ts - 通用工具函数\n\nsrc/pages - 页面组件\nauth - 认证相关页面\nhome - 主页\nroom - 房间管理页面\ncanvas/Pixi_STM_modules - Pixi.js 状态管理模块\n\ncore - 核心类和初始化逻辑\ninteraction - 交互处理模块（例如拖拽、缩放、选择等）\nutils - 工具函数目录（各项操作的封装）\nshared - 共享类型定义\n\n\n\nsrc/stores - 状态管理（Yjs + IndexedDB - 复杂的协同数据存储，用于存储画布元素数据，支持实时协同和离线编辑）\ncanvasStore.ts - 画布状态管理\npersistenceStore.ts - 持久化状态管理\nthemeStore.ts - 主题状态管理\n\n后端部分的设计：\n\n房间管理系统 - 支持创建、修改、删除和查询房间\n用户认证系统 - 提供用户登录、注册和权限验证\n实时协作支持 - 通过  collab.ts  实现\n数据库 - 通过  db.ts  连接和操作数据库\n\n数据库设计（sqlite，原型验证阶段所使用）\n\n每个房间的画布数据在对应表中的 content 中\n项目中如何处理前端与后端（ALD_Backend）的交互？\n该项目前后端分离，交互采用 REST API（表现层状态转移应用编程接口，是一种基于 REST 架构风格设计的 Web API），前端通过 TypeScript 封装的 API 层统一管理所有 HTTP 请求，使用 Axios 作为 HTTP 客户端，配置了请求和响应拦截器来处理认证、错误处理和加载状态。其通过环境变量管理不同环境的基础 URL，定义了统一的响应格式和类型定义来确保类型安全，同时并在需要实时协作的场景下使用 WebSocket 进行双向通信。\n\nAxios 是一个基于 Promise 的网络请求库，用于在浏览器和 Node.js 中进行 HTTP 请求，并支持请求/响应拦截、取消，并发请求，自动转换数据等功能\n详情见博客文章：\n前端学习-接口类型定义、Axios 封装与请求规范 | 笔记站 (zhongye1.github.io)\n身份验证管理实现：\n\n使用 JWT Token 进行身份验证\n通过  setAuthToken  和  clearAuthToken  管理认证状态\nonAuthenticate  钩子验证用户权限\n\n详情见博客文章：\n前端学习-身份验证管理-基于 JWT Token 的实现 (zhongye1.github.io)\n\n实时协作部分是如何实现的？\n实时协作功能通过 Yjs、Hocuspocus 和 IndexedDB 实现：\n可以看博客：\n2025-12-27-前端画布设计 Vol.3 实现 CRDT | Notes|笔记站 (zhongye1.github.io)\n\n前端(react)\n\n\n使用 Yjs 的 CRDT 数据结构实现多客户端状态同步\n通过  HocuspocusProvider  连接到后端 WebSocket 服务器\n结合 IndexedDB 持久化，实现离线编辑功能\n\n\n后端（bun）\n\n\n使用 Hocuspocus 作为 Yjs 的协作服务器\n实现了数据库扩展，将 Yjs 文档状态持久化到 SQLite 数据库\n通过 WebSocket 协议处理实时通信\n\n\n认证与权限控制\n\n\nWebSocket 连接需要 JWT Token 认证\n服务器验证用户是否有权限访问特定房间\n如果用户没有访问权限，会自动将其添加到房间成员中\n\n\n数据同步\n\n\n前端使用 Yjs 的  Y.Map  存储画布元素数据\n通过  IndexeddbPersistence  将数据持久化到浏览器的 IndexedDB\n使用  HocuspocusProvider  将数据同步到服务器和其他客户端\n\n\n在线/离线处理\n\n\n当用户在线时，数据实时同步到服务器\n当用户离线时，数据保存在本地 IndexedDB 中\n重新连接后，本地更改会自动同步到服务器（CRDT）\n\n\n用户状态管理\n\n\n使用 Yjs 的 Awareness 功能跟踪在线用户\n广播机制实时显示协作者的光标位置和选中状态\n通过后端认证机制确保只有授权用户可以加入协作\n\n\n2. 状态管理（Zustand）Zustand 是项目核心状态工具，轻量且无 boilerplate。\n\n为什么选择 Zustand 而非 Redux 或 Context API？在画布状态管理中，它相比其他方案的优势体现在哪里？\n\n\nZustand 的 API 设计非常简洁，避免了 Redux 中大量样板代码（boilerplate code）的问题。在 Redux 中，我们需要定义 actions、reducers、store 等多个部分，而 Zustand 只需一个函数即可创建 store\n\nZustand 在性能优化方面，可以实现选择性订阅，避免不必要的组件重新渲染。Context API 在状态更新时会触发所有子组件的重新渲染，而 Zustand 允许我们精确地控制哪些组件需要响应特定状态变化。\n\n\n如何使用 Zustand 管理画布元素状态（elements: Record）？如何实现持久化（Zustand-persist + localForage + IndexedDB）？\n\n如何使用 Zustand 管理画布元素状态？在我们的项目中，画布元素状态是通过  CanvasState  接口定义的，其中  elements  属性是一个  Record&lt;string, CanvasElement&gt;  类型的对象，用于存储所有画布元素：\ninterface CanvasState {  elements: Record&lt;string, CanvasElement&gt;;  selectedIds: string[];  // ... 其他状态}\n我们通过直接操作 Yjs 共享数据类型来管理元素状态，从而实现协同编辑功能：\n// 添加元素addElement: (el) =&gt; {  currentYDoc?.transact(() =&gt; {    currentYElements?.set(el.id, el)  })},// 更新元素updateElement: (id, attrs) =&gt; {  currentYDoc?.transact(() =&gt; {    const oldEl = currentYElements?.get(id)    if (oldEl) {      currentYElements?.set(id, { ...oldEl, ...attrs })    }  })},// 删除元素removeElements: (ids) =&gt; {  currentYDoc?.transact(() =&gt; {    ids.forEach((id) =&gt; currentYElements?.delete(id))  })}\n如何实现持久化（Zustand-persist + localForage + IndexedDB）？在我们的实现中，持久化是通过 Yjs 的 IndexedDB 持久化机制完成的，而不是使用传统的 zustand-persist。我们使用  IndexeddbPersistence  与 HocuspocusProvider 组合：\n// 在 persistenceStore.ts 中创建持久化提供者const indexeddbProvider = new IndexeddbPersistence(  `canvas-local-db-${roomId}`,  yDoc);\n这种设计的优势在于:\n\nYjs 会自动处理 IndexedDB 的读写操作，无需手动管理\n提供了离线支持，即使在断网情况下数据也能保存在本地\n当重新连接网络时，会自动同步本地和远程数据\nIndexedDB 的异步操作不会阻塞 UI 线程，保证了应用的响应性\n\n在多用户协作场景下，Zustand 与 Y.js CRDT 如何结合？如何处理冲突和状态同步？Zustand 作为前端状态管理工具，提供状态访问接口Y.js 作为协同编辑引擎，处理多用户间的数据同步和冲突解决通过 Y.js 的 observe 机制，将 Y.js 的数据变化同步到 Zustand 状态中\n3. 高性能渲染与 PixiJS 集成PixiJS WebGL 渲染是项目性能关键，面试官会深入考察。\n为什么引入 PixiJS 而非纯 Canvas 或 SVG？它在实现 60 FPS 和无限画布时发挥了什么作用？\nPixiJS 是一个基于 WebGL 的 2D 渲染引擎，它具有极高的性能优势，可以充分利用 GPU 加速。相比纯 Canvas API，PixiJS 提供了更高层次的抽象，开发者无需手动管理底层的渲染细节，同时能够获得更好的性能表现。\n\n与 SVG 相比，PixiJS 在处理大量图形元素时表现更佳。SVG 是基于 DOM 的，当元素数量增加时，DOM 操作的开销会显著增加，导致性能下降。而 PixiJS 直接在 GPU 层面进行渲染，即使处理数千个元素也能保持流畅性能。\n\n对于无限画布的实现，PixiJS 提供了强大的 pixi-viewport 插件，它可以处理大规模场景的渲染优化。通过视口裁剪（view culling）技术，PixiJS 只渲染当前可见区域内的元素，大幅减少了渲染开销。\n\n如何使用 pixi-viewport 实现无限画布的缩放、平移和边界限制？实现缩放、平移和边界限制：\n// 在 Stage_InteractionHandler.ts 中实现视口功能viewport  .drag() // 启用拖拽平移  .pinch() // 启用双指缩放  .wheel() // 启用滚轮缩放  .clamp({ direction: \"all\" }) // 边界限制  .bounce(); // 边界弹性效果\n缩放功能通过 pinch 和 wheel 插件实现，用户可以通过双指手势或鼠标滚轮进行缩放。平移功能通过 drag 插件实现，用户可以拖拽画布。clamp 功能用于限制视口边界，防止用户将视口拖拽到画布内容之外的区域。\nviewport 提供多个配置选项，如缩放级别限制、平滑动画等\n项目中如何缓存 PixiJS 对象（spriteMap）以避免拖拽/缩放时的重复创建？这对性能有何影响？在项目中，我们使用  spriteMap  来缓存 PixiJS 对象，避免在拖拽、缩放等操作中重复创建和销毁元素。spriteMap  是一个以元素 ID 为键的 Map，存储了每个画布元素对应的 PixiJS 显示对象。\n// 在 Pixi_stageManager.ts 中定义spriteMap private spriteMap: Map&lt;string, PIXI.DisplayObject&gt; = new Map()\n当画布元素更新时，我们首先检查  spriteMap  中是否已存在对应的显示对象，如果存在则直接更新其属性，而不是创建新的对象。\n\n减少了对象创建和垃圾回收的开销\n提高了渲染效率，因为现有对象只需更新属性而非重新创建\n保持了对象状态的连续性，例如动画状态、事件监听器等\n\n图像滤镜（BlurFilter、ColorMatrixFilter）和富文本（HTMLText）是如何在 PixiJS 中实现的？遇到过哪些渲染挑战？在项目中，我们使用 PixiJS 的滤镜系统实现图像效果。对于 BlurFilter 和 ColorMatrixFilter 等滤镜，我们通过以下方式应用：\nimport { BlurFilter, ColorMatrixFilter } from \"pixi.js\";// 为图像元素添加滤镜const blurFilter = new BlurFilter();const colorFilter = new ColorMatrixFilter();sprite.filters = [blurFilter, colorFilter];\n对于富文本渲染，我们使用了 pixi-text-html 库，它允许我们在 PixiJS 中渲染 HTML 样式的文本。HTMLText 组件可以解析 HTML 标签并渲染出格式化的文本。\n小地图（Minimap）如何通过 cacheAsBitmap 实现实时更新？为什么需要单独的 Pixi Application？小地图的实现主要通过 cacheAsBitmap 属性来优化性能。cacheAsBitmap 将显示对象及其子对象渲染到一个内部纹理中，后续渲染只需绘制该纹理，而无需重新计算所有子对象的渲染，从而大幅提升性能。\nstage.cacheAsBitmap = true;\n小地图需要单独的 Pixi Application 实例，主要原因包括：\n性能隔离：小地图的渲染频率可能与主画布不同，独立的实例可以更好地控制渲染性能独立交互：小地图可能需要独立的交互逻辑，如点击跳转到画布特定位置资源管理：独立的实例可以更好地管理小地图相关的纹理和资源缩放独立性：小地图需要保持固定比例的缩略图，独立的渲染上下文更容易实现这一功能\n4. 撤销/重做机制（命令模式）项目中撤销/重做是如何实现的？为什么采用 Command Pattern？撤销/重做功能是通过命令模式（Command Pattern）实现的。我们定义了一个  Command  接口，它包含  execute、undo  和  redo  三个方法：\nexport interface Command {  execute(): void;  undo(): void;  redo(): void;}\n我们为不同类型的画布操作创建了相应的命令类，如  AddElementCommand、RemoveElementCommand  和  UpdateElementCommand  等。每个命令类都保存了执行操作所需的信息，能够在  undo  和  redo  时恢复到相应的状态。\n采用命令模式的主要原因有以下几点：\n解耦：命令模式将操作的执行者与请求者解耦，使我们可以轻松地添加新的命令类型而无需修改现有代码。状态一致性：在协同编辑环境中，命令模式确保所有操作都可以被准确地撤销和重做，保持状态一致性。易于扩展：我们可以轻松地添加新的命令类型，如分组、取消分组等。\n每个命令（如 AddElementCommand、UpdateElementCommand）如何存储前后状态快照（structuredClone）？这在内存和性能上有哪些权衡？AddElementCommand 的撤销与重做实现export class AddElementCommand implements Command {  constructor(private payload: { element: CanvasElement }) {}  execute = () =&gt; {    // 添加元素到画布    useStore.getState().addElement(this.payload.element);  };  undo = () =&gt; {    // 从画布移除元素，实现撤销    useStore.getState().removeElements([this.payload.element.id]);  };  redo = () =&gt; {    // 重新添加元素，实现重做（与 execute 相同）    useStore.getState().addElement(this.payload.element);  };}\n\n撤销（undo）：通过移除新增的元素恢复原状态，仅需元素 ID。\n重做（redo）：直接重复添加操作，无需额外存储数据。\n\nRemoveElementCommand 的撤销与重做实现export class RemoveElementCommand implements Command {  private elementData: CanvasElement | null = null;  constructor(private payload: { element: CanvasElement }) {}  execute = () =&gt; {    // 先保存被移除元素的完整数据（用于后续恢复）    this.elementData = { ...this.payload.element };    // 执行移除    useStore.getState().removeElements([this.payload.element.id]);  };  undo = () =&gt; {    // 使用保存的数据重新添加元素，实现撤销移除    if (this.elementData) {      useStore.getState().addElement(this.elementData);    }  };  redo = () =&gt; {    // 重复移除操作，实现重做    if (this.elementData) {      useStore.getState().removeElements([this.elementData.id]);    }  };}\n\n撤销（undo）：依赖 execute 时存储的元素完整数据进行恢复。\n重做（redo）：使用存储的数据重复移除，避免直接依赖外部状态。\n\nUpdateElementCommand 的撤销与重做实现export class UpdateElementCommand implements Command {  private previousValues: Partial&lt;CanvasElement&gt;;  constructor(    private elementId: string,    private newValues: Partial&lt;CanvasElement&gt;  ) {    // 在构造函数中保存更新前的属性值（旧状态）    const currentState = useStore.getState().elements[this.elementId];    this.previousValues = {};    Object.keys(newValues).forEach((key) =&gt; {      this.previousValues[key as keyof CanvasElement] =        currentState[key as keyof CanvasElement];    });  }  execute = () =&gt; {    // 应用新值    useStore.getState().updateElement(this.elementId, this.newValues);  };  undo = () =&gt; {    // 恢复旧值，实现撤销    useStore.getState().updateElement(this.elementId, this.previousValues);  };  redo = () =&gt; {    // 重新应用新值，实现重做（与 execute 相同）    useStore.getState().updateElement(this.elementId, this.newValues);  };}\n\n撤销（undo）：通过存储的 previousValues 恢复属性原值。\n重做（redo）：重复应用新值，确保操作可重复性。\n\n此设计的核心原则是：在命令对象中存储足够的信息（而非完整状态快照），以独立实现 undo 和 redo 操作，从而支持高效的命令模式撤销/重做栈管理。\n在内存和性能上的权衡包括：\n\n内存占用：每个命令都需要保存足够的信息来执行撤销/重做操作，这会增加内存使用。特别是  SnapshotCommand  会保存整个状态的副本，这在元素较多时会占用大量内存。\n性能影响：创建状态快照需要时间，特别是当画布中有大量元素时。使用  structuredClone  深拷贝大型对象会影响性能。\n存储优化：为减少内存占用，我们对不同的操作采用不同的存储策略。对于添加/删除操作，只需存储元素本身；对于更新操作，只需存储变更前的值和变更的属性。\n\n改进：限制历史栈大小以防止内存溢出对于连续的多个操作，可以合并成一个批量命令，减少栈中命令的数量对于包含大量数据的命令，如图像元素操作，可以在命令不再需要时清理其内部引用的数据对于频繁的操作（如拖拽移动），可以使用防抖机制将连续操作合并为一个命令，减少命令栈的增长速度操作分组：将相关的连续操作视为一个逻辑操作，例如，将创建一个复杂图形的多个步骤合并为一个撤销单位操作描述：为每个命令添加描述，让用户在 UI 上看到具体可撤销/重做的操作内容历史持久化：将撤销/重做历史保存到本地存储，即使页面刷新后也能恢复历史记录。自适应栈大小：根据当前画布复杂度动态调整栈大小，元素较多时使用较小的栈，元素较少时使用较大的栈\n5. 交互与用户体验变换控件（Transform Controls）的检测与处理变换控件由 TF_controler_Renderer.ts 模块负责渲染，包括包围选中元素的边界框、8 个缩放手柄（位于边角）和 1 个旋转手柄（通常位于顶部或底部）\n手柄检测基于鼠标位置与手柄边界框的距离计算：\n\n当鼠标进入手柄区域时，光标样式相应改变（例如，边角手柄显示对角箭头，旋转手柄显示旋转图标）\n每个手柄对应特定操作：\n8 个边角手柄：用于非均匀缩放（保持或不保持宽高比，根据修饰键）\n旋转手柄：用于旋转选中元素（可能以组中心为旋转锚点）\n\n\n\n在 Stage_InteractionHandler.ts 中处理实际变换逻辑：\n// 处理缩放操作handleScale(dx: number, dy: number, handleType: string) {  const updates: Record&lt;string, Partial&lt;CanvasElement&gt;&gt; = {};  selectedIds.forEach(id =&gt; {    const element = elements[id];    // 根据手柄类型（e.g., 'top-left', 'bottom-right'）计算缩放比例和位置偏移    updates[id] = calculateNewDimensions(element, dx, dy, handleType);  });  // 批量更新元素，避免多次重渲染  useStore.getState().batchUpdateElements(updates);}// 处理旋转操作（示例）handleRotate(deltaAngle: number, pivotPoint: { x: number; y: number }) {  const updates: Record&lt;string, Partial&lt;CanvasElement&gt;&gt; = {};  selectedIds.forEach(id =&gt; {    const element = elements[id];    updates[id] = calculateRotatedElement(element, deltaAngle, pivotPoint);  });  useStore.getState().batchUpdateElements(updates);}\n交互模式切换逻辑项目定义了多种交互模式，主要在 Stage_InteractionHandler.ts 中管理，确保同一时刻仅一种模式活跃。\nonPointerDown = (event: PIXI.FederatedPointerEvent) =&gt; {  const { x, y } = this.viewport.toLocal(event.global);  // 1. 优先检测变换手柄（最高优先级）  if (this.isOverTransformHandle(x, y)) {    this.currentMode = 'transforming';    this.startTransform(x, y, this.getCurrentHandleType());    return;  }  // 2. 检测是否点击元素  const hitElementId = this.isOverElement(x, y);  if (hitElementId) {    if (event.data.originalEvent.shiftKey) {      // Shift + 点击：多选切换      this.toggleSelection(hitElementId);    } else {      // 普通点击：单选或重新开始选择      this.selectElement(hitElementId);    }    this.currentMode = 'dragging';    this.startDrag(x, y);    return;  }  // 3. 空格键平移  if (event.data.originalEvent.code === 'Space') {    this.currentMode = 'panning';    this.startPan(event);    return;  }  // 4. 默认：框选模式  this.currentMode = 'selecting';  this.startSelectionBox(x, y);};\n模式优先级：transforming &gt; dragging &gt; panning &gt; selecting &gt; idle，确保变换手柄始终优先响应。\n对齐指南（Alignment Guidelines）的计算与绘制对齐指南功能由 guidelineUtils.ts 实现，在元素拖拽过程中实时提供视觉反馈和吸附效果。\n// 检测对齐位置function detectAlignments(  movingElements: CanvasElement[],  allElements: CanvasElement[],  tolerance: number = 5) {  const alignments = {    vertical: [] as { position: number; type: string }[],    horizontal: [] as { position: number; type: string }[],  };  movingElements.forEach(moving =&gt; {    allElements.forEach(element =&gt; {      if (movingElements.some(m =&gt; m.id === element.id)) return;      // 左/右边缘对齐      if (Math.abs(element.x - moving.x) &lt; tolerance) {        alignments.vertical.push({ position: element.x, type: 'left-edge' });      }      if (Math.abs(element.x + element.width - (moving.x + moving.width)) &lt; tolerance) {        alignments.vertical.push({ position: element.x + element.width, type: 'right-edge' });      }      // 水平中心对齐      const movingCenterX = moving.x + moving.width / 2;      const elementCenterX = element.x + element.width / 2;      if (Math.abs(movingCenterX - elementCenterX) &lt; tolerance) {        alignments.vertical.push({ position: elementCenterX, type: 'center' });      }      // 类似处理水平对齐（top/bottom/center）...    });  });  // 等间距检测（可选扩展）  // detectEqualSpacing(...);  return alignments;}\n绘制与吸附：\n\n在拖拽过程中，每帧调用 detectAlignments，若检测到对齐，则使用 PixiJS 的 Graphics 对象绘制虚线指南（通常为蓝色或绿色，带一定透明度）。\n若移动偏移导致对齐，则自动吸附（snap）元素位置到精确对齐点，提供精准布局体验。\n\n6. 性能优化与工程实践项目中具体的性能优化措施项目采用了多项针对性优化，确保在复杂画布场景下的流畅运行：\n\n对象缓存机制 使用 spriteMap 缓存 PixiJS 显示对象，避免频繁创建和销毁导致的性能开销。\n\n// 在 Pixi_stageManager.ts 中private spriteMap: Map&lt;string, PIXI.DisplayObject&gt; = new Map();updateElement(id: string, attrs: Partial&lt;CanvasElement&gt;) {  const sprite = this.spriteMap.get(id);  if (sprite) {    // 重用现有对象，直接更新属性    Object.assign(sprite, attrs);  } else {    // 首次创建并缓存    const newSprite = this.createSprite(attrs);    this.spriteMap.set(id, newSprite);    this.container.addChild(newSprite);  }}\n\nWebGL 渲染优化 充分利用 PixiJS 的 GPU 加速，并通过 pixi-viewport 实现视口裁剪，仅渲染可见区域元素，显著减少绘制调用。\n\n// viewport 配置示例const viewport = new Viewport({  interaction: app.renderer.plugins.interaction,  cull: true, // 启用视口裁剪});viewport.on(\"frame-end\", () =&gt; {  // 帧结束时可执行额外优化，如清理不可见资源});\n\nVite HMR（热模块替换） 在开发环境中利用 Vite 的快速热更新，无需完整页面刷新即可反映代码变更，大幅提升迭代效率。\n\nTypeScript 在项目中的作用：\n类型安全 通过严格接口定义，确保数据一致性与错误早发现。\n\nexport interface CanvasElement {  id: string;  type: ToolType;  x: number;  y: number;  width: number;  height: number;  fill: string;  stroke: string;  strokeWidth: number;  alpha?: number;  points?: number[][];  rotation?: number;  // 文本相关  text?: string;  fontSize?: number;  fontFamily?: string;  textAlign?: \"left\" | \"center\" | \"right\";  // 图像相关  imageUrl?: string;  filter?: \"none\" | \"blur\" | \"brightness\" | \"grayscale\";  // 分组相关  groupId?: string;}\n\n智能提示与类型推断：显著提高编码效率。\n重构安全：类型系统可在大型重构时快速定位影响范围。\n接口契约：明确模块间数据结构，提升代码可维护性。\n\n构建与部署方面\n选用 Vite 的原因\n极快的开发服务器启动与构建速度\n即时热模块替换（HMR）\n出色的构建性能与 Tree Shaking\n开箱即用的 TypeScript、JSX 和 CSS Modules 支持\n\n\nDocker 与 GitHub Actions CI/CD\n项目根目录提供 Dockerfile 和 docker-compose.yml，支持容器化部署。\nGitHub Actions 配置自动化流程：代码检查 → 单元测试 → 构建产物 → 镜像推送 → 部署至目标环境。\n\n\n\n样式一致性保证为统一多组件库外观，项目实施以下策略：\n\nTailwindCSS 统一设计系统\n\n// tailwind.config.jsmodule.exports = {  theme: {    extend: {      colors: {        primary: colors.blue,        secondary: colors.gray,      },      spacing: {        '18': '4.5rem',        '88': '22rem',      },    },  },};\n\nCSS 变量系统：定义全局变量（如 —color-primary），确保所有组件引用统一值。\n主题管理：通过 themeStore.ts（基于 Zustand 或类似状态管理）集中控制主题切换。\n组件包装：对第三方库组件进行二次封装，统一应用项目样式和行为规范。\n\n7. 挑战与改进开发过程中遇到的主要技术难点及解决方案在项目开发中，我们遇到了几个关键技术挑战，主要集中在实时协作、渲染同步以及性能优化方面。\n\n实时协作冲突处理 最大的难点之一是多用户同时编辑画布时的数据冲突，可能导致操作覆盖或状态不一致。\n\n采用 Yjs 的 CRDT（Conflict-free Replicated Data Type）算法，自动合并并发修改，无需中央锁定机制，确保最终一致性。\n通过 HocuspocusProvider 建立 WebSocket 连接，实现低延迟实时同步。\n在 canvasStore.ts 中，利用 Yjs 的 observe 机制监听变更并同步到本地状态管理器：\nyElements.observe(() =&gt; {  useStore.setState({    elements: yElements.toJSON(),  });});\n\n额外实现锁定机制，防止同步过程中向撤销/重做栈添加无效命令，避免历史污染。\n\n\n\nPixiJS 与 React 状态同步 另一个重大挑战是保持 PixiJS 渲染层与 React/Zustand 状态的实时一致性，尤其在元素数量较多时易导致延迟或不一致。\n\n创建 Pixi_stageManager.ts 作为桥梁层，负责双向同步 React 状态与 PixiJS 显示对象。\n使用 spriteMap 缓存 PixiJS 对象，避免重复创建/销毁。\n引入防抖（debounce）机制，限制频繁同步频率。\n实现选择性更新，仅针对变更元素进行渲染。\n\n\n性能优化挑战 当画布元素数量激增时，渲染和交互性能显著下降。\n\n启用视口裁剪（viewport culling），仅渲染当前可见区域元素。\n引入对象池和缓存机制，减少内存分配开销。\n采用批量更新（batchUpdateElements），降低状态变更引起的多次重渲染。\n针对静态元素启用 cacheAsBitmap，将内容烘焙为位图以减少重绘。\n// 示例：针对静态元素启用位图缓存if (sprite.isStatic &amp;&amp; !sprite.cacheAsBitmap) {  sprite.cacheAsBitmap = true;}\n\n\n\n\n","categories":["归档"]},{"title":"2026-01-03-论文实训草稿","url":"/Arknight-notes/posts/38065.html","content":"汽车保险领域面临的日益严峻的欺诈风险使行业经济损失巨大。为有效应对此类问题，本研究运用传统机器学习技术构建欺诈识别系统，提供了数据处理、特征提取以及模型构建的完整流程，采用汽车保险理赔数据集，进行相关实验，重点考察随机森林算法与其他分类器的性能对比，包括数据清洗、特征选择和不平衡处理。通过交叉验证和指标评估，结果显示优化后的随机森林模型在 AUC 和召回率方面表现出色。该研究验证了传统算法在实际场景中的可靠性，并为保险企业风险管理提供实用建议。\n}\n% 中文关键词(每个关键词之间用”；”分开,最后一个关键词不打标点符号。)\n\\ckeywords{汽车保险欺诈；随机森林算法；传统机器学习；数据不平衡；特征提取；性能评估}\n\n1保险业通过风险聚合与转移机制为社会经济活动提供安全保障，在全球经济运行中扮演着至关重要的角色。其庞大的资金池更是资本市场长期资本的重要来源之一 (Barry &amp; Charpentier, 2020)。根据经济合作与发展组织的报告，保险业的稳定性直接关系到全球金融系统的韧性 (OECD, 2023)。在财产保险领域，汽车保险覆盖面最为广泛并与日常生活紧密联系，构成了该领域的核心业务板块，同时其受到日益猖獗的保险欺诈行为的严峻挑战。\n汽车保险欺诈已成为一个全球性的顽疾，对行业的财务健康和社会的诚信体系造成持续性的损害。欺诈行为导致保险公司支付了本不应承担的赔款，这些巨大的“渗漏”最终会通过提高保费的形式转嫁给所有诚实投保人，破坏了保险的公平性原则 (Viaene &amp; Dedene, 2004)。据美国反保险欺诈联盟（Coalition Against Insurance Fraud）的最新报告，保险欺诈每年给美国造成的损失已超过 3000 亿美元，其中车险领域是重灾区 (CAIF, 2022)。欺诈的成因复杂，一方面，信息不对称使得保险公司难以在承保和理赔环节完全掌握投保人的真实风险与行为 (Cohen &amp; Siegelman, 2010)；另一方面，技术的进步，特别是数字化理赔流程的普及，在提升效率的同时，也为新型、更隐蔽的欺诈手段提供了可乘之机 (Severino &amp; Peng, 2021)。这不仅侵蚀了保险公司的承保利润，还可能导致定价模型失真，扭曲风险信号，长期而言将削弱保险的风险分担功能和社会效益。\n从广义上讲，保险欺诈是指任何以非法获取保险金为目的的故意行为。根据欺诈主体的不同，可分为保单持有人欺诈、第三方欺诈以及内部人员欺诈等 (Derrig, 2002)。鉴于数据的可获得性与研究的可操作性，本文的研究焦点将集中于汽车理赔欺诈，即保单持有人或相关方在理赔环节，通过故意制造事故、夸大损失、伪造单据等手段骗取保险赔偿金的行为。这类欺诈是车险欺诈中最常见的形式，拥有相对丰富的公开研究数据基础，是应用数据驱动方法进行自动化检测的主要战场 (Bhattacharyya et al., 2011)。\n为应对这类欺诈威胁，保险公司正从依赖专家规则和人工审核，转向基于数据挖掘与机器学习（ML）的自动化检测系统。传统的规则引擎虽然解释性强，但难以捕捉复杂的非线性关系和新型欺诈模式。机器学习，特别是监督学习算法，能够从历史理赔数据中自动学习欺诈模式，展现出巨大潜力。在众多机器学习方法中，集成学习因其卓越的预测性能和鲁棒性而备受关注。以随机森林（Random Forest）为代表的集成算法，通过构建多棵决策树并综合其结果，能有效缓解单棵树的过拟合问题，对高维特征和非线性关系有良好的处理能力 (Breiman, 2001; Polikar, 2012)。更重要的是，保险欺诈数据天然具有高度不平衡性（正常理赔远多于欺诈理赔），而随机森林通过自助采样（Bootstrap sampling）和随机特征子空间选择，能在不均衡数据上构建多样化的基分类器，从而在一定程度上提升对少数类（欺诈）样本的识别能力 (Xia et al., 2023; Phua et al., 2010)。\n尽管机器学习在欺诈检测中的应用已取得丰硕成果，但现有研究仍存在一些有待深化之处。许多研究侧重于单一高级分类器（如 XGBoost、深度神经网络）的性能比拼，而相对忽视了数据预处理阶段与分类模型的系统性整合与优化。特征工程、处理类别不平衡的重采样技术（如 SMOTE、ADASYN）以及特征选择，对于最终模型性能的影响至关重要，有时甚至不亚于分类器本身的选择 (Wang et al., 2021; Chawla et al., 2002)。此外，在真实的汽车保险公开数据集上，对包含预处理流程在内的多种传统机器学习算法进行端到端的、公平的对比实验研究相对有限，特别是深入探讨不同预处理技术如何与不同算法交互以提升欺诈检测性能的研究尚不充分 (He &amp; Garcia, 2009; Gomes et al., 2021)。\n本文旨在探索并验证一套结合预处理技术与经典机器学习算法的汽车保险欺诈检测框架。具体而言，本研究将在公开的汽车保险理赔数据集上，以随机森林算法为核心检测模型，系统性地集成多种特征编码、不平衡数据处理（如过采样与欠采样）及特征选择方法，构建一个完整的分析管道。通过设计详尽的对比实验，本文将评估该集成框架相对于单一模型及其他主流机器学习算法（如逻辑回归、支持向量机、XGBoost）在欺诈检测准确率、召回率、F1 分数等关键指标上的性能表现，从而为构建高效、实用的车险欺诈检测系统提供实证依据。主要要点如下：\n\n提出一个基于机器学习的欺诈检测分析框架：将数据处理、特征工程、不平衡学习、特征选择与随机森林分类器进行有机整合，形成了一个可复现、可评估的完整机器学习工作流，强调了预处理环节在模型构建中的基础性地位。\n进行了相关的算法对比实验：在公开基准数据集上，对包括随机森林在内的多种传统机器学习算法，在统一的预处理标准和评估指标下进行了性能对比与分析，为算法选择提供了实证参考。\n深入探讨了不平衡数据处理策略的有效性：实证检验了多种重采样技术在缓解保险欺诈数据类不平衡问题上的作用，并分析了其与不同分类器结合时的性能变化规律。\n提供了结构化的方法学实现：研究过程注重方法论的清晰描述与代码的结构化，确保了实验的可复现性，为后续研究者提供了可直接借鉴的技术路径和比较基线。\n\n本文结构安排如下：第 2 章将对保险欺诈检测，特别是基于机器学习的检测方法的相关文献进行综述；第 3 章将详细阐述本文所采用的研究方法，包括数据集描述、预处理技术、特征工程、使用的机器学习算法以及实验设计；第 4 章将展示并分析实验结果，对不同模型和策略的性能进行对比与讨论；第 5 章将总结全文，概括主要研究发现，指出本研究的局限性，并对未来研究方向提出展望。\n2本章旨在回顾保险欺诈检测方法的技术演进，梳理传统机器学习算法在该领域的应用现状、优势与挑战，明确本研究的理论背景与创新点。\n2.1 欺诈检测方法的演进保险欺诈检测的演进与信息技术的发展脉络高度吻合。早期的检测完全依赖具有丰富经验的核保员，主观性极强。随后，基于规则的专家系统（Expert Systems）通过将反欺诈知识编码为“IF-THEN”逻辑，实现了初步自动化 (Bentley, 2000)。然而，该系统难以应对高度协同且隐蔽的新型欺诈模式。\n20 世纪 90 年代末，统计方法被引入该领域。逻辑回归（Logistic Regression）因其能够量化风险概率而成为早期的主流工具 (Brockett et al., 2002)。进入 21 世纪后，数据挖掘与机器学习范式确立，研究焦点从简单的线性模型转向能够处理高维、非线性关系的复杂模型。现代欺诈检测已形成以监督学习为主、异常检测与图神经网络为辅的多维检测体系 (Phua et al., 2010; West &amp; Bhattacharya, 2016)。\n2.2 传统机器学习算法在保险欺诈检测中的应用在众多机器学习算法中，传统（或经典）算法因其计算效率高、在中小规模数据集上表现稳健且易于部署，至今仍是行业应用的核心。\n单一分类器如决策树（DT）、支持向量机（SVM）和朴素贝叶斯在早期研究中应用广泛。决策树因其天然的解释性被青睐，但单棵树极易产生过拟合 (Baesens et al., 2015)。SVM 通过核函数处理高维非线性空间，但在大规模数据集上的训练开销较大。\n为克服单一模型的局限，集成学习（Ensemble Learning）成为该领域的最优解。随机森林（Random Forest, RF） 通过自助采样（Bootstrap）和随机特征选择构建决策树森林，能显著提升模型的泛化能力和抗噪性能 (Breiman, 2001; Sahin et al., 2013)。Itri 等人 (2019) 在汽车保险数据集上的对比实验表明，随机森林在 AUC 和准确率上始终处于领先地位。此外，以 XGBoost (Chen &amp; Guestrin, 2016) 和 LightGBM (Ke et al., 2017) 为代表的梯度提升框架，通过迭代修正残差，进一步刷新了欺诈检测的精度上限。Jovanovic 等人 (2022) 的研究证实，经过精细参数调优的提升树模型在处理车险理赔数据时，其召回率（Recall）显著优于传统线性模型。\n2.3 多模型比较研究与算法选择策略由于保险欺诈模式在不同地区和产品线之间存在显著差异，不存在“一劳永逸”的通用算法，因此多模型对比（Benchmarking）成为该领域实证研究的标准范式 (Lessmann et al., 2015)。\n多数实证研究（如 Nordin et al., 2024）表明，基于树的集成方法（RF, XGBoost, CatBoost）在整体性能上优于逻辑回归和感知器。由于欺诈检测是一个典型的非平衡代价问题，评估指标已从单纯的准确率转向更具代表性的 AUC-ROC、F1 分数以及在特定误报率下的召回率 (Dal Pozzolo et al., 2015)。然而，目前的对比研究大多聚焦于算法本身，对于预处理技术（如不同编码方式）与分类器之间的交互影响缺乏系统性探讨。\n2.4 数据不平衡与特征工程保险欺诈检测本质上属于典型的类别不平衡分类问题，在本数据集中，欺诈样本仅占约 24.7%，这种分布会导致模型在训练过程中过度偏向多数类（非欺诈），从而牺牲了对少数类（欺诈）的捕获能力 (He &amp; Garcia, 2009)。在保险理赔实务中，分类错误的成本是非对称的：漏检一个真实的欺诈案例（假阴性，False Negative）所导致的直接经济赔付损失，通常远高于对正常理赔进行额外审核所产生的行政成本（假阳性，False Positive） (Dal Pozzolo et al., 2015; Severino &amp; Peng, 2021)。\n针对这一挑战，本研究引入了合成少数类过采样技术（Synthetic Minority Over-sampling Technique, SMOTE） (Chawla et al., 2002)。与简单的随机过采样（Random Over-sampling）不同，SMOTE 通过在少数类样本及其最近邻之间进行线性插值来生成“合成”样本，从而有效地扩展了少数类的决策区域，并缓解了简单复制样本导致的过拟合风险 (Fernández et al., 2018)。通过应用 SMOTE 算法，本研究将训练集的正负样本比例调整至 1:1，使欺诈样本的表征更加充分，从而显著增强了模型对欺诈模式的学习效率和泛化性能 (Jovanovic et al., 2022)。\n2.5 可进一步探索的空间综上所述，尽管基于传统机器学习的欺诈检测已相对成熟，但仍存在以下待解决的问题：现有的研究往往将预处理、不平衡处理与分类器训练割裂开来，缺乏一个高度整合、可复现且端到端的分析框架。此外，虽然深度学习（如 TabNet）开始崭露头角，但传统算法在解释性要求较高的保险合规场景下仍具有不可替代的价值。本文将基于公开的车险数据集，系统验证一套集成了先进重采样策略与随机森林分类器的优化框架，旨在为该领域的工程实践提供清晰的方法论基准。\n本文将以一个公开的汽车保险理赔数据集为基础，构建一个系统化的分析流程，核心内容包括：（1）实施一套完整的预处理与特征工程方案；（2）在公平的实验设置下，系统对比包括逻辑回归、支持向量机、K 近邻、决策树、随机森林、AdaBoost 和 XGBoost 在内的七种传统机器学习算法的性能；（3）深入探讨随机森林算法在该任务中的优势及其原因；（4）实证分析不同的类不平衡处理策略对关键分类器性能的影响。本研究期望通过这些工作，为汽车保险欺诈检测的模型选择与工程实践提供一份实证参考与方法论范例。\n\n3本章详细阐述本研究的实验框架，包括数据集来源、数据预处理、类不平衡处理、分类算法选择以及实验设计。\n3.1 数据集描述本研究采用公开的汽车保险理赔数据集，该数据集源于 Kaggle 平台上的“Vehicle Insurance Claim Fraud Detection” https://www.kaggle.com/datasets/buntyshah/auto-insurance-claims-data/code ，该数据集包含 1000 行数据，每一行代表一个理赔案例。包含 40 个特征（如保单信息、事故地点、车辆型号等）\n其目标变量为“fraud_reported”，取值为“Y”（欺诈）或“N”（非欺诈），属于典型的二分类任务。其中，欺诈样本（Y）数量为 247 条，非欺诈样本（N）数量为 753 条，欺诈样本占比约为 24.7%。这一类别不平衡现象符合保险行业中欺诈案例的特征。\n数据集特征涵盖客户个人信息、保单细节、事故信息以及理赔金额等维度。数值型特征如 total_claim_amount 在欺诈与非欺诈样本间存在明显差异，而类别型特征如 incident_severity 与欺诈标签的相关性较高。这些初步观察为后续特征工程提供了重要的依据。\n\n3.2 数据预处理为确保数据质量并满足模型输入要求，本研究实施了一系列数据预处理：\n缺失值处理：数据集部分特征（如 collision_type、property_damage、police_report_available）以“？”标记缺失值。本研究将“？”替换为 NaN，并采用众数填充策略（Mode Imputation）进行处理。\n为了降低维度和减少噪声干扰，进行无用特征剔除：移除了唯一标识符、高基数或对分类任务贡献有限的列，包括 policy_number（保单编号）、policy_bind_date（保单绑定日期）、policy_state（投保州）、insured_zip（邮编）、incident_location（事故地点）、incident_date（事故日期）、incident_state（事故州）、incident_city（事故城市）、insured_hobbies（爱好）、auto_make（车辆品牌）、auto_model（车型）、auto_year（生产年份）以及_c39（空列）。\n机器学习模型要求输入数据为数值型。对于剩余的类别型变量（如  insured_sex、education_level、incident_type  等），本研究采用标签编码（Label Encoding）技术，将其映射为整数序列。同时，目标变量  fraud_reported  被转换为二元数值标签，其中“N”映射为 0，“Y”映射为 1。\n预处理后，数据集保留了一些判别特征，包括数值型特征（如 months_as_customer、age、policy_deductable、policy_annual_premium、umbrella_limit、capital-gains、capital-loss、incident_hour_of_the_day、number_of_vehicles_involved、bodily_injuries、witnesses、total_claim_amount、injury_claim、property_claim、vehicle_claim）和编码后的类别特征，构成模型训练的输入向量空间。\n3.3 Handling Class Imbalance保险欺诈检测本质上属于高度类别不平衡的分类问题，欺诈样本仅占约 24.7%，多数类（非欺诈）主导数据集。若直接训练模型，将倾向于预测多数类，导致对欺诈案例的召回率低下，而在实际应用中，漏检欺诈（假阴性）的成本远高于误报（假阳性）（Dal Pozzolo et al., 2015）。\n本研究引入 Synthetic Minority Over-sampling Technique（SMOTE）算法（Chawla et al., 2002）。SMOTE 通过在少数类样本间进行线性插值合成新样本，避免简单复制带来的过拟合风险。通过应用 SMOTE，使训练集正负样本比例调整至 1:1（欺诈样本比例从约 24.7%提升至 50%），来增强模型对少数类的学习能力。\n3.4 实验设置与评估指标为验证所提方法的有效性并确保实验的可复现性，本研究设计了如下实验方案：\n3.4.1 数据集划分在应用 SMOTE 算法后，将平衡后的数据集按 80% : 20% 的比例随机划分为训练集和测试集。训练集用于模型的构建与参数学习，测试集仅用于最终性能评估，以验证模型的泛化能力。划分过程设置随机种子（random_state=42）以确保结果的一致性。\n3.4.2 模型选择本研究选取  随机森林（Random Forest, RF）  作为核心分类模型。随机森林作为一种集成学习算法，通过构建多棵决策树并利用 Bagging 策略进行投票，能够有效处理高维特征并具有较强的抗过拟合能力。为评估随机森林的性能优势，本研究选取了两个经典算法作为基线模型（Baseline）：\n\n逻辑回归（Logistic Regression, LR）：作为线性模型的代表，用于衡量非线性特征交互的重要性。\n支持向量机（Support Vector Machine, SVM）：作为经典的核方法分类器，用于对比不同决策边界的划分效果。\n\n所有模型均在经过标准化（StandardScaler）处理的特征上进行训练，其中随机森林的基学习器数量设置为 100（n_estimators=100）。\n3.5 实验设计与评估指标 (Experimental Design and Metrics)3.5.1 实验设置所有实验均在 Python 环境下基于 Scikit-Learn 库实现。\n\n数据划分：采用  80/20 划分原则。在应用 SMOTE 之前，将原始数据按 80% 划分为训练集，20% 划分为测试集。\n标准化：对所有特征进行  StandardScaler  标准化处理，消除量纲差异对 SVM 和 LR 等距离敏感模型的影响。\n\n3.5.2 评估指标鉴于准确率（Accuracy）在类别不平衡数据集中的局限性（例如，若模型将所有样本预测为多数类非欺诈，可轻松获得约 75%的准确率，从而掩盖对少数类的识别能力），本研究采用多维度评估指标，以全面衡量模型在欺诈检测任务中的性能。这些指标特别关注对少数类（欺诈）的识别能力，同时考虑整体泛化性能。\n\n准确率（Accuracy）：模型整体分类正确的比例。计算公式为\n\n\\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}其中，TP（True Positive）为正确预测的欺诈样本，TN（True Negative）为正确预测的非欺诈样本，FP（False Positive）为误报的欺诈样本，FN（False Negative）为漏报的欺诈样本。尽管该指标直观，但在本研究中仅作为辅助参考。\n\n精确率（Precision）：预测为欺诈的样本中实际为欺诈的比例。计算公式为\n\n\\text{Precision} = \\frac{TP}{TP + FP}该指标衡量模型的误报控制能力，在保险场景中有助于评估额外审核成本。\n\n召回率（Recall / Sensitivity）：实际欺诈样本中被正确识别的比例。计算公式为\n\n\\text{Recall} = \\frac{TP}{TP + FN}在反欺诈应用中，召回率是首要优化目标，因为漏检欺诈（FN）的经济代价远高于误报（FP）。\n\nF1 分数（F1-score）：精确率与召回率的调和平均，适用于不平衡数据下的综合评估。计算公式为\n\n\\text{F1-score} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}该指标在 Precision 与 Recall 间取得平衡，提供单一数值总结模型效能。\n\nAUC-ROC（Area Under the Receiver Operating Characteristic Curve）：ROC 曲线下的面积，衡量模型在不同分类阈值下的区分能力。AUC 值介于 0.5（随机猜测）与 1.0（完美分类）之间，对类别不平衡具有较强鲁棒性，是本研究评估模型综合性能的核心指标。\n\n混淆矩阵（Confusion Matrix）：以矩阵形式直观展示 TP、TN、FP、FN 的分布，便于分析模型在具体类别上的错误类型。\n\n\n\n4 实验结果与分析本章基于公开的汽车保险理赔数据集（1000条记录，欺诈样本占比约24.7%），呈现扩展后的对比实验结果。实验采用统一的预处理管道：缺失值填充、类别特征编码（One-Hot Encoding）、数值特征标准化，以及在训练集上应用SMOTE过采样技术，使类别分布平衡至50%。所有模型通过网格搜索进行超参数优化，并使用分层抽样划分训练/测试集（比例约7:3，测试集302条记录）。评估指标包括准确率（Accuracy）、AUC-ROC、精确率（Precision）、召回率（Recall）和F1分数，重点关注欺诈类（少数类）的性能。\n4.1 实验环境与设置实验在一台配备 12th Gen Intel(R) Core(TM) i7-12700H (20) @ 4.70 GHz 的电脑上进行，内存为 32 GB，操作系统是 64 位 Windows 11。\n主要使用 Python3.10 实现。Pandas 的数据帧负责加载数据集。Scikit Learn 库实现了机器学习和集成模型。作品的源代码、可视化和数据发布在作者的 GitHub 网站上。\n【链接！】\n4.1 模型性能对比实验对比了七种经典机器学习算法：逻辑回归（Logistic Regression）、支持向量机（SVM）、决策树（Decision Tree）、K-最近邻（KNN）、AdaBoost、随机森林（Random Forest） 和 XGBoost。\n关键性能指标汇总如下（表4-1）：\n\n\n\n\n模型\n准确率\nAUC\n欺诈类精确率\n欺诈类召回率\n欺诈类F1分数\n\n\n\n\nLogistic Regression\n0.7119\n0.7749\n0.73\n0.72\n0.73\n\n\nSVM\n0.8642\n0.9255\n0.86\n0.89\n0.87\n\n\nDecision Tree\n0.7417\n0.7416\n0.76\n0.74\n0.75\n\n\nKNN\n0.7185\n0.8234\n0.67\n0.94\n0.78\n\n\nAdaBoost\n0.8311\n0.8975\n0.84\n0.84\n0.84\n\n\nRandom Forest\n0.8675\n0.9382\n0.88\n0.86\n0.87\n\n\nXGBoost\n0.8444\n0.9232\n0.87\n0.82\n0.85\n\n\n\n\n从以上结果可见，随机森林在AUC（0.9382）和整体准确率（0.8675）上表现最佳，欺诈类F1分数达0.87，实现了精确率与召回率的良好平衡。XGBoost和SVM紧随其后，AUC分别达0.9232和0.9255，显示出梯度提升树和核方法在非线性模式捕获上的优势。KNN虽在欺诈类召回率上最高（0.94），但精确率较低，导致整体F1分数不如集成模型。线性模型如逻辑回归和单一决策树性能相对较弱，AUC低于0.80，表明其难以有效处理高维非线性关系。\nROC曲线比较进一步证实，随机森林曲线最接近左上角，主导其他模型，尤其在低假阳性率区间表现出色。\n4.2 ROC曲线分析ROC曲线用于评估模型在不同分类阈值下的真阳性率（True Positive Rate）与假阳性率（False Positive Rate）的权衡关系，曲线下面积（AUC）值越高，模型的整体区分能力越强。图4-1展示了七种模型的ROC曲线对比结果。\n\n图4-1 不同模型的ROC曲线对比\n（如图像ID:0所示，随机森林的ROC曲线最靠近左上角，AUC达到0.9382；XGBoost（AUC=0.9232）和SVM（AUC=0.9255）紧随其后；AdaBoost（AUC=0.8975）表现良好；KNN（AUC=0.8234）和逻辑回归（AUC=0.7749）相对较低；决策树（AUC=0.7416）表现最弱。随机分类器的对角线作为基准参考。）\n从图中可见，随机森林的ROC曲线在几乎整个假阳性率区间内均主导其他模型，尤其在低假阳性率（&lt;0.2）区域上升更快，表明其能够在保持较低误报率的同时实现较高的欺诈捕获率。XGBoost和SVM的曲线高度重叠，性能接近随机森林，体现了梯度提升树和核方法在非线性模式识别上的优势。相比之下，单一决策树和逻辑回归的曲线较低，反映了其对复杂交互特征和类别不平衡的处理能力不足。KNN虽在高假阳性率区间召回较高，但早期上升缓慢，导致整体AUC较低。\n该结果进一步证实，集成学习算法（随机森林、XGBoost、AdaBoost）在本数据集上具有显著优越性，与SMOTE过采样相结合后，其对少数类（欺诈）的敏感性得到有效提升。随机森林的最高AUC值验证了其作为本研究核心模型的合理性，为实际部署提供了更可靠的阈值选择依据。\n4.3 随机森林模型详细分析作为核心模型，随机森林的混淆矩阵如下（图4-2）：\n\n图4-2 随机森林混淆矩阵\n\n真阴性（TN）：124（正确识别非欺诈）\n假阳性（FP）：18（误报欺诈）\n假阴性（FN）：22（漏检欺诈）\n真阳性（TP）：138（正确识别欺诈）\n\n模型对欺诈类的召回率达0.86，误报率较低，适合实际业务中平衡审核成本与风险控制的需求。\n特征重要性分析（基于Gini不纯度下降）显示前10个关键特征（图4-3）：\n\n图4-3 随机森林Top 10特征重要性\n\nincident_severity（事故严重程度）：0.2294\ntotal_claim_amount（总赔付金额）：0.0528\nvehicle_claim（车辆赔付金额）：0.0499\nwitnesses（目击证人数）：0.0492\nauthorities_contacted（当局联系情况）：0.0453\ninsured_occupation（投保人职业）：0.0431\npolicy_annual_premium（年保费）：0.0424\ninjury_claim（伤残赔付金额）：0.0406\nproperty_claim（财产赔付金额）：0.0401\nincident_hour_of_the_day（事故发生小时）：0.0373\n\n这些特征与保险实务高度一致：轻微事故伴随高赔付金额、缺乏外部证据等往往为欺诈信号。该分析提升了模型的可解释性。\n4.4 不平衡数据处理策略的有效性分析为系统评估不平衡处理策略的影响，本研究对比了三种场景：无重采样、SMOTE过采样和随机欠采样。表4-2展示了随机森林在不同策略下的性能（测试集保持原始分布）。\n\n\n\n\n策略\n准确率\nAUC\n欺诈类召回率\n欺诈类F1分数\n\n\n\n\n无重采样\n0.7800\n0.7348\n0.47\n0.54\n\n\nSMOTE过采样\n0.8675\n0.9382\n0.86\n0.87\n\n\n随机欠采样\n0.7172\n0.8225\n0.69\n0.70\n\n\n\n\n表4-2 不同不平衡处理策略对随机森林性能的影响\nSMOTE过采样显著提升了AUC和欺诈类召回率（从0.47提高至0.86），F1分数提升明显。随机欠采样虽提高了召回率，但整体准确率和AUC下降，表明信息损失较大。无重采样策略下模型对少数类敏感性不足。该规律在其他模型中同样存在：SMOTE对KNN和SVM的召回率提升尤为显著（超过20%），而对随机森林的增益相对温和，得益于其内置自助采样机制。综合而言，SMOTE在本数据集上是最稳健的不平衡处理策略。\n4.5 特征选择的影响分析本研究采用递归特征消除（RFE）结合随机森林进行特征选择，对比了使用全部特征与Top 20特征的模型性能。\n\n\n\n\n特征集\n准确率\nAUC\n欺诈类召回率\n欺诈类F1分数\n训练时间减少\n\n\n\n\n全部特征\n0.9091\n0.9777\n0.88\n0.90\n\n\n\nRFE选择20个特征\n0.7650\n0.7501\n0.58\n0.58\n约30%\n\n\n\n\n表4-3 特征选择对随机森林性能的影响\n结果显示，使用全部特征的模型性能显著优于仅选20个特征的模型（AUC下降约0.2276）。这表明数据集特征整体信息丰富，强行降维会导致关键信号丢失。尽管特征选择可减少约30%训练时间，但在本任务中不推荐大幅降维，以优先保证检测精度。\n4.6 结果讨论扩展对比实验表明，集成学习算法（随机森林、XGBoost、AdaBoost）在本欺诈检测任务中显著优于传统单一分类器，其中随机森林综合性能最优。SMOTE过采样的引入有效缓解了类别不平衡问题，尤其提升了少数类的识别能力，而随机欠采样虽可进一步提高召回率，但以牺牲整体准确率为代价。特征选择实验显示，本数据集特征冗余度较低，保留全部特征更有利于模型性能。\n整体框架在中小规模结构化数据上表现出高效性和鲁棒性，随机森林结合SMOTE与特征重要性分析，不仅实现了高精度检测，还提供了业务可解释的洞察，为汽车保险欺诈风险管理提供了实用参考。尽管XGBoost性能接近，但随机森林在可解释性和计算稳定性上的优势使其更适合实际部署。\n第5章 结论与展望5.1 研究结论本研究针对汽车保险理赔欺诈检测问题，构建了一个系统化的机器学习分析框架。该框架涵盖数据预处理、类别不平衡处理、模型训练以及多维度性能评估等环节。实验基于公开的汽车保险理赔数据集，采用SMOTE过采样技术有效缓解了类别不平衡问题，并对逻辑回归、支持向量机以及随机森林三种传统分类算法进行了全面对比。\n实证结果表明：\n\n随机森林模型在综合性能上表现出色，其AUC值达到0.9382，整体准确率达0.8675，欺诈类召回率为0.86，F1分数为0.87。该模型在精确率与召回率的平衡方面优于支持向量机（AUC=0.9255），并显著优于逻辑回归（AUC=0.7749）。\nSMOTE过采样策略显著提升了模型对少数类样本的识别能力，证实了数据层面不平衡处理在欺诈检测任务中的关键作用。\n特征重要性分析揭示了incident_severity（事故严重程度）、total_claim_amount（总赔付金额）以及vehicle_claim（车辆赔付金额）等特征对欺诈预测的主导贡献，这些发现与保险业务实践高度契合，增强了模型的可解释性。\n\n上述结论验证了传统集成学习算法，特别是随机森林，在处理高维、不平衡保险数据时的鲁棒性和有效性。该框架不仅实现了较高的预测精度，还保持了较强的解释能力，为数据驱动的欺诈检测提供了可靠的实证依据。\n5.2 理论与实践意义从理论层面，本研究丰富了保险欺诈检测领域的实证文献，强调了预处理阶段（尤其是类别不平衡处理）与分类模型的系统性整合。该框架回应了现有研究中对端到端流程优化的呼吁，并通过多模型公平对比为算法选择提供了参考基准。\n从实践层面，本研究为保险机构提供了可操作的自动化检测工具。该模型可集成至理赔审核系统，实现对潜在欺诈案件的优先筛选，从而降低经济损失并优化资源分配。同时，特征重要性分析为业务人员提供了明确的的风险信号指引，有助于构建分层审核机制，提升整体风控效率。\n5.3 研究局限性本研究仍存在若干局限性：\n\n数据集规模较小（仅1000条记录），且欺诈样本比例（约25%）高于实际行业水平，可能影响模型在极度不平衡场景下的泛化性能。\n特征集主要限于理赔环节结构化数据，未能融入多源异构信息（如事故照片、投保人信用记录），限制了模型的判别潜力。\n研究聚焦传统机器学习方法，未涉及深度学习或混合模型的对比。\n\n5.4 未来研究展望基于本研究的基础，未来可从在更大规模的企业内部数据集上验证框架，评估其在真实分布下的稳健性与部署效果，同时也可以扩展至多模态数据融合（如结合图像与文本信息）或在线学习机制，以应对欺诈模式的动态演变。从而汽车保险欺诈检测技术有望向更高精度、更强解释性和更广适用性的方向演进，为行业数字化风险管理贡献更大价值。\n目前的工作展现了传统机器学习方法在保险欺诈检测中的应用潜力，期望为相关领域的理论发展与实践创新提供有益参考。\n\n\nBarry, S., &amp; Charpentier, A. (2020). Machine Learning for Insurance. CRC Press. (经典教材，奠定背景)\n\nBhattacharyya, S., et al. (2011). Data mining for credit card fraud: A comparative study. Decision Support Systems. (关于数据驱动欺诈检测的经典对比研究)\n\nBreiman, L. (2001). Random Forests. Machine Learning. (随机森林算法的开创性文献)\n\nCAIF (2022). The Impact of Insurance Fraud on the U.S. Economy. Coalition Against Insurance Fraud. (权威行业损失数据)\n\nChawla, N. V., et al. (2002). SMOTE: Synthetic Minority Over-sampling Technique. JAIR. (处理不平衡数据的基石研究)\n\nCohen, A., &amp; Siegelman, P. (2010). Testing for Adverse Selection in Insurance Markets. Journal of Risk and Insurance. (信息不对称理论应用)\n\nDerrig, R. A. (2002). Insurance Fraud. Journal of Risk and Insurance. (保险欺诈定义的权威来源)\n\nGomes, H. M., et al. (2021). Machine learning for streaming data: state of the art, challenges, and opportunities. ACM SIGKDD. (讨论端到端流程的现代挑战)\n\nHe, H., &amp; Garcia, E. A. (2009). Learning from Imbalanced Data. IEEE Transactions on Knowledge and Data Engineering. (不平衡学习的系统性评述)\n\nOECD (2023). Global Insurance Market Trends 2023. (全球保险市场宏观背景)\n\nSeverino, M. K., &amp; Peng, Y. (2021). Machine learning algorithms for fraud detection in property-casualty insurance: A review. Decision Support Systems. (最新的车险欺诈综述，非常契合本文)\n\nXia, X., et al. (2023). Random forest-based fraud detection in automobile insurance. Expert Systems with Applications. (2023年针对随机森林在车险应用的最新实证研究)\n\n\n\n\nBreiman, L. (2001). Random Forests. Machine Learning. (奠基性引用)\n\nCAIF. (2022). The Impact of Insurance Fraud on the U.S. Economy. (最新行业数据)\n\nChen, T., &amp; Guestrin, C. (2016). XGBoost: A Scalable Tree Boosting System. SIGKDD. (XGBoost 核心文献)\n\nHan, W., et al. (2022). Learning from imbalanced data: A comparative study of SMOTE and its variations. Information Sciences. (重采样技术的最新对比)\n\nJohnson, J. M., &amp; Khoshgoftaar, T. M. (2019). Survey on deep learning with class imbalance. Journal of Big Data. (虽然讨论深度学习，但对不平衡问题的总结非常权威)\n\nJovanovic, M., et al. (2022). Building an efficient fraud detection system in the insurance industry. Decision Support Systems. (针对车险的最新应用研究)\n\nKe, G., et al. (2017). LightGBM: A Highly Efficient Gradient Boosting Decision Tree. NeurIPS. (LightGBM 核心文献)\n\nNordin, N., et al. (2024). Machine learning for insurance fraud detection: A performance-based comparative analysis. Financial Innovation. (2024 年最新的多算法对比实证研究)\n\nSeverino, M. K., &amp; Peng, Y. (2021). Machine learning algorithms for fraud detection in property-casualty insurance: A review. Decision Support Systems. (该领域最权威的最新综述)\n\nHe, H., &amp; Garcia, E. A. (2009). Learning from Imbalanced Data. (不平衡学习领域的引用率最高、最权威的综述，定义了该问题的基本挑战)。\n\nDal Pozzolo, A., et al. (2015). Calibrating Probability with Undersampling for Unbalanced Classification. (论证了非对称代价函数和不平衡分类在反欺诈中的关联)。\n\nSeverino, M. K., &amp; Peng, Y. (2021). Machine learning algorithms for fraud detection in property-casualty insurance: A review. (2021年最新的车险欺诈综述，专门强调了漏检欺诈的昂贵代价)。\n\nChawla, N. V., et al. (2002). SMOTE: Synthetic Minority Over-sampling Technique. (SMOTE 算法的开创性文献，必须保留)。\n\nFernández, A., et al. (2018). SMOTE for Learning from Imbalanced Data: Progress and Challenges, Marking the 15-year Anniversary. (发表于《Nature》子刊或顶级期刊的综述，对 SMOTE 15年来的应用进行了权威总结，证明其在结构化数据上的稳健性)。\n\nJovanovic, M., et al. (2022). Building an efficient fraud detection system in the insurance industry. (针对保险行业最新的实证研究，证明了 SMOTE 在提升车险欺诈检测召回率方面的实效)。\n\n\n\n\nBhattacharyya, S., et al. (2011). Data mining for credit card fraud: A comparative study. Decision Support Systems.\nBreiman, L. (2001). Random Forests. Machine Learning.\nCAIF (2022). The Impact of Insurance Fraud on the U.S. Economy. Coalition Against Insurance Fraud.\nChawla, N. V., et al. (2002). SMOTE: Synthetic Minority Over-sampling Technique. Journal of Artificial Intelligence Research (JAIR).\nCohen, A., &amp; Siegelman, P. (2010). Testing for Adverse Selection in Insurance Markets. Journal of Risk and Insurance.\nDerrig, R. A. (2002). Insurance Fraud. Journal of Risk and Insurance.\nHe, H., &amp; Garcia, E. A. (2009). Learning from Imbalanced Data. IEEE Transactions on Knowledge and Data Engineering.\nOECD (2023). Global Insurance Market Trends 2023. Organisation for Economic Co-operation and Development.\nChen, T., &amp; Guestrin, C. (2016). XGBoost: A Scalable Tree Boosting System. Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.\nJohnson, J. M., &amp; Khoshgoftaar, T. M. (2019). Survey on deep learning with class imbalance. Journal of Big Data.\nKe, G., et al. (2017). LightGBM: A Highly Efficient Gradient Boosting Decision Tree. Advances in Neural Information Processing Systems (NeurIPS).\nDal Pozzolo, A., et al. (2015). Calibrating Probability with Undersampling for Unbalanced Classification. IEEE Symposium Series on Computational Intelligence.\nFernández, A., et al. (2018). SMOTE for Learning from Imbalanced Data: Progress and Challenges, Marking the 15-year Anniversary. Journal of Artificial Intelligence Research.\n\n","categories":["归档"]},{"title":"2026-01-06-人工智能导论复习","url":"/Arknight-notes/posts/64338.html","content":"第一章1.1 什么是人类智能？它有哪些特点？\n\n人类智能是指人类在认识、适应和改造客观世界的过程中，由一系列核心能力构成的综合性心智功能。其本质在于能理解、推理、学习并运用知识解决复杂问题。\n主要特点：\n感知与理解：能通过感官获取信息，并理解其含义。\n学习与适应：能从经验中学习，更新知识，适应新环境。\n推理与解决问题：能运用逻辑、归纳、演绎等方法，从已知推知未知，并制定策略解决问题。\n使用语言：能用复杂的符号系统（语言）进行交流、表达和思考。\n具有意识与能动性：有自我意识，能进行有目的、有计划的主动行为。\n\n\n\n1.2 什么是人工智能？它的发展过程经历了哪些阶段？\n\n人工智能是计算机科学的一个分支，旨在研究、开发用于模拟、延伸和扩展人的智能的理论、方法、技术及应用系统。其目标是使机器能够胜任一些通常需要人类智能才能完成的复杂工作。\n主要发展阶段：\n孕育期（1956 年以前）：数理逻辑、控制论、信息论等理论为 AI 诞生奠定基础。图灵提出“机器能思考吗？”的划时代问题。\n形成与热潮期（1956-1970s 初）：1956 年达特茅斯会议正式提出“人工智能”学科名称。早期在问题求解、定理证明、机器翻译等方面取得突破，乐观情绪高涨。\n知识应用与专家系统时期（1970s-1980s）：研究者意识到“知识”的重要性，专家系统（将人类专家的知识规则化）成为主流，AI 走向商业化应用。\n机器学习兴起与平稳发展期（1980s 末-2010 初）：随着互联网兴起和数据量增长，以统计学习和神经网络复兴（连接主义）为代表的机器学习方法成为核心。支持向量机、决策树等方法广泛应用。\n深度学习与大数据驱动期（2010s 至今）：得益于大数据、强算力（如 GPU）和算法改进（如深度神经网络），深度学习在图像识别、自然语言处理等领域取得突破性进展，引发新一轮 AI 热潮。\n\n\n\n1.3 人工智能研究的基本内容有哪些？\n根据您图片中的提示并综合常见分类，其基本内容包括：\n\n知识表示：研究如何用机器可处理的形式来表示和存储人类的知识（如事实、规则）。\n机器感知：研究如何让机器通过“感官”获取外部信息，核心领域包括计算机视觉（看）和语音识别（听）。\n机器思维：在感知的基础上，研究如何对信息进行推理、决策和问题求解，是 AI 的核心。\n机器学习：研究如何让机器自动从数据中学习规律和知识，从而不断改进性能，是实现人工智能的关键途径。\n自然语言处理：研究如何实现人机间的自然语言通信，包括理解和生成。\n行为主义与智能系统：研究如何将上述能力综合，构建能对外界环境做出合理反应和行动的智能体或机器人。\n\n1.4 人工智能有哪些主要的研究领域？\n（以下是部分核心与活跃的研究领域）\n\n机器感知：计算机视觉、语音识别、多模态感知。\n自然语言处理：机器翻译、文本理解与生成、对话系统（聊天机器人）。\n机器学习：深度学习、强化学习、迁移学习、联邦学习。\n知识表示与推理：知识图谱、自动推理、专家系统。\n机器人学：环境感知、运动控制、人机协作。\n人工智能交叉与应用领域：\n\n智能控制：如智能驾驶。\n智能计算：演化计算、群智能优化。\n数据挖掘与大数据分析。\n人工智能与其他学科的交叉：如生物信息学、计算金融、智慧医疗等。\n\n\n\n\n第二章2.1 什么是知识？它有哪些特性？有哪几种分类方法？\n2.2 什么是知识表示？如何选择知识表示方法？\n2.3 什么是命题？请写出三个真值为 T 及真值为 F 的命题。\n2.4 什么是谓词？什么是谓词个体及个体域？函数与谓词的区别是什么？\n2.5 谓词逻辑和命题逻辑的关系如何？有何异同？\n2.6 什么是谓词的项？什么是谓词的阶？请写出谓词的一般形式。\n2.7 什么是谓词公式？什么是谓词公式的解释？\n2.8 一阶谓词逻辑表示法是结构化知识还是非结构化知识？适合于表示哪种类型的知识？它有哪些特点？\n2.9 请写出用一阶谓词逻辑表示法表示知识的步骤。\n2.10 产生式的基本形式是什么？它与谓词逻辑中蕴涵式有什么共同处和不同处？\n2.11 产生式系统由哪几部分组成？\n2.12 试述产生式系统求解问题的一般步骤。\n2.13 产生式系统中，推理机的推理方式有哪几种？在产生式推理过程中，如果发生策略冲突，如何解决？\n2.14 试述产生式表示法的特点。\n2.15 框架的一般表示形式是什么？\n2.16 框架表示法有何特点？请叙述用框架表示法表示知识的步骤。\n2.17 试构造一个描述读者的办公室或卧室的框架系统。\n2.18 试构造一个描述计算机主机的框架系统。\n2.19 请给出一个知识图谱实例。\n参考答案\n2.1 什么是知识？它有哪些特性？有哪几种分类方法？\n\n知识：知识是经过加工、整理、解释、挑选和改造的信息，是人们在长期实践中积累的对客观世界的规律性认识。在人工智能中，知识是使机器具备智能的基石。\n特性：相对正确性（在特定条件下成立）、不确定性、可表示性、可利用性。\n分类方法：\n\n按作用层次：事实性知识、过程性知识、控制性知识。\n按确定性：确定性知识、不确定性知识。\n按表现形式：显性知识（可编码）、隐性知识（经验、直觉）。\n\n2.2 什么是知识表示？如何选择知识表示方法？\n\n知识表示：将人类知识形式化、模型化，以便计算机能够存储、处理和运用的一套方法和约定。它是数据结构和解释过程的结合。\n\n选择依据：① 充分表示领域知识；② 支持高效推理；③ 便于知识的获取与管理；④ 易于理解、维护。\n2.3 什么是命题？请写出三个真值为 T 及真值为 F 的命题。\n\n命题：一个能判断其真（T）或假（F）​ 的陈述句。\n\n示例：\n\n真命题：北京是中国的首都。1+1=2。太阳从东方升起。\n假命题：2 大于 3。鱼在天上飞。地球是平的。\n\n2.4 什么是谓词？什么是谓词个体及个体域？函数与谓词的区别是什么？\n\n谓词：用于描述个体性质或个体间关系的语句成分。例如，“是红色的(x)”描述性质，“朋友(x, y)”描述关系。\n\n个体：可以独立存在的具体或抽象对象（如“小明”、“5”）。\n个体域：个体所组成的集合（讨论范围）。\n函数与谓词的区别：函数的返回值是一个个体（如 父亲(小明)返回一个人），而谓词的返回值是一个真值（T 或 F）（如 朋友(小明, 小红)判断真假）。\n2.5 谓词逻辑和命题逻辑的关系如何？有何异同？\n\n关系：命题逻辑是谓词逻辑的基础，谓词逻辑是命题逻辑的细化和扩展。\n\n相同点：都使用逻辑连接词（与、或、非等）和真值运算。\n不同点：\n\n描述粒度：命题逻辑以整个句子为基本单元，无法分析内部结构。谓词逻辑可分析到个体、谓词和量词。\n表达能力：谓词逻辑能表达“所有”、“存在”等量化的普遍性知识，表达能力远强于命题逻辑。\n\n2.6 什么是谓词的项？什么是谓词的阶？请写出谓词的一般形式。\n\n谓词的项：充当谓词逻辑自变量的个体。可以是常量、变量或函数。\n\n谓词的阶：由项的取值范围决定。一阶谓词的项是个体，二阶谓词的项可以是谓词或集合。\n一般形式：P(x1, x2, ..., xn)。其中 P 是谓词名，x1~xn 是项。\n2.7 什么是谓词公式？什么是谓词公式的解释？\n\n谓词公式：由谓词、项、逻辑连接词、量词和括号按规则组成的合法符号串，用于表达一个完整的判断。\n\n解释：给谓词公式中的个体常量、函数符号、谓词符号赋予具体的含义（指定个体域、对应关系和函数映射），从而确定公式的真值。\n2.8 一阶谓词逻辑表示法是结构化知识还是非结构化知识？适合于表示哪种类型的知识？它有哪些特点？\n\n结构化/非结构化：属于结构化知识表示。它精确地描述了知识内部的逻辑结构（个体、谓词、量词）。\n\n适合类型：适合表示事物的状态、属性、概念以及它们之间精确的逻辑关系。尤其擅长表达“所有 A 都是 B”、“存在某个 A 具有性质 P”这类精确的、能用公式严格定义的事实和规则。\n特点：\n\n优点：严密性、精确性、自然性好，接近自然语言和人类思维。\n缺点：知识粒度细，表示复杂知识时组合爆炸；推理效率相对较低；处理不确定性知识能力弱。\n\n2.9 请写出用一阶谓词逻辑表示法表示知识的步骤。\n\n\n\n定义个体域：确定所讨论对象的集合。\n定义谓词和函数：用符号表示个体性质和关系。\n用连接词和量词将原子谓词公式组合，构成复合公式。\n对公式进行化简，化为标准式（如前束范式），便于推理。\n\n2.10 产生式的基本形式是什么？它与谓词逻辑中蕴涵式有什么共同处和不同处？\n\n基本形式：IF (前提) THEN (结论/动作)，也称为条件-行动对。\n与谓词逻辑蕴涵式的异同：\n\n共同点：在确定性知识下，形式上都表现为“如果 P，则 Q”。\n不同点：\n匹配过程：产生式规则的前提与动态数据库匹配，匹配即执行；蕴涵式是静态逻辑关系。\n操作：产生式的 THEN 部分不仅可以断言新事实，也可以执行动作（如修改数据库、输出）；蕴涵式仅表示逻辑推导关系。\n控制：产生式系统有独立的推理机控制规则触发顺序；逻辑系统依赖通用推理规则。\n\n\n\n2.11 产生式系统由哪几部分组成？\n\n\n\n规则库：存储所有产生式规则的知识库。\n综合数据库/工作存储器：存储当前已知的事实、初始数据和中间结论的动态数据库。\n推理机：控制系统的运行。负责匹配（规则前提与数据库事实）、冲突消解（选择激活的规则）、执行（执行规则结论，更新数据库）。\n\n2.12 试述产生式系统求解问题的一般步骤。\n\n初始化：将初始事实和数据存入综合数据库。\n匹配：推理机将规则库中每条规则的前提与综合数据库中的当前事实进行比对。\n冲突消解：若有多条规则可被激活，按某种策略（如优先级、特殊性、顺序）选择一条。\n执行：执行被选中规则的 THEN 部分，可能添加新事实、修改旧事实或执行外部动作，从而更新综合数据库。\n循环：重复步骤 2-4，直到达到目标状态（数据库包含目标事实）或没有规则可被激活为止。\n\n2.13 产生式系统中，推理机的推理方式有哪几种？在产生式推理过程中，如果发生策略冲突，如何解决？\n\n推理方式：\n正向推理（数据驱动）：从已知事实出发，匹配规则前提，逐步推出结论。\n反向推理（目标驱动）：从假设目标出发，寻找支持该目标的证据（规则）。\n混合推理：结合正向和反向推理。\n\n\n冲突解决策略：\n\n专一性排序：优先选择条件更具体、更特殊的规则。\n规则排序：按事先指定的固定优先级。\n数据排序：按前提中条件的新鲜性（新加入的事实优先）或特殊性排序。\n就近排序：优先选择最近使用过的规则。\n规模排序：优先选择前提条件多的规则。\n\n2.14 试述产生式表示法的特点。\n\n优点：\n\n自然性：接近人类“如果…那么…”的思维习惯。\n模块性：规则形式单一、相互独立，易于增、删、改。\n清晰性：知识与控制分离，结构清晰。\n\n\n缺点：\n\n效率低：匹配是组合爆炸问题，求解效率可能不高。\n不能表达结构性知识：不擅长描述具有复杂内在结构的知识对象。\n\n2.15 框架的一般表示形式是什么？\n\n\n框架是一种描述固定、典型情景中对象的结构化表示。其一般形式为：\n框架名：&lt;框架名&gt;槽 1：&lt;侧面 11&gt; &lt;值 111&gt;…       &lt;侧面 12&gt; &lt;值 121&gt;…槽 2：&lt;侧面 21&gt; &lt;值 211&gt;……约束：&lt;约束条件 1&gt;     …\n其中，“槽”描述对象的属性或方面，“侧面”描述属性的更详细信息（如默认值、取值范围、触发过程等）。\n2.16 框架表示法有何特点？请叙述用框架表示法表示知识的步骤。\n\n特点：结构性好、继承性（通过 AKO 槽实现）、自然性（符合人们对典型事物的认知）、便于表达默认知识。\n表示步骤：\n\n分析待描述对象，确定其框架名。\n确定描述该对象所需的关键属性，作为槽。\n为每个槽配备相应的侧面（如值类型、默认值、附加过程）。\n填写各侧面的具体值。\n确定与其它框架的继承关系（如AKO， ISA槽）。\n\n2.17 试构造一个描述读者的办公室或卧室的框架系统。\n\n\n框架名：&lt;卧室&gt;AKO：&lt;房间&gt;位置：&lt;家&gt;面积：&lt;15 平方米&gt;功能：&lt;休息， 学习， 储物&gt;包含家具：&lt;床&gt;， &lt;书桌&gt;， &lt;衣柜&gt;   子框架：&lt;床&gt;       类型：&lt;双人床&gt;       材质：&lt;实木&gt;   子框架：&lt;书桌&gt;       位置：&lt;窗前&gt;       状态：&lt;正在使用&gt;       上放物品：&lt;笔记本电脑&gt;， &lt;台灯&gt;， &lt;书本&gt;所有者：&lt;读者的名字&gt;\n2.18 试构造一个描述计算机主机的框架系统。\n框架名：&lt;计算机主机&gt;AKO：&lt;电子设备&gt;品牌：&lt;Dell&gt;型号：&lt;OptiPlex 7080&gt;状态：&lt;运行中&gt;包含组件：   槽：&lt;中央处理器&gt;       型号：       主频：&lt;2.9 GHz&gt;   槽：&lt;内存&gt;       容量：&lt;16 GB&gt;       类型：&lt;DDR4&gt;  槽：&lt;硬盘&gt;       类型：&lt;SSD&gt;       容量：&lt;512 GB&gt;   槽：&lt;主板&gt;       型号：&lt;Dell 0WVNPW&gt;   槽：&lt;电源&gt;       功率：&lt;260W&gt;操作系统：&lt;Windows 10 专业版&gt;\n2.19 请给出一个知识图谱实例。\n知识图谱是一种以图结构表示实体及其关系的语义网络。\n\n示例：一个关于《红楼梦》的微型知识图谱。\n表示（三元组形式）：\n(曹雪芹， 创作， 《红楼梦》)\n(《红楼梦》， 文学体裁， 长篇小说)\n(《红楼梦》， 主角， 贾宝玉)\n(《红楼梦》， 主角， 林黛玉)\n(贾宝玉， 居住地， 大观园)\n(林黛玉， 性格特点， 多愁善感)\n(贾宝玉， 爱慕， 林黛玉)\n(林黛玉， 表兄妹， 贾宝玉)\n\n\n可视化：可以想象成一个图，其中“曹雪芹”、“《红楼梦》”、“贾宝玉”、“林黛玉”、“大观园”等是节点（实体），“创作”、“文学体裁”、“主角”、“居住地”、“爱慕”等是边（关系）。\n\n\n第三章3.1​ 什么是推理、正向推理、逆向推理、混合推理？试列出常用的几种推理方式并列出每种推理方式的特点。\n3.2​ 什么是冲突？在产生式系统中解决冲突的策略有哪些？\n3.3​ 什么是子句？什么是子句集？请写出求谓词公式子句集的步骤。\n3.4​ 谓词公式与它的子句集等价吗？在什么情况下它们才会等价？\n3.5​ 引入鲁宾孙归结原理有何意义？什么是归结原理？什么是归结式？\n3.6​ 请写出利用归结原理求解问题答案的步骤。\n解答\n3.1 什么是推理、正向推理、逆向推理、混合推理？试列出常用的几种推理方式并列出每种推理方式的特点。\n\n推理：从已知事实出发，运用知识推出结论的思维过程。\n推理方式及其特点：\n正向推理（数据驱动）：从已知事实出发，匹配规则，不断推出新事实直至目标。特点：适用于初始数据明确、目标众多的场合，但可能进行大量与目标无关的推理。\n逆向推理（目标驱动）：从假设目标出发，反向寻找支持它的证据。特点：目的性强，适用于目标单一的场合，但对初始数据的指导性弱。\n混合推理：结合正向与逆向推理。特点：从初始事实正向推理，得到中间结论；再从目标逆向推理，寻求支持，效率更高。\n\n\n\n3.2 什么是冲突？在产生式系统中解决冲突的策略有哪些？\n\n冲突：在推理的某一时刻，有多条规则的前提同时与综合数据库匹配成功的情况。\n冲突解决策略：\n专一性排序：优先使用条件更具体、范围更小的规则。\n规则排序：按规则优先级事先固定排序。\n数据排序：按匹配事实的“新旧”程度（如最新加入的事实优先）或特定性排序。\n就近排序：优先使用最近被触发过的规则。\n\n\n\n3.3 什么是子句？什么是子句集？请写出求谓词公式子句集的步骤。\n\n子句：若干文字的析取式（L₁ ∨ L₂ ∨ ...），其中每个文字是原子公式或其否定。\n子句集：若干子句的集合，是合取范式（即子句之间是“与”的关系）。\n求子句集的步骤：\n消去蕴涵符号：用 ¬A ∨ B替换 A → B。\n内移否定符：将 ¬移到原子公式前，如 ¬(A ∧ B)化为 ¬A ∨ ¬B。\n变量标准化：使不同量词约束的变量名不同。\n消去存在量词（Skolem 化）。\n化为前束形：将所有全称量词移到公式最前面。\n化为合取范式：将公式内化为子句的合取。\n消去全称量词和合取词，得到子句集。\n\n\n\n3.4 谓词公式与它的子句集等价吗？在什么情况下它们才会等价？\n\n谓词公式与其子句集并不等价。在转化过程中（特别是 Skolem 化）​ 会引入新常量/函数，导致两者在逻辑上不完全等价。\n它们只是在不可满足性上等价。即，原谓词公式是不可满足的，当且仅当其子句集是不可满足的。这是归结原理能用于自动定理证明的基础。\n\n3.5 引入鲁宾孙归结原理有何意义？什么是归结原理？什么是归结式？\n\n意义：为定理的机器自动证明提供了一个简洁、规范且完备的推理方法。它将复杂的推理过程归结为简单的子句归结，奠定了自动推理的理论基础。\n归结原理：在子句集中进行。如果两个子句中分别包含互补文字（如 P和 ¬P），则可消去这对互补文字，将两个子句的其余部分合并构成新子句。\n归结式：由归结操作生成的新子句。\n\n3.6 请写出利用归结原理求解问题答案的步骤。\n\n化已知条件为谓词公式：将已知事实和知识表示为谓词公式集合 F。\n化待证目标为谓词公式：将待证明的结论表示为谓词公式 G。\n构造子句集：将公式集合 {F, ¬G}化为子句集 S。\n归结演绎：对子句集 S反复应用归结原理，若最终能推出空子句（□），则说明 F → G成立，证明结束。若无法归结出空子句，且无法继续归结，则说明原结论不成立。\n\n\n第四章4.1​ 什么是不确定性推理？有哪几类不确定性推理方法？不确定性推理中需要解决的基本问题有哪些？ 4.2​ 什么是可信度？由可信度因子 CF(H,E)的定义说明它的含义。 4.3​ 简述求取问题结论可信度的步骤。 4.4​ 说明概率分配函数、信任函数、似然函数的含义。 4.5​ 概率分配函数与概率相同吗？为什么？ 4.6​ 如何用 D-S 证据理论描述假设、规则和证据的不确定性，并实现不确定性的推理组合？ 4.7​ 什么是模糊性？它与随机性有什么区别？试举出几个日常生活中的模糊概念。 4.8​ 模糊推理的一般过程是什么？\n答案\n4.1 什么是不确定性推理？有哪几类不确定性推理方法？不确定性推理中需要解决的基本问题有哪些？\n\n定义：不确定性推理是指在知识（规则）和证据（事实）不精确、不完备、模糊或存在矛盾的情况下，依然能够进行推理并得出结论的一种方法。其结论通常附带有不确定性度量。\n主要方法：\n可信度方法（如 MYCIN 系统模型）\n主观贝叶斯方法\n证据理论（D-S 理论）\n模糊推理\n\n\n基本问题：\n不确定性的表示：如何描述知识、证据和结论的不确定性度量（如可信度、概率、隶属度等）。\n不确定性的计算：如何定义不确定性在推理过程中的传播、更新和组合的算法。\n不确定性度量的语义：明确不确定性度量的实际含义（如可信度是信任增长度，概率是客观频率等）。\n证据的组合：当多条证据支持同一结论时，如何合并它们的影响。\n\n\n\n4.2 什么是可信度？由可信度因子 CF(H,E)的定义说明它的含义。\n\n可信度：是专家系统中用来表示假设 H在证据 E成立的前提下，其为真的信任程度的一种不确定性度量。\n可信度因子 CF(H,E)：定义为信任增长度。其经典定义为： CF(H,E) = MB(H,E) - MD(H,E)\nMB(H,E)：证据 E 对假设 H 的信任增加度量。\nMD(H,E)：证据 E 对假设 H 的不信任增加度量。\n\n\n含义：\nCF(H,E) &gt; 0：表示证据 E 的出现增加了假设 H 为真的信任度，正值越大，信任度增加越多。\nCF(H,E) = 0：表示证据 E 与假设 H 无关，或MB=MD，即信任与不信任的增量相同。\nCF(H,E) &lt; 0：表示证据 E 的出现增加了假设 H 为假的不信任度。\n\n\n\n4.3 简述求取问题结论可信度的步骤。\n\n建立规则库：用IF...THEN...的形式定义知识，并为每条规则赋予可信度因子CF(Rule)。\n初始化证据可信度：为已知的初始证据E赋予初始可信度CF(E)。\n进行正向推理：从已知证据出发，匹配可用的规则。\n计算结论的可信度：对于匹配成功的规则IF E THEN H (CF(Rule))，结论H的可信度CF(H)由前提E的可信度CF(E)和规则的可信度CF(Rule)共同决定，公式通常为：CF(H) = CF(E) * CF(Rule)。\n组合不同证据：如果同一个结论H被多条路径（规则）推导出来，得到多个CFi(H)，则需使用组合公式（如合成法）计算最终的CF(H)。\n\n4.4 说明概率分配函数、信任函数、似然函数的含义。\n这是 D-S 证据理论中的核心概念。设Θ为识别框架（所有可能假设的集合）。\n\n概率分配函数(m)：是一个从Θ的幂集2^Θ到[0,1]的映射，满足m(∅)=0且∑m(A)=1。m(A)表示证据本身支持命题A成立的基本概率分配，而不支持A的任何子集。\n信任函数(Bel)：对任意命题A ⊆ Θ，Bel(A) = ∑_{B ⊆ A} m(B)。表示证据对A的总信任度，即所有支持A的子集（B ⊆ A）的基本概率之和。\n似然函数(Pl)：对任意命题A ⊆ Θ，Pl(A) = 1 - Bel(¬A)。表示不否定A的程度，即A的可能信任度。区间[Bel(A), Pl(A)]构成了信任区间，描述了对A的不确定性。\n\n4.5 概率分配函数与概率相同吗？为什么？\n不同。​ 主要原因：\n\n定义域不同：概率分配函数m的定义域是识别框架Θ的幂集2^Θ（即所有子集），而概率函数的定义域是Θ本身（基本事件）。\n分配对象不同：m(A)可以分配给任何命题（子集）A，表示证据对A本身的直接支持度，无需将支持度再分配给A的内部元素。而概率必须满足可加性，分配给复合事件（如{A, B}）的概率必须等于分配给基本事件P(A)+P(B)。\n对未知的处理不同：证据理论允许m(Θ) &gt; 0，即保留一部分信任度给“未知”，表示对识别框架中所有可能性的无知。而在经典概率中，P(Θ)=1是确定的，无法表示这种无知。\n\n4.6 如何用 D-S 证据理论描述假设、规则和证据的不确定性，并实现不确定性的推理组合？\n\n描述不确定性：\n证据：用基本概率分配函数m来描述。每个证据对应一个m函数，表示该证据对识别框架Θ中各个命题的支持程度。\n规则：通常可以表示为IF E THEN H, with m的形式，或者用规则强度、信度函数等与证据组合。\n假设：是识别框架Θ中的子集。其不确定性由信任函数Bel和似然函数Pl构成的信任区间[Bel, Pl]来描述。\n\n\n推理组合：通过Dempster 组合规则实现。对于两个相互独立的证据源E1和E2，其对应的概率分配为m1和m2，组合后的新概率分配m = m1 ⊕ m2计算公式为： m(C) = K^{-1} * ∑_{A∩B=C} m1(A)*m2(B)，其中C ≠ ∅。 K = 1 - ∑_{A∩B=∅} m1(A)*m2(B)是归一化常数，用于排除冲突证据的影响。\n\n4.7 什么是模糊性？它与随机性有什么区别？试举出几个日常生活中的模糊概念。\n\n模糊性：指事物在概念和外延上所具有的不分明性，源于事物类属的“亦此亦彼”性。是对静态事物本身状态的描述。\n区别：\n产生原因：随机性源于因果律的缺失，是事件是否发生的不确定性；模糊性源于排中律的缺失，是事件本身状态的不确定性。\n描述工具：随机性用概率论描述（事件发生的机会）；模糊性用模糊集合论描述（对象属于集合的程度）。\n举例：“明天可能下雨”是随机性；“现在是阴天”是模糊性（“阴天”的边界是模糊的）。\n\n\n日常模糊概念：高个子、年轻人、热水、天气很好、有点咸、打扫干净。\n\n4.8 模糊推理的一般过程是什么？\n\n模糊化：将输入的精确值，根据预先定义的隶属度函数，转化为对应模糊语言变量（如“高”，“中”，“低”）的隶属度。\n模糊规则匹配：将模糊化后的输入，与知识库中的模糊规则（IF-THEN 形式）的前件进行匹配，计算每条规则的激活强度（通常用取小min或乘积运算）。\n模糊推理：根据规则的激活强度，裁剪或缩放规则后件对应的模糊集的隶属度函数，得到每条规则输出的模糊结论。\n模糊结论合成：将所有被激活的规则输出的模糊结论进行聚合（通常用取大max运算），形成一个综合的输出模糊集合。\n去模糊化：将聚合后的输出模糊集合，通过某种算法（如重心法、最大隶属度法、中位数法等）转换成一个精确的输出值。\n\n第五章5.1​ 什么是搜索？有哪两大类不同的搜索方法？两者的区别是什么？\n5.2​ 什么是启发式搜索？什么是启发信息？\n5.3​ 用状态空间法表示问题时，什么是问题的解？求解过程的本质是什么？什么是最优解？最优解唯一吗？\n5.4​ 请写出状态空间图的一般搜索过程。在搜索过程中 open 表和 closed 表的作用分别是什么？有何区别？\n5.5​ 什么是盲目搜索？主要有几种盲目搜索策略？\n5.6​ 在深度优先搜索中，每个结点的子结点是按某种次序生成和扩展的，在决定生成子状态的最优次序时，应该用什么标准来衡量？\n5.7​ 宽度优先搜索与深度优先搜索有何不同？分析深度和宽度优先的优缺点。在何种情况下，宽度优先搜索优于深度优先搜索？在何种情况下，深度优先搜索优于宽度优先搜索？\n5.8​ 什么是 A搜索算法？它的估价函数是如何确定的？A搜索算法与 A 搜索算法的区别是什么？\n解答\n5.1 搜索：在状态空间中寻找从初始状态到目标状态的路径的过程。分为盲目搜索（无额外信息，按固定顺序搜索）和启发式搜索（利用启发信息指导搜索）。区别在于是否使用启发信息。\n5.2 启发式搜索：利用启发信息（即问题领域的额外知识，常表示为启发函数 h(n)，用于估计到目标的代价）来引导搜索方向，提高效率的搜索方法。\n5.3 问题的解：一个从初始状态到目标状态的操作序列。求解本质：在状态空间中找路径。最优解：总代价最小的解。最优解不一定唯一。\n5.4 一般搜索过程：\n\n初始状态放入 OPEN 表。\n若 OPEN 空则失败。\n取一状态。\n若是目标则成功。\n否则扩展，生成后继状态。\n处理后继状态。\n新状态按策略放入 OPEN，父状态移入 CLOSED。\n重复 2-7。\nOPEN 表：存放待考察节点（前沿）。CLOSED 表：存放已考察节点（历史）。区别在于节点状态（待扩展 vs 已扩展）。\n\n\n5.5 盲目搜索：不利用问题特定信息，按预定顺序搜索的策略。主要有：宽度优先搜索、深度优先搜索、一致代价搜索、深度受限搜索、迭代加深搜索。\n5.6 在深度优先搜索中，决定子状态生成的最优次序：DFS 本身无最优次序，按预设顺序（如字母序）。若想引入启发性，可按启发函数h(n)排序，优先扩展h(n)小的子节点（即更接近目标的状态）。\n5.7 宽度优先 vs 深度优先：\n\n不同：BFS 用队列逐层扩展；DFS 用栈沿分支深入。\n优缺点：BFS 完备且（在等代价时）最优，但空间开销大；DFS 空间开销小，但可能不完备，且找到的解不一定最优。\nBFS 优于 DFS：解在浅层、需求最优解、空间足够时。\nDFS 优于 BFS：空间深度大、只求可行解、BFS 空间无法承受时。\n\n_5.8 A搜索算法_*：一种启发式搜索，用估价函数f(n)=g(n)+h(n)（g(n)为实际代价，h(n)为估计代价）选择节点扩展。\n\n估价函数确定：h(n)需根据问题领域知识设计（如直线距离）。\n与 A 搜索算法的区别：A 算法泛指使用f(n)=g(n)+h(n)的算法；A_算法是 A 算法的特例，要求h(n)满足可采纳性（即h(n) ≤ h*(n)，h*(n)为真实最小代价），此条件下 A_能保证找到最优解。\n\n\n第六章6.1​ 遗传算法的基本步骤和主要特点是什么？\n6.2​ 适应度函数在遗传算法中的作用是什么？试举例说明如何构造适应度函数。\n6.3​ 选择的基本思想是什么？\n6.4​ 简述多种群遗传算法与基本遗传算法的异同。\n6.5​ 简述多倍体遗传算法与基本遗传算法的异同。\n6.6​ 群智能算法的基本思想是什么？\n6.7​ 群智能算法的主要特点是什么？\n6.8​ 列举几种典型的群智能算法，分析它们的主要优点、缺点。\n6.9​ 简述群智能算法与进化算法的异同。\n6.10​ 简述粒子群算法的流程。\n6.11​ 简述粒子群算法位置更新方程中各部分的影响。\n6.12​ 举例说明粒子群算法的搜索原理，并简要叙述粒子群算法有哪些特点。\n6.13​ 粒子群算法的寻优过程包含哪几个阶段？寻优的准则有哪些？\n6.14​ 粒子群算法中的参数如何选择？\n6.15​ 举例说明蚁群算法的搜索原理，并简要叙述蚁群算法的特点。\n6.16​ 蚁群算法的寻优过程包含哪几个阶段？寻优的准则有哪些？\n6.17​ 蚁群算法中的参数如何选择？\n\n6.1 遗传算法的基本步骤和主要特点是什么？\n\n基本步骤：\n初始化：随机生成初始种群（一组候选解）。\n适应度评估：计算种群中每个个体的适应度值。\n选择：根据适应度高低，选择优良个体作为父代。\n交叉：将选出的父代个体两两配对，以一定概率交换部分基因，产生新个体（子代）。\n变异：以较低概率改变子代个体中某些基因的值，引入新特征。\n生成新种群：用子代个体替换部分或全部父代，形成新一代种群。\n终止判断：若满足终止条件（如达到最大迭代次数或找到满意解），则输出最优解；否则返回步骤 2。\n\n\n主要特点：\n群体搜索：同时对解空间中的多个点进行搜索，并行性好。\n启发性随机搜索：通过概率规则（选择、交叉、变异）引导搜索，非确定性。\n无需梯度信息：仅需目标函数（适应度函数）值，不依赖函数的连续、可微等性质。\n隐含并行性：通过种群内个体的信息交换实现全局搜索。\n\n\n\n6.2 适应度函数在遗传算法中的作用是什么？试举例说明如何构造适应度函数。\n\n作用：\n评价个体优劣：适应度值高低直接反映个体（解）的质量。\n指导选择操作：适应度越高，被选中遗传到下一代的机会越大，是算法进化的驱动力。\n\n\n构造举例：求解函数 f(x) = x²在 [0, 31]上的最大值。\n编码：用 5 位二进制串表示x。\n直接法：个体解码后的值x代入目标函数，fit(x) = f(x) = x²即可作为适应度。\n若求最小值，可构造 fit(x) = C_max - f(x)或 fit(x) = 1 / (f(x) + ε)，确保适应度非负且与目标值成反比。\n\n\n\n6.3 选择的基本思想是什么？\n\n模拟“适者生存”的自然法则，使种群中适应度高的个体有更大的概率被选中，将其优良基因遗传给下一代。其核心是基于概率的优胜劣汰，引导搜索方向朝着更优解的区域进行。\n\n6.4 简述多种群遗传算法与基本遗传算法的异同。\n\n相同点：基本操作单元都是个体，都包含选择、交叉、变异等遗传操作。\n不同点：\n种群结构：基本 GA 为单一同质种群；多种群 GA 则并行维护多个子种群，并可能定期在种群间迁移（交换）部分优秀个体。\n目的：多种群 GA 旨在维持种群多样性，有效防止早熟收敛，增强全局探索能力，是并行 GA的一种典型实现。\n\n\n\n6.5 简述多倍体遗传算法与基本遗传算法的异同。\n\n相同点：遵循类似的进化流程。\n不同点：\n基因编码：基本 GA 个体为单倍体染色体（一套基因）；多倍体 GA 个体为多倍体（如二倍体，具有两套基因）。\n表达与遗传：多倍体存在显隐性关系，只有显性基因决定个体性状（适应度），但遗传时两套基因共同参与。这增强了算法的记忆能力和对环境变化的鲁棒性。\n\n\n\n6.6 群智能算法的基本思想是什么？\n\n模拟生物群体（如鸟群、蚁群、鱼群）的集体智能行为。群体中简单的个体（智能体）遵循相对简单的规则，并且个体之间以及个体与环境之间进行局部交互和信息共享，通过这些分散的、自组织的局部互动，在群体层面涌现出复杂的、高效的全局智能行为，从而解决复杂的优化或协同问题。\n\n6.7 群智能算法的主要特点是什么？\n\n分布式、自组织：无中心控制，依靠个体简单规则和局部交互。\n正反馈：好的解/路径能吸引更多个体（如蚁群的信息素增强）。\n负反馈：防止陷入局部最优（如信息素挥发）。\n鲁棒性强：个体简单，部分失效不影响群体功能。\n并行性强：个体可同时独立行动。\n通用性好：对目标函数要求低，适合黑箱优化。\n\n6.8 列举几种典型的群智能算法，分析它们的主要优点、缺点。\n\n粒子群优化算法：\n\n优点：原理简单，参数少，收敛速度快，易于实现。\n缺点：后期易陷入局部最优，对离散问题处理不便。\n\n\n蚁群优化算法：\n\n优点：正反馈强，适合路径优化等组合问题，鲁棒性好。\n缺点：初期信息素积累慢，收敛速度较慢，参数设置复杂。\n\n\n人工鱼群算法/狼群算法等：\n\n优点：模拟更复杂的生物行为，全局搜索能力可能更强。\n缺点：模型更复杂，计算开销大，理论分析较难。\n\n\n\n6.9 简述群智能算法与进化算法的异同。\n\n相同点：都是受自然启发的元启发式优化算法，属于群体智能范畴，用于复杂问题求解。\n不同点：\n灵感来源：进化算法源于生物进化（遗传、变异、选择）；群智能算法源于生物群体的社会行为（协作、竞争、信息共享）。\n核心操作：进化算法核心是基因操作（交叉、变异）；群智能算法核心是个体间信息交互与行为模仿（如跟随最优粒子、信息素跟踪）。\n“代”的概念：进化算法迭代代次明显；群智能算法中个体持续更新，代次界限模糊。\n\n\n\n6.10 简述粒子群算法的流程。\n\n初始化：随机初始化粒子的位置和速度，设定参数（惯性权重、加速常数等）。\n评估：计算每个粒子的适应度值。\n更新个体与群体历史最优：对每个粒子，将其当前位置与自身历史最优位置比较并更新；与群体历史最优位置比较并更新。\n更新速度与位置：根据公式更新每个粒子的速度和位置。\n\n速度更新公式：v_i(t+1) = w * v_i(t) + c1*r1*(pbest_i - x_i(t)) + c2*r2*(gbest - x_i(t))\n位置更新公式：x_i(t+1) = x_i(t) + v_i(t+1)\n\n\n终止判断：满足终止条件（如达到精度或最大迭代次数）则停止，输出全局最优解；否则返回步骤 2。\n\n\n6.11 简述粒子群算法位置更新方程中各部分的影响。\n\nv_i(t)(惯性部分)：代表粒子先前速度的继承，w为惯性权重，平衡全局与局部搜索能力。w大则探索能力强，w小则开发能力强。\nc1*r1*(pbest_i - x_i(t))(认知部分)：代表粒子向自身历史最优位置学习的趋势。c1为认知加速常数，控制个体经验的影响力。\nc2*r2*(gbest - x_i(t))(社会部分)：代表粒子向群体历史最优位置学习的趋势。c2为社会加速常数，控制社会信息的影响力。\nr1, r2：随机数，增加搜索的随机性。\n\n6.12 举例说明粒子群算法的搜索原理，并简要叙述粒子群算法有哪些特点。\n\n搜索原理举例：想象一群鸟在随机搜索一片区域的食物。每只鸟不知道食物在哪，但知道自己和同伴们曾找到的最近食物的位置。鸟通过不断调整自己的飞行方向和速度，既根据自己的经验向自己记忆中的最好位置飞，也向整个鸟群公认的最好位置飞，最终整个鸟群会聚集到食物最多的地方。\n特点：\n原理简单，易实现。\n参数少，收敛速度快。\n需调整参数少，但惯性权重w等对性能影响大。\n本质上是全局搜索，但后期易陷入局部最优。\n\n\n\n6.13 粒子群算法的寻优过程包含哪几个阶段？寻优的准则有哪些？\n\n阶段：\n探索阶段：初期，粒子在解空间广泛探索，寻找有希望的区域。\n开发阶段：后期，粒子集中在最有希望的区域进行精细搜索。\n\n\n寻优准则：\n收敛准则：如全局最优位置gbest在连续若干代内不再变化，或变化小于阈值。\n迭代次数：达到预设的最大迭代次数。\n精度准则：找到的解的适应度值达到预设目标。\n\n\n\n6.14 粒子群算法中的参数如何选择？\n\n惯性权重w：常采用线性递减策略，初期w较大（如 0.9）利于探索，后期w较小（如 0.4）利于开发。\n加速常数c1, c2：通常取c1 = c2 = 2左右。c1大可增强个体经验，c2大可增强社会学习。有研究建议c1从大到小，c2从小到大变化。\n种群规模：通常 20-50，复杂问题可增大。\n速度限制V_max：通常设定为变量范围的 10%-20%，防止搜索步长过大。\n\n6.15 举例说明蚁群算法的搜索原理，并简要叙述蚁群算法的特点。\n\n搜索原理举例：求解旅行商问题。蚂蚁随机选择路径，在路径上释放信息素。较短的路径因为蚂蚁往返更快，单位时间内信息素积累更多。后续蚂蚁倾向于选择信息素浓度更高的路径，从而进一步强化该路径。通过“信息素正反馈”和“挥发负反馈”（防止信息素无限累积），最终所有蚂蚁倾向于收敛到最短路径上。\n特点：\n正反馈机制，能快速发现较好解。\n分布式计算，易于并行。\n强启发性，与问题结合紧密。\n初期信息素匮乏，收敛速度慢。\n参数设置对性能影响显著。\n\n\n\n6.16 蚁群算法的寻优过程包含哪几个阶段？寻优的准则有哪些？\n\n阶段：\n初始化阶段：设定参数，初始化信息素。\n迭代构建阶段：每只蚂蚁根据路径上的信息素浓度和启发信息（如距离倒数），以一定概率构建完整路径。\n信息素更新阶段：所有蚂蚁走完后，根据路径质量（长度）更新信息素（增加优质路径信息素，同时所有路径信息素挥发）。\n\n\n寻优准则：同 PSO，包括最大迭代次数、最优解连续不变代数、达到期望精度等。\n\n6.17 蚁群算法中的参数如何选择？\n\n信息素重要性因子α：值越大，蚂蚁越倾向于选择信息素浓的路径，加速收敛但易早熟。\n启发信息重要性因子β：值越大，蚂蚁越倾向于选择看起来近的路径，贪心性越强。\n信息素挥发系数ρ：(0,1)之间。值小则信息素留存久，全局搜索能力强但收敛慢；值大则信息素挥发快，利于抛弃差解但可能丢失历史信息。\n信息素强度Q：影响信息素增量的绝对值，与问题规模相关。\n蚂蚁数量m：一般与问题节点数相当。太多则收敛慢，太少则正反馈不足。\n\n","categories":["归档"]},{"title":"2026-01-07-机器学习相关算法","url":"/Arknight-notes/posts/11390.html","content":"评估方法（留出法）import randomimport numpy as npdef train_test_split(X,test_size=0.2,random_state=5):    random.seed(random_state)    n_samples = len(X)    indices = np.arange(n_samples)    train_indexs = list(set(random.sample(indices.tolist(),int(n_samples*(1-test_size)))))    test_indexs = [k for k in indices if k not in train_indexs]    return X[train_indexs],X[test_indexs]test_size = 0.2X = np.array([1,2,3,4,5,6,7,8,9,10])train_X,test_X = train_test_split(X,test_size=test_size)print(train_X,test_X)print(\"debug_begin\");print(len(test_X) == int(len(X)*test_size))print(\"debug_end\");\n评估方法（交叉验证法）import numpy as npimport randomdef KFold(X,n_splits,is_shuffle=True,random_state=0):    random.seed(random_state)    n_samples = len(X)    indices = np.arange(n_samples)    train_index = []    test_index = []    result = []    fold_sizes = np.full(n_splits,n_samples//n_splits,dtype=np.int)    fold_sizes[:n_samples%n_splits] += 1    current = 0    for fold_size in fold_sizes:        start, stop = current, current+fold_size        test_index = indices[start:stop]        train_index = list(set(indices)-set(indices[start:stop]))        current = stop        result.append([X[train_index],X[test_index]])    return resultX = np.array([int(i) for i in input().strip().split()])n_splits = int(input())result = KFold(X,n_splits)for S,T in result:    print(S,T)print(\"debug_begin\");res = []for _,T in result:    res += list(T)if set(res)==set(list(X)) and len(X)==len(res):    print(True)else:    print(False)print(\"debug_end\");\n优化算法-梯度下降法 1import mathprint(\"debug_begin\");def func_1d_test1(x):    return x**2+1def grad_1d_test1(x):    return x*2def func_1d_test2(x):    return x**2 - 4*x +14def grad_1d_test2(x):    return x*2-4print(\"debug_end\");def gradient_descent_1d(grad, cur_x=0.1, learning_rate=0.01, precision=0.0001, max_iters=10000):    for i in range(max_iters):        grad_cur = grad(cur_x)        if abs(grad_cur) &lt; precision:            break  # 当梯度趋近为 0 时，视为收敛        cur_x = cur_x - grad_cur * learning_rate    return cur_xprint(\"debug_begin\");def test():    print(\"%.7f\" %gradient_descent_1d(grad_1d_test1, cur_x=10, learning_rate=0.2, precision=0.0001, max_iters=10000))    print(\"%.7f\" %gradient_descent_1d(grad_1d_test2, cur_x=10, learning_rate=0.2, precision=0.0001, max_iters=10000))print(\"debug_end\");test()\n优化算法-梯度下降法 2import mathimport numpy as npprint(\"debug_begin\");import numpy as npdef func_2d_test1(x):    return - math.exp(-(x[0] ** 2 + x[1] ** 2))def grad_2d_test1(x):    deriv0 = 2 * x[0] * math.exp(-(x[0] ** 2 + x[1] ** 2))    deriv1 = 2 * x[1] * math.exp(-(x[0] ** 2 + x[1] ** 2))    return np.array([deriv0, deriv1])def func_2d_test2(x):    return x[0]**2 + x[1]**2 +2*x[0]+1def grad_2d_test2(x):    deriv0 = 2*x[0]+2    deriv1 = 2*x[1]    return np.array([deriv0,deriv1])print(\"debug_end\");def gradient_descent_2d(grad, cur_x=np.array([0.1,0.1]), learning_rate=0.01, precision=0.0001, max_iters=10000):    for i in range(max_iters):        grad_cur = grad(cur_x)        if np.linalg.norm(grad_cur, ord=2) &lt; precision:            break  # 当梯度趋近为 0 时，视为收敛        cur_x = cur_x - grad_cur * learning_rate    return cur_xprint(\"debug_begin\");import numpy as npdef test():    res = gradient_descent_2d(grad_2d_test1, cur_x=np.array([1,-1]), learning_rate=0.2, precision=0.0001, max_iters=10000)    print(\"%.7f %.7f\" %(res[0],res[1]) )    res2 = gradient_descent_2d(grad_2d_test2, cur_x=np.array([2,2]), learning_rate=0.2, precision=0.0001, max_iters=10000)    print(\"%.7f %.7f\" %(res2[0],res2[1]) )print(\"debug_end\");test()\n线性回归-糖尿病预测import mathimport numpy as npimport randomimport  warningswarnings.filterwarnings(\"ignore\")def load_diabetes():    X = []    y = []    line = input()    while line:        dx = []        data = [l for l in line.strip().split(',')]        X.append(np.array([np.float(d) for d in data[:-1]]))        y.append(np.float(data[-1]))        line = input()    return np.array(X),np.array(y)def train_test_split(X,Y,test_size=0.2,random_state=2333):    random.seed(random_state)    n_samples = len(X)    indices = np.arange(n_samples)    train_indexs = list(set(random.sample(indices.tolist(),int(n_samples*(1-test_size)))))    test_indexs = [k for k in indices if k not in train_indexs]    return X[train_indexs],X[test_indexs],Y[train_indexs],Y[test_indexs]X,y = load_diabetes()import mathimport numpy as npimport randomimport  warningswarnings.filterwarnings(\"ignore\")def load_diabetes():    X = []    y = []    line = input()    while line:        dx = []        data = [l for l in line.strip().split(',')]        X.append(np.array([np.float(d) for d in data[:-1]]))        y.append(np.float(data[-1]))        line = input()    return np.array(X),np.array(y)def train_test_split(X,Y,test_size=0.2,random_state=2333):    random.seed(random_state)    n_samples = len(X)    indices = np.arange(n_samples)    train_indexs = list(set(random.sample(indices.tolist(),int(n_samples*(1-test_size)))))    test_indexs = [k for k in indices if k not in train_indexs]    return X[train_indexs],X[test_indexs],Y[train_indexs],Y[test_indexs]X,y = load_diabetes()class LinearRegression:  def __init__(self):    '''初始化模型'''    self.coef_ = None    self.interception_ = None    self._theta = None  def fit_normal(self,X_train,y_train):    '''根据训练数据集X_train,y_train训练模型'''    assert X_train.shape[0] == y_train.shape[0],'the number of X_train must equal to the number of y_train'    X_b = np.hstack([np.ones((len(X_train),1)),X_train])    self._theta = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y_train)    self.interception_ = self._theta[0]    self.coef_ = self._theta[1:]    return self  def predict(self,X_predict):    assert self._theta is not None,'must fit before predict'    assert X_predict.shape[1] == len(self.coef_),'the feature number of X_predict must equal to X_train '    X_b = np.hstack([np.ones((len(X_predict),1)),X_predict])    return X_b.dot(self._theta)  def mse(self,y,y_pre):    return np.average((y-y_pre)**2)  def rmse(self,y,y_pre):    return np.sqrt(self.mse(y,y_pre))  def r2_score(self,y,y_pre):    return 1-(self.mse(y,y_pre)/np.var(y))  def score(self,X_test,y_test):    '''根据测试数据集确定当前模型的准确度'''    y_predict = self.predict(X_test)    return self.r2_score(y_test,y_predict),self.rmse(y_test,y_predict)  def __repr__(self):    return 'LinearRegression()'x_train,x_test,y_train,y_test = train_test_split(X,y)reg = LinearRegression()reg.fit_normal(x_train,y_train)r2,rmse = reg.score(x_test,y_test)print(\"debug_begin\");def test(rmse,r2):    if rmse&gt;50 or r2&gt;0.5:        print(True)    else:        print(False)print(\"debug_end\");test(rmse,r2)print(\"debug_begin\");def test(rmse,r2):    if rmse&gt;50 or r2&gt;0.5:        print(True)    else:        print(False)print(\"debug_end\");test(rmse,r2)\n逻辑回归-乳腺癌预测import numpy as npimport randomimport warningswarnings.filterwarnings(\"ignore\")def load_breast_cancer():    X = []    y = []    line = input()    while line:        dx = []        data = [np.float64(l) for l in line.strip().split(',')]        X.append(np.array(data[:-1]))        y.append(int(data[-1]))        line = input()    return np.array(X),np.array(y)def train_test_split(X,Y,test_size=0.2,random_state=5):    n_samples = len(X)    indices = np.arange(n_samples)    train_indexs = list(set(random.sample(indices.tolist(),int(n_samples*(1-test_size)))))    test_indexs = [k for k in indices if k not in train_indexs]    return X[train_indexs],X[test_indexs],Y[train_indexs],Y[test_indexs]X,y = load_breast_cancer()x_train,x_test,y_train,y_test = train_test_split(X,y)class Logisticregression():    def __init__(self, learn_rate = 0.001, max_iteration=10000):        self.learn_rate = learn_rate        self.max_iteration = max_iteration        self._X_train = None        self._y_train = None        self._w = None    def fit(self, X_train, y_train):        m_samples, n_features = X_train.shape        self._X_train = np.insert(X_train, 0, 1, axis=1)        self._y_train = np.reshape(y_train, (m_samples, 1))        limit = np.sqrt(1 / n_features)        w = np.random.uniform(-limit, limit, (n_features, 1))        b = 0        self.w = np.insert(w, 0, b, axis=0)        iteration = 0        while iteration &lt; self.max_iteration:            h_x = self._X_train.dot(self.w)            y_pred = 1/(1+np.exp(- h_x))            w_grad = self._X_train.T.dot(y_pred - self._y_train)            self.w = self.w - self.learn_rate * w_grad            iteration = iteration + 1    def predict(self, X_test):        X_test = np.insert(X_test, 0, 1, axis=1)        h_x = X_test.dot(self.w)        y_pripr_1 = (1/(1+np.exp(-h_x)))        y_pripr_0 = 1 - y_pripr_1        y_cal = y_pripr_1 - y_pripr_0        y_class = np.where(y_cal &gt; 0, 1, 0)        return y_class    def score(self, X_test, y_test):        j = 0        y_test = np.reshape(y_test,(len(y_test),1))        y_hat = self.predict(X_test)        for i in range(y_test.shape[0]):            if y_hat[i,0] == y_test[i,0]:                j += 1        acc = j / len(y_test)        y_test = list(y_test.reshape((1,-1))[0])        y_hat = list(y_hat.reshape((1,-1))[0])        precision = self.get_precision(y_test,y_hat)        recall = self.get_recall(y_test,y_hat)        auc = self.get_auc(y_test,y_hat)        return acc,precision,recall,auc    def get_precision(self,y,y_hat):        true_positive = sum(yi and yi_hat for yi,yi_hat in zip(y,y_hat))        predicted_positive = sum(y_hat)        return true_positive/predicted_positive    def get_recall(self,y,y_hat):        true_positive = sum(yi and yi_hat for yi,yi_hat in zip(y,y_hat))        actual_positive = sum(y)        return true_positive/actual_positive    def get_tnr(self,y,y_hat):        true_negative = sum(1-(yi or yi_hat) for yi,yi_hat in zip(y,y_hat))        actual_negative = len(y) - sum(y)        return true_negative/actual_negative    def get_roc(self,y,y_hat):        thresholds = sorted(set(y_hat),reverse=True)        ret = [[0,0]]        for threshold in thresholds:            y_hat = [int(yi_hat &gt;= threshold) for yi_hat in y_hat]            ret.append([self.get_recall(y,y_hat),1-self.get_tnr(y,y_hat)])        return ret    def get_auc(self,y,y_hat):        roc = iter(self.get_roc(y,y_hat))        tpr_pre, fpr_pre = next(roc)        auc = 0        for tpr,fpr in roc:            auc += (tpr+tpr_pre)*(fpr-fpr_pre)/2            tpr_pre = tpr            fpr_pre = fpr        return auclr = Logisticregression()lr.fit(x_train,y_train)acc,precision,recall,auc = lr.score(x_test,y_test)print(\"debug_begin\");def test(acc,auc):    if acc&gt;0.8 or auc&gt;0.8:        print(True)    else:        print(False)print(\"debug_end\");test(acc,auc)\nsvm-手写数字识别import numpy as npimport  warningsimport randomwarnings.filterwarnings(\"ignore\")def load_digits():    X = []    y = []    line = input()    while line:        dx = []        data = [l for l in line.strip().split(',')]        X.append(np.array([np.float(d) for d in data[:-1]]))        y.append(np.int(data[-1]))        line = input()        if '#' in line:            break    return np.array(X),np.array(y)def train_test_split(X,Y,test_size=0.2,random_state=5):    n_samples = len(X)    assert len(X)==len(Y)    indices = np.arange(n_samples)    random.seed(random_state)    train_indexs = list(set(random.sample(indices.tolist(),int(n_samples*(1-test_size)))))    test_indexs = [k for k in indices if k not in train_indexs]    return X[train_indexs,:],X[test_indexs,:],Y[train_indexs],Y[test_indexs]X,y = load_digits()X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)class SVC():    def __init__(self,X,Y,alpha,steps,reg):        self.X = X        self.y = Y        self.alpha = alpha        self.steps = steps        self.reg = reg        self.model(self.X,self.y,self.alpha,self.steps,self.reg)    def lossAndGradNaive(self,X,Y,W,reg):        dW=np.zeros(W.shape)        loss = 0.0        num_class=W.shape[0]        num_X=X.shape[0]        for i in range(num_X):            scores=np.dot(W,X[i])            cur_scores=scores[int(Y[i])]            for j in range(num_class):                if j==Y[i]:                    continue                margin=scores[j]-cur_scores+1                if margin&gt;0:                    loss+=margin                    dW[j,:]+=X[i]                    dW[int(Y[i]),:]-=X[i]        loss/=num_X        dW/=num_X        loss+=reg*np.sum(W*W)        dW+=2*reg*W        return loss,dW    def lossAndGradVector(self,X,Y,W,reg):        dW=np.zeros(W.shape)        N=X.shape[0]        Y_=X.dot(W.T)        margin=Y_-Y_[range(N),Y.astype(int)].reshape([-1,1])+1.0        margin[range(N),Y.astype(int)]=0.0        margin=(margin&gt;0)*margin        loss=0.0        loss+=np.sum(margin)/N        loss+=reg*np.sum(W*W)        countsX=(margin&gt;0).astype(int)        countsX[range(N),Y.astype(int)]=-np.sum(countsX,axis=1)        dW+=np.dot(countsX.T,X)/N+2*reg*W        return loss,dW    def predict(self,X,W):        X=np.hstack([X, np.ones((X.shape[0], 1))])        Y_=np.dot(X,W.T)        Y_pre=np.argmax(Y_,axis=1)        return Y_pre    def accuracy(self,X,Y):        Y_pre=self.predict(X,self.W)        acc=(Y_pre==Y).mean()        return acc    def model(self,X,Y,alpha,steps,reg):        X=np.hstack([X, np.ones((X.shape[0], 1))])        W = np.random.randn(10,X.shape[1]) * 0.0001        for step in range(steps):            loss,grad=self.lossAndGradNaive(X,Y,W,reg)            W-=alpha*grad        self.W = Wsvc=SVC(X_train,y_train,0.01,25,0.5)acc = svc.accuracy(X_test,y_test)print(\"debug_begin\");def test_acc(acc):    res = True if acc&gt;0.85 else False    print(res)print(\"debug_end\");test_acc(acc)\nsvm-梯度下降实现 SVM 多分类问题import numpy as npimport warningsdef  load_iris():        X  =  []        y  =  []        line  =  input()        while  line:            dx  =  []            data  =  [l  for  l  in  line.strip().split(',')]            X.append(np.array([np.float(d)  for  d  in  data[:-1]]))            y.append(np.int(data[-1]))            line  =  input()            if '#' in line:                break        return  np.array(X),np.array(y)x,y = load_iris()print(\"debug_begin\");def test_acc(acc):        res = True if acc&gt;=0.9 else False        print(res)print(\"debug_end\");def normalize_data(data):    mean = np.mean(data, axis=0)    std = np.std(data, axis=0)    for i in range(data.shape[0]):        data[i, :] = (data[i, :] - mean) / std    return  datadef convert_to_one_hot(y, C):    return np.eye(C)[y.reshape(-1)]batchsz = 150def obtain_w_via_gradient_descent(x, c, y, penalty_c, threshold = 1e-19, learn_rate = 1e-4):    \"\"\" 利用梯度下降法求解如下的SVM问题：min 1/2 * w^T * w + C * Σ_i=1:n（max(0, 1 - y_i * (w^T * x_i + b))）    :param x: 训练样本 x = [x_1, x_2, ..., x_i]    :param c: 类别数    :param y: 样本标签 y = [y_1, y_2, ..., y_c]    :param threshold: 梯度下降停止阈值    \"\"\"    data_num = np.shape(x)[1]    feature_dim = np.shape(x)[0]    w = np.ones([feature_dim, c], dtype=np.float32)    b = np.ones([c, 1], dtype=np.float32)    dl_dw = np.zeros([feature_dim, c], dtype=np.float)    dl_db = np.zeros([c, 1], dtype=np.float)    it = 1    th = 0.1    while it &lt; 50000 and th &gt; threshold:        a = np.tile(b, [1, data_num])        ksi = (np.transpose(w) @ x + np.tile(b, [1, data_num])) * y        index_martix = ksi &lt; 1        for class_num in range(c):            index_vector = index_martix[class_num, :]            if True in index_vector:                x_c = x[:, index_vector]                data_num_c = np.shape(x_c)[1]                e = np.ones([data_num_c, 1], dtype=np.float)                y_c = np.reshape(y[class_num, index_vector], [data_num_c, 1])                w_c = np.reshape(w[:, class_num], [feature_dim, 1])                b_c = b[class_num]                dl_dw[:, class_num] = (w_c + 2 * penalty_c * (x_c @ np.transpose(x_c) @ w_c +                                                              x_c @ e * b_c -                                                              x_c @ y_c))[:, 0]                dl_db[class_num, 0] = 2 * penalty_c * (b_c * data_num_c +                                                       np.transpose(w_c) @ x_c @ e -                                                       np.transpose(y_c) @ e)            else:                w_c = np.reshape(w[:, class_num], [feature_dim, 1])                dl_dw[:, class_num] = w_c[:, 0]                dl_db[class_num, 0] = 0        w_ = w - learn_rate * (dl_dw / np.linalg.norm(dl_dw, ord=2))        b_ = b - learn_rate * dl_db        th = np.sum(np.square(w_ - w)) + np.sum(np.square(b_ - b))        it = it + 1        w = w_        b = b_        y_predict = np.transpose(w) @ x + np.tile(b, [1, data_num])        correct_prediction = np.equal(np.argmax(y_predict, 0), np.argmax(y, 0))        accuracy = np.mean(correct_prediction.astype(np.float))    return accuracywarnings.filterwarnings(\"ignore\")x = normalize_data(x)y = y.astype(np.int)y_onehot = convert_to_one_hot(y,3)y_onehot[y_onehot==0]=-1x = np.transpose(x)y_onehot = np.transpose(y_onehot)w = np.array([[1,1,1],[1,1,1]])b = np.array([[1],[1],[1]])acc = obtain_w_via_gradient_descent(x,3,y_onehot,0.5)test_acc(acc)\n","categories":["归档"]},{"title":"SITE-193","url":"/Arknight-notes/posts/4183.html","content":"\n\nZhongye\n\n来自湖北，南漂广州\n数据科学与大数据技术专业\n广州大学大三在读\n正在寻找前后端开发/数据分析相关实习，欢迎联系\n\n\n\n加入信工组，参与我们的校园信息化项目与学生技术社区建设！https://github.com/Guangzhou-University-SITE-193/ Open Source Organization from Guangzhou-University\n\n关注站长博客！本站： https://zhongye1.github.io/Arknight-notes/\n本站 RSS 订阅： https://zhongye1.github.io/Arknight-notes/rss.xml\n主站： https://zhongye1.github.io\n主站 RSS 订阅： https://zhongye1.github.io/atom.xml\n工作站： https://github.com/Guangzhou-University-SITE-193\nGitHub： https://github.com/Zhongye1\nQQ：2760913192\n关于本站用于做归档页面整理和知识储备，建设中\n","categories":["日志"],"tags":["日志"]},{"title":"2026-01-08-机器学习复习","url":"/Arknight-notes/posts/2418.html","content":"\n应付期末考试，整理了一些题目\n1. 以下哪些是机器学习中的数据预处理步骤?（）A. 数据清洗\nB. 数据归一化\nC. 特征选择\nD. 数据可视化\n答案: ABC\n2. 监督学习包括以下哪些类型?（）A. 分类\nB. 回归\nC. 聚类\nD. 降维\n答案: AB\n3. 以下哪些算法属于无监督学习?（）A. K-均值聚类\nB. 主成分分析(PCA)\nC. 关联规则挖掘\nD. 线性判别分析(LDA)\n答案: ABC\n4. 神经网络中的激活函数有哪些作用?（）A. 增加模型的非线性\nB. 防止梯度消失\nC. 对输入进行归一化\nD. 加快模型收敛速度\n答案: AB\n5. 影响机器学习模型性能的因素有（）A. 数据质量\nB. 算法选择\nC. 超参数设置\nD. 硬件性能\n答案: ABC\n6. 在构建决策树时，以下哪些可以作为分裂节点的选择标准?（）A. 信息增益\nB. 基尼指数\nC. 均方误差\nD. 准确率\n答案: AB\n7. 以下哪些技术可以用于处理过拟合问题?（）A. 增加数据量\nB. 正则化\nC. 早停法\nD. 降低模型复杂度\n答案: ABCD\n8. 以下关于交叉验证的说法正确的是（）A. 可以有效评估模型的泛化能力\nB. 常见的有 K-折交叉验证\nC. 能避免数据划分的随机性影响\nD. 只适用于小数据集\n答案: AB\n9. 以下哪些是深度学习中的优化算法?（）A. 随机梯度下降(SGD)\nB. Adagrad\nC. Adam\nD. 梯度提升(Gradient Boosting)\n答案: ABC\n10. 对于一个二分类问题，以下哪些指标可以全面评估模型性能?（）A. 准确率\nB. 召回率\nC. F1-分数\nD. 特异度\n答案: ABCD\n11. 以下属于机器学习中常用的特征工程方法的有（）A. 数据标准化\nB. 独热编码\nC. 特征缩放\nD. 交叉验证\n答案: ABC\n12. 下列关于支持向量机(SVM)的说法正确的是（）A. SVM 可以用于线性可分的数据分类\nB. SVM 可以通过核函数处理非线性分类问题\nC. SVM 的目标是找到一个最大间隔的超平面\nD. SVM 对异常值不敏感\n答案: ABC\n13. 以下哪些是无监督学习的应用场景?（）A. 客户细分\nB. 图像识别\nC. 异常检测\nD. 语音识别\n答案: AC\n14. 机器学习中常用的损失函数有（）A. 交叉熵损失函数\nB. 铰链损失函数\nC. 指数损失函数\nD. 对数损失函数\n答案: ABCD\n15. 以下属于深度学习框架的有（）A. TensorFlow\nB. PyTorch\nC. Scikit-learn\nD. Keras\n答案: ABD\n16. 以下属于监督学习任务的有（）A. 分类\nB. 聚类\nC. 回归\nD. 降维\n答案: AC\n17. 常用的数据预处理操作包括（）A. 数据清洗\nB. 特征工程\nC. 数据采样\nD. 模型评估\n答案: ABC\n18. 以下哪些是决策树的优点（）A. 易于理解和解释\nB. 对数据的准备要求低\nC. 抗过拟合能力强\nD. 能处理多分类问题\n答案: ABD\n19. 属于集成学习算法的有（）A. 决策树集成\nB. 随机森林\nC. AdaBoost\nD. K-Means\n答案: ABC\n20. 神经网络中常用的激活函数有（）A. sigmoid\nB. ReLU\nC. tanh\nD. Softmax\n答案: ABCD\n21. 评估分类模型的指标有（）A. 准确率\nB. 精确率\nC. 召回率\nD. F1 值\n答案: ABCD\n22. 以下哪些方法可以防止模型过拟合（）A. 增加数据量\nB. 正则化\nC. 减少特征数量\nD. 早停法\n答案: ABCD\n23. 线性回归模型的假设包括（）A. 自变量与因变量之间存在线性关系\nB. 误差项服从正态分布\nC. 误差项方差齐性\nD. 自变量之间不存在多重共线性\n答案: ABCD\n24. 支持向量机的核函数类型有（）A. 线性核\nB. 多项式核\nC. RBF 核\nD. 高斯核\n答案: ABCD\n25. 以下关于 K-Means 算法的描述正确的有（）A. 是无监督学习算法\nB. 需要预先指定聚类数 K\nC. 对初始聚类中心敏感\nD. 最终聚类结果唯一\n答案: ABC\n26. 下列哪些是机器学习的常见应用领域（）A. 图像识别\nB. 自然语言处理\nC. 推荐系统\nD. 数据加密\nE. 金融预测\n答案: ABCE\n27. 下列哪些是数据预处理的方法（）A. 缺失值处理\nB. 数据标准化\nC. 特征选择\nD. 数据分类\nE. 数据归一化\n答案: ABE\n28. 下列哪些是监督学习算法（）A. 线性回归\nB. 决策树\nC. 支持向量机\nD. K 均值聚类\nE. 逻辑回归\n答案: ABCE\n29. 下列哪些是评估模型性能的指标（）A. 准确率\nB. 精确率\nC. 召回率\nD. F1 分数\nE. 相关系数\n答案: ABCD\n30. 下列哪些是特征工程的常用方法（）A. 特征缩放\nB. 特征编码\nC. 特征选择\nD. 特征组合\nE. 数据标准化\n答案: ABCD\n31. 下列哪些是集成学习算法（）A. 决策树集成\nB. 随机森林\nC. AdaBoost\nD. bagging\nE. 支持向量机\n答案: ABCD\n32. 下列哪些是过拟合的解决方法（）A. 增加数据量\nB. 正则化\nC. 减少模型复杂度\nD. 增加模型参数\nE. 交叉验证\n答案: ABCE\n33. 下列哪些是降维方法（）A. 主成分分析\nB. 因子分析\nC. 线性判别分析\nD. K 均值聚类\nE. 基于矩阵分解的方法\n答案: ABCE\n34. 下列哪些是数据挖掘的步骤（）A. 数据收集\nB. 数据预处理\nC. 模型训练\nD. 模型评估\nE. 数据可视化\n答案: ABCDE\n35. 下列哪些是特征选择的方法（）A. 单变量特征选择\nB. 基于模型的特征选择\nC. 递归特征消除\nD. 岭回归\nE. Lasso 回归\n答案: ABCE\n36. 下列哪些是常用的特征工程方法（）A. 特征缩放\nB. 特征编码\nC. 特征选择\nD. 特征组合\nE. 数据归一化\n答案: ABCDE\n37. 下列哪些是评估分类模型性能的指标（）A. 准确率\nB. 精确率\nC. 召回率\nD. F1 分数\nE. 相关系数\n答案: ABCD\n38. 下列哪些是集成学习算法（）A. 决策树集成\nB. 随机森林\nC. AdaBoost\nD. bagging\nE. 支持向量机\n答案: ABCD\n39. 下列哪些是过拟合的解决方法（）A. 增加数据量\nB. 正则化\nC. 减少模型复杂度\nD. 增加模型参数\nE. 交叉验证\n答案: ABCE\n40. 下列哪些是降维方法（）A. 主成分分析\nB. 因子分析\nC. 线性判别分析\nD. K 均值聚类\nE. 基于矩阵分解的方法\n答案: ABCE\n41. 下列哪些是监督学习算法（）A. 线性回归\nB. 决策树\nC. 支持向量机\nD. K 均值聚类\nE. 逻辑回归\n答案: ABCE\n42. 下列哪些是数据预处理的方法（）A. 缺失值处理\nB. 数据标准化\nC. 特征选择\nD. 数据分类\nE. 数据归一化\n答案: ABE\n43. 下列哪些是特征选择的方法（）A. 单变量特征选择\nB. 基于模型的特征选择\nC. 递归特征消除\nD. 岭回归\nE. Lasso 回归\n答案: ABCE\n44. 下列哪些是数据挖掘的步骤（）A. 数据收集\nB. 数据预处理\nC. 模型训练\nD. 模型评估\nE. 数据可视化\n答案: ABCDE\n45. 下列哪些是常用的交叉验证方法（）A. 留出法\nB. K 折交叉验证\nC. 移动窗口交叉验证\nD. 留一法\nE. 分层交叉验证\n答案: ABCDE\n46. 以下属于监督学习任务的有:（）A. 图像分类\nB. 语音识别\nC. 聚类分析\nD. 回归分析\n答案: ABD\n47. 以下哪些方法可以用于降低过拟合风险?（）A. 增加训练数据\nB. 正则化\nC. 早停法\nD. 减少特征数量\n答案: ABCD\n48. 以下关于支持向量机(SVM)的说法，正确的有:（）A. SVM 可以处理线性可分和线性不可分的数据\nB. 核函数是 SVM 处理线性不可分数据的关键\nC. SVM 的目标是找到一个最大间隔超平面\nD. SVM 对异常值不敏感\n答案: ABC\n49. 以下属于无监督学习算法的有:（）A. 主成分分析(PCA)\nB. 高斯混合模型(GMM)\nC. 决策树\nD. 自编码器\n答案: ABD\n50. 以下哪些是评估分类模型性能的指标?（）A. 准确率\nB. 召回率\nC. F1 值\nD. 均方误差\n答案: ABC\n51. 以下关于随机森林的说法，正确的有:（）A. 随机森林是由多个决策树组成的集成模型\nB. 随机森林可以并行训练多个决策树\nC. 随机森林对缺失值和异常值不敏感\nD. 随机森林只能用于分类问题\n答案: ABC\n52. 以下哪些方法可以用于数据降维?（）A. 主成分分析(PCA)\nB. 线性判别分析(LDA)\nC. 特征选择\nD. 奇异值分解(SVD)\n答案: ABCD\n53. 以下关于 K 近邻算法的说法，正确的有:（）A. K 值越小，模型越容易过拟合\nB. K 值越大，模型越容易欠拟合\nC. 该算法的时间复杂度较高\nD. 该算法对数据的尺度比较敏感\n答案: ABCD\n54. 以下关于集成学习的方法，正确的有:（）A. Bagging 方法通过自助采样得到多个训练集，训练多个弱学习器\nB. Boosting 方法通过迭代训练多个弱学习器，每个弱学习器关注前一个弱学习器的错误样本\nC. Stacking 方法将多个弱学习器的输出作为新的特征，再训练一个元学习器\nD. 集成学习一定能提高模型的性能\n答案: ABC\n55. 以下关于深度学习的说法，正确的有:（）A. 深度学习通常使用大规模的数据集进行训练\nB. 深度学习模型通常具有很多层\nC. 深度学习可以自动学习数据中的特征\nD. 深度学习只适用于图像和语音领域\n答案: ABC\n56. 以下哪些是逻辑回归的特点?（）A. 用于分类问题\nB. 输出是概率值\nC. 可以处理多分类问题\nD. 模型具有线性决策边界\n答案: ABCD\n57. 以下关于聚类算法的说法，正确的有:（）A. K 均值聚类是基于距离的聚类算法\nB. DBSCAN 是基于密度的聚类算法\nC. 层次聚类可以构建聚类的层次结构\nD. 高斯混合模型聚类是基于概率模型的聚类方法\n答案: ABCD\n58. 以下哪些方法可以用于处理类别不平衡问题?（）A. 过采样\nB. 欠采样\nC. 调整分类阈值\nD. 使用代价敏感学习\n答案: ABCD\n59. 以下关于梯度下降法的说法，正确的有:（）A. 批量梯度下降(BGD)使用所有训练样本进行参数更新\nB. 随机梯度下降(SGD)每次只使用一个训练样本进行参数更新\nC. 小批量梯度下降(MBGD)使用一部分训练样本进行参数更新\nD. 梯度下降法的目标是最小化损失函数\n答案: ABCD\n60. 下列哪些是机器学习的常见应用领域（）A. 图像识别\nB. 自然语言处理\nC. 推荐系统\nD. 数据加密\nE. 金融预测\n答案: ABCE\n61. 下列哪些是数据预处理的方法（）A. 缺失值处理\nB. 数据标准化\nC. 特征选择\nD. 数据分类\nE. 数据归一化\n答案: ABE\n62. 下列哪些是监督学习算法（）A. 线性回归\nB. 决策树\nC. 支持向量机\nD. K 均值聚类\nE. 逻辑回归\n答案: ABCE\n63. 下列哪些是评估模型性能的指标（）A. 准确率\nB. 精确率\nC. 召回率\nD. F1 分数\nE. 相关系数\n答案: ABCD\n64. 下列哪些是特征工程的常用方法（）A. 特征缩放\nB. 特征编码\nC. 特征选择\nD. 特征组合\nE. 数据标准化\n答案: ABCD\n65. 下列哪些是集成学习算法（）A. 决策树集成\nB. 随机森林\nC. AdaBoost\nD. bagging\nE. 支持向量机\n答案: ABCD\n66. 下列哪些是过拟合的解决方法（）A. 增加数据量\nB. 正则化\nC. 减少模型复杂度\nD. 增加模型参数\nE. 交叉验证\n答案: ABCE\n67. 下列哪些是降维方法（）A. 主成分分析\nB. 因子分析\nC. 线性判别分析\nD. K 均值聚类\nE. 基于矩阵分解的方法\n答案: ABCE\n68. 下列哪些是数据挖掘的步骤（）A. 数据收集\nB. 数据预处理\nC. 模型训练\nD. 模型评估\nE. 数据可视化\n答案: ABCDE\n69. 下列哪些是特征选择的方法（）A. 单变量特征选择\nB. 基于模型的特征选择\nC. 递归特征消除\nD. 岭回归\nE. Lasso 回归\n答案: ABCE\n70. 下列哪些是常用的特征工程方法（）A. 特征缩放\nB. 特征编码\nC. 特征选择\nD. 特征组合\nE. 数据归一化\n答案: ABCDE\n71. 下列哪些是评估分类模型性能的指标（）A. 准确率\nB. 精确率\nC. 召回率\nD. F1 分数\nE. 相关系数\n答案: ABCD\n72. 下列哪些是集成学习算法（）A. 决策树集成\nB. 随机森林\nC. AdaBoost\nD. bagging\nE. 支持向量机\n答案: ABCD\n73. 下列哪些是过拟合的解决方法（）A. 增加数据量\nB. 正则化\nC. 减少模型复杂度\nD. 增加模型参数\nE. 交叉验证\n答案: ABCE\n74. 下列哪些是降维方法（）A. 主成分分析\nB. 因子分析\nC. 线性判别分析\nD. K 均值聚类\nE. 基于矩阵分解的方法\n答案: ABCE\n75. 下列哪些是监督学习算法（）A. 线性回归\nB. 决策树\nC. 支持向量机\nD. K 均值聚类\nE. 逻辑回归\n答案: ABCE\n76. 下列哪些是数据预处理的方法（）A. 缺失值处理\nB. 数据标准化\nC. 特征选择\nD. 数据分类\nE. 数据归一化\n答案: ABE\n77. 下列哪些是特征选择的方法（）A. 单变量特征选择\nB. 基于模型的特征选择\nC. 递归特征消除\nD. 岭回归\nE. Lasso 回归\n答案: ABCE\n78. 下列哪些是数据挖掘的步骤（）A. 数据收集\nB. 数据预处理\nC. 模型训练\nD. 模型评估\nE. 数据可视化\n答案: ABCDE\n79. 下列哪些是常用的交叉验证方法（）A. 留出法\nB. K 折交叉验证\nC. 移动窗口交叉验证\nD. 留一法\nE. 分层交叉验证\n答案: ABCDE\n80. 以下属于监督学习任务的有:（）A. 图像分类\nB. 语音识别\nC. 聚类分析\nD. 回归分析\n答案: ABD\n81. 以下哪些方法可以用于降低过拟合风险?（）A. 增加训练数据\nB. 正则化\nC. 早停法\nD. 减少特征数量\n答案: ABCD\n82. 以下关于支持向量机(SVM)的说法，正确的有:（）A. SVM 可以处理线性可分和线性不可分的数据\nB. 核函数是 SVM 处理线性不可分数据的关键\nC. SVM 的目标是找到一个最大间隔超平面\nD. SVM 对异常值不敏感\n答案: ABC\n83. 以下属于无监督学习算法的有:（）A. 主成分分析(PCA)\nB. 高斯混合模型(GMM)\nC. 决策树\nD. 自编码器\n答案: ABD\n84. 以下哪些是评估分类模型性能的指标?（）A. 准确率\nB. 召回率\nC. F1 值\nD. 均方误差\n答案: ABC\n85. 以下关于随机森林的说法，正确的有:（）A. 随机森林是由多个决策树组成的集成模型\nB. 随机森林可以并行训练多个决策树\nC. 随机森林对缺失值和异常值不敏感\nD. 随机森林只能用于分类问题\n答案: ABC\n86. 以下哪些方法可以用于数据降维?（）A. 主成分分析(PCA)\nB. 线性判别分析(LDA)\nC. 特征选择\nD. 奇异值分解(SVD)\n答案: ABCD\n87. 以下关于 K 近邻算法的说法，正确的有:（）A. K 值越小，模型越容易过拟合\nB. K 值越大，模型越容易欠拟合\nC. 该算法的时间复杂度较高\nD. 该算法对数据的尺度比较敏感\n答案: ABCD\n88. 以下关于集成学习的方法，正确的有:（）A. Bagging 方法通过自助采样得到多个训练集，训练多个弱学习器\nB. Boosting 方法通过迭代训练多个弱学习器，每个弱学习器关注前一个弱学习器的错误样本\nC. Stacking 方法将多个弱学习器的输出作为新的特征，再训练一个元学习器\nD. 集成学习一定能提高模型的性能\n答案: ABC\n89. 以下关于深度学习的说法，正确的有:（）A. 深度学习通常使用大规模的数据集进行训练\nB. 深度学习模型通常具有很多层\nC. 深度学习可以自动学习数据中的特征\nD. 深度学习只适用于图像和语音领域\n答案: ABC\n90. 以下哪些是逻辑回归的特点?（）A. 用于分类问题\nB. 输出是概率值\nC. 可以处理多分类问题\nD. 模型具有线性决策边界\n答案: ABCD\n91. 以下关于聚类算法的说法，正确的有:（）A. K 均值聚类是基于距离的聚类算法\nB. DBSCAN 是基于密度的聚类算法\nC. 层次聚类可以构建聚类的层次结构\nD. 高斯混合模型聚类是基于概率模型的聚类方法\n答案: ABCD\n92. 以下哪些方法可以用于处理类别不平衡问题?（）A. 过采样\nB. 欠采样\nC. 调整分类阈值\nD. 使用代价敏感学习\n答案: ABCD\n141、SVM 算法的性能取决于（ ）。\nA. 核函数的选择\nB. 核函数的参数\nC. 软间隔参数\nD. 以上所有\n正确答案：D\n142、SVM 中的代价参数 C 表示什么？（ ）\nA. 在分类准确性和模型复杂度之间的权衡\nB. 交叉验证的次数\nC. 以上都不对\nD. 用到的核函数\n正确答案：A\n143、下列有关支持向量机说法不正确的是（ ）。\nA. 得到的是局部最优解\nB. 具有很好的推广能力\nC. 是凸二次优化问题\nD. 采用结构风险最小化原理\n正确答案：A\n144、下列有关核函数不正确的是（ ）。\nA. 可以采用 cross-validation 方法选择最佳核函数\nB. 满足 Mercer 条件的函数不一定能作为支持向量机的核函数\nC. 极大地提高了学习机器的非线性处理能力\nD. 函数与非线性映射并不是一一对应的关系\n正确答案：B\n145、一对一法分类器，k 个类别需要多少个 SVM（ ）。\nA. k(k-1)/2\nB. k(k-1)\nC. k\nD. k!\n正确答案：A\n146、有关聚类分析说法错误的是（ ）。\nA. 无须有标记的样本\nB. 可以用于提取一些基本特征\nC. 可以解释观察数据的一些内部结构和规律\nD. 聚类分析一个簇中的数据之间具有高差异性\n正确答案：D\n147、两个 n 维向量 𝛼(𝑥11, 𝑥12, ⋯ , 𝑥1𝑛) 和 𝛽(𝑥21, 𝑥22, ⋯ , 𝑥2𝑛)之间的欧式距离（euclidean distance)为（ ）。\nA. 𝑑12 = √(𝛼 − 𝛽)(𝛼 − 𝛽)^𝑇\nB. 𝑑12 = ∑ |𝑥1𝑘 − 𝑥2𝑘|\nC. 𝑑12 = max(|𝑥1𝑖 − 𝑥2𝑖|)\nD. cos(𝜃) = (𝛼 ∙ 𝛽)/(|𝛼||𝛽|)\n正确答案：A\n148、闵可夫斯基距离表示为曼哈顿距离时 p 为（ ）。\nA. 1\nB. 2\nC. 3\nD. 4\n正确答案：A\n149、关于 K-means 说法不正确的是（ ）。\nA. 算法可能终止于局部最优解\nB. 簇的数目 k 必须事先给定\nC. 对噪声和离群点数据敏感\nD. 适合发现非凸形状的簇\n正确答案：D\n150、k 中心点算法每次迭代的计算复杂度是多少？（ ）\nA. 𝑂(1)\nB. 𝑂(𝑘)\nC. 𝑂(𝑛𝑘)\nD. 𝑂(𝑘(𝑛 − 𝑘)^2)\n正确答案：D\n概率与贝叶斯相关题目151、假设某事件发生的概率为 p，则此事件发生的几率为（ ）。\nA. p\nB. 1-p\nC. p/(1-p)\nD. (1-p)/p\n正确答案：C\n152、贝叶斯网络起源于贝叶斯统计学，是以（ ）为基础的有向图模型，它为处理不确定知识提供了有效的方法。\nA. 线性代数\nB. 逻辑学\nC. 概率论\nD. 信息论\n正确答案：C\n164. 在机器学习中，交叉验证的目的是：\nA. 减少训练时间\nB. 增加模型复杂度\nC. 减少过拟合\nD. 增加模型的泛化能力\n答案：C\n165. 以下关于 K 近邻算法的说法，错误的是：\nA. K 值的选择对算法性能影响很大\nB. 算法的计算复杂度主要取决于特征维度\nC. 该算法不需要进行显式的训练过程\nD. 算法的预测结果可能会受到样本分布的影响\n答案：B\n解析： K 近邻算法的计算复杂度主要取决于样本数量，而不是特征维度。K 值的选择会影响算法的性能，K 值过小容易过拟合，K 值过大容易欠拟合；该算法不需要进行显式的训练，直接利用训练数据进行预测；样本分布也会影响预测结果。\n166. 决策树中，信息增益是通过以下哪种方式计算的？\nA. 父节点的信息熵减去子节点的信息熵\nB. 子节点的信息熵减去父节点的信息熵\nC. 父节点的信息熵减去各子节点信息熵的加权和\nD. 各子节点信息熵的加权和减去父节点的信息熵\n答案：C\n解析： 信息增益的计算公式为父节点的信息熵减去各子节点信息熵的加权和，用于衡量划分前后信息的减少程度，信息增益越大，划分越有效。\n167. 支持向量机（SVM）的目标是：\nA. 最大化分类间隔\nB. 最小化分类间隔\nC. 最大化训练误差\nD. 最小化特征维度\n答案：A\n解析： 支持向量机的目标是在特征空间中找到一个最优的超平面，使得不同类别的样本之间的分类间隔最大，这样可以提高模型的泛化能力。\n168. 以下哪种聚类算法是基于密度的聚类算法？\nA. K 均值聚类\nB. 层次聚类\nC. DBSCAN\nD. 高斯混合模型聚类\n答案：C\n解析： DBSCAN 是基于密度的聚类算法，它通过寻找数据点的密度相连区域来进行聚类。K 均值聚类是基于距离的聚类算法，通过迭代更新聚类中心；层次聚类是通过构建层次结构进行聚类；高斯混合模型聚类是基于概率模型的聚类方法。\n229、SVM 的原理的简单描述，可概括为：\nA. 最小均方误差分类\nB. 最小距离分类\nC. 最大间隔分类\nD. 最近邻分类\n答案：C\n230、SVM 的算法性能取决于：\nA. 核函数的选择\nB. 核函数的参数\nC. 软间隔参数 C\nD. 以上所有\n答案：D\n231、支持向量机的对偶问题是：\nA. 线性优化问题\nB. 二次优化\nC. 凸二次优化\nD. 有约束的线性优化\n答案：C\n232、以下对支持向量机中的支撑向量描述正确的是：\nA. 最大特征向量\nB. 最优投影向量\nC. 最大间隔支撑面上的向量\nD. 最速下降方向\n答案：C\n233、假定你使用阶数为 2 的线性核 SVM，将模型应用到实际数据集上后，其训练准确率和测试准确率均为 100%。现在增加模型复杂度（增加核函数的阶），会发生以下哪种情况：\nA. 过拟合\nB. 欠拟合\nC. 什么都不会发生，因为模型准确率已经到达极限\nD. 以上都不对\n答案：A\n234、避免直接的复杂非线性变换，采用线性手段实现非线性学习的方法是：\nA. 核函数方法\nB. 集成学习\nC. 决策树\nD. Logistic 回归\n答案：A\n235、关于决策树节点划分指标描述正确的是：\nA. 类别非纯度越大越好\nB. 信息增益越大越好\nC. 信息增益率越小越好\nD. 基尼指数越大越好\n答案：B\n236、以下描述中，属于决策树策略的是：\nA. 最优投影方向\nB. 梯度下降方法\nC. 最大特征值\nD. 最大信息增益\n答案：D\n237、集成学习中基分类器的选择如何，学习效率通常越好：\nA. 分类器相似\nB. 都为线性分类器\nC. 都为非线性分类器\nD. 分类器多样，差异大\n答案：D\n238、集成学习中，每个基分类器的正确率的最低要求：\nA. 50% 以上\nB. 60% 以上\nC. 70% 以上\nD. 80% 以上\n答案：A\n239、下面属于 Bagging 方法的特点是：\nA. 构造训练集时采用 Bootstraping 的方式\nB. 每一轮训练时样本权重不同\nC. 分类器必须按顺序训练\nD. 预测结果时，分类器的比重不同\n答案：A\n240、下面属于 Boosting 方法的特点是：\nA. 构造训练集时采用 Bootstraping 的方式\nB. 每一轮训练时样本权重相同\nC. 分类器可以并行训练\nD. 预测结果时，分类器的比重不同\n答案：D\n241、随机森林方法属于：\nA. 梯度下降优化\nB. Bagging 方法\nC. Boosting 方法\nD. 线性分类\n答案：B\n242、假定有一个数据集 S，但该数据集有很多误差，采用软间隔 SVM 训练，阈值为 C，如果 C 的值很小，以下那种说法正确：\nA. 会发生误分类现象\nB. 数据将被正确分类\nC. 不确定\nD. 以上都不对\n答案：A\n243、软间隔 SVM 的阈值趋于无穷，下面哪种说法正确：\nA. 只要最佳分类超平面存在，它就能将所有数据全部正确分类\nB. 软间隔 SVM 分类器将正确分类数据\nC. 会发生误分类现象\nD. 以上都不对\n答案：A\n244、一般，K-NN 最近邻方法在什么情况下效果好：\nA. 样本较多但典型性不好\nB. 样本较少但典型性较好\nC. 样本呈团状分布\nD. 样本呈链状分布\n答案：B\n注： 最近邻属于分类算法，样本多而且典型性不好容易造成分类错误（尤其是在分类边界上的样本点）。样本分布对聚类算法的影响较大。\n245、混合高斯聚类中，运用了以下哪种过程：\nA. EM 算法\nB. 集合运算\nC. 密度可达\nD. 样本与集合运算\n答案：A\n246、主成分分析方法是一种什么方法：\nA. 分类方法\nB. 回归方法\nC. 降维方法\nD. 参数估计方法\n答案：C\n247、过拟合现象中：\nA. 训练样本的测试误差最小，测试样本的正确识别率却很低\nB. 训练样本的测试误差最小，测试样本的正确识别率也很高\nC. 模型的泛化能力很高\nD. 通常为线性模型\n答案：A\n248、已知均值和方差，下面哪种分布的熵最大：\nA. 几何分布\nB. 指数分布\nC. 高斯分布\nD. 均匀分布\n答案：C\n249、梯度下降算法的正确步骤是什么：\n(1)计算预测值和真实值之间的误差\n(2)迭代更新，直到找到最佳权重\n(3)把输入传入网络，得到输出值\n(4)初始化随机权重和偏差\n(5)对每一个产生误差的神经元，改变相应的（权重）值以减小误差\nA. 1,2,3,4,5\nB. 4,3,1,5,2\nC. 3,2,1,5,4\nD. 5,4,3,2,1\n答案：B\n250、以下哪种方法会增加模型的欠拟合风险：\nA. 添加新特征\nB. 增加模型复杂度\nC. 减小正则化系数\nD. 数据增强\n答案：D\n251、关于 k-means 算法，正确的描述是：\nA. 能找到任意形状的聚类\nB. 初始值不同，最终结果可能不同\nC. 每次迭代的时间复杂度是 O(n^2)，其中 n 是样本数量\nD. 不能使用核函数\n答案：B\n252、下列关于过拟合现象的描述中，哪个是正确的：\nA. 训练误差小，测试误差大\nB. 训练误差小，测试误差小\nC. 模型的泛化能力高\nD. 其余选项都不对\n答案：A\n253、下方法中属于无监督学习算法的是：\nA. 线性回归\nB. 支持向量机\nC. 决策树\nD. K-Means 聚类\n答案：D\n254、下面关于贝叶斯分类器描述错误的是：\nA. 以贝叶斯定理为基础\nB. 是基于后验概率，推导出先验概率\nC. 可以解决有监督学习的问题\nD. 可以用极大似然估计法解贝叶斯分类器\n答案：B\n255、下面关于 Adaboost 算法的描述中，错误的是：\nA. 是弱分类器的线性组合\nB. 提升树是以分类树或者回归树为基本分类器的提升办法\nC. 该算法实际上是前向分步算法的一个实现，在这个方法里，模型是加法模型，损失函数是指数损失，算法是前向分步算法。\nD. 同时独立地学习多个弱分类器\n答案：D\n256、二分类任务中，有三个分类器 h1, h2, h3，三个测试样本 x1, x2, x3。假设 1 表示分类结果正确，0 表示错误，h1 在 x1, x2, x3 的结果分别 (1,1,0)，h2, h3 分别为 (0,1,1), (1,0,1)，按投票法集成三个分类器，下列说法正确的是：\nA. 集成提高了性能\nB. 集成没有效果\nC. 集成降低了性能\nD. 集成效果不能确定\n答案：A\n257、下列哪个不属于常用的文本分类的特征选择算法：\nA. 卡方检验值\nB. 互信息\nC. 信息增益\nD. 主成分分析\n答案：D\n258、以下哪个模型不是分类模型：\nA. 最近邻\nB. K 均值\nC. 朴素贝叶斯\nD. 逻辑回归\n答案：B\n262、机器学习进行的第一步是（）\nA. 数据收集\nB. 特征提取\nC. 交叉验证\nD. 模型训练\n正确答案：A\n解析：机器学习流程的第一步是数据收集，因为所有后续步骤（如特征提取、模型训练）都依赖于数据。没有数据，机器学习无法进行。特征提取是数据预处理的一部分，属于后续步骤。\n264、如果一个样本空间线性可分，那么，我们能找到（）个平面来划分样本。\nA. 1\nB. 无数\nC. K\nD. 不确定\n正确答案：B\n解析：线性可分时，存在无数个分离超平面。只要超平面不越过样本点，稍微平移或旋转仍能保持分类正确。\n265、向量 x=[1,2,3,4,-9,0]的 L1 范数是多少\nA. 1\nB. 19\nC. 6\nD. 20\n正确答案：B\n解析：L1 范数是各元素绝对值之和：\n\\|x\\|_1=|1|+|2|+|3|+|4|+|-9|+|0|=19266、向量 X=[1,2,3,4,-9,0] 的 L2 范数为（ ）\nA. 1\nB. 19\nC. 6\nD. √111\n正确答案：D\n解析：L2 范数是各元素平方和的平方根：\n\\|x\\|_2=\\sqrt{1^2+2^2+3^2+4^2+(-9)^2+0^2}=\\sqrt{111}267、一般，k-NN 最近邻方法在（ ）的情况下效果较好\nA. 样本较多但典型性不好\nB. 样本较少但典型性好\nC. 样本呈团状分布\nD. 样本呈链状分布\n正确答案：B\n解析：KNN 依赖局部相似性，样本少但典型性好时，最近邻投票更可靠。团状分布是理想假设，但”少而典型”是更根本的前提。\n268、以下哪些方法不可以直接来对文本分类？\nA. K-Means\nB. 决策树\nC. 支持向量机\nD. kNN\n正确答案：A\n解析：K-Means 是无监督聚类算法，不依赖标签，无法直接用于分类。其他选项均为有监督分类算法。\n269、以下说法错误的一项是\nA. 负梯度方向是使函数值下降最快的方向\nB. 当目标函数是凸函数时，梯度下降法的解是全局最优解\nC. 梯度下降法比牛顿法收敛速度快\nD. 拟牛顿法不需要计算 Hesse 矩阵\n正确答案：C\n解析：牛顿法（二阶）在最优解附近收敛速度（二次）快于梯度下降法（线性）。C 选项表述错误。\n270、下列说法错误的是？\nA. 当目标函数是凸函数时，梯度下降算法的解一般就是全局最优解\nB. 进行 PCA 降维时，需要计算协方差矩阵\nC. 沿负梯度的方向一定是最优的方向\nD. 利用拉格朗日函数能解带约束的优化问题\n正确答案：C\n解析：负梯度方向是局部下降最快方向，但非全局最优（可能产生锯齿现象）。其他选项正确。\n271、交叉验证方法执行时间排序（样本量 1000）\nA. 1 &gt; 2 &gt; 3 &gt; 4\nB. 2 &gt; 3 &gt; 4 &gt; 1\nC. 4 &gt; 1 &gt; 2 &gt; 3\nD. 2 &gt; 4 &gt; 3 &gt; 1\n正确答案：D\n解析：时间开销：\n\n留一法（1000 次训练）最慢（2）\n重复两次 5 折（10 次训练）次慢（4）\n5 折（5 次训练）较快（3）\nBootstrap（1 次训练）最快（1）排序：2 &gt; 4 &gt; 3 &gt; 1\n\n273、下面哪句话是正确\nA. 机器学习模型的精准度越高，则模型的性能越好\nB. 增加模型的复杂度，总能减小测试样本误差\nC. 增加模型的复杂度，总能减小训练样本误差\nD. 以上说法都不对\n正确答案：C\n解析：增加复杂度会提升模型拟合能力，训练误差通常减小（可能过拟合）。A 错（需综合评估），B 错（测试误差可能增大）。\n274、集成学习中，下列说法正确的是？\nA. 基本模型之间相关性高\nB. 基本模型之间相关性低\nC. 集成方法中，使用加权平均代替投票方法\nD. 基本模型都来自于同一算法\n正确答案：B\n解析：集成学习要求基模型”好而不同”，低相关性使错误相互纠正，提升泛化能力。\n275、SVM 训练后只保留支持向量是否影响分类能力？\nA. 正确\nB. 错误\n正确答案：A\n解析：支持向量决定了分离超平面，非支持向量不影响模型，这是 SVM 的稀疏性。\n276、Soft-SVM 中如何保证线性可分？\nA. C = 0\nB. C = 1\nC. C 正无穷大\nD. C 负无穷大\n正确答案：C\n解析：C 趋于无穷大时，对分类错误的惩罚无限大，迫使所有样本分类正确（退化为硬间隔）。\n278、点击率预测（99%负样本）中，正确率 99%说明？\nA. 模型正确率很高，不需要优化模型了\nB. 模型正确率并不高，应该建立更好的模型\nC. 无法对模型做出好坏评价\nD. 以上说法都不对\n正确答案：B\n解析：极端不平衡时，将所有样本预测为负类即可达到 99%准确率，模型未学到区分能力，需优化。\n279、关于 k 折交叉验证，下列说法正确的是？\nA. k 值并不是越大越好，k 值过大，会降低运算速度\nB. 选择更大的 k 值，会让偏差更小，因为 k 值越大，训练集越接近整个训练样本\nC. 选择合适的 k 值，能减小验证方差\nD. 以上说法都正确\n正确答案：D\n解析：A、B、C 均正确：k 过大计算开销大；k 大时训练集接近全集，偏差小；合适 k 可平衡偏差-方差。\n289、EM 算法的核心思想是？\nA. 通过不断地求取目标函数的下界的最优值，从而实现最优化的目标\nB. 列出优化目标函数，通过方法计算出最优值\nC. 列出优化目标函数，通过数值优化方法计算出最优值\nD. 列出优化目标函数，通过坐标下降的优化方法计算出最优值\n正确答案：A\n解析：EM 算法通过 E 步构造下界、M 步最大化下界，迭代逼近最优解。\n291、SVM 中的代价参数 C 表示什么？\nA. 在分类准确性和模型复杂度之间的权衡\nB. 交叉验证的次数\nC. 以上都不对\nD. 用到的核函数\n正确答案：A\n解析：C 控制误分类惩罚与模型复杂度（间隔大小）的权衡：C 越大，越倾向正确分类（可能过拟合）。\n293、下列有关核函数不正确的是\nA. 可以采用 cross-validation 方法选择最佳核函数\nB. 满足 Mercer 条件的函数不一定能作为支持向量机的核函数\nC. 极大地提高了学习机器的非线性处理能力\nD. 函数与非线性映射并不是一一对应的关系\n正确答案：B\n解析：核函数必须满足 Mercer 条件才能用于 SVM。B 选项错误，反过来说才成立。\n298、关于 K-means 说法不正确的是\nA. 算法可能终止于局部最优解\nB. 簇的数目 k 必须事先给定\nC. 对噪声和离群点数据敏感\nD. 适合发现非凸形状的簇\n正确答案：D\n解析：K-means 假设簇呈凸形（球形），对非凸形状（如流形、环状）效果差。\n300、同质集成中的个体学习器亦称\nA. 组件学习器\nB. 基学习器\nC. 异质学习器\nD. 同质学习器\n正确答案：B\n解析：同质集成中，相同类型的个体学习器称为基学习器。\n302、关于 logistic 回归和 SVM 不正确的是\nA. Logistic 回归目标函数是最小化后验概率\nB. Logistic 回归可以用于预测事件发生概率的大小\nC. SVM 可以有效避免模型过拟合\nD. SVM 目标是结构风险最小化\n正确答案：A\n解析：Logistic 回归通过最大似然估计参数，目标是得到后验概率的估计值，而非最小化后验概率。\n303、下面关于 SVM 算法叙述不正确的是\nA. SVM 是一种基于经验风险最小化准则的算法\nB. SVM 求得的解为全局唯一最优解\nC. SVM 在解决小样本、非线性及高维模式识别问题中具有优势\nD. SVM 最终分类结果只与少数支持向量有关\n正确答案：A\n解析：SVM 目标是结构风险最小化（间隔最大化+误差惩罚），而非单纯经验风险最小化。\n305、下列中为生成模型的是\nA. 决策树\nB. 支持向量机 SVM\nC. K 近邻\nD. 贝叶斯分类器\n正确答案：D\n解析：生成模型对联合概率 P(X,Y)建模（如朴素贝叶斯），判别模型直接对 P(Y|X)或决策边界建模（其他选项）。\n308、距离度量不需要满足的特性是\nA. 非负性\nB. 同一性\nC. 对称性\nD. 递增性\n正确答案：D\n解析：距离度量需满足非负性、同一性、对称性、三角不等式，无需”递增性”。\n315、朴素贝叶斯利用了\nA. 先验概率\nB. 后验概率\nC. 以上都是\nD. 以上都不是\n正确答案：C\n解析：朴素贝叶斯基于贝叶斯定理，利用先验概率 P(Y)和似然 P(X|Y)计算后验概率 P(Y|X)。\n317、模型评估的常用方法有哪些\nA. 留出法\nB. 交叉验证法\nC. 自助法\nD. 以上都是\n正确答案：D\n解析：留出法、交叉验证、自助法均为常用模型评估方法。\n321、关于 EM 算法正确的是\nA. EM 算法包括两步：E 算法和 M 算法\nB. EM 算法一定能收敛到全局最大值点\nC. 英文全称是 Expectation-Minimization\nD. 以上都不正确\n正确答案：A\n解析：EM 算法包括 E 步（期望）和 M 步（最大化）。B 错（可能收敛到局部最优），C 错（全称 Expectation-Maximization）。\n在构建决策树时，以下哪些可以作为分裂节点的选择标准？（ ）A. 信息增益 B. 基尼指数 C. 均方误差 D. 准确率答案：A\n以下关于交叉验证的说法正确的是（ ）A. 可以有效评估模型的泛化能力 B. 常见的有 K - 折交叉验证 C. 能避免数据划分的随机性影响 D. 只适用于小数据集答案：AB\n155、以下哪些算法是无监督学习算法?A.空间聚类 149 B.主成分分析 C.支持向量机 D.Q-LEARNING正确答案：A、B\n156、以下哪些算法是监督学习算法?A.人工神经网络 B.高斯混合模型概率密度估计 C.ACTOR-CRITIC 算法 D.支持向量机正确答案：A、D\n157、当我们利用二分类支持向量机来解决多分类问题是，我们有哪两种策略？ （）A.一类对另一类 B.一类对 K-1 类 C.一类对 K 类 D.2 类对 K-2 类正确答案：A、B159、核函数满足的两个条件（）。A.交换性 B.正交性 C.鲁棒性 D.半正定性正确答案：A、D\n135、直观上看，我们希望“物以类聚”，即聚类的结果“簇内相似度”⾼，且 “簇间”相似度低。（√）136、关于 EM 算法的收敛性，EM 算法理论上不能够保证收敛。（×）137、关于 EM 算法的用途，EM 算法只适用不完全数据的情形。（×）\n138、Jessen 不等式等号成立的条件是：变量为常数。 正确答案：√139、Jessen 不等式 E(f(x)) &gt;= f(E(x)), 左边部分大于等于右边部分的条件 是函数 f 是凸函数，如果 f 是凹函数，左边部分应该是小于等于右边部分。 正确答案：√ 140、EM 算法因为是理论可以保证收敛的，所以肯定能够取得最优解。（×\n143、EM 算法通常不需要设置步长，而且收敛速度一般很快。 正确答案：√ 144、吉布斯采样是一种通用的采样方法，对于任何概率分布都可以采样出对应 的样本。（×）\n136、关于 EM 算法的收敛性，EM 算法理论上不能够保证收敛。（×）137、关于 EM 算法的用途，EM 算法只适用不完全数据的情形。（×）138、Jessen 不等式等号成立的条件是：变量为常数。 正确答案：√\n139、Jessen 不等式 E(f(x)) &gt;= f(E(x)), 左边部分大于等于右边部分的条件 是函数 f 是凸函数，如果 f 是凹函数，左边部分应该是小于等于右边部分。 正确答案：√\n140、EM 算法因为是理论可以保证收敛的，所以肯定能够取得最优解。（×）\n141、EM 算法首先猜测每个数据来自哪个高斯分布，然后求取每个高斯的参 数，之后再去重新猜测每个数据来自哪个高斯分布，类推进一步迭代，直到收 敛，从而得到最后的参数估计值。 正确答案：√\n142、EM 算法，具有通用的求解形式，因此对任何问题，其求解过程都是一 样，都能很容易求得结果。（×）\n","categories":["归档"]},{"title":"使用Neo4j图数据科学库（GDS）进行中心度分析","url":"/Arknight-notes/posts/19918.html","content":"安装并加载GDS库  \n​    确保已安装并启用GDS插件。若未安装，需从Neo4j官网下载对应版本。​    \n创建图投影在 GDS 中创建内存中的图投影：\nCALL gds.graph.project(  'nodeGraph',      // 图名称  'Node',           // 节点标签  'NEIGHBOR',       // 关系类型  {    nodeProperties: ['degree'],  // 需要加载的节点属性    relationshipProperties: {}  // 关系属性（可选）  });\n\n运行度中心性算法并写入属性 \n使用gds.degree.write方法计算每个节点的度（可指定入度、出度或总度数），并将结果存储为节点属性degree：\nCALL gds.degree.write('nodeGraph', {    writeProperty: 'degree',   // 写入的属性名    orientation: 'UNDIRECTED'  // 方向：UNDIRECTED（总度数）、NATURAL（出度）、REVERSE（入度）})YIELD nodePropertiesWritten\n\n计算中心性指标1. PageRankCALL gds.pageRank.write('nodeGraph', {  maxIterations: 20,  dampingFactor: 0.85,  writeProperty: 'pagerank'});\n2. 度中心性 (Degree Centrality)CALL gds.degree.write('nodeGraph', {  writeProperty: 'degree_centrality'});\n3. 亲密中心性 (Closeness Centrality)CALL gds.closeness.write('nodeGraph', {  writeProperty: 'closeness_centrality'});\n4. 介数中心性 (Betweenness Centrality)CALL gds.betweenness.write('nodeGraph', {  writeProperty: 'betweenness_centrality'});\n\n查询结果MATCH (n:Node)RETURN   n.address AS Address,  n.pagerank AS PageRank,  n.degree_centrality AS DegreeCentrality,  n.closeness_centrality AS ClosenessCentrality,  n.betweenness_centrality AS BetweennessCentralityORDER BY PageRank DESC;\n╒═════════════╤═══════════════════╤════════════════╤═══════════════════╤═════════════════════╕│Address      │PageRank           │DegreeCentrality│ClosenessCentrality│BetweennessCentrality│╞═════════════╪═══════════════════╪════════════════╪═══════════════════╪═════════════════════╡│\"10.104.0.73\"│0.17143947585331437│0.0             │1.0                │0.0                  │├─────────────┼───────────────────┼────────────────┼───────────────────┼─────────────────────┤│\"10.105.0.71\"│0.17143947585331437│0.0             │1.0                │0.0                  │├─────────────┼───────────────────┼────────────────┼───────────────────┼─────────────────────┤│\"10.105.0.72\"│0.17143947585331437│0.0             │1.0                │0.0                  │├─────────────┼───────────────────┼────────────────┼───────────────────┼─────────────────────┤│\"10.101.0.73\"│0.17143947585331437│0.0             │1.0                │0.0                  │├─────────────┼───────────────────┼────────────────┼───────────────────┼─────────────────────┤│\"10.103.0.71\"│0.17143947585331437│0.0             │1.0                │0.0                  │├─────────────┼───────────────────┼────────────────┼───────────────────┼─────────────────────┤│\"10.101.0.71\"│0.17143947585331437│0.0             │1.0                │0.0                  │├─────────────┼───────────────────┼────────────────┼───────────────────┼─────────────────────┤│\"10.107.0.73\"│0.17143947585331437│0.0             │1.0                │0.0                  │├─────────────┼───────────────────┼────────────────┼───────────────────┼─────────────────────┤│\"10.108.0.73\"│0.17143947585331437│0.0             │1.0                │0.0                  │├─────────────┼───────────────────┼────────────────┼───────────────────┼─────────────────────┤│\"10.107.0.71\"│0.17143947585331437│0.0             │1.0                │0.0                  │├─────────────┼───────────────────┼────────────────┼───────────────────┼─────────────────────┤│\"10.103.0.73\"│0.17143947585331437│0.0             │1.0                │0.0                  │├─────────────┼───────────────────┼────────────────┼───────────────────┼─────────────────────┤│\"10.106.0.71\"│0.17143947585331437│0.0             │1.0                │0.0                  │├─────────────┼───────────────────┼────────────────┼───────────────────┼─────────────────────┤│\"10.101.0.72\"│0.17143947585331437│0.0             │1.0                │0.0                  │├─────────────┼───────────────────┼────────────────┼───────────────────┼─────────────────────┤│\"10.104.0.71\"│0.17143947585331437│0.0             │1.0                │0.0                  │├─────────────┼───────────────────┼────────────────┼───────────────────┼─────────────────────┤│\"10.109.0.72\"│0.17143947585331437│0.0             │1.0                │0.0                  │├─────────────┼───────────────────┼────────────────┼───────────────────┼─────────────────────┤│\"10.109.0.73\"│0.17143947585331437│0.0             │1.0                │0.0                  │├─────────────┼───────────────────┼────────────────┼───────────────────┼─────────────────────┤│\"10.103.0.72\"│0.16639351504031516│0.0             │0.8                │0.0                  │├─────────────┼───────────────────┼────────────────┼───────────────────┼─────────────────────┤│\"10.102.0.73\"│0.16639351504031516│0.0             │0.8                │0.0                  │├─────────────┼───────────────────┼────────────────┼───────────────────┼─────────────────────┤│\"10.102.0.71\"│0.16639351504031516│0.0             │0.8                │0.0                  │├─────────────┼───────────────────┼────────────────┼───────────────────┼─────────────────────┤│\"10.107.0.72\"│0.16638840173142871│0.0             │0.8                │0.0                  │├─────────────┼───────────────────┼────────────────┼───────────────────┼─────────────────────┤│\"10.106.0.73\"│0.16638840173142871│0.0             │0.8                │0.0                  │├─────────────┼───────────────────┼────────────────┼───────────────────┼─────────────────────┤│\"10.100.0.72\"│0.16638840173142871│28.0            │1.0                │6.833333333333333    │├─────────────┼───────────────────┼────────────────┼───────────────────┼─────────────────────┤│\"10.104.0.73\"│0.16620703459522992│27.0            │1.0                │4.166666666666666    │├─────────────┼───────────────────┼────────────────┼───────────────────┼─────────────────────┤│\"10.102.0.72\"│0.16620703459522992│0.0             │0.8                │0.0                  │├─────────────┼───────────────────┼────────────────┼───────────────────┼─────────────────────┤│\"10.109.0.71\"│0.16532947619296923│0.0             │0.8                │0.0                  │├─────────────┼───────────────────┼────────────────┼───────────────────┼─────────────────────┤│\"10.100.0.72\"│0.16532947619296923│23.0            │1.0                │2.0                  │├─────────────┼───────────────────┼────────────────┼───────────────────┼─────────────────────┤│\"10.105.0.73\"│0.16532947619296923│0.0             │0.8                │0.0                  │├─────────────┼───────────────────┼────────────────┼───────────────────┼─────────────────────┤│\"10.108.0.71\"│0.16532947619296923│0.0             │0.8                │0.0                  │├─────────────┼───────────────────┼────────────────┼───────────────────┼─────────────────────┤│\"10.104.0.72\"│0.16532947619296923│0.0             │0.8                │0.0                  │├─────────────┼───────────────────┼────────────────┼───────────────────┼─────────────────────┤│\"10.100.0.74\"│0.16028351537997002│27.0            │0.75               │2.0                  │├─────────────┼───────────────────┼────────────────┼───────────────────┼─────────────────────┤│\"10.106.0.72\"│0.16009703493488484│0.0             │0.6666666666666666 │0.0                  │├─────────────┼───────────────────┼────────────────┼───────────────────┼─────────────────────┤│\"10.108.0.72\"│0.16009703493488484│0.0             │0.6666666666666666 │0.0                  │└─────────────┴───────────────────┴────────────────┴───────────────────┴─────────────────────┘\n```\n","categories":["笔记"],"tags":["Neo4j"]},{"title":"利用chrome F12 测试应用实践详解","url":"/Arknight-notes/posts/41925.html","content":"首先介绍 Chrome 开发者工具中，调试时使用最多的三个功能页面是：元素（ELements）、控制台（Console）、源代码（Sources），此外还有网络（Network）等。\n\n\n元素（Elements）：用于查看或修改 HTML 元素的属性、CSS 属性、监听事件、断点等。\n控制台（Console）：控制台一般用于执行一次性代码，查看 JavaScript 对象，查看调试日志信息或异常信息。\n源代码（Sources）：该页面用于查看页面的 HTML 文件源代码、JavaScript 源代码、CSS 源代码，此外最重要的是可以调试 JavaScript 源代码，可以给 JS 代码添加断点等。\n网络（Network）：网络页面主要用于查看 header 等与网络连接相关的信息。\n\n1、元素（Elements）\n查看元素代码：点击如图\n\n箭头（或用者用快捷键 Ctrl+Shift+C）进入选择元素模式，然后从页面中选择需要查看的元素，然后可以在开发者工具元素（Elements）一栏中定位到该元素源代码的具体位置 。\n查看元素属性：可从被定位的源码中查看部分，如 class、src，也可在右边的侧栏中查看全部的属性，如下图位置查看\n\n修改元素的代码与属性：可直接双击想要修改的部分，然后就进行修改，或者选中要修改部分后点击右键进行修改，如下图\n**\n\n**\n注意：这个修改也仅对当前的页面渲染生效，不会修改服务器的源代码，故而这个功能也是作为调试页面效果而使用。\n右边的侧栏个功能的介绍:如下图所示\n\n2、控制台（Console）\n\n查看 JS 对象的及其属性\n执行 JS 语句\n查看控制台日志：当网页的 JS 代码中使用了 console.log()函数时，该函数输出的日志信息会在控制台中显示。日志信息一般在开发调试时启用，而当正式上线后，一般会将该函数去掉。\n\n3、源代码（Sources）其主要功能如下介绍\n\n4、网络（Network）大体功能如下：\n\n\n打开浏览器,按 f12,点击 Network,可以查看相关网络请求信息,记得是打开 f12 之后再刷新页面才会开始记录的\n\n\n\n查看 Network 基本信息,请求了哪些地址及每个 URL 的网络相关请求信息都可以看的到 URL，响应状态码，响应数据类型，响应数据大小，响应时间\n\n\n\n请求 URL 可进行筛选和分类，选择不同分类,查看请求 URL,方便查找\n\n\n\n也可以直接 Filter 搜索查询相关 URL，可以输入关键字或者正则表达式进行查询\n\n\n\nWaterfall 能分割重要的请求耗时,查看具体请求耗时在哪个地方,鼠标指到相关区域可以看到具体耗时\n\n\n\n我们具体分析下里面每个各代表什么意思,分别耗时多少,通过这个来分析服务器到底是哪个环节出了问题\n\n\nQueueing 是排队的意思\nStalled 是阻塞 请求访问该 URL 的主机是有并发和连接数限制的,必须要等之前的执行才能执行之后的,这段时间的耗时\nDNS Lookup 是指域名解析所耗时间\nInitial connection 初始化连接时间,这里一般是 TCP 3 次连接握手时间\nSSL https 特有,是一种协议\nRequest sent 发送请求所消耗的时间\nWaiting 等待响应时间,这里一般是最耗时的\nContent Download 下载内容所需要消耗的时间\n\n请求文件具体说明\n\n一共分为四个模块：\n\nHeader：面板列出资源的请求 url、HTTP 方法、响应状态码、请求头和响应头及它们各自的值、请求参数等等\nPreview：预览面板，用于资源的预览。\nResponse：响应信息面板包含资源还未进行格式处理的内容\nTiming：资源请求的详细信息花费时间\n\n转载自 chrome 浏览器中 F12 功能的简单介绍 - 知乎 (zhihu.com)\n","categories":["笔记"],"tags":["前端开发"]},{"title":"数据结构-算法复杂度","url":"/Arknight-notes/posts/25842.html","content":"算法复杂度算法复杂度旨在计算在输入数据量 N的情况下，算法的「时间使用」和「空间使用」情况；体现算法运行使用的时间和空间随「数据大小 N」而增大的速度。\n算法复杂度主要可从 时间 、空间 两个角度评价：\n\n时间： 假设各操作的运行时间为固定常数，统计算法运行的「计算操作的数量」 ，以代表算法运行所需时间；\n空间： 统计在最差情况下，算法运行所需使用的「最大空间」；\n\n「输入数据大小N」指算法处理的输入数据量；根据不同算法，具有不同定义，例如：\n\n排序算法： N代表需要排序的元素数量；\n搜索算法： N代表搜索范围的元素总数，例如数组大小、矩阵大小、二叉树节点数、图节点和边数等；\n\n接下来，我们将分别从概念定义、符号表示、常见种类、时空权衡、示例解析、示例题目等角度入手，学习「时间复杂度」和「空间复杂度」。\n时间复杂度代码执行次数的简化估算值就是时间复杂度。\n一些例子\n\n线性复杂度O(N)：单层循环，如遍历数组求和。\n\n对数复杂度O(logN)：二分查找。\n\n线性对数复杂度O(NlogN)：快速排序或归并排序的分治策略。\n\n平方复杂度O(N^2)：双重循环，如冒泡排序。\n\n指数复杂度O(2^N)：递归斐波那契。\n\n阶乘复杂度O(N!)：全排列生成。\n\n\n   其中有：O(1)&lt;O(logN)&lt;O(N)&lt;O(NlogN)&lt;O(N^2)&lt;O(2^N)&lt;O(N!)\n\n基本复杂度计算层层（循环、递归）相加：比如有2层循环，第一层循环共执行n次基本语句，每个基本语句执行1次，也就是n个“1”次相加，为n；第二层循环执行log2n次第一次循环，每个第一次循环执行n次，总的也就是log2n个“n”次相加为nlog2n，故时间复杂度为O(nlogn)。\n复杂度计算的核心规则\n单层循环：直接取循环次数，如 O(n).  \n嵌套循环：各层循环次数相乘，如 O(n²) 或 O(n log n).  \n递归算法：• 递归次数 × 每次递归的操作次数，如斐波那契数列的 O(2ⁿ).• 分治策略（如归并排序）通过主定理计算，结果为 O(n log n).  \n忽略低阶项：如 T(n) = 3n² + 2n + 1 简化为 O(n²).  \n\n1. O(1) — 常数复杂度特点：运行次数与 N 大小呈常数关系，即不随输入数据大小 N 的变化而变化。\n示例：访问数组元素或交换变量。  \n// 访问数组元素int getElement(int arr[], int index) &#123;    return arr[index]; // 无论数组大小，直接访问固定位置&#125;// 交换变量void swap(int *a, int *b) &#123;    int temp = *a;    *a = *b;    *b = temp; // 仅需三次赋值操作&#125;\n\n\n2. O(log n) — 对数复杂度特点：每次操作将问题规模缩减为固定比例（如折半）。示例：二分查找。  \nint binarySearch(int arr[], int left, int right, int target) &#123;    while (left &lt;= right) &#123;        int mid = left + (right - left) / 2;        if (arr[mid] == target) return mid;        if (arr[mid] &lt; target) left = mid + 1;        else right = mid - 1; // 每次搜索范围减半    &#125;    return -1;&#125;\n如下图所示，为二分查找的时间复杂度示意图，每次二分将搜索区间缩小一半。\n\n\n3. O(n) — 线性复杂度特点：执行时间与输入规模成线性正比。示例：遍历数组求和。  \nint sumArray(int arr[], int size) &#123;    int sum = 0;    for (int i = 0; i &lt; size; i++) &#123;        sum += arr[i]; // 遍历所有元素，执行次数为n    &#125;    return sum;&#125;\n\n\n4. O(n log n) — 对数线性复杂度特点：两层循环相互独立，第一层和第二层时间复杂度分别为 O(log⁡N) 和 O(N)，则总体时间复杂度为 O(Nlog⁡N)\n结合线性与对数操作，常见于分治算法。示例：快速排序。  \nvoid quickSort(int arr[], int low, int high) &#123;    if (low &lt; high) &#123;        int pivot = partition(arr, low, high); // 分区操作O(n)        quickSort(arr, low, pivot - 1);  // 递归左半部分        quickSort(arr, pivot + 1, high); // 递归右半部分    &#125;&#125;// 每次递归将问题规模分半，递归深度为log n，每层总操作次数为n\n线性对数阶常出现于排序算法，例如「快速排序」、「归并排序」、「堆排序」等，其时间复杂度原理如下图所示。\n\n\n5. O(nᵏ) — 多项式复杂度（k=2为例）特点：嵌套循环导致时间复杂度为输入规模的k次方。示例：冒泡排序。 第一层和第二层时间复杂度分别为 O(N) 和 O(N)，则总体时间复杂度为 O(N^2) \nvoid bubbleSort(int arr[], int size) &#123;    for (int i = 0; i &lt; size-1; i++) &#123;        for (int j = 0; j &lt; size-i-1; j++) &#123;            if (arr[j] &gt; arr[j+1]) &#123;                swap(&amp;arr[j], &amp;arr[j+1]); // 双重循环，操作次数为n²            &#125;        &#125;    &#125;&#125;\n\n\n6. O(kⁿ) — 指数复杂度特点：问题规模每增加1，计算量翻倍。示例：斐波那契数列的递归实现。  \nint fibonacci(int n) &#123;    if (n &lt;= 1) return n;    return fibonacci(n-1) + fibonacci(n-2); // 每次递归分裂为两次调用，复杂度为O(2ⁿ)&#125;\n\n\n7. O(n!) — 阶乘复杂度特点：问题规模每增加1，计算量增长为阶乘级。示例：生成全排列，给定 NN 个互不重复的元素，求其所有可能的排列方案（递归回溯）。  \nint algorithm(int N) &#123;    if (N &lt;= 0) return 1;    int count = 0;    for (int i = 0; i &lt; N; i++) &#123;        count += algorithm(N - 1);    &#125;    return count;&#125;\n\n时间复杂度的意义时间复杂度不同，随着输入数据量的增加，代码运行的时间也会增加。\n例如O(1)无论输入数据如何增多，代码运行时间都不变。而O(n)的运行时间和输入数据量成正比。如果时间复杂度过高，例如O(2^n)，那么在小数据情况下，代码还可以运行，一旦数据量增大，则代码的运行时间将会几何级增加。\n\n\n代码执行时间总结如下：\n\n\n\n\n名称\n时间复杂度\n\n\n\n\n常数时间\nO(1)\n\n\n对数时间\nO(log n)\n\n\n线性时间\nO(n)\n\n\n线性对数时间\nO(nlog n)\n\n\n二次时间\nO(n^2)\n\n\n三次时间\nO(n^3)\n\n\n指数时间\nO(2^n)\n\n\n\n\n常见的时间复杂度\n\n\n\n空间复杂度\n空间复杂度是对一个算法在运行过程中临时占用存储空间大小的量度。空间复杂度不是程序占用了多少字节的空间，因为这个也没太大意义，所以空间复杂度算的是变量的个数。空间复杂度计算规则基本跟时间复杂度类似，也使用大O渐进表示法。\n\n常数 O(1)//计算冒泡排序函数的空间复杂度void BubbleSort(int* a, int N)&#123;\tassert(a);\tfor (int i = 0; i &lt; N; i++)\t&#123;\t\tint exchange = 0;\t\tfor (int j = 0; j &lt; N - 1 - i; j++)\t\t&#123;\t\t\tif (a[j]&gt;a[j + 1])\t\t\t&#123;\t\t\t\tint tmp = a[j];\t\t\t\ta[j] = a[j + 1];\t\t\t\ta[j + 1] = tmp;\t\t\t\texchange = 1;\t\t\t&#125;\t\t&#125;\t\tif (exchange == 0)\t\t\tbreak;\t&#125;&#125;\n冒泡排序函数中使用了常数个额外空间（即常数个变量），所以用大O的渐进表示法表示冒泡排序函数的空间复杂度为O(1) 。\n线性 O(N)//计算阶乘递归函数的空间复杂度long long Factorial(size_t N)&#123;\treturn N &lt; 2 ? N : Factorial(N - 1)*N;&#125;\n阶乘递归函数会依次调用Factorial(N),Factorial(N-1),…,Factorial(2),Factorial(1)，开辟了N个空间，所以空间复杂度为O(N) 。\n\n平方 O(N²)元素数量与 N呈平方关系的任意类型集合（常见于矩阵），皆使用平方大小的空间。\n\n递归调用栈的深度每次递归调用参数递减 1，直到 N ≤ 0。递归深度为 N 次（例如 N=5 时调用链为 algorithm(5) → algorithm(4) → … → algorithm(0)）\n每次递归的临时空间占用每次递归调用时，会在栈上动态创建一个大小为 N 的整型数组 int nums[N]。随着递归深度增加，数组长度的变化为 N, N-1, N-2, …, 1\n空间累计计算总空间占用为各次递归调用中数组大小的累加：S(N)=N+(N−1)+(N−2)+⋯+1=2N(N+1)​根据大 O 表示法，简化为 ​​O(N²)​​\n\nint algorithm(int N) &#123;    if (N &lt;= 0) return 0;    int nums[N];    return algorithm(N - 1);&#125;\n\n指数 O(2ᴺ)指数阶常见于二叉树、多叉树的空间分析，例如：\n\n满二叉树\n高度为 N 的满二叉树，节点总数为 2ᴺ，空间复杂度为 O(2ᴺ)。\n\n满 m 叉树\n高度为 N 的满 m 叉树，节点总数为 mᴺ。\n当 m 为常数时，O(mᴺ) = O(2ᴺ)（指数级增长性质相同）。\n\n\n指数阶常见于二叉树、多叉树。例如，高度为 N的「满二叉树」的节点数量为 2^N，占用 O(2^N)大小的空间；同理，高度为 N的「满 m叉树」的节点数量为 m^N，占用 O(m^N)大小的空间。\n\n对数 O(log N)对数阶常出现于分治算法的栈帧空间累计、数据类型转换等，例如：\n\n快速排序，平均空间复杂度为 Θ(log N)，最差空间复杂度为 O(N)。通过应用尾递归优化，可以将快速排序的最差空间复杂度限定至 O(N)。\n数字转化为字符串，设某正整数为 N，则字符串的空间复杂度为 O(log N)。正整数 N 的位数为 log₁₀ N，即转化的字符串长度为 log₁₀ N，因此空间复杂度为 O(log N)。\n\n注：递归算法的空间复杂度通常是递归的深度（即递归多少层）。\n","categories":["数据结构"],"tags":["数据结构"]},{"title":"数据结构-栈","url":"/Arknight-notes/posts/33985.html","content":"栈的基本概念栈的定义栈：是只允许在一端进行插入或删除的线性表。首先栈是一种线性表，但限定这种线性表只能在某一端进行插入和删除操作。栈顶（Top）：线性表允许进行插入删除的那一端。栈底（Bottom)：固定的，不允许进行插入和删除的另一端。空栈：不含任何元素的空表。\n栈又称为后进先出（Last In First Out）的线性表，简称LIFO结构\n栈的常见基本操作InitStack(&amp;S)：初始化一个空栈S\nStackEmpty(S)：判断一个栈是否为空，若栈为空则返回true，否则返回false\nPush(&amp;S, x)：进栈（栈的插入操作），若栈S未满，则将x加入使之成为新栈顶\nPop(&amp;S, &amp;x)：出栈（栈的删除操作），若栈S非空，则弹出栈顶元素，并用x返回\nGetTop(S, &amp;x)：读栈顶元素，若栈S非空，则用x返回栈顶元素\nDestroyStack(&amp;S)：栈销毁，并释放S占用的存储空间（“&amp;”表示引用调用）\n栈的顺序存储结构栈的顺序存储采用顺序存储的栈称为顺序栈，它利用一组地址连续的存储单元存放自栈底到栈顶的数据元素，同时附设一个指针（top）指示当前栈顶元素的位置。若存储栈的长度为MAXSIZE，则栈顶位置top必须小于MAXSIZE。当栈存在一个元素时，top等于0，因此通常把空栈的判断条件定位top等于-1。栈的顺序存储结构可描述为：\n#define MAXSIZE 5  //定义栈中元素的最大个数typedef struct SqStack&#123;    int data[MAXSIZE];    int top;&#125;SqStack;\n若现在有一个栈，MAXSIZE是5，则栈的普通情况、空栈、满栈的情况分别如下图所示：\n\n初始化void InitStack(SqStack* S)&#123;     //SqStack&amp; S 是 C++ 的引用参数，用于直接修改外部栈对象    //若用 C 语言，需改用指针（SqStack* S）    S-&gt;top = -1;             //初始化栈顶指针&#125;\n为什么要用 S-&gt;top = -1？\n顺序栈的本质是一个数组，栈顶指针 top 表示当前栈顶元素在数组中的位置索引。初始化时 top = -1 有\n空栈条件：top == -1当栈中没有元素时，top 指向数组的“前一个位置”（即无效索引），逻辑上表示“无元素”。\n入栈操作\n先让 top++，移动到下一个可用位置；将新元素存入 data[top]。例如，第一次入栈时，top 从 -1 变为 0，元素存入 data[0]，对应数组的第一个索引。\n判断栈满\n栈满条件：top == MAX_SIZE - 1如果数组大小为 MAX_SIZE，当 top 指向最后一个位置（即 MAX_SIZE - 1）时，表示栈已满。\n判断栈空bool StackEmpty(SqStack* S)&#123;    if( S-&gt;top == -1)&#123;        return true;        //栈中没有元素时，`top` 指向数组的“前一个位置”（即无效索引），逻辑上表示“无元素”    &#125;    return false;&#125;\n进栈bool Push(SqStack* S, int x)&#123;    if( S-&gt;top == MAXSIZE - 1 )&#123; //栈满，报错        return false;            &#125;    S-&gt;top++ ;                  //栈顶指针加1    S-&gt;data[S-&gt;top] = x;         //入栈,写入元素到新栈顶位置    //S-&gt;data[S-&gt;top]代表栈顶元素    return true;&#125;\n出栈bool Pop(SqStack* S, int* x) &#123;//通过指针修改外部变量    if (StackEmpty(S)) &#123;        printf(&quot;栈空，无法出栈\\n&quot;);        return false;    &#125;    *x = S-&gt;data[S-&gt;top];    S-&gt;top--;    printf(&quot;出栈元素: %d\\n&quot;, *x);    return x;&#125;\n读栈顶元素bool GetTop(SqStack* S, int* x) &#123;//通过指针修改外部变量    if (StackEmpty(S)) &#123;        printf(&quot;栈空，无栈顶元素\\n&quot;);        return false;    &#125;    *x = S-&gt;data[S-&gt;top];    printf(&quot;当前栈顶元素: %d\\n&quot;, *x);    return true;&#125;\n出栈和读栈顶元素操作需要返回两个信息：\n\n是否成功（通过 bool 返回值）。\n得到的元素值（通过 int* x 指针参数）。\n\n完整代码实现#include &lt;stdio.h&gt;#include &lt;stdbool.h&gt;#define MAXSIZE 5  // 示例栈容量设为5//栈结构定义typedef struct SqStack &#123;    int data[MAXSIZE];    int top;&#125; SqStack;// 初始化栈void InitStack(SqStack* S) &#123;    S-&gt;top = -1;&#125;// 判断栈空bool StackEmpty(SqStack* S) &#123;    return (S-&gt;top == -1);&#125;// 判断栈满bool StackFull(SqStack* S) &#123;    return (S-&gt;top == MAXSIZE - 1);&#125;// 入栈bool Push(SqStack* S, int x) &#123;    if (StackFull(S)) &#123;        printf(&quot;栈已满，无法入栈 %d\\n&quot;, x);        return false;    &#125;    S-&gt;top++;    S-&gt;data[S-&gt;top] = x;    printf(&quot;入栈元素: %d\\n&quot;, x);    return true;&#125;// 出栈（通过指针返回栈顶元素）bool Pop(SqStack* S, int* x) &#123;    if (StackEmpty(S)) &#123;        printf(&quot;栈空，无法出栈\\n&quot;);        return false;    &#125;    *x = S-&gt;data[S-&gt;top];    S-&gt;top--;    printf(&quot;出栈元素: %d\\n&quot;, *x);    return x;&#125;// 获取栈顶元素（通过指针返回）bool GetTop(SqStack* S, int* x) &#123;    if (StackEmpty(S)) &#123;        printf(&quot;栈空，无栈顶元素\\n&quot;);        return false;    &#125;    *x = S-&gt;data[S-&gt;top];    printf(&quot;当前栈顶元素: %d\\n&quot;, *x);    return true;&#125;// 打印栈内容（辅助函数）void PrintStack(SqStack* S) &#123;    if (StackEmpty(S)) &#123;        printf(&quot;栈空\\n&quot;);        return;    &#125;    printf(&quot;栈内容 (从底到顶): &quot;);    for (int i = 0; i &lt;= S-&gt;top; i++) &#123;        printf(&quot;%d &quot;, S-&gt;data[i]);    &#125;    printf(&quot;\\n&quot;);&#125;int main() &#123;    SqStack S;    int val;  // 用于接收出栈/栈顶元素的值    InitStack(&amp;S);    PrintStack(&amp;S);  // 栈空    // 入栈测试    Push(&amp;S, 10);    Push(&amp;S, 20);    Push(&amp;S, 30);    Push(&amp;S, 40);    Push(&amp;S, 50);   // 栈满    Push(&amp;S, 60);   // 触发栈满报错    PrintStack(&amp;S);  // 10 20 30 40 50    // 获取栈顶    GetTop(&amp;S, &amp;val);  // 50    // 出栈测试    Pop(&amp;S, &amp;val);     // 50出栈    Pop(&amp;S, &amp;val);     // 40出栈    PrintStack(&amp;S);    // 10 20 30    // 继续出栈直到栈空    Pop(&amp;S, &amp;val);     // 30    Pop(&amp;S, &amp;val);     // 20    Pop(&amp;S, &amp;val);     // 10    Pop(&amp;S, &amp;val);     // 触发栈空报错    PrintStack(&amp;S);    // 栈空    return 0;&#125;\n\n栈的链式存储结构采用链式存储的栈称为链栈，链栈的优点是便于多个栈共享存储空间和提高其效率，且不存在栈满上溢的情况。通常采用单链表实现，并规定所有操作都是在单链表的表头进行的。这里规定链栈没有头节点，Lhead指向栈顶元素\n\n对于空栈来说，链表原定义是头指针指向空，那么链栈的空其实就是top=NULL的时候。\n链栈的结构定义：// 定义链式栈的节点结构体typedef struct LinkedStackNode &#123;\t    int data;                       // 存储栈元素    struct LinkedStackNode * next;  // 指向下一节点的指针&#125; LinkedStackNode, * LinkedStack;   // 类型别名：LinkedStackNode表示节点，LinkedStack表示节点指针LinkedStack top; // 声明一个栈顶指针（本质是LinkedStackNode*类型）\n初始化空栈//初始化LinkedStack Init_LinkedStack()                                       &#123;\t\tLinkedStack top=(LinkedStackNode * )malloc (sizeof( LinkedStackNode));\tif(top!=NULL)//申请空间成功\ttop-&gt;next=NULL;//设置栈顶指针为空\treturn top;&#125;\n判断栈空//判栈空int LinkedStack_Empty(LinkedStack top)                            &#123;\t\tif(top-&gt;next==NULL)//检查栈顶指针的值 \t&#123;\t\treturn 1;//栈S为空，函数返回1\t&#125;\t\telse\t&#123;\t\treturn 0;\t&#125;&#125;\n入栈int Push_LinkedStack(LinkedStack top,elemtype x)                     \t//插入数据元素x为新的栈顶元素&#123;\t\tLinkedStackNode * node;\tnode=(LinkedStackNode * )malloc(sizeof(LinkedStackNode));\tif(node==NULL)\t&#123;\t\treturn 0;//申请结点空间失败,插入失败，函数返回0\t&#125;\telse\t&#123;\t\tnode-&gt;data=x;//设置新结点的数据域\t\tnode-&gt;next=top-&gt;next;//设置新结点的指针城\t\ttop-&gt;next=node;//设置头结点指针城指向新的栈顶元素\t\treturn 1;//插入成功，函数返回1\t&#125;&#125;\n出栈int Pop_LinkedStack(LinkedStack top, elemtype *x)                    &#123;\tLinkedStackNode * node;\tif(top-&gt;next==NULL)\t&#123;\t\treturn 0;\t&#125;\telse\t&#123;\t\tnode=top-&gt;next;//将原栈顶数据元素弹出并赋给node\t\t*x=node-&gt;data;//将原栈顶数据元素的数据赋值给x\t\ttop-&gt;next=node-&gt;next;//top指向链栈中的下一个数据元素\t\tfree (node);//释放原栈顶数据元素所占的空间\t\treturn 1;\t&#125;&#125;  \n取栈顶元素int GetTop_LinkedStack(LinkedStack top)                &#123; \tif(top-&gt;next)      &#123;            return top-&gt;next-&gt;data;      &#125;      return -1;&#125;\n求栈长设置计数器，随top指针后移，计数器加1，直到遍历完所有元素。\n//求栈长int Length_LinkedStack(LinkedStack top)                                       &#123;\tint count = 0;\twhile(top-&gt;next!=NULL) \t&#123;\t\t++count;\t\ttop=top-&gt;next;\t&#125;\treturn count;&#125;\n完整代码实现#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;// 定义链式栈的节点结构体typedef struct LinkedStackNode &#123;\t    int data;                       // 存储栈元素    struct LinkedStackNode * next;  // 指向下一节点的指针&#125; LinkedStackNode, * LinkedStack;   // 类型别名：LinkedStackNode表示节点，LinkedStack表示节点指针LinkedStack top; // 声明一个栈顶指针（本质是LinkedStackNode*类型）//初始化LinkedStack Init_LinkedStack()                                       &#123;\t\tLinkedStack top=(LinkedStackNode * )malloc (sizeof( LinkedStackNode));\tif(top!=NULL)//申请空间成功\ttop-&gt;next=NULL;//设置栈顶指针为空\treturn top;&#125;//判栈空int LinkedStack_Empty(LinkedStack top)                            &#123;\t\tif(top-&gt;next==NULL)//检查栈顶指针的值 \t&#123;\t\treturn 1;//栈S为空，函数返回1\t&#125;\t\telse\t&#123;\t\treturn 0;\t&#125;&#125;//入栈int Push_LinkedStack(LinkedStack top,elemtype x)                     \t//插入数据元素x为新的栈顶元素&#123;\t\tLinkedStackNode * node;\tnode=(LinkedStackNode * )malloc(sizeof(LinkedStackNode));\tif(node==NULL)\t&#123;\t\treturn 0;//申请结点空间失败,插入失败，函数返回0\t&#125;\telse\t&#123;\t\tnode-&gt;data=x;//设置新结点的数据域\t\tnode-&gt;next=top-&gt;next;//设置新结点的指针城\t\ttop-&gt;next=node;//设置头结点指针城指向新的栈顶元素\t\treturn 1;//插入成功，函数返回1\t&#125;&#125;//求栈长int Length_LinkedStack(LinkedStack top)                                       &#123;\tint count = 0;\twhile(top-&gt;next!=NULL) \t&#123;\t\t++count;\t\ttop=top-&gt;next;\t&#125;\treturn count;&#125;//出栈int Pop_LinkedStack(LinkedStack top, elemtype *x)                    &#123;\tLinkedStackNode * node;\tif(top-&gt;next==NULL)\t&#123;\t\treturn 0;\t&#125;\telse\t&#123;\t\tnode=top-&gt;next;//将原栈顶数据元素弹出并赋给node\t\t*x=node-&gt;data;//将原栈顶数据元素的数据赋值给x\t\ttop-&gt;next=node-&gt;next;//top指向链栈中的下一个数据元素\t\tfree (node);//释放原栈顶数据元素所占的空间\t\treturn 1;\t&#125;&#125;  //取栈顶元素int GetTop_LinkedStack(LinkedStack top)                &#123; \tif(top-&gt;next)      &#123;            return top-&gt;next-&gt;data;      &#125;      return -1;&#125;//主函数void main()&#123;\tint i,t,x,a[20];\tLinkedStack top=Init_LinkedStack();//初始化栈\tx=LinkedStack_Empty(top);//判栈空结果赋值给X\tif(x=0)\t&#123;\t\tprintf(&quot;栈为空\\n&quot;);\t&#125;\tprintf(&quot;请依次输入5个数,开始入栈：\\n&quot;);\tfor(i=0;i&lt;5;i++) \t&#123;\t\tscanf(&quot;%d&quot;,&amp;a[i]);\t\tPush_LinkedStack(top,a[i]);\t\tx=GetTop_LinkedStack(top);\t\tif(x!=-1)\t\t&#123;\t\t\tprintf(&quot;当前栈顶元素为%d\\n&quot;,x);\t\t&#125;\t&#125;\tprintf(&quot;入栈结束\\n&quot;);\tprintf(&quot;栈长为%d\\n&quot;,Length_LinkedStack(top));\tprintf(&quot;开始出栈:\\n&quot;);\tfor (i=0;i&lt;5;i++)\t&#123;\t\tPop_LinkedStack(top,&amp;t);        printf(&quot;%d&quot;,t);\t&#125;\tprintf(&quot;\\n&quot;);\tprintf(&quot;出栈后栈长为%d\\n&quot;,Length_LinkedStack(top));&#125;\n","categories":["数据结构"],"tags":["数据结构"]},{"title":"数据结构-绪论","url":"/Arknight-notes/posts/45088.html","content":"1.1 数据结构的基本概念　　数据、数据元素、数据对象、数据结构、存储结构、数据类型和抽象数据类型。\n\n数据(data)是对客观事物的符号表示。在计算机科学中是指所有能输入到计算机中并被计算机程序处理的符号的总称。数据元素(data element)是数据的基本单位，在计算机程序中通常作为一个整体进行考虑和处理。数据对象(data object)是性质相同的数据元素的集合，是数据的一个子集。数据结构(data structure)是相互之间存在一种或多种特定关系的数据元素的集合。存储结构（物理结构）是数据结构在计算机中的表示（又称映像）。数据类型(data type)是一个值的集合和定义在这个值集上的一组操作的总称。抽象数据类型(Abstract Data Type)是指一个数学模型以及定义在该模型上的一组操作。\n\n抽象数据类型的定义ADT 抽象数据类型名&#123;    数据对象：数据对象的定义    数据关系：数据关系的定义    基本操作：基本操作的定义&#125;ADT 抽象数据类型名\n例子如下\n抽象数据类型复数和有理数的定义（有理数是其分子、分母均为自然数且分母不为零的分数）。\n复数定义：ADT Complex  //复数定义 a±bi&#123;    数据对象：D = &#123;a, b | a,b为实数&#125;    数据关系：R = &#123;&lt;a, b&gt;&#125;    基本操作：        InitComplex(&amp;C, re, im)            操作结果：构造一个复数C，其实部和虚部分别为re和im        DestroyCmoplex(&amp;C)            操作结果：销毁复数C        Get(C, k, &amp;e)            初始条件：复数C已存在            操作结果：用e返回复数C的第k元的值        Put(&amp;C, k, e)            初始条件：复数C已存在            操作结果：改变复数C的第k元的值为e        IsAscending(C)            初始条件：复数C已存在            操作结果：如果复数C的两个元素按升序排列，则返回1，否则返回0        IsDescending(C)            初始条件：复数C已存在            操作结果：如果复数C的两个元素按降序排列，则返回1，否则返回0        Max(C, &amp;e)            初始条件：复数C已存在            操作结果：用e返回复数C的两个元素中值较大的一个        Min(C, &amp;e)            初始条件：复数C已存在            操作结果：用e返回复数C的两个元素中值较小的一个&#125;ADT Complex\n有理数定义：ADT RationalNumber  //有理数定义&#123;    数据对象：D=&#123;s, m | s,m为自然数，且m不为0&#125;    数据关系：R=&#123;&lt;s, m&gt;&#125;    基本操作：        InitRationalNumber(&amp;R, s, m)            操作结果：构造一个有理数R，其分子和分母分别为s和m        DestroyRationalNumber(&amp;R)            操作结果：销毁有理数R        Get(R, k, &amp;e)            初始条件：有理数R已存在            操作结果：用e返回有理数R的第k元的值        Put(&amp;R, k, e)            初始条件：有理数R已存在            操作结果：改变有理数R的第k元的值为e        IsAscending(R)            初始条件：有理数R已存在            操作结果：若有理数R的两个元素按升序排列，则返回1，否则返回0        IsDescending(R)            初始条件：有理数R已存在            操作结果：若有理数R的两个元素按降序排列，则返回1，否则返回0        Max(R, &amp;e)            初始条件：有理数R已存在            操作结果：用e返回有理数R的两个元素中值较大的一个        Min(R, &amp;e)            初始条件：有理数R已存在            操作结果：用e返回有理数R的两个元素中值较小的一个&#125;ADT RationalNumber\n　　\n根据数据元素之间关系的 不同特性，通常有下列几种类基本结构：\n(1) 集合 结构中的 如生 数据元素之间除了“同属千一个集合”的关系外，别无其他关系\n(2) 线性结构 结构中的数据元素之间存在一个对 一个的关系；\n(3) 树形结构 结构中的数据元素之间存在一 个对多个的关系； \n(4) 图状结构或网状结构 结构中的数据 元素之间存在多个对多个的关系。\n1.1.2 数据结构三要素　　　　① 逻辑结构\n　　　　　　逻辑结构指数据元素之间存在的逻辑关系，是固有的客观联系；\n　　　　　　逻辑结构分为线性结构与非线性结构，比如：线性表、树、图等；\n　　　　② 存储结构\n　　　　　　存储结构又称为物理结构，指数据结构在计算机中的表示（映像），是计算机内部的存储方法；\n　　　　　　存储结构主要有顺序存储、链式存储、索引存储和散列存储；\n　　　　　　一种逻辑结构通过映像便可以得到它的存储结构；\n　　　　　　诸如顺序表、哈希表、链表这样的表述，它们既体现了逻辑结构（均为线性），又体现了存储结构（顺序、散列、链式）；\n　　　　　　而这样的表述我们往往就直接称之为数据结构；\n　　　　　　诸如有序表，它只体现了逻辑结构（线性），而存储结构是未知的（可以是顺序、链式……）；\n　　　　　　不存在只体现存储结构而不体现逻辑结构的表述；\n　　　　　　所以，我们认为：逻辑结构独立于存储结构。\n　　　　③ 数据的运算（算法）\n　　　　　　算法包括运算的定义（取决于逻辑结构，体现算法功能）与实现（取决于存储结构，体现于操作步骤）。\n1.2 算法的基本概念　　算法的 5 个重要特性：有穷性、确定性、有效性（可行性）、输入，输出；\n　　一个好的算法的目标：正确性、可读性、鲁棒性、效率与低存储量需求。\n1.3 算法分析\n　　时间复杂度指算法所有语句被重复执行次数总和的数量级。\n　　常见时间复杂度比较：\n　　　　O(1) &lt; O(log n) &lt; O(n) &lt; O(n log n) &lt; O(n^2) &lt; O(n^3) &lt; O(2^n) &lt; O(n!) &lt; O(n^n)\n　　　　(log 表示以 2 为底的对数)\n　　空间复杂度指算法耗费存储空间的数量级。\n1.4 时间复杂度的计算\n计算时间复杂度问题规模——&gt; 输入量的多少\n语句频度——&gt; 一条语句的重复执行次数\n执行时间&lt;—— 所有语句频度之和\n\n1.基本操作，即只有常数项，认为其时间复杂度为O(1)2.顺序结构，时间复杂度按加法进行计算3.循环结构，时间复杂度按乘法进行计算4.分支结构，时间复杂度取最大值 判断一个算法的效率时，往往只需要关注操作数量的最高次项，其它次要项和常数项可以忽略5.在没有特殊说明时，我们所分析的算法的时间复杂度都是指最坏时间复杂度\n\n　　\n循环条件包含主体变量\n将执行次数代入循环条件进行求解：\n示例1：\nint i = 1;while (i &lt;= n)     i = i * 2;\n\n每次循环后 i =2t（t 为执行次数）\n终止条件：2t ≤ n\n解得 t ≤ log2n\n时间复杂度：T(n) = O(logn)\n\n示例2：\nint i = 3;while ((i + 1) * (i + 1) &lt; n)     i = i + 1;\n\n令 t=i−3，则 i=t+3\n代入条件：(t+3+1)2&lt;n⟹(t+4)2&lt;n\n解得 t&lt;n−4\n时间复杂度：T(n)=O(n)\n\n\n循环条件与主体变量无关\n通过数学归纳法或递归展开直接计数：\n示例（递归函数）：\nint fact(int n) &#123;    if (n &lt;= 1) return 1;    return n * fact(n - 1);&#125;\n\n递归方程：T(n)=1+T(n−1)\n展开递推：T(n)=1+T(n−1)=1+1+T(n−2) ⋮=k+T(n−k)(当 k=n−1)=(n−1)+T(1)=O(n)\n时间复杂度：T(n)=O(n)\n\n常见的数据结构如下图所示，常见的数据结构可分为「线性数据结构」与「非线性数据结构」，具体为：「数组」、「链表」、「栈」、「队列」、「树」、「图」、「散列表」、「堆」。\n\n\n数组数组是将相同类型的元素存储于连续内存空间的数据结构，其长度不可变。\n如下图所示，构建此数组需要在初始化时给定长度，并对数组每个索引元素赋值，代码如下：\n// 初始化一个长度为 5 的数组 arrayint array[5];// 元素赋值array[0] = 2;array[1] = 3;array[2] = 1;array[3] = 0;array[4] = 2;\n或者可以使用直接赋值的初始化方式，代码如下：\nint array[] = &#123;2, 3, 1, 0, 2&#125;;\n\n「可变数组」是经常使用的数据结构，其基于数组和扩容机制实现，相比普通数组更加灵活。常用操作有：访问元素、添加元素、删除元素。\n// 初始化可变数组vector&lt;int&gt; array;// 向尾部添加元素array.push_back(2);array.push_back(3);array.push_back(1);array.push_back(0);array.push_back(2);\n\n链表链表以节点为单位，每个元素都是一个独立对象，在内存空间的存储是非连续的。链表的节点对象具有两个成员变量：「值 val」，「后继节点引用 next」 。\nstruct ListNode &#123;    int val;        // 节点值    ListNode *next; // 后继节点引用    ListNode(int x) : val(x), next(NULL) &#123;&#125;&#125;;\n如下图所示，建立此链表需要实例化每个节点，并构建各节点的引用指向。\n// 实例化节点ListNode *n1 = new ListNode(4); // 节点 headListNode *n2 = new ListNode(5);ListNode *n3 = new ListNode(1);// 构建引用指向n1-&gt;next = n2;n2-&gt;next = n3;\n\n\n栈栈是一种具有 「先入后出」 特点的抽象数据结构，可使用数组或链表实现。\nstack&lt;int&gt; stk;\n如下图所示，通过常用操作「入栈 push()」,「出栈 pop()」，展示了栈的先入后出特性。\nstk.push(1); // 元素 1 入栈stk.push(2); // 元素 2 入栈stk.pop();   // 出栈 -&gt; 元素 2stk.pop();   // 出栈 -&gt; 元素 1\n\n\n队列队列是一种具有 「先入先出」 特点的抽象数据结构，可使用链表实现。\nqueue&lt;int&gt; que;\n如下图所示，通过常用操作「入队 push()」,「出队 pop()」，展示了队列的先入先出特性。\nque.push(1); // 元素 1 入队que.push(2); // 元素 2 入队que.pop();   // 出队 -&gt; 元素 1que.pop();   // 出队 -&gt; 元素 2\n\n\n树树是一种非线性数据结构，根据子节点数量可分为 「二叉树」 和 「多叉树」，最顶层的节点称为「根节点 root」。以二叉树为例，每个节点包含三个成员变量：「值 val」、「左子节点 left」、「右子节点 right」 。\nstruct TreeNode &#123;    int val;         // 节点值    TreeNode *left;  // 左子节点    TreeNode *right; // 右子节点    TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125;&#125;;\n如下图所示，建立此二叉树需要实例化每个节点，并构建各节点的引用指向。\n// 初始化节点TreeNode *n1 = new TreeNode(3); // 根节点 rootTreeNode *n2 = new TreeNode(4);TreeNode *n3 = new TreeNode(5);TreeNode *n4 = new TreeNode(1);TreeNode *n5 = new TreeNode(2);// 构建引用指向n1-&gt;left = n2;n1-&gt;right = n3;n2-&gt;left = n4;n2-&gt;right = n5;\n\n\n图图是一种非线性数据结构，由「节点（顶点）vertex」和「边 edge」组成，每条边连接一对顶点。根据边的方向有无，图可分为「有向图」和「无向图」。本文 以无向图为例 开展介绍。\n如下图所示，此无向图的 顶点 和 边 集合分别为：\n\n顶点集合： vertices = &#123;1, 2, 3, 4, 5&#125;\n边集合： edges = &#123;(1, 2), (1, 3), (1, 4), (1, 5), (2, 4), (3, 5), (4, 5)&#125;\n\n\n表示图的方法通常有两种：\n邻接矩阵：\nint vertices[5] = &#123;1, 2, 3, 4, 5&#125;;int edges[5][5] = &#123;&#123;0, 1, 1, 1, 1&#125;,                   &#123;1, 0, 0, 1, 0&#125;,                   &#123;1, 0, 0, 0, 1&#125;,                   &#123;1, 1, 0, 0, 1&#125;,                   &#123;1, 0, 1, 1, 0&#125;&#125;;\n\n邻接表：\n\n顶点存储: 数组 vertices 存储顶点值\n边存储: 二维容器 edges 存储边关系\n第一维 i 表示顶点索引（对应 vertices[i]）\n第二维 edges[i] 存储该顶点连接的目标顶点值集合\nedges[i] 中的数字直接表示目标顶点值**（非索引）\n例如 edges[0] = [1,2,3,4] 表示顶点1连接到值2/3/4/5（注意实际值比索引大1）\n\n\n\nint vertices[5] = &#123;1, 2, 3, 4, 5&#125;;vector&lt;vector&lt;int&gt;&gt; edges;vector&lt;int&gt; edge_1 = &#123;1, 2, 3, 4&#125;;vector&lt;int&gt; edge_2 = &#123;0, 3&#125;;vector&lt;int&gt; edge_3 = &#123;0, 4&#125;;vector&lt;int&gt; edge_4 = &#123;0, 1, 4&#125;;vector&lt;int&gt; edge_5 = &#123;0, 2, 3&#125;;edges.push_back(edge_1);edges.push_back(edge_2);edges.push_back(edge_3);edges.push_back(edge_4);edges.push_back(edge_5);\n\n邻接矩阵 VS 邻接表 ：\n邻接矩阵的大小只与节点数量有关，即 N2N2 ，其中 NN 为节点数量。因此，当边数量明显少于节点数量时，使用邻接矩阵存储图会造成较大的内存浪费。因此，邻接表 适合存储稀疏图（顶点较多、边较少）； 邻接矩阵 适合存储稠密图（顶点较少、边较多）。\n\n\n散列表散列表是一种非线性数据结构，通过利用 Hash 函数将指定的「键 key」映射至对应的「值 value」，以实现高效的元素查找。\n\n设想一个简单场景：小力、小特、小扣的学号分别为 10001, 10002, 10003 。现需求从「姓名」查找「学号」。\n\n则可通过建立姓名为 key ，学号为 value 的散列表实现此需求，代码如下：\n// 初始化散列表unordered_map&lt;string, int&gt; dic;// 添加 key -&gt; value 键值对dic[&quot;小力&quot;] = 10001;dic[&quot;小特&quot;] = 10002;dic[&quot;小扣&quot;] = 10003;// 从姓名查找学号dic.find(&quot;小力&quot;)-&gt;second; // -&gt; 10001dic.find(&quot;小特&quot;)-&gt;second; // -&gt; 10002dic.find(&quot;小扣&quot;)-&gt;second; // -&gt; 10003\n\nHash 函数设计示例 ：\n\n假设需求：从「学号」查找「姓名」。\n\n将三人的姓名存储至以下数组中，则各姓名在数组中的索引分别为 0, 1, 2 。\nstring names[] = &#123; &quot;小力&quot;, &quot;小特&quot;, &quot;小扣&quot; &#125;;\n此时，我们构造一个简单的 Hash 函数（ %% 为取余符号 ），公式和封装函数如下所示：\nhash(key)=(key−1)%10000\nint hash(int id) &#123;    int index = (id - 1) % 10000;    return index;&#125;\n则我们构建了以学号为 key 、姓名对应的数组索引为 value 的散列表。利用此 Hash 函数，则可在 O(1)O(1) 时间复杂度下通过学号查找到对应姓名，即：\nnames[hash(10001)] // 小力names[hash(10002)] // 小特names[hash(10003)] // 小扣\n\n以上设计只适用于此示例，实际的 Hash 函数需保证低碰撞率、 高鲁棒性等，以适用于各类数据和场景。\n\n堆堆是一种基于「完全二叉树」的数据结构，可使用数组实现。以堆为原理的排序算法称为「堆排序」，基于堆实现的数据结构为「优先队列」。堆分为「大顶堆」和「小顶堆」，大（小）顶堆：任意节点的值不大于（小于）其父节点的值。\n\n完全二叉树定义： 设二叉树深度为 kk ，若二叉树除第 kk 层外的其它各层（第 11 至 k−1k−1 层）的节点达到最大个数，且处于第 kk 层的节点都连续集中在最左边，则称此二叉树为完全二叉树。\n\n如下图所示，为包含 1, 4, 2, 6, 8 元素的小顶堆。将堆（完全二叉树）中的结点按层编号，即可映射到右边的数组存储形式。\n\n通过使用「优先队列」的「压入 push()」和「弹出 pop()」操作，即可完成堆排序，实现代码如下：\n// 初始化小顶堆priority_queue&lt;int, vector&lt;int&gt;, greater&lt;int&gt;&gt; heap;// 元素入堆heap.push(1);heap.push(4);heap.push(2);heap.push(6);heap.push(8);// 元素出堆（从小到大）heap.pop(); // -&gt; 1heap.pop(); // -&gt; 2heap.pop(); // -&gt; 4heap.pop(); // -&gt; 6heap.pop(); // -&gt; 8\n","categories":["数据结构"],"tags":["数据结构"]},{"title":"数据结构-线性表（顺序表）","url":"/Arknight-notes/posts/23014.html","content":"\n线性表说起这个问题，我们一定不陌生。打开QQ或微信，我们可以看到好友列表，打开PTA，我们能看到题目列表，打开音乐软件，我们可以看见歌曲列表，线性表在我们的生活中无处不在。线性表是怎么呈现的呢？线性表把我们在生活中需要的信息，按照顺序进行排列，使得这些信息直观、有条理，如果是按照某种顺序排列的列表，我们可以做到信息的快速检索。\n\n1) 线性表（线性存储结构）线性表又称线性存储结构，是最简单的一种存储结构，专门用来存储逻辑关系为“一对一”的数据。\n在一个数据集中，如果每个数据的左侧都有且仅有一个数据和它有关系，数据的右侧也有且仅有一个数据和它有关系，那么这些数据之间就是“一对一“的逻辑关系。\n所谓线性表，是零个或多个数据元素的有限序列，线性表的元素具有相同的特征，数据元素之间的关系是一对一的关系。\n\n如上图所示，在 {1,2,3,4,5} 数据集中，每个数据的左侧都有且仅有一个数据和它紧挨着（除 1 外），右侧也有且仅有一个数据和它紧挨着（除 5 外），这些数据之间就是“一对一“的关系。\n使用线性表存储具有“一对一“逻辑关系的数据，不仅可以将所有数据存储到内存中，还可以将“一对一”的逻辑关系也存储到内存中。\n线性表存储数据的方案可以这样来理解，先用一根线将所有数据按照先后次序“串”起来，如下图所示：\n\n数据和“一对一”的逻辑关系\n左侧是“串”起来的数据，右侧是空闲的物理空间。将这“一串儿”数据存放到物理空间中，有以下两种方法：\n\n两种存储方式都可以将数据之间的关系存储起来，从线的一头开始捋，可以依次找到每个数据，且数据的前后位置没有发生改变。\n像上图这样，用一根线将具有“一对一”逻辑关系的数据存储起来，这样的存储方式就称为线性表或者线性存储结构。\n顺序存储结构和链式存储结构从图 3 不难看出，线性表存储数据的实现方案有两种，分别是：\n\n像图 3a) 那样，不破坏数据的前后次序，将它们连续存储在内存空间中，这样的存储方案称为顺序存储结构（简称顺序表）；\n像图 3b) 那样，将所有数据分散存储在内存中，数据之间的逻辑关系全靠“一根线”维系，这样的存储方案称为链式存储结构（简称链表）。\n\n也就是说，使用线性表存储数据，有两种真正可以落地的存储方案，分别是顺序表和链表。\n前驱和后继在具有“一对一“逻辑关系的数据集中，每个个体习惯称为数据元素（简称元素）。例如，图 1 显示的这组数据集中，一共有 5 个元素，分别是 1、2、3、4 和 5。\n此外，很多教程中喜欢用前驱和后继来描述元素之间的前后次序：\n\n某一元素的左侧相邻元素称为该元素的“直接前驱”，此元素左侧的所有元素统称为该元素的“前驱元素”；\n某一元素的右侧相邻元素称为该元素的“直接后继”，此元素右侧的所有元素统称为该元素的“后继元素”；\n\n以图 1 数据中的元素 3 来说，它的直接前驱是 2 ，此元素的前驱元素有 2 个，分别是 1 和 2；同理，此元素的直接后继是 4 ，后继元素也有 2 个，分别是 4 和 5。\n\n2) 顺序表（顺序存储结构）顺序表又称顺序存储结构，是线性表的一种，专门存储逻辑关系为“一对一”的数据。\n顺序表存储数据的具体实现方案是：将数据全部存储到一整块内存空间中，数据元素之间按照次序挨个存放。\n举个简单的例子，将 {1,2,3,4,5} 这些数据使用顺序表存储，数据最终的存储状态如下图所示：\n\n线性表的抽象数据结构ADT List&#123;    Data:        D = &#123;ai | 1 ≤ i ≤ n, n ≥ 0, ai 为 ElemType 类型&#125;    Relation：        R = &#123; &lt;ai,ai+1&gt; | ai,ai+1 ∈ D, i = 1, i ∈ (0,n)&#125;    Operation:        InitList(&amp;L);    //初始化，建立一个空的线性表L        MakeList(&amp;L);    //建立线性表，向表中存入数据        ListEmpty(*L);    //空表判断，是则返回true,否则返回false        DestroyList(&amp;L);    //清除操作，清空线性表的元素        GetElem(L,i,&amp;e);    //获取线性表的元素，将线性表L的第i个元素的值返回给e        LocateElem(L,e);    //按值查找元素，在线性表L中查找与e元素相等的元素，查找成功返回对应的序号，查找失败则返回0        ListInsert(&amp;L,i,e);    //插入操作，在线性表L的第i个位置插入元素e        ListDelete(&amp;L,i,&amp;e);    //删除操作，删除线性表L中的第i个位置的元素，并将其用e返回        ListLength(L);    //计算表长，返回线性表L的元素个数        DispList(L);    //输出线性表，当线性表不为空表时，按顺序输出表中的每一个元素&#125;\n顺序表的建立使用顺序表存储数据，除了存储数据本身的值以外，通常还会记录以下两样数据：\n\n顺序表的最大存储容量：顺序表最多可以存储的数据个数；\n顺序表的长度：当前顺序表中存储的数据个数。\n\nC 语言中，可以定义一个结构体来表示顺序表：\ntypedef struct&#123;    int * head; //定义一个名为head的长度不确定的数组，也叫“动态数组”    int length; //记录当前顺序表的长度    int size; //记录顺序表的存储容量&#125;Table;\n尝试建立一个顺序表，例如：\n#define Size 5 //对Size进行宏定义，表示顺序表的最大容量void initTable(Table * t) &#123;    //构造一个空的顺序表，动态申请存储空间    t-&gt;head = (int*)malloc(Size * sizeof(int)); //申请内存空间    //如果申请失败，作出提示并直接退出程序    if (!t-&gt;head)    &#123;        printf(&quot;初始化失败&quot;);        exit(0);    &#125;    //空表的长度初始化为0    t-&gt;length = 0;    //空表的初始存储空间为Size    t-&gt;size = Size;&#125;\n如上所示，整个建立顺序表的过程都封装在一个函数中，建好的顺序表可以存储 5 个逻辑关系为“一对一”的整数。\n在顺序表的实现中，t-&gt;head 是一个指向动态数组基地址的指针，其核心作用是为顺序表提供存储数据的连续内存空间。以下是具体解析：\n\n1. t-&gt;head 的定义与作用• 定义：  t-&gt;head 是顺序表结构体中的一个成员变量，通常声明为动态数组的起始地址指针。例如在 C 语言中，顺序表的结构体定义如下：  typedef struct &#123;    int *head;  // 动态数组基地址    int length; // 当前元素个数    int size;   // 总存储容量&#125; Table;\n顺序表的使用通过调用 initTable() 函数，就可以成功地创建一个顺序表，还可以往顺序表中存储一些元素。\n例如，将 {1,2,3,4,5} 存储到顺序表中，实现代码如下：\n#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#define Size 5 //对Size进行宏定义，表示顺序表的最大容量typedef struct&#123;    int* head;    int length;    int size;&#125;Table;void initTable(Table * t) &#123;    //构造一个空的顺序表，动态申请存储空间    t-&gt;head = (int*)malloc(Size * sizeof(int));    //如果申请失败，作出提示并直接退出程序    if (!t-&gt;head) //无头（申请失败）    &#123;        printf(&quot;初始化失败&quot;);        exit(0);    &#125;    //空表的长度初始化为0    t-&gt;length = 0; //t-&gt;length：当前元素个数    //空表的初始存储空间为Size    t-&gt;size = Size; //t-&gt;size：总存储容量&#125;//输出顺序表中元素的函数void displayTable(Table t) &#123;    int i;    for (i = 0; i &lt; t.length; i++) &#123;        printf(&quot;%d &quot;, t.head[i]);    &#125;    printf(&quot;\\n&quot;);&#125;int main() &#123;    int i;    Table t = &#123; NULL,0,0 &#125;;    initTable(&amp;t);    //向顺序表中添加&#123;1,2,3,4,5&#125;    for (i = 1; i &lt;= Size; i++) &#123;        t.head[i - 1] = i;        t.length++;    &#125;    printf(&quot;顺序表中存储的元素分别是：\\n&quot;);    displayTable(t);    free(t.head);//释放申请的堆内存    return 0;&#125;\n程序运行结果如下：\n\n顺序表中存储的元素分别是： 1 2 3 4 5\n\n3) 顺序表的基本操作我们学习了顺序表及初始化的过程，本节学习有关顺序表的一些基本操作，以及如何使用 C 语言实现它们。\n顺序表插入元素向已有顺序表中插入数据元素，根据插入位置的不同，可分为以下 3 种情况：\n\n插入到顺序表的表头；\n在表的中间位置插入元素；\n尾随顺序表中已有元素，作为顺序表中的最后一个元素；\n\n虽然数据元素插入顺序表中的位置有所不同，但是都使用的是同一种方式去解决，即：通过遍历，找到数据元素要插入的位置，然后做如下两步工作：\n\n将要插入位置元素以及后续的元素整体向后移动一个位置；\n将元素放到腾出来的位置上；\n\n例如，在 {1,2,3,4,5} 的第 3 个位置上插入元素 6，实现过程如下：\n\n遍历至顺序表存储第 3 个数据元素的位置\n\n\n\n将元素 3、4 和 5 整体向后移动一个位置\n\n\n\n将新元素 6 放入腾出的位置\n\n\n因此，顺序表插入数据元素的 C 语言实现代码如下：\n//插入函数，其中，elem为插入的元素，add为插入到顺序表的位置void insertTable(Table* t, int elem, int add)&#123;    int i;            //如果插入元素位置(add)比整张表的长度+1(t-&gt;length + 1)还大（如果相等，是尾随的情况），或者插入的位置本身不存在，程序作为提示并自动退出    if (add &gt; t-&gt;length + 1 || add &lt; 1) &#123;        printf(&quot;插入位置有问题\\n&quot;);        return;    &#125;            //做插入操作时，首先需要看顺序表是否有多余的存储空间提供给插入的元素，有就是(t-&gt;length &lt; t-&gt;size)，如果没有就是(t-&gt;length == t-&gt;size)，需要申请    if (t-&gt;length == t-&gt;size) &#123;        t-&gt;head = (int*)realloc(t-&gt;head, (t-&gt;size + 1) * sizeof(int));        //重新分配内存，动态数组额外申请更多物理空间        if (!t-&gt;head) &#123;            printf(&quot;存储分配失败\\n&quot;);            return;        &#125;        t-&gt;size += 1;    &#125;            //插入操作，需要将自插入位置之后的所有元素(从t-&gt;length - 1倒数到add - 1)全部后移一位    for (i = t-&gt;length - 1; i &gt;= add - 1; i--) &#123;        t-&gt;head[i + 1] = t-&gt;head[i];    &#125;        //后移完成后，直接插入元素    t-&gt;head[add - 1] = elem;    t-&gt;length++;&#125;\n注意，动态数组额外申请更多物理空间使用的是 realloc 函数。此外在实现元素整体后移的过程中，目标位置其实是有数据的，还是 3，只是下一步新插入元素时会把旧元素直接覆盖。\n顺序表删除元素从顺序表中删除指定元素，实现起来非常简单，只需找到目标元素，并将其后续所有元素整体前移 1 个位置即可。\n后续元素整体前移一个位置，会直接将目标元素删除，可间接实现删除元素的目的。\n例如，从 {1,2,3,4,5} 中删除元素 3 的过程如图 4 所示：\n\n因此，顺序表删除元素的 C 语言实现代码为：\nvoid delTable(Table* t, int add) &#123;    int i;    if (add &gt; t-&gt;length || add &lt; 1) &#123;  //删除元素位置大于表长或小于0        printf(&quot;被删除元素的位置有误\\n&quot;);        return;    &#125;    //删除操作    for (i = add; i &lt; t-&gt;length; i++) &#123;        t-&gt;head[i - 1] = t-&gt;head[i];    &#125;    t-&gt;length--;//表长减短&#125;\n顺序表查找元素顺序表中查找目标元素，可以使用多种查找算法实现，比如说二分查找算法、插值查找算法等。\n这里，我们选择顺序查找算法，具体实现代码为：\n//查找函数，其中，elem表示要查找的数据元素的值int selectTable(table t,int elem)&#123;    for (int i=0; i&lt;t.length; i++) &#123;        if (t.head[i]==elem) &#123;            return i+1;        &#125;    &#125;    return -1;//如果查找失败，返回-1&#125;\n顺序表更改元素顺序表更改元素的实现过程是：\n\n找到目标元素；\n直接修改该元素的值；\n\n顺序表更改元素的 C 语言实现代码为：\nvoid amendTable(Table* t, int elem, int newElem) &#123;    int add = selectTable(*t, elem);    if (add == -1) &#123;        printf(&quot;顺序表中没有找到目标元素\\n&quot;);        return;    &#125;    t-&gt;head[add - 1] = newElem;&#125;\n关于 t-&gt;head,t-&gt;length和 t-&gt;size• 物理存储管理：  t-&gt;head 指向通过 malloc 或 realloc 动态申请的内存块的首地址。顺序表中的所有元素按逻辑顺序连续存储在这段内存中。\n• 操作接口：  通过 t-&gt;head 可直接访问顺序表的元素，例如：  • 插入：t-&gt;head[add-1] = elem 将元素写入指定位置。  • 遍历：通过 t-&gt;head[i] 访问第 i 个元素。\n顺序表初始化时，t-&gt;head 被赋予动态分配的内存地址。例如：  \nvoid initTable(Table *t) &#123;    t-&gt;head = (int*)malloc(Size * sizeof(int));  // 申请初始内存    t-&gt;length = 0;    t-&gt;size = Size;&#125;\n若内存分配失败，t-&gt;head 会指向 NULL，此时需进行错误处理。\n所有对顺序表元素的增删查改均通过 t-&gt;head 实现：• 插入元素：将后续元素右移后，直接通过 t-&gt;head[add-1] 写入新值。• 删除元素：左移覆盖目标元素后，通过 t-&gt;head 重新定位后续元素。\nt-&gt;head 是顺序表实现中动态内存管理的核心，它指向存储数据的连续内存块，并通过指针操作支持元素的增删查改。\n在顺序表的实现中，t-&gt;length和t-&gt;size是两个关键字段，它们的含义及设计逻辑如下：\n\n1. t-&gt;length：当前元素个数\n• 定义：表示顺序表中实际存储的有效元素数量，即当前表内数据的逻辑长度。• 作用：  • 控制插入/删除操作的合法性（例如插入位置不能超过length+1，删除位置不能超过length）。  • 遍历时确定元素范围（从下标0到length-1）。• 示例：若顺序表存储&#123;1,2,3&#125;，则length=3。\n\n2. t-&gt;size：总存储容量\n• 定义：表示顺序表已申请的内存空间能容纳的最大元素数量，即物理存储容量。• 作用：  • 判断是否需要扩容（当length == size时，表已满需扩展内存）。  • 动态调整内存时记录当前分配的空间上限。• 示例：若初始分配容量为size=5，插入5个元素后length=5，此时需扩容才能继续插入。\n\n3. 两者的区别与联系\n\n\n\n\n字段\n意义\n操作触发条件\n命名逻辑\n\n\n\n\nlength\n实际元素个数（动态变化）\n插入时位置需满足1 ≤ add ≤ length+1\n直观体现“逻辑长度”，类似数组的size()\n\n\nsize\n最大容量（静态/动态）\n扩容条件为length == size\n体现“物理容量上限”，类似容器的capacity()\n\n\n\n\n\n逻辑与物理分离：• length关注数据逻辑层面的使用情况，size关注物理内存的管理，两者分离便于维护动态内存。\n\n操作安全性：• 通过length限制插入/删除位置，避免越界访问；通过size判断内存是否耗尽，防止溢出。\n\n动态扩容机制：• 当length达到size时，触发realloc扩展内存（例如每次扩容固定步长或按倍数增长），保证数据连续性。\n插入函数中：\n\n\nif (add &gt; t-&gt;length + 1 || add &lt; 1) &#123;    printf(&quot;插入位置有问题\\n&quot;);    return;&#125;if (t-&gt;length == t-&gt;size) &#123;    t-&gt;head = (int*)realloc(t-&gt;head, (t-&gt;size + 1) * sizeof(int));    // 扩容逻辑...&#125;\n• add &gt; t-&gt;length + 1：确保插入位置不超过逻辑长度的下一个合法位置（如length=3时，允许插入到第4位，但不可到第5位）。• t-&gt;length == t-&gt;size：触发扩容的条件，保证物理空间始终足够容纳逻辑元素。\nt-&gt;length和t-&gt;size是顺序表实现中动态内存管理与逻辑操作控制的核心字段。通过两者的协同，既能高效利用内存，又能确保数据操作的合法性。\n其他操作的实现逆序void reverseTable(Table* t) &#123;    if (t-&gt;length &lt;= 1) return; // 空表或单元素表无需处理        for (int i = 0; i &lt; t-&gt;length / 2; i++) &#123;        int temp = t-&gt;head[i];        t-&gt;head[i] = t-&gt;head[t-&gt;length - 1 - i];        t-&gt;head[t-&gt;length - 1 - i] = temp;    &#125;&#125;\n输出表长int ListLength(Table* t) &#123;    return L-&gt;length; // 直接返回顺序表的当前长度&#125;\n删除全表void SeqListDestory(Table* t) &#123;    assert(t);  // 确保传入的指针非空    free(t-&gt;head);  // 释放动态数组内存    t-&gt;head = NULL;  // 指针置空    t-&gt;size = 0;  // 容量归零    t-&gt;length = 0;  // 元素个数归零&#125;\n完整代码实现以下是一个完整的顺序表操作示例代码，包含初始化、插入、删除、查找、修改、逆序、销毁等操作，并在main函数中展示了具体调用逻辑：\n#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;assert.h&gt;#define INIT_SIZE 5  // 初始容量typedef struct &#123;    int* head;    // 动态数组基地址    int length;   // 当前元素个数    int size;     // 总存储容量&#125; Table;// 初始化顺序表void initTable(Table* t) &#123;    t-&gt;head = (int*)malloc(INIT_SIZE * sizeof(int));    if (!t-&gt;head) &#123;        printf(&quot;内存分配失败\\n&quot;);        exit(EXIT_FAILURE);    &#125;    t-&gt;length = 0;    t-&gt;size = INIT_SIZE;&#125;// 插入元素（位置从1开始）void insertTable(Table* t, int elem, int pos) &#123;    if (pos &lt; 1 || pos &gt; t-&gt;length + 1) &#123;        printf(&quot;非法插入位置: %d\\n&quot;, pos);        return;    &#125;        // 容量检查与扩容    if (t-&gt;length == t-&gt;size) &#123;        int new_size = t-&gt;size * 2;  // 容量翻倍        int* new_head = (int*)realloc(t-&gt;head, new_size * sizeof(int));        if (!new_head) &#123;            printf(&quot;扩容失败\\n&quot;);            return;        &#125;        t-&gt;head = new_head;        t-&gt;size = new_size;        printf(&quot;已扩容至 %d\\n&quot;, new_size);    &#125;    // 元素后移    for (int i = t-&gt;length; i &gt;= pos; i--) &#123;        t-&gt;head[i] = t-&gt;head[i - 1];    &#125;        t-&gt;head[pos - 1] = elem;    t-&gt;length++;&#125;// 删除元素（位置从1开始）void delTable(Table* t, int pos) &#123;    if (pos &lt; 1 || pos &gt; t-&gt;length) &#123;        printf(&quot;非法删除位置: %d\\n&quot;, pos);        return;    &#125;        // 元素前移覆盖    for (int i = pos; i &lt; t-&gt;length; i++) &#123;        t-&gt;head[i - 1] = t-&gt;head[i];    &#125;    t-&gt;length--;&#125;// 查找元素（返回位置，从1开始）int selectTable(Table* t, int elem) &#123;    for (int i = 0; i &lt; t-&gt;length; i++) &#123;        if (t-&gt;head[i] == elem) &#123;            return i + 1;// 返回元素位置        &#125;    &#125;    return -1;  // 未找到&#125;// 修改元素值void amendTable(Table* t, int old_elem, int new_elem) &#123;    int pos = selectTable(t, old_elem); // 查找元素    if (pos == -1) &#123;        printf(&quot;元素 %d 不存在\\n&quot;, old_elem);        return;    &#125;    t-&gt;head[pos - 1] = new_elem;&#125;// 逆序顺序表void reverseTable(Table* t) &#123;    for (int i = 0; i &lt; t-&gt;length / 2; i++) &#123;        int temp = t-&gt;head[i];        t-&gt;head[i] = t-&gt;head[t-&gt;length - 1 - i];        t-&gt;head[t-&gt;length - 1 - i] = temp;    &#125;&#125;// 销毁顺序表void destroyTable(Table* t) &#123;    free(t-&gt;head);    t-&gt;head = NULL;    t-&gt;length = 0;    t-&gt;size = 0;&#125;// 打印顺序表void displayTable(Table* t) &#123;    printf(&quot;[当前表长: %d, 总容量: %d]\\n&quot;, t-&gt;length, t-&gt;size);    for (int i = 0; i &lt; t-&gt;length; i++) &#123;        printf(&quot;%d &quot;, t-&gt;head[i]);    &#125;    printf(&quot;\\n\\n&quot;);&#125;int main() &#123;    Table my_table; //声明一个名为 my_table 的变量，其类型为 Table 结构体        // 1. 初始化    initTable(&amp;my_table);    //&amp;my_table的作用是将结构体的地址传递给函数，使函数能通过指针直接修改原始变量    printf(&quot;=== 初始化顺序表 ===\\n&quot;);    displayTable(&amp;my_table);    // 2. 插入初始元素    for (int i = 1; i &lt;= 5; i++) &#123;        insertTable(&amp;my_table, i, i);    &#125;    printf(&quot;=== 插入5个元素 ===\\n&quot;);    displayTable(&amp;my_table);    // 3. 测试扩容插入    insertTable(&amp;my_table, 6, 3);  // 在第3位插入6    printf(&quot;=== 插入第6个元素触发扩容 ===\\n&quot;);    displayTable(&amp;my_table);    // 4. 删除元素    delTable(&amp;my_table, 2);  // 删除第2个元素    printf(&quot;=== 删除第2个元素 ===\\n&quot;);    displayTable(&amp;my_table);    // 5. 查找元素    int target = 6;    int pos = selectTable(&amp;my_table, target);    printf(&quot;=== 查找元素 %d ===\\n&quot;, target);    if (pos != -1) &#123;        printf(&quot;元素 %d 位于第 %d 位\\n&quot;, target, pos);    &#125; else &#123;        printf(&quot;元素不存在\\n&quot;);    &#125;    // 6. 修改元素    amendTable(&amp;my_table, 6, 66);    printf(&quot;=== 修改元素 6 → 66 ===\\n&quot;);    displayTable(&amp;my_table);    // 7. 逆序操作    reverseTable(&amp;my_table);    printf(&quot;=== 逆序顺序表 ===\\n&quot;);    displayTable(&amp;my_table);    // 8. 销毁顺序表    destroyTable(&amp;my_table);    printf(&quot;=== 销毁后的状态 ===\\n&quot;);    printf(&quot;指针状态: %s\\n&quot;, (my_table.head == NULL) ? &quot;已释放&quot; : &quot;未释放&quot;);        return 0;&#125;\n关键调用逻辑说明：\n初始化顺序表 \ninitTable(&amp;my_table);\n• 创建空表，初始容量为5• 时间复杂度：O(1)\n\n批量插入元素\nfor (int i = 1; i &lt;= 5; i++) &#123;    insertTable(&amp;my_table, i, i);&#125;\n• 插入5个元素填满初始容量• 时间复杂度：O(n)\n\n触发扩容插入 \ninsertTable(&amp;my_table, 6, 3);\n• 当插入第6个元素时触发动态扩容（容量翻倍为10）• 时间复杂度：O(n)\n\n删除元素 \ndelTable(&amp;my_table, 2);\n• 删除第2个元素（值为2），后续元素前移• 时间复杂度：O(n)\n\n元素查找 \nselectTable(&amp;my_table, target);\n• 使用顺序查找，返回元素位置• 时间复杂度：O(n)\n\n逆序操作\nreverseTable(&amp;my_table);\n• 通过对称交换实现逆序• 时间复杂度：O(n)\n\n销毁顺序表 \ndestroyTable(&amp;my_table);\n• 释放动态内存并将指针置空• 防止内存泄漏的关键操作\n\n\n执行结果示例：=== 初始化顺序表 ===[当前表长: 0, 总容量: 5]=== 插入5个元素 ===[当前表长: 5, 总容量: 5]1 2 3 4 5 已扩容至 10=== 插入第6个元素触发扩容 ===[当前表长: 6, 总容量: 10]1 2 6 3 4 5 === 删除第2个元素 ===[当前表长: 5, 总容量: 10]1 6 3 4 5 === 查找元素 6 ===元素 6 位于第 2 位=== 修改元素 6 → 66 ===[当前表长: 5, 总容量: 10]1 66 3 4 5 === 逆序顺序表 ===[当前表长: 5, 总容量: 10]5 4 3 66 1 === 销毁后的状态 ===指针状态: 已释放\n复杂度对比：\n\n\n\n操作\n最好情况\n最坏情况\n平均情况\n\n\n\n\n插入\nO(1)\nO(n)\nO(n)\n\n\n删除\nO(1)\nO(n)\nO(n)\n\n\n查找\nO(1)\nO(n)\nO(n)\n\n\n逆序\n-\nO(n)\nO(n)\n\n\n初始化\nO(1)\nO(1)\nO(1)\n\n\n\n\n​    首先是插入操作，插入操作时间复杂度最小的情况是，当元素要插入到最后一个位置时，你就不需要移动任何元素即可实现，只需要将需要插入的元素插在表的末端即可，时间复杂度O(1)，最费时的操作就是插入的元素要放在表头，那我们就需要把表中的所有元素都移动了,时间复杂度为O(n)。\n​    删除操作也如此，当我们要删除最后一个元素，也不需要移动顺序表，而删除第一个元素时需要移动整个表。我们知道，在实际的操作中，删除表中的任何一个位置需要被插入删除的可能性是相同的，因此从平均角度来分析，移动表的平均次数为 (n - 1) / 2，时间复杂度为O(n)。​    因此我们可以看出，顺序表在插入、删除操作时是比较费时间的，然而其他的基本操作例如初始化、建表或者销毁，时间复杂度都是O(1)，因此我们在使用顺序表的时候，要尽量让表保持不变，而是多多使用顺序表的存储和随机提取等优点。\n优缺点分析顺序表主要有如下一些优点：\n\n顺序表进行随机提取元素的效率较高，能够快速存储、提取元素；\n建表时无需对表中元素的逻辑关系进行描述，各元素在存储地址上是连续的；\n对于CPU，顺序表的高速缓存效率更高，且CPU流水线也不会总是被打断。\n\n顺序表主要有如下一些缺点：\n\n申请顺序表时，顺序表存储元素的上限是固定的，这就导致了存在溢出的可能性；\n插入、删除元素时，时间复杂度较大，需要大范围移动表中的元素；\n由于我们在很多情况下无法预知需要存储多少元素，因此容易导致内存碎片的现象，即申请了空间却没有充分利用。\n\n关于链表再新开一个页面\n","categories":["数据结构"],"tags":["数据结构","顺序表"]},{"title":"数据结构-线性表（链表）","url":"/Arknight-notes/posts/42928.html","content":"链表（链式存储结构）链表又称单链表、链式存储结构，用于存储逻辑关系为“一对一”的数据。\n和顺序表不同，使用链表存储数据，不强制要求数据在内存中集中存储，各个元素可以分散存储在内存中。例如，使用链表存储 {1,2,3}，各个元素在内存中的存储状态可能是：\n\n可以看到，数据不仅没有集中存放，在内存中的存储次序也是混乱的。那么，链表是如何存储数据间逻辑关系的呢？\n链表存储数据间逻辑关系的实现方案是：为每一个元素配置一个指针，每个元素的指针都指向自己的直接后继元素，如下图所示：\n\n显然，我们只需要记住元素 1 的存储位置，通过它的指针就可以找到元素 2，通过元素 2 的指针就可以找到元素 3，以此类推，各个元素的先后次序一目了然。\n像图 2 这样，数据元素随机存储在内存中，通过指针维系数据之间“一对一”的逻辑关系，这样的存储结构就是链表。\n结点（节点）\n很多教材中，也将“结点”写成“节点”，它们是一个意思。\n\n在链表中，每个数据元素都配有一个指针，这意味着，链表上的每个“元素”都长下图这个样子：\n\n数据域用来存储元素的值，指针域用来存放指针。数据结构中，通常将图 3 这样的整体称为结点。\n也就是说，链表中实际存放的是一个一个的结点，数据元素存放在各个结点的数据域中。举个简单的例子，图 2 中 {1,2,3} 的存储状态用链表表示，如下图所示：\n\n在 C 语言中，可以用结构体表示链表中的结点，例如：\ntypedef struct link&#123;    char elem; //代表数据域    struct link * next; //代表指针域，指向直接后继元素&#125;Link;\n\n我们习惯将结点中的指针命名为 next，因此指针域又常称为“Next 域”。\n\n头结点、头指针和首元结点图 4 所示的链表并不完整，一个完整的链表应该由以下几部分构成：\n\n头指针：一个和结点类型相同的指针，它的特点是：永远指向链表中的第一个结点。上文提到过，我们需要记录链表中第一个元素的存储位置，就是用头指针实现。\n结点：链表中的节点又细分为头结点、首元结点和其它结点：\n\n\n头结点：某些场景中，为了方便解决问题，会故意在链表的开头放置一个空结点，这样的结点就称为头结点。也就是说，头结点是位于链表开头、数据域为空（不利用）的结点。\n首元结点：指的是链表开头第一个存有数据的结点。\n其他节点：链表中其他的节点。\n\n也就是说，一个完整的链表是由头指针和诸多个结点构成的。每个链表都必须有头指针，但头结点不是必须的。\n例如，创建一个包含头结点的链表存储 {1,2,3}，如下图所示：\n\n再次强调，头指针永远指向链表中的第一个结点。换句话说，如果链表中包含头结点，那么头指针指向的是头结点，反之头指针指向首元结点。\n链表的创建创建一个链表，实现步骤如下：\n\n定义一个头指针；\n创建一个头结点或者首元结点，让头指针指向它；\n每创建一个结点，都令其直接前驱结点的指针指向它。\n\n例如，创建一个存储 {1,2,3,4} 且无头节点的链表，C 语言实现代码为：\nLink* initLink() &#123;    int i;    //1、创建头指针    Link* p = NULL;    //2、创建首元结点    Link* temp = (Link*)malloc(sizeof(Link));    temp-&gt;elem = 1;    temp-&gt;next = NULL;    //头指针指向首元结点    p = temp;    //3、每创建一个结点，都令其直接前驱结点的指针指向它    for (i = 2; i &lt; 5; i++) &#123;        //创建一个结点        Link* a = (Link*)malloc(sizeof(Link));        a-&gt;elem = i;        a-&gt;next = NULL;        //每次 temp 指向的结点就是 a 的直接前驱结点        temp-&gt;next = a;        //temp指向下一个结点（也就是a),为下次添加结点做准备        temp = temp-&gt;next;    &#125;    return p;&#125;\n再比如，创建一个存储 {1,2,3,4} 且含头节点的链表，则 C 语言实现代码为：\nLink* initLink() &#123;    int i;    //1、创建头指针    Link* p = NULL;    //2、创建头结点    Link* temp = (Link*)malloc(sizeof(Link));    temp-&gt;elem = 0;    temp-&gt;next = NULL;    //头指针指向头结点    p = temp;    //3、每创建一个结点，都令其直接前驱结点的指针指向它    for (i = 1; i &lt; 5; i++) &#123;        //创建一个结点        Link* a = (Link*)malloc(sizeof(Link));        a-&gt;elem = i;        a-&gt;next = NULL;        //每次 temp 指向的结点就是 a 的直接前驱结点        temp-&gt;next = a;        //temp指向下一个结点（也就是a),为下次添加结点做准备        temp = temp-&gt;next;    &#125;    return p;&#125;\n链表的使用对于创建好的链表，我们可以依次获取链表中存储的数据，例如：\n#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;//链表中节点的结构typedef struct link &#123;    int  elem;    struct link* next;&#125;Link;Link* initLink() &#123;    int i;    //1、创建头指针    Link* p = NULL;    //2、创建头结点    Link* temp = (Link*)malloc(sizeof(Link));    temp-&gt;elem = 0;    temp-&gt;next = NULL;    //头指针指向头结点    p = temp;    //3、每创建一个结点，都令其直接前驱结点的指针指向它    for (i = 1; i &lt; 5; i++) &#123;        //创建一个结点        Link* a = (Link*)malloc(sizeof(Link));        a-&gt;elem = i;        a-&gt;next = NULL;        //每次 temp 指向的结点就是 a 的直接前驱结点        temp-&gt;next = a;        //temp指向下一个结点（也就是a),为下次添加结点做准备        temp = temp-&gt;next;    &#125;    return p;&#125;void display(Link* p) &#123;    Link* temp = p;//temp指针用来遍历链表    //只要temp指向结点的next值不是NULL，就执行输出语句。    while (temp) &#123;        Link* f = temp;//准备释放链表中的结点        printf(&quot;%d &quot;, temp-&gt;elem);        temp = temp-&gt;next;        free(f);    &#125;    printf(&quot;\\n&quot;);&#125;int main() &#123;    Link* p = NULL;    printf(&quot;初始化链表为：\\n&quot;);    //创建链表&#123;1,2,3,4&#125;    p = initLink();    //输出链表中的数据    display(p);    return 0;&#125;\n程序中创建的是带头结点的链表，头结点的数据域存储的是元素 0，因此最终的输出结果为：\n\n0 1 2 3 4\n\n如果不想输出头结点的值，可以将 p-&gt;next 作为实参传递给 display() 函数。\n如果程序中创建的是不带头结点的链表，最终的输出结果应该是：\n\n1 2 3 4\n\n单链表的基本操作学会创建链表之后，本节继续讲解链表的一些基本操作，包括向链表中添加数据、删除链表中的数据、查找和更改链表中的数据。\n首先，创建一个带头结点的链表，链表中存储着 {1,2,3,4}：\n//链表中节点的结构typedef struct link &#123;    int  elem;    struct link* next;&#125;Link;Link* initLink() &#123;    int i;    //1、创建头指针    Link* p = NULL;    //2、创建头结点    Link* temp = (Link*)malloc(sizeof(Link));    temp-&gt;elem = 0;    temp-&gt;next = NULL;    //头指针指向头结点    p = temp;    //3、每创建一个结点，都令其直接前驱结点的指针指向它    for (i = 1; i &lt; 5; i++) &#123;        //创建一个结点        Link* a = (Link*)malloc(sizeof(Link));        a-&gt;elem = i;        a-&gt;next = NULL;        //每次 temp 指向的结点就是 a 的直接前驱结点        temp-&gt;next = a;        //temp指向下一个结点（也就是a),为下次添加结点做准备        temp = temp-&gt;next;    &#125;    return p;&#125;\n链表插入元素同顺序表一样，向链表中增添元素，根据添加位置不同，可分为以下 3 种情况：\n\n插入到链表的头部，作为首元节点；\n插入到链表中间的某个位置；\n插入到链表的最末端，作为链表中最后一个结点；\n\n对于有头结点的链表，3 种插入元素的实现思想是相同的，具体步骤是：\n\n将新结点的 next 指针指向插入位置后的结点；\n将插入位置前结点的 next 指针指向插入结点；\n\n例如，在链表 {1,2,3,4}的基础上分别实现在头部、中间、尾部插入新元素 5，其实现过程如下图所示：\n\n从图中可以看出，虽然新元素的插入位置不同，但实现插入操作的方法是一致的，都是先执行步骤 1 ，再执行步骤 2。实现代码如下：\nvoid insertElem(Link* p, int elem, int add) &#123;    int i;    Link* c = NULL;    Link* temp = p;//创建临时结点temp    //首先找到要插入位置的上一个结点    for (i = 1; i &lt; add; i++) &#123;        temp = temp-&gt;next;        if (temp == NULL) &#123;            printf(&quot;插入位置无效\\n&quot;);            return;        &#125;    &#125;    //创建插入结点c    c = (Link*)malloc(sizeof(Link));    c-&gt;elem = elem;    //① 将新结点的 next 指针指向插入位置后的结点    c-&gt;next = temp-&gt;next;    //② 将插入位置前结点的 next 指针指向插入结点；    temp-&gt;next = c;&#125;\n注意：链表插入元素的操作必须是先步骤 1，再步骤 2；反之，若先执行步骤 2，除非再添加一个指针，作为插入位置后续链表的头指针，否则会导致插入位置后的这部分链表丢失，无法再实现步骤 1。\n对于没有头结点的链表，在头部插入结点比较特殊，需要单独实现。\n\n和 2)、3) 种情况相比，由于链表没有头结点，在头部插入新结点，此结点之前没有任何结点，实现的步骤如下：\n\n将新结点的指针指向首元结点；\n将头指针指向新结点。\n\n实现代码如下：\nLink* insertElem(Link* p, int elem, int add) &#123;    if (add == 1) &#123;        //创建插入结点c        Link* c = (Link*)malloc(sizeof(Link));        c-&gt;elem = elem;        c-&gt;next = p;        p = c;        return p;    &#125;    else &#123;        int i;        Link* c = NULL;        Link* temp = p;//创建临时结点temp        //首先找到要插入位置的上一个结点        for (i = 1; i &lt; add-1; i++) &#123;            temp = temp-&gt;next;            if (temp == NULL) &#123;                printf(&quot;插入位置无效\\n&quot;);                return p;            &#125;        &#125;        //创建插入结点c        c = (Link*)malloc(sizeof(Link));        c-&gt;elem = elem;        //向链表中插入结点        c-&gt;next = temp-&gt;next;        temp-&gt;next = c;        return p;    &#125;&#125;\n\n注意当 add==1 成立时，形参指针 p 的值会发生变化，因此需要它的新值作为函数的返回值返回。\n\n链表删除元素从链表中删除指定数据元素时，实则就是将存有该数据元素的节点从链表中摘除。\n对于有头结点的链表来说，无论删除头部（首元结点）、中部、尾部的结点，实现方式都一样，执行以下三步操作：\n\n找到目标元素所在结点的直接前驱结点；\n将目标结点从链表中摘下来;\n手动释放结点占用的内存空间；\n\n从链表上摘除目标节点，只需找到该节点的直接前驱节点 temp，执行如下操作：\ntemp-&gt;next=temp-&gt;next-&gt;next;\n例如，从存有 {1,2,3,4}的链表中删除存储元素 3 的结点，则此代码的执行效果如图 3 所示：\n\n实现代码如下：\n//p为原链表，elem 为要删除的目标元素int delElem(Link* p, int elem) &#123;    Link* del = NULL, *temp = p;    int find = 0;    //1、找到目标元素的直接前驱结点    while (temp-&gt;next) &#123;        if (temp-&gt;next-&gt;elem == elem) &#123;            find = 1;            break;        &#125;        temp = temp-&gt;next;    &#125;    if (find == 0) &#123;        return -1;//删除失败    &#125;    else    &#123;        //标记要删除的结点        del = temp-&gt;next;        //2、将目标结点从链表上摘除        temp-&gt;next = temp-&gt;next-&gt;next;        //3、释放目标结点        free(del);        return 1;    &#125;&#125;\n对于不带头结点的链表，需要单独考虑删除首元结点的情况，删除其它结点的方式和上图完全相同，如下图所示：\n\n实现代码如下：\n//p为原链表，elem 为要删除的目标元素int delElem(Link** p, int elem) &#123;    Link* del = NULL, *temp = *p;    //删除首元结点需要单独考虑    if (temp-&gt;elem == elem) &#123;        (*p) = (*p)-&gt;next;        free(temp);        return 1;    &#125;    else    &#123;        int find = 0;        //1、找到目标元素的直接前驱结点        while (temp-&gt;next) &#123;            if (temp-&gt;next-&gt;elem == elem) &#123;                find = 1;                break;            &#125;            temp = temp-&gt;next;        &#125;        if (find == 0) &#123;            return -1;//删除失败        &#125;        else        &#123;            //标记要删除的结点            del = temp-&gt;next;            //2、将目标结点从链表上摘除            temp-&gt;next = temp-&gt;next-&gt;next;            //3、释放目标结点            free(del);            return 1;        &#125;    &#125;&#125;\n函数返回 1 时，表示删除成功；返回 -1，表示删除失败。注意，该函数的形参 p 为二级指针，调用时需要传递链表头指针的地址。\n链表查找元素在链表中查找指定数据元素，最常用的方法是：从首元结点开始依次遍历所有节点，直至找到存储目标元素的结点。如果遍历至最后一个结点仍未找到，表明链表中没有存储该元素。\n因此，链表中查找特定数据元素的 C 语言实现代码为：\n//p为原链表，elem表示被查找元素int selectElem(Link* p, int elem) &#123;    int i = 1;    //带头结点，p 指向首元结点    p = p-&gt;next;    while (p) &#123;        if (p-&gt;elem == elem) &#123;            return i;        &#125;        p = p-&gt;next;        i++;    &#125;    return -1;//返回-1，表示未找到&#125;\n注意第 5 行代码，对于有结点的链表，需要先将 p 指针指向首元结点；反之，对于不带头结点的链表，注释掉第 5 行代码即可。\n链表更新元素更新链表中的元素，只需通过遍历找到存储此元素的节点，对节点中的数据域做更改操作即可。\n直接给出链表中更新数据元素的 C 语言实现代码：\n//p 为有头结点的链表，oldElem 为旧元素，newElem 为新元素int amendElem(Link* p, int oldElem, int newElem) &#123;    p = p-&gt;next;    while (p) &#123;        if (p-&gt;elem == oldElem) &#123;            p-&gt;elem = newElem;            return 1;        &#125;        p = p-&gt;next;    &#125;    return -1;&#125;\n函数返回 1，表示更改成功；返回数字 -1，表示更改失败。如果是没有头结点的链表，直接删除第 3 行代码即可。\n\n双向链表目前我们所学到的链表，无论是动态链表还是静态链表，表中各个节点都只包含一个指针（游标），且都统一指向直接后继节点，这类链表又统称为单向链表或单链表。\n虽然单链表能 100% 存储逻辑关系为 “一对一” 的数据，但在解决某些实际问题时，单链表的执行效率并不高。例如，若实际问题中需要频繁地查找某个结点的前驱结点，使用单链表存储数据显然没有优势，因为单链表的强项是从前往后查找目标元素，不擅长从后往前查找元素。\n解决此类问题，可以建立双向链表（简称双链表）。\n双向链表是什么从名字上理解双向链表，即链表是 “双向” 的，如下图所示：\n\n“双向”指的是各节点之间的逻辑关系是双向的，头指针通常只设置一个。\n从上图中可以看到，双向链表中各节点包含以下 3 部分信息（如图 2 所示）：\n\n指针域：用于指向当前节点的直接前驱节点；\n数据域：用于存储数据元素。\n指针域：用于指向当前节点的直接后继节点；\n\n\n因此，双链表的节点结构用 C 语言实现为：\ntypedef struct line&#123;    struct line * prior; //指向直接前趋    int data;    struct line * next; //指向直接后继&#125;Line;\n双向链表的创建同单链表相比，双链表仅是各节点多了一个用于指向直接前驱的指针域。因此，我们可以在单链表的基础轻松实现对双链表的创建。\n需要注意的是，与单链表不同，双链表创建过程中，每创建一个新节点都要与其前驱节点建立两次联系，分别是：\n\n将新节点的 prior 指针指向直接前驱节点；\n将直接前驱节点的 next 指针指向新节点；\n\n这里给出创建双向链表的 C 语言实现代码：\nLine* initLine(Line* head) &#123;    Line* list = NULL;    head = (Line*)malloc(sizeof(Line));//创建链表第一个结点（首元结点）    head-&gt;prior = NULL;    head-&gt;next = NULL;    head-&gt;data = 1;    list = head;    for (int i = 2; i &lt;= 5; i++) &#123;        //创建并初始化一个新结点        Line* body = (Line*)malloc(sizeof(Line));        body-&gt;prior = NULL;        body-&gt;next = NULL;        body-&gt;data = i;        //直接前趋结点的next指针指向新结点        list-&gt;next = body;        //新结点指向直接前趋结点        body-&gt;prior = list;        list = list-&gt;next;    &#125;    return head;&#125;\n我们可以尝试着在 main 函数中输出创建的双链表，C 语言代码如下：\n#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;typedef struct line &#123;    struct line* prior; //指向直接前趋    int data;    struct line* next; //指向直接后继&#125;Line;Line* initLine(Line* head) &#123;    int i;    Line* list = NULL;    head = (Line*)malloc(sizeof(Line));//创建链表第一个结点（首元结点）    head-&gt;prior = NULL;    head-&gt;next = NULL;    head-&gt;data = 1;    list = head;    for (i = 2; i &lt;= 5; i++) &#123;        //创建并初始化一个新结点        Line* body = (Line*)malloc(sizeof(Line));        body-&gt;prior = NULL;        body-&gt;next = NULL;        body-&gt;data = i;        //直接前趋结点的next指针指向新结点        list-&gt;next = body;        //新结点指向直接前趋结点        body-&gt;prior = list;        list = list-&gt;next;    &#125;    return head;&#125;//输出链表中的数据void display(Line* head) &#123;    Line* temp = head;    while (temp) &#123;        //如果该节点无后继节点，说明此节点是链表的最后一个节点        if (temp-&gt;next == NULL) &#123;            printf(&quot;%d\\n&quot;, temp-&gt;data);        &#125;        else &#123;            printf(&quot;%d &lt;-&gt; &quot;, temp-&gt;data);        &#125;        temp = temp-&gt;next;    &#125;&#125;//释放链表中结点占用的空间void free_line(Line* head) &#123;    Line* temp = head;    while (temp) &#123;        head = head-&gt;next;        free(temp);        temp = head;    &#125;&#125;int main()&#123;    //创建一个头指针    Line* head = NULL;    //调用链表创建函数    head = initLine(head);    //输出创建好的链表    display(head);    //显示双链表的优点    printf(&quot;链表中第 4 个节点的直接前驱是：%d&quot;, head-&gt;next-&gt;next-&gt;next-&gt;prior-&gt;data);    free_line(head);    return 0;&#125;\n程序运行结果：\n\n1 &lt;-&gt; 2 &lt;-&gt; 3 &lt;-&gt; 4 &lt;-&gt; 5 链表中第 4 个节点的直接前驱是：3\n\n双向链表基本操作前面学习了如何创建一个双向链表，本节学习有关双向链表的一些基本操作，即如何在双向链表中添加、删除、查找或更改数据元素。\n本节知识基于已熟练掌握双向链表创建过程的基础上，我们继续上节所创建的双向链表来学习本节内容，创建好的双向链表如下图所示：\n\n图 双向链表示意图\n双向链表添加节点根据数据添加到双向链表中的位置不同，可细分为以下 3 种情况：\n1) 添加至表头\n将新数据元素添加到表头，只需要将该元素与表头元素建立双层逻辑关系即可。\n换句话说，假设新元素节点为 temp，表头节点为 head，则需要做以下 2 步操作即可：\n\ntemp-&gt;next=head; head-&gt;prior=temp;\n将 head 移至 temp，重新指向新的表头；\n\n例如，将新元素 7 添加至双链表的表头，则实现过程如图 2 所示：\n\n图 添加元素至双向链表的表头\n2) 添加至表的中间位置\n同单链表添加数据类似，双向链表中间位置添加数据需要经过以下 2 个步骤，如下图所示：\n\n新节点先与其直接后继节点建立双层逻辑关系；\n新节点的直接前驱节点与之建立双层逻辑关系；\n\n\n图 双向链表中间位置添加数据元素\n3) 添加至表尾\n与添加到表头是一个道理，实现过程如下（如图 4 所示）：\n\n找到双链表中最后一个节点；\n让新节点与最后一个节点进行双层逻辑关系；\n\n\n图 双向链表尾部添加数据元素\n因此，我们可以试着编写双向链表添加数据的 C 语言代码，参考代码如下：\nLine* insertLine(Line* head, int data, int add) &#123;    //新建数据域为data的结点    Line* temp = (Line*)malloc(sizeof(Line));    temp-&gt;data = data;    temp-&gt;prior = NULL;    temp-&gt;next = NULL;    //插入到链表头，要特殊考虑    if (add == 1) &#123;        temp-&gt;next = head;        head-&gt;prior = temp;        head = temp;    &#125;    else &#123;        int i;        Line* body = head;        //找到要插入位置的前一个结点        for (i = 1; i &lt; add - 1; i++) &#123;            body = body-&gt;next;            //只要 body 不存在，表明插入位置输入错误            if (!body) &#123;                printf(&quot;插入位置有误！\\n&quot;);                return head;            &#125;        &#125;        //判断条件为真，说明插入位置为链表尾，实现第 2 种情况        if (body &amp;&amp; (body-&gt;next == NULL)) &#123;            body-&gt;next = temp;            temp-&gt;prior = body;        &#125;        else &#123;            //第 2 种情况的具体实现            body-&gt;next-&gt;prior = temp;            temp-&gt;next = body-&gt;next;            body-&gt;next = temp;            temp-&gt;prior = body;        &#125;    &#125;    return head;&#125;\n双向链表删除节点和添加结点的思想类似，在双向链表中删除目标结点也分为 3 种情况。\n1) 删除表头结点\n删除表头结点的过程如下图所示：\n\n删除表头结点的实现过程是：\n\n新建一个指针指向表头结点；\n断开表头结点和其直接后续结点之间的关联，更改 head 头指针的指向，同时将其直接后续结点的 prior 指针指向 NULL；\n释放表头结点占用的内存空间。\n删除表中结点\n\n删除表中结点的过程如下图所示：\n\n删除表中结点的实现过程是：\n\n找到目标结点，新建一个指针指向改结点；\n将目标结点从链表上摘除；\n释放该结点占用的内存空间。\n删除表尾结点\n\n删除表尾结点的过程如下图所示：\n\n删除表尾结点的实现过程是：\n\n找到表尾结点，新建一个指针指向该结点；\n断点表尾结点和其直接前驱结点的关联，并将其直接前驱结点的 next 指针指向 NULL；\n释放表尾结点占用的内存空间。\n\n双向链表删除节点的 C 语言实现代码如下：\n//删除结点的函数，data为要删除结点的数据域的值Line* delLine(Line* head, int data) &#123;    Line* temp = head;    while (temp) &#123;        if (temp-&gt;data == data) &#123;            //删除表头结点            if (temp-&gt;prior == NULL) &#123;                head = head-&gt;next;                if (head) &#123;                    head-&gt;prior = NULL;                    temp-&gt;next = NULL;                &#125;                free(temp);                return head;            &#125;            //删除表中结点            if (temp-&gt;prior &amp;&amp; temp-&gt;next) &#123;                temp-&gt;next-&gt;prior = temp-&gt;prior;                temp-&gt;prior-&gt;next = temp-&gt;next;                free(temp);                return head;            &#125;            //删除表尾结点            if (temp-&gt;next == NULL) &#123;                temp-&gt;prior-&gt;next = NULL;                temp-&gt;prior = NULL;                free(temp);                return head;            &#125;        &#125;        temp = temp-&gt;next;    &#125;    printf(&quot;表中没有目标元素，删除失败\\n&quot;);    return head;&#125;\n双向链表查找节点通常情况下，双向链表和单链表一样都仅有一个头指针。因此，双链表查找指定元素的实现同单链表类似，也是从表头依次遍历表中元素。\nC 语言实现代码为：\n//head为原双链表，elem表示被查找元素int selectElem(line * head,int elem)&#123;//新建一个指针t，初始化为头指针 head    line * t=head;    int i=1;    while (t) &#123;        if (t-&gt;data==elem) &#123;            return i;        &#125;        i++;        t=t-&gt;next;    &#125;    //程序执行至此处，表示查找失败    return -1;&#125;\n双向链表更改节点更改双链表中指定结点数据域的操作是在查找的基础上完成的。实现过程是：通过遍历找到存储有该数据元素的结点，直接更改其数据域即可。\n实现此操作的 C 语言实现代码如下：\n//更新函数，其中，add 表示要修改的元素，newElem 为新数据的值void amendElem(Line* p, int oldElem, int newElem) &#123;    Line* temp = p;    int find = 0;    //找到要修改的目标结点    while (temp)    &#123;        if (temp-&gt;data == oldElem) &#123;            find = 1;            break;        &#125;        temp = temp-&gt;next;    &#125;    //成功找到，则进行更改操作    if (find == 1) &#123;        temp-&gt;data = newElem;        return;    &#125;    //查找失败，输出提示信息    printf(&quot;链表中未找到目标元素，更改失败\\n&quot;);&#125;\n循环链表无论静态链表还是动态链表，有时在解决具体问题时，需要我们对其结构进行稍微地调整。比如，可以把链表的两头连接，使其成为了一个环状链表，通常称为循环链表。\n和它名字的表意一样，只需要将表中最后一个结点的指针指向头结点，链表就能成环儿，如下图所示。\n\n需要注意的是，虽然循环链表成环状，但本质上还是链表，因此在循环链表中，依然能够找到头指针和首元节点等。循环链表和普通链表相比，唯一的不同就是循环链表首尾相连，其他都完全一样。\n这里给大家一个循环链表的实例，用循环链表实现约瑟夫环\n循环链表实现约瑟夫环 - 玩转C语言和数据结构xiexuewu.github.io/view/7.html\n双向循环链表我们知道，单链表通过首尾连接可以构成单向循环链表，如下图所示：\n\n同样，双向链表也可以进行首尾连接，构成双向循环链表。如下图所示：\n\n解决某些问题，可能既需要正向遍历数据，又需要逆向遍历数据，这时就可以考虑使用双向循环链表。\n双向循环链表的创建创建双向循环链表，只需在创建完成双向链表的基础上，将其首尾节点进行双向连接即可。\nC 语言实现代码如下：\n//创建双向循环链表Line* initLine(Line* head) &#123;    int i;    Line* list = NULL;    head = (Line*)malloc(sizeof(Line));//创建链表第一个结点（首元结点）    head-&gt;prior = NULL;    head-&gt;next = NULL;    head-&gt;data = 1;    list = head;    for (i = 2; i &lt;= 3; i++) &#123;        //创建并初始化一个新结点        Line* body = (Line*)malloc(sizeof(Line));        body-&gt;prior = NULL;        body-&gt;next = NULL;        body-&gt;data = i;        //直接前趋结点的next指针指向新结点        list-&gt;next = body;        //新结点指向直接前趋结点        body-&gt;prior = list;        list = list-&gt;next;    &#125;    //通过以上代码，已经创建好双线链表，接下来将链表的首尾节点进行双向连接    list-&gt;next=head;    head-&gt;prior=list;    return head;&#125;\n通过向 main 函数中调用 initLine 函数，就可以成功创建一个存储有 {1,2,3} 数据的双向循环链表，其完整的 C 语言实现代码为：\n#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;typedef struct line &#123;    struct line* prior; //指向直接前趋    int data;    struct line* next; //指向直接后继&#125;Line;//创建双向循环链表Line* initLine(Line* head) &#123;    int i;    Line* list = NULL;    head = (Line*)malloc(sizeof(Line));//创建链表第一个结点（首元结点）    head-&gt;prior = NULL;    head-&gt;next = NULL;    head-&gt;data = 1;    list = head;    for (i = 2; i &lt;= 3; i++) &#123;        //创建并初始化一个新结点        Line* body = (Line*)malloc(sizeof(Line));        body-&gt;prior = NULL;        body-&gt;next = NULL;        body-&gt;data = i;        //直接前趋结点的next指针指向新结点        list-&gt;next = body;        //新结点指向直接前趋结点        body-&gt;prior = list;        list = list-&gt;next;    &#125;    //通过以上代码，已经创建好双线链表，接下来将链表的首尾节点进行双向连接    list-&gt;next = head;    head-&gt;prior = list;    return head;&#125;//输出链表中的数据void display(Line* head) &#123;    Line* temp = head;    //由于是循环链表，所以当遍历指针temp指向的下一个节点是head时，证明此时已经循环至链表的最后一个节点    while (temp-&gt;next != head) &#123;        if (temp-&gt;next == NULL) &#123;            printf(&quot;%d\\n&quot;, temp-&gt;data);        &#125;        else &#123;            printf(&quot;%d-&gt;&quot;, temp-&gt;data);        &#125;        temp = temp-&gt;next;    &#125;    //输出循环链表中最后一个节点的值    printf(&quot;%d&quot;, temp-&gt;data);&#125;//释放链表中结点占用的空间void free_line(Line* head) &#123;    Line* temp = NULL;    //切断循环    head-&gt;prior-&gt;next = NULL;    //从第一个结点开始，依次 free    temp = head;    while (temp) &#123;        head = head-&gt;next;        free(temp);        temp = head;    &#125;&#125;int main()&#123;    //创建一个头指针    Line* head = NULL;    //调用链表创建函数    head = initLine(head);    //输出创建好的链表    display(head);    //手动释放链表占用的内存    free_line(head);    return 0;&#125;\n程序输出结果如下：\n\n1-&gt;2-&gt;3\n\n","categories":["数据结构"],"tags":["数据结构","链表"]},{"title":"关于数据结构的一些想法","url":"/Arknight-notes/posts/12835.html","content":"\n鉴于我校 [已编辑] 的教学安排，在刚学完c语言程序设计后，大一下就开始了基于c++的数据结构的学习，由于算法基础过于薄弱，数据结构拼尽全力期末复习只考了70而且掌握不足，写不出东西来，现在重拾旧事把数据结构重新学一遍\n个人认为学不明白踩过的坑有几点：\n\n第一，在大学的课程里并没有讲明白一个问题，就是数据结构算法应该怎么样和实际场景结合。比如，老师讲到树形结构的时候会说，树形效率很高，它的插入和查找时间复杂度都是O(LogN)，是一种非常重要的数据结构，在计算机中应用非常广泛，讲到这里就讲完了,留下我们一头雾水。\n\n第二，在实际其实没有机会从零开始手写一个数据结构和算法，在主流的编程语言中都已经封装好了。\n\n第三，你广州大学的数据结构排课极少，这么难学的课竟然课时还没思政课多。不知道计算机学院那边是什么情况，蹭课时那边一个时间复杂度讲了三节课，心死了，还是得靠自己学\n\n\n  很多时候我们能说出队列是什么原理，栈是什么原理，树的旋转是怎么回事， 但如果让我们自己实现一个队列或者栈还是有点难度的，尤其是在需要考虑一些性能问题的时候，遂决定把这些重新拾起来。\n\n","categories":["数据结构"],"tags":["数据结构"]}]