<!DOCTYPE html><html lang="en" theme-mode="dark"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>2026-01-07-机器学习相关算法 | Notes|笔记站</title><link rel="icon" type="image/x-icon" href="/Arknight-notes/favicon.ico"><link rel="preload" as="font" crossorigin="anonymous" href="/Arknight-notes/font/Bender.ttf"><link rel="preload" as="font" crossorigin="anonymous" href="/Arknight-notes/font/BenderLight.ttf"><link rel="preload" as="font" crossorigin="anonymous" href="/Arknight-notes/font/JetBrainsMono-Regular.woff2"><link rel="stylesheet" href="/Arknight-notes/css/arknights.css"><style>@font-face {
  font-family: Bender;
  src: local('Bender'), url("/Arknight-notes/font/Bender.ttf"), url("/Arknight-notes/font/Bender.otf");
}
@font-face {
  font-family: BenderLight;
  src: local('BenderLight'), url("/Arknight-notes/font/BenderLight.ttf");
}
@font-face {
  font-family: 'JetBrains Mono';
  src: local('JetBrains Mono'), url('/Arknight-notes/font/JetBrainsMono-Regular.woff2') format('woff2');
}
</style><script>var config = {"root":"/Arknight-notes/","code_fold":90,"search":{"preload":false,"activeHolder":"键入以继续","blurHolder":"数据检索","noResult":"无 $0 相关数据"},"code":{"codeInfo":"$0 - $1 行","copy":"复制"}}</script><link type="text/css" rel="stylesheet" href="/Arknight-notes/lib/encrypt/hbe.style.css"><script src="/Arknight-notes/js/gitalk.js"></script><script src="//unpkg.com/mermaid@10.5.0/dist/mermaid.min.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.6.1/MathJax.js"></script><script>MathJax.Hub.Config({
 menuSettings: {
   zoom: "None"
 },
 showMathMenu: false,
 jax: ["input/TeX","output/CommonHTML"],
 extensions: ["tex2jax.js"],
 TeX: {
   extensions: ["AMSmath.js","AMSsymbols.js"],
   equationNumbers: {
     autoNumber: "AMS"
   }
 },
 tex2jax: {
   inlineMath: [["\\(", "\\)"]],
   displayMath: [["\\[", "\\]"]]
 }
});</script><link type="text/css" rel="stylesheet" href="//unpkg.com/lightgallery@2.7.1/css/lightgallery.css"><link type="text/css" rel="stylesheet" href="//unpkg.com/lightgallery@2.7.1/css/lg-zoom.css"><link type="text/css" rel="stylesheet" href="//unpkg.com/lightgallery@2.7.1/css/lg-thumbnail.css"><link type="text/css" rel="stylesheet" href="/Arknight-notes/lib/fontawesome/css/all.min.css"><script>if (window.localStorage.getItem('theme-mode') === 'light')
 document.documentElement.setAttribute('theme-mode', 'light')
if (window.localStorage.getItem('theme-mode') === 'dark')
 document.documentElement.setAttribute('theme-mode', 'dark')</script><style>@font-face {
 font-family: BenderLight;
 src: local('Bender'), url("/Arknight-notes/font/BenderLight.woff2") format('woff2');
}
@font-face {
 font-family: 'JetBrains Mono';
 src: local('JetBrains Mono'), url('/Arknight-notes/font/JetBrainsMono-Regular.woff2') format('woff2');
}</style><style>:root {
 --dark-background: url('https://pica.zhimg.com/v2-1d14a5f80bbe62302dce99b273e3a948_r.jpg');
 --light-background: url('https://pic2.zhimg.com/v2-6269d74b4dafe14781d03790e5a86b21_r.jpg');
 --theme-encrypt-confirm: '确认'
}</style><script defer src="/Arknight-notes/js/arknights.js"></script><script defer src="/Arknight-notes/js/search.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script async src="/Arknight-notes/js/gitalk.js"></script><script defer type="module">import mermaid from '//unpkg.com/mermaid@10.5.0/dist/mermaid.esm.mjs';
window.mermaid = mermaid;
code.paintMermaid();
</script><script src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.6.1/MathJax.js"></script><script>MathJax.Hub.Config({
  menuSettings: {
    zoom: "None"
  },
  showMathMenu: false,
  jax: ["input/TeX","output/CommonHTML"],
  extensions: ["tex2jax.js"],
  TeX: {
    extensions: ["AMSmath.js","AMSsymbols.js"],
    equationNumbers: {
      autoNumber: "AMS"
    }
  },
  tex2jax: {
    inlineMath: [["\\(", "\\)"]],
    displayMath: [["\\[", "\\]"]]
  }
});
</script><script async src="//unpkg.com/lightgallery@2.7.1/lightgallery.min.js"></script><script async src="//unpkg.com/lightgallery@2.7.1/plugins/zoom/lg-zoom.min.js"></script><script async src="//unpkg.com/lightgallery@2.7.1/plugins/thumbnail/lg-thumbnail.min.js"></script><script async src="/Arknight-notes/lib/encrypt/hbe.js"></script><script async src="/Arknight-notes/js/pjax.js"></script><script class="pjax-js">reset= () => {gitalk = new Gitalk({
 clientID: 'Ov23ct13Fb0b67x23wnT',
 clientSecret: 'f18ce69dd545e3c0f5e2456afde9c756fe8a254a',
 repo: 'Arknight-notes',
 owner: 'Zhongye1',
 admin: ['Zhongye1'],
 distractionFreeMode: false,
 id: location.pathname
});
if (document.querySelector("#gitalk")) gitalk.render("gitalk");document.querySelector('.lg-container')?.remove()
lightGallery(document.getElementById('post-bg'), {
  plugins: [lgZoom,lgThumbnail],
  selector: '.item-img'})}</script><script>window.addEventListener("load",() => {pjax = new Pjax({
 cacheBust: false,
 selectors: ['title','article','#aside-block','.pjax-js','data-pjax','.busuanzi'],
 switches: {'article': Pjax.switches.sideBySide},
 switchesOptions: {
   'article': {
     classNames: {
       remove: "pjax-out",
       add: "pjax-in"
     }
   }
 }
});
document.addEventListener("pjax:complete", reset);document.addEventListener('pjax:success', _ => bszCaller.fetch(
 "//busuanzi.ibruce.info/busuanzi?jsonpCallback=BusuanziCallback", a => {
  bszTag.texts(a),
  bszTag.shows()
}));reset()})</script><script class="pjax-js">reset= () => {gitalk = new Gitalk({
 clientID: 'Ov23ct13Fb0b67x23wnT',
 clientSecret: 'f18ce69dd545e3c0f5e2456afde9c756fe8a254a',
 repo: 'Arknight-notes',
 owner: 'Zhongye1',
 admin: ['Zhongye1'],
 distractionFreeMode: false,
 id: location.pathname
});
if (document.querySelector("#gitalk")) gitalk.render("gitalk");document.querySelector('.lg-container')?.remove()
lightGallery(document.getElementById('post-bg'), {
  plugins: [lgZoom,lgThumbnail],
  selector: '.item-img'})}</script><script>window.addEventListener("load",() => {pjax = new Pjax({
 cacheBust: false,
 selectors: ['title','article','#aside-block','.pjax-js'],
 switches: {'article': Pjax.switches.sideBySide},
 switchesOptions: {
   'article': {
     classNames: {
       remove: "pjax-out",
       add: "pjax-in"
     }
   }
 }
});
document.addEventListener("pjax:complete", reset);reset()})</script><meta name="generator" content="Hexo 7.3.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style><link rel="alternate" href="/Arknight-notes/rss.xml" title="Notes|笔记站" type="application/atom+xml">
</head><body><div class="loading" style="opacity: 0;"><div class="loadingBar left"></div><div class="loadingBar right"></div></div><main><header class="closed"><div class="navBtn"><i class="navBtnIcon"><span class="navBtnIconBar"></span><span class="navBtnIconBar"></span><span class="navBtnIconBar"></span></i></div><nav><div class="navItem" id="search-header"><span class="navItemTitle"><input autocomplete="off" autocorrect="off" autocapitalize="none" placeholder="数据检索" spellcheck="false" maxlength="50" type="text" id="search-input"></span></div><div class="navItem" id="search-holder"></div><div class="search-popup" tabindex="0"><div id="search-result"></div></div><ol class="navContent"><li class="navItem"><a class="navBlock" href="/Arknight-notes/"><span class="navItemTitle">Home</span></a></li><li class="navItem" matchdata="categories,tags"><a class="navBlock" href="/Arknight-notes/archives/"><span class="navItemTitle">Archives</span></a></li><li class="navItem"><a class="navBlock" href="/Arknight-notes/about/"><span class="navItemTitle">About</span></a></li></ol></nav></header><article><div id="post-bg"><div id="post-title"><h1>2026-01-07-机器学习相关算法</h1><div id="post-info"><span>文章发布时间: <div class="control"><time datetime="2026-01-07T18:28:13.000Z" id="date"> 2026-01-08</time></div></span><br><span>最后更新时间: <div class="control"><time datetime="2026-01-08T21:22:22.648Z" id="updated"> 2026-01-09</time></div></span><br><span id="busuanzi_container_page_pv">页面浏览: <span class="control" id="busuanzi_value_page_pv">加载中...</span></span></div></div><hr><div id="post-content"><h2 id="评估方法（留出法）"><a href="#评估方法（留出法）" class="headerlink" title="评估方法（留出法）"></a>评估方法（留出法）</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> random<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_test_split</span>(<span class="hljs-params">X,test_size=<span class="hljs-number">0.2</span>,random_state=<span class="hljs-number">5</span></span>):<br>    random.seed(random_state)<br>    n_samples = <span class="hljs-built_in">len</span>(X)<br>    indices = np.arange(n_samples)<br>    train_indexs = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">set</span>(random.sample(indices.tolist(),<span class="hljs-built_in">int</span>(n_samples*(<span class="hljs-number">1</span>-test_size)))))<br>    test_indexs = [k <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> indices <span class="hljs-keyword">if</span> k <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> train_indexs]<br>    <span class="hljs-keyword">return</span> X[train_indexs],X[test_indexs]<br><br><br>test_size = <span class="hljs-number">0.2</span><br>X = np.array([<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>,<span class="hljs-number">7</span>,<span class="hljs-number">8</span>,<span class="hljs-number">9</span>,<span class="hljs-number">10</span>])<br>train_X,test_X = train_test_split(X,test_size=test_size)<br><span class="hljs-built_in">print</span>(train_X,test_X)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">"debug_begin"</span>);<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">len</span>(test_X) == <span class="hljs-built_in">int</span>(<span class="hljs-built_in">len</span>(X)*test_size))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">"debug_end"</span>);<br></code></pre></td></tr></table></figure>
<h3 id="评估方法（交叉验证法）"><a href="#评估方法（交叉验证法）" class="headerlink" title="评估方法（交叉验证法）"></a>评估方法（交叉验证法）</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> random<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">KFold</span>(<span class="hljs-params">X,n_splits,is_shuffle=<span class="hljs-literal">True</span>,random_state=<span class="hljs-number">0</span></span>):<br>    random.seed(random_state)<br>    n_samples = <span class="hljs-built_in">len</span>(X)<br><br>    indices = np.arange(n_samples)<br><br>    train_index = []<br>    test_index = []<br>    result = []<br>    fold_sizes = np.full(n_splits,n_samples//n_splits,dtype=np.<span class="hljs-built_in">int</span>)<br>    fold_sizes[:n_samples%n_splits] += <span class="hljs-number">1</span><br>    current = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> fold_size <span class="hljs-keyword">in</span> fold_sizes:<br>        start, stop = current, current+fold_size<br>        test_index = indices[start:stop]<br>        train_index = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">set</span>(indices)-<span class="hljs-built_in">set</span>(indices[start:stop]))<br>        current = stop<br>        result.append([X[train_index],X[test_index]])<br>    <span class="hljs-keyword">return</span> result<br><br>X = np.array([<span class="hljs-built_in">int</span>(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">input</span>().strip().split()])<br>n_splits = <span class="hljs-built_in">int</span>(<span class="hljs-built_in">input</span>())<br>result = KFold(X,n_splits)<br><br><br><span class="hljs-keyword">for</span> S,T <span class="hljs-keyword">in</span> result:<br>    <span class="hljs-built_in">print</span>(S,T)<br><br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">"debug_begin"</span>);<br>res = []<br><span class="hljs-keyword">for</span> _,T <span class="hljs-keyword">in</span> result:<br>    res += <span class="hljs-built_in">list</span>(T)<br><span class="hljs-keyword">if</span> <span class="hljs-built_in">set</span>(res)==<span class="hljs-built_in">set</span>(<span class="hljs-built_in">list</span>(X)) <span class="hljs-keyword">and</span> <span class="hljs-built_in">len</span>(X)==<span class="hljs-built_in">len</span>(res):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-literal">True</span>)<br><span class="hljs-keyword">else</span>:<br>    <span class="hljs-built_in">print</span>(<span class="hljs-literal">False</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">"debug_end"</span>);<br></code></pre></td></tr></table></figure>
<h3 id="优化算法-梯度下降法-1"><a href="#优化算法-梯度下降法-1" class="headerlink" title="优化算法-梯度下降法 1"></a>优化算法-梯度下降法 1</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> math<br><span class="hljs-built_in">print</span>(<span class="hljs-string">"debug_begin"</span>);<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">func_1d_test1</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">return</span> x**<span class="hljs-number">2</span>+<span class="hljs-number">1</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">grad_1d_test1</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">return</span> x*<span class="hljs-number">2</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">func_1d_test2</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">return</span> x**<span class="hljs-number">2</span> - <span class="hljs-number">4</span>*x +<span class="hljs-number">14</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">grad_1d_test2</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">return</span> x*<span class="hljs-number">2</span>-<span class="hljs-number">4</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">"debug_end"</span>);<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">gradient_descent_1d</span>(<span class="hljs-params">grad, cur_x=<span class="hljs-number">0.1</span>, learning_rate=<span class="hljs-number">0.01</span>, precision=<span class="hljs-number">0.0001</span>, max_iters=<span class="hljs-number">10000</span></span>):<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(max_iters):<br>        grad_cur = grad(cur_x)<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">abs</span>(grad_cur) &lt; precision:<br>            <span class="hljs-keyword">break</span>  <span class="hljs-comment"># 当梯度趋近为 0 时，视为收敛</span><br>        cur_x = cur_x - grad_cur * learning_rate<br><br>    <span class="hljs-keyword">return</span> cur_x<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">"debug_begin"</span>);<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">test</span>():<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">"%.7f"</span> %gradient_descent_1d(grad_1d_test1, cur_x=<span class="hljs-number">10</span>, learning_rate=<span class="hljs-number">0.2</span>, precision=<span class="hljs-number">0.0001</span>, max_iters=<span class="hljs-number">10000</span>))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">"%.7f"</span> %gradient_descent_1d(grad_1d_test2, cur_x=<span class="hljs-number">10</span>, learning_rate=<span class="hljs-number">0.2</span>, precision=<span class="hljs-number">0.0001</span>, max_iters=<span class="hljs-number">10000</span>))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">"debug_end"</span>);<br><br>test()<br></code></pre></td></tr></table></figure>
<h2 id="优化算法-梯度下降法-2"><a href="#优化算法-梯度下降法-2" class="headerlink" title="优化算法-梯度下降法 2"></a>优化算法-梯度下降法 2</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> math<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">"debug_begin"</span>);<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">func_2d_test1</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">return</span> - math.exp(-(x[<span class="hljs-number">0</span>] ** <span class="hljs-number">2</span> + x[<span class="hljs-number">1</span>] ** <span class="hljs-number">2</span>))<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">grad_2d_test1</span>(<span class="hljs-params">x</span>):<br>    deriv0 = <span class="hljs-number">2</span> * x[<span class="hljs-number">0</span>] * math.exp(-(x[<span class="hljs-number">0</span>] ** <span class="hljs-number">2</span> + x[<span class="hljs-number">1</span>] ** <span class="hljs-number">2</span>))<br>    deriv1 = <span class="hljs-number">2</span> * x[<span class="hljs-number">1</span>] * math.exp(-(x[<span class="hljs-number">0</span>] ** <span class="hljs-number">2</span> + x[<span class="hljs-number">1</span>] ** <span class="hljs-number">2</span>))<br>    <span class="hljs-keyword">return</span> np.array([deriv0, deriv1])<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">func_2d_test2</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">return</span> x[<span class="hljs-number">0</span>]**<span class="hljs-number">2</span> + x[<span class="hljs-number">1</span>]**<span class="hljs-number">2</span> +<span class="hljs-number">2</span>*x[<span class="hljs-number">0</span>]+<span class="hljs-number">1</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">grad_2d_test2</span>(<span class="hljs-params">x</span>):<br>    deriv0 = <span class="hljs-number">2</span>*x[<span class="hljs-number">0</span>]+<span class="hljs-number">2</span><br>    deriv1 = <span class="hljs-number">2</span>*x[<span class="hljs-number">1</span>]<br>    <span class="hljs-keyword">return</span> np.array([deriv0,deriv1])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">"debug_end"</span>);<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">gradient_descent_2d</span>(<span class="hljs-params">grad, cur_x=np.array(<span class="hljs-params">[<span class="hljs-number">0.1</span>,<span class="hljs-number">0.1</span>]</span>), learning_rate=<span class="hljs-number">0.01</span>, precision=<span class="hljs-number">0.0001</span>, max_iters=<span class="hljs-number">10000</span></span>):<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(max_iters):<br>        grad_cur = grad(cur_x)<br>        <span class="hljs-keyword">if</span> np.linalg.norm(grad_cur, <span class="hljs-built_in">ord</span>=<span class="hljs-number">2</span>) &lt; precision:<br>            <span class="hljs-keyword">break</span>  <span class="hljs-comment"># 当梯度趋近为 0 时，视为收敛</span><br>        cur_x = cur_x - grad_cur * learning_rate<br><br><br>    <span class="hljs-keyword">return</span> cur_x<br><br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">"debug_begin"</span>);<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">test</span>():<br>    res = gradient_descent_2d(grad_2d_test1, cur_x=np.array([<span class="hljs-number">1</span>,-<span class="hljs-number">1</span>]), learning_rate=<span class="hljs-number">0.2</span>, precision=<span class="hljs-number">0.0001</span>, max_iters=<span class="hljs-number">10000</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">"%.7f %.7f"</span> %(res[<span class="hljs-number">0</span>],res[<span class="hljs-number">1</span>]) )<br>    res2 = gradient_descent_2d(grad_2d_test2, cur_x=np.array([<span class="hljs-number">2</span>,<span class="hljs-number">2</span>]), learning_rate=<span class="hljs-number">0.2</span>, precision=<span class="hljs-number">0.0001</span>, max_iters=<span class="hljs-number">10000</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">"%.7f %.7f"</span> %(res2[<span class="hljs-number">0</span>],res2[<span class="hljs-number">1</span>]) )<br><span class="hljs-built_in">print</span>(<span class="hljs-string">"debug_end"</span>);<br><br>test()<br></code></pre></td></tr></table></figure>
<h2 id="线性回归-糖尿病预测"><a href="#线性回归-糖尿病预测" class="headerlink" title="线性回归-糖尿病预测"></a>线性回归-糖尿病预测</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> math<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> random<br><span class="hljs-keyword">import</span>  warnings<br>warnings.filterwarnings(<span class="hljs-string">"ignore"</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_diabetes</span>():<br>    X = []<br>    y = []<br>    line = <span class="hljs-built_in">input</span>()<br>    <span class="hljs-keyword">while</span> line:<br>        dx = []<br>        data = [l <span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> line.strip().split(<span class="hljs-string">','</span>)]<br>        X.append(np.array([np.<span class="hljs-built_in">float</span>(d) <span class="hljs-keyword">for</span> d <span class="hljs-keyword">in</span> data[:-<span class="hljs-number">1</span>]]))<br>        y.append(np.<span class="hljs-built_in">float</span>(data[-<span class="hljs-number">1</span>]))<br>        line = <span class="hljs-built_in">input</span>()<br>    <span class="hljs-keyword">return</span> np.array(X),np.array(y)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_test_split</span>(<span class="hljs-params">X,Y,test_size=<span class="hljs-number">0.2</span>,random_state=<span class="hljs-number">2333</span></span>):<br>    random.seed(random_state)<br>    n_samples = <span class="hljs-built_in">len</span>(X)<br>    indices = np.arange(n_samples)<br>    train_indexs = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">set</span>(random.sample(indices.tolist(),<span class="hljs-built_in">int</span>(n_samples*(<span class="hljs-number">1</span>-test_size)))))<br>    test_indexs = [k <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> indices <span class="hljs-keyword">if</span> k <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> train_indexs]<br>    <span class="hljs-keyword">return</span> X[train_indexs],X[test_indexs],Y[train_indexs],Y[test_indexs]<br><br>X,y = load_diabetes()<br><span class="hljs-keyword">import</span> math<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> random<br><span class="hljs-keyword">import</span>  warnings<br>warnings.filterwarnings(<span class="hljs-string">"ignore"</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_diabetes</span>():<br>    X = []<br>    y = []<br>    line = <span class="hljs-built_in">input</span>()<br>    <span class="hljs-keyword">while</span> line:<br>        dx = []<br>        data = [l <span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> line.strip().split(<span class="hljs-string">','</span>)]<br>        X.append(np.array([np.<span class="hljs-built_in">float</span>(d) <span class="hljs-keyword">for</span> d <span class="hljs-keyword">in</span> data[:-<span class="hljs-number">1</span>]]))<br>        y.append(np.<span class="hljs-built_in">float</span>(data[-<span class="hljs-number">1</span>]))<br>        line = <span class="hljs-built_in">input</span>()<br>    <span class="hljs-keyword">return</span> np.array(X),np.array(y)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_test_split</span>(<span class="hljs-params">X,Y,test_size=<span class="hljs-number">0.2</span>,random_state=<span class="hljs-number">2333</span></span>):<br>    random.seed(random_state)<br>    n_samples = <span class="hljs-built_in">len</span>(X)<br>    indices = np.arange(n_samples)<br>    train_indexs = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">set</span>(random.sample(indices.tolist(),<span class="hljs-built_in">int</span>(n_samples*(<span class="hljs-number">1</span>-test_size)))))<br>    test_indexs = [k <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> indices <span class="hljs-keyword">if</span> k <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> train_indexs]<br>    <span class="hljs-keyword">return</span> X[train_indexs],X[test_indexs],Y[train_indexs],Y[test_indexs]<br><br>X,y = load_diabetes()<br><span class="hljs-keyword">class</span> <span class="hljs-title class_">LinearRegression</span>:<br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>    <span class="hljs-string">'''初始化模型'''</span><br>    <span class="hljs-variable language_">self</span>.coef_ = <span class="hljs-literal">None</span><br>    <span class="hljs-variable language_">self</span>.interception_ = <span class="hljs-literal">None</span><br>    <span class="hljs-variable language_">self</span>._theta = <span class="hljs-literal">None</span><br><br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">fit_normal</span>(<span class="hljs-params">self,X_train,y_train</span>):<br>    <span class="hljs-string">'''根据训练数据集X_train,y_train训练模型'''</span><br>    <span class="hljs-keyword">assert</span> X_train.shape[<span class="hljs-number">0</span>] == y_train.shape[<span class="hljs-number">0</span>],<span class="hljs-string">'the number of X_train must equal to the number of y_train'</span><br>    X_b = np.hstack([np.ones((<span class="hljs-built_in">len</span>(X_train),<span class="hljs-number">1</span>)),X_train])<br>    <span class="hljs-variable language_">self</span>._theta = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y_train)<br>    <span class="hljs-variable language_">self</span>.interception_ = <span class="hljs-variable language_">self</span>._theta[<span class="hljs-number">0</span>]<br>    <span class="hljs-variable language_">self</span>.coef_ = <span class="hljs-variable language_">self</span>._theta[<span class="hljs-number">1</span>:]<br>    <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span><br><br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>(<span class="hljs-params">self,X_predict</span>):<br>    <span class="hljs-keyword">assert</span> <span class="hljs-variable language_">self</span>._theta <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>,<span class="hljs-string">'must fit before predict'</span><br>    <span class="hljs-keyword">assert</span> X_predict.shape[<span class="hljs-number">1</span>] == <span class="hljs-built_in">len</span>(<span class="hljs-variable language_">self</span>.coef_),<span class="hljs-string">'the feature number of X_predict must equal to X_train '</span><br><br>    X_b = np.hstack([np.ones((<span class="hljs-built_in">len</span>(X_predict),<span class="hljs-number">1</span>)),X_predict])<br>    <span class="hljs-keyword">return</span> X_b.dot(<span class="hljs-variable language_">self</span>._theta)<br><br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">mse</span>(<span class="hljs-params">self,y,y_pre</span>):<br>    <span class="hljs-keyword">return</span> np.average((y-y_pre)**<span class="hljs-number">2</span>)<br><br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">rmse</span>(<span class="hljs-params">self,y,y_pre</span>):<br>    <span class="hljs-keyword">return</span> np.sqrt(<span class="hljs-variable language_">self</span>.mse(y,y_pre))<br><br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">r2_score</span>(<span class="hljs-params">self,y,y_pre</span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">1</span>-(<span class="hljs-variable language_">self</span>.mse(y,y_pre)/np.var(y))<br><br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">score</span>(<span class="hljs-params">self,X_test,y_test</span>):<br>    <span class="hljs-string">'''根据测试数据集确定当前模型的准确度'''</span><br>    y_predict = <span class="hljs-variable language_">self</span>.predict(X_test)<br>    <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>.r2_score(y_test,y_predict),<span class="hljs-variable language_">self</span>.rmse(y_test,y_predict)<br><br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">__repr__</span>(<span class="hljs-params">self</span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-string">'LinearRegression()'</span><br><br>x_train,x_test,y_train,y_test = train_test_split(X,y)<br><br>reg = LinearRegression()<br>reg.fit_normal(x_train,y_train)<br>r2,rmse = reg.score(x_test,y_test)<br><br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">"debug_begin"</span>);<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">test</span>(<span class="hljs-params">rmse,r2</span>):<br>    <span class="hljs-keyword">if</span> rmse&gt;<span class="hljs-number">50</span> <span class="hljs-keyword">or</span> r2&gt;<span class="hljs-number">0.5</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-literal">True</span>)<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-literal">False</span>)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">"debug_end"</span>);<br>test(rmse,r2)<br><br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">"debug_begin"</span>);<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">test</span>(<span class="hljs-params">rmse,r2</span>):<br>    <span class="hljs-keyword">if</span> rmse&gt;<span class="hljs-number">50</span> <span class="hljs-keyword">or</span> r2&gt;<span class="hljs-number">0.5</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-literal">True</span>)<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-literal">False</span>)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">"debug_end"</span>);<br>test(rmse,r2)<br><br></code></pre></td></tr></table></figure>
<h2 id="逻辑回归-乳腺癌预测"><a href="#逻辑回归-乳腺癌预测" class="headerlink" title="逻辑回归-乳腺癌预测"></a>逻辑回归-乳腺癌预测</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> random<br><span class="hljs-keyword">import</span> warnings<br>warnings.filterwarnings(<span class="hljs-string">"ignore"</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_breast_cancer</span>():<br>    X = []<br>    y = []<br>    line = <span class="hljs-built_in">input</span>()<br>    <span class="hljs-keyword">while</span> line:<br>        dx = []<br>        data = [np.float64(l) <span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> line.strip().split(<span class="hljs-string">','</span>)]<br>        X.append(np.array(data[:-<span class="hljs-number">1</span>]))<br>        y.append(<span class="hljs-built_in">int</span>(data[-<span class="hljs-number">1</span>]))<br>        line = <span class="hljs-built_in">input</span>()<br>    <span class="hljs-keyword">return</span> np.array(X),np.array(y)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_test_split</span>(<span class="hljs-params">X,Y,test_size=<span class="hljs-number">0.2</span>,random_state=<span class="hljs-number">5</span></span>):<br>    n_samples = <span class="hljs-built_in">len</span>(X)<br>    indices = np.arange(n_samples)<br>    train_indexs = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">set</span>(random.sample(indices.tolist(),<span class="hljs-built_in">int</span>(n_samples*(<span class="hljs-number">1</span>-test_size)))))<br>    test_indexs = [k <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> indices <span class="hljs-keyword">if</span> k <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> train_indexs]<br>    <span class="hljs-keyword">return</span> X[train_indexs],X[test_indexs],Y[train_indexs],Y[test_indexs]<br><br>X,y = load_breast_cancer()<br>x_train,x_test,y_train,y_test = train_test_split(X,y)<br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Logisticregression</span>():<br><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, learn_rate = <span class="hljs-number">0.001</span>, max_iteration=<span class="hljs-number">10000</span></span>):<br><br>        <span class="hljs-variable language_">self</span>.learn_rate = learn_rate<br>        <span class="hljs-variable language_">self</span>.max_iteration = max_iteration<br>        <span class="hljs-variable language_">self</span>._X_train = <span class="hljs-literal">None</span><br>        <span class="hljs-variable language_">self</span>._y_train = <span class="hljs-literal">None</span><br>        <span class="hljs-variable language_">self</span>._w = <span class="hljs-literal">None</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">fit</span>(<span class="hljs-params">self, X_train, y_train</span>):<br><br>        m_samples, n_features = X_train.shape<br>        <span class="hljs-variable language_">self</span>._X_train = np.insert(X_train, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, axis=<span class="hljs-number">1</span>)<br>        <span class="hljs-variable language_">self</span>._y_train = np.reshape(y_train, (m_samples, <span class="hljs-number">1</span>))<br>        limit = np.sqrt(<span class="hljs-number">1</span> / n_features)<br>        w = np.random.uniform(-limit, limit, (n_features, <span class="hljs-number">1</span>))<br>        b = <span class="hljs-number">0</span><br>        <span class="hljs-variable language_">self</span>.w = np.insert(w, <span class="hljs-number">0</span>, b, axis=<span class="hljs-number">0</span>)<br>        iteration = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">while</span> iteration &lt; <span class="hljs-variable language_">self</span>.max_iteration:<br>            h_x = <span class="hljs-variable language_">self</span>._X_train.dot(<span class="hljs-variable language_">self</span>.w)<br>            y_pred = <span class="hljs-number">1</span>/(<span class="hljs-number">1</span>+np.exp(- h_x))<br>            w_grad = <span class="hljs-variable language_">self</span>._X_train.T.dot(y_pred - <span class="hljs-variable language_">self</span>._y_train)<br>            <span class="hljs-variable language_">self</span>.w = <span class="hljs-variable language_">self</span>.w - <span class="hljs-variable language_">self</span>.learn_rate * w_grad<br>            iteration = iteration + <span class="hljs-number">1</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>(<span class="hljs-params">self, X_test</span>):<br><br>        X_test = np.insert(X_test, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, axis=<span class="hljs-number">1</span>)<br>        h_x = X_test.dot(<span class="hljs-variable language_">self</span>.w)<br>        y_pripr_1 = (<span class="hljs-number">1</span>/(<span class="hljs-number">1</span>+np.exp(-h_x)))<br>        y_pripr_0 = <span class="hljs-number">1</span> - y_pripr_1<br>        y_cal = y_pripr_1 - y_pripr_0<br>        y_class = np.where(y_cal &gt; <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>)<br>        <span class="hljs-keyword">return</span> y_class<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">score</span>(<span class="hljs-params">self, X_test, y_test</span>):<br><br>        j = <span class="hljs-number">0</span><br>        y_test = np.reshape(y_test,(<span class="hljs-built_in">len</span>(y_test),<span class="hljs-number">1</span>))<br>        y_hat = <span class="hljs-variable language_">self</span>.predict(X_test)<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(y_test.shape[<span class="hljs-number">0</span>]):<br>            <span class="hljs-keyword">if</span> y_hat[i,<span class="hljs-number">0</span>] == y_test[i,<span class="hljs-number">0</span>]:<br>                j += <span class="hljs-number">1</span><br>        acc = j / <span class="hljs-built_in">len</span>(y_test)<br>        y_test = <span class="hljs-built_in">list</span>(y_test.reshape((<span class="hljs-number">1</span>,-<span class="hljs-number">1</span>))[<span class="hljs-number">0</span>])<br>        y_hat = <span class="hljs-built_in">list</span>(y_hat.reshape((<span class="hljs-number">1</span>,-<span class="hljs-number">1</span>))[<span class="hljs-number">0</span>])<br><br>        precision = <span class="hljs-variable language_">self</span>.get_precision(y_test,y_hat)<br>        recall = <span class="hljs-variable language_">self</span>.get_recall(y_test,y_hat)<br>        auc = <span class="hljs-variable language_">self</span>.get_auc(y_test,y_hat)<br>        <span class="hljs-keyword">return</span> acc,precision,recall,auc<br><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_precision</span>(<span class="hljs-params">self,y,y_hat</span>):<br>        true_positive = <span class="hljs-built_in">sum</span>(yi <span class="hljs-keyword">and</span> yi_hat <span class="hljs-keyword">for</span> yi,yi_hat <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(y,y_hat))<br>        predicted_positive = <span class="hljs-built_in">sum</span>(y_hat)<br>        <span class="hljs-keyword">return</span> true_positive/predicted_positive<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_recall</span>(<span class="hljs-params">self,y,y_hat</span>):<br>        true_positive = <span class="hljs-built_in">sum</span>(yi <span class="hljs-keyword">and</span> yi_hat <span class="hljs-keyword">for</span> yi,yi_hat <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(y,y_hat))<br>        actual_positive = <span class="hljs-built_in">sum</span>(y)<br>        <span class="hljs-keyword">return</span> true_positive/actual_positive<br><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_tnr</span>(<span class="hljs-params">self,y,y_hat</span>):<br>        true_negative = <span class="hljs-built_in">sum</span>(<span class="hljs-number">1</span>-(yi <span class="hljs-keyword">or</span> yi_hat) <span class="hljs-keyword">for</span> yi,yi_hat <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(y,y_hat))<br>        actual_negative = <span class="hljs-built_in">len</span>(y) - <span class="hljs-built_in">sum</span>(y)<br>        <span class="hljs-keyword">return</span> true_negative/actual_negative<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_roc</span>(<span class="hljs-params">self,y,y_hat</span>):<br>        thresholds = <span class="hljs-built_in">sorted</span>(<span class="hljs-built_in">set</span>(y_hat),reverse=<span class="hljs-literal">True</span>)<br>        ret = [[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>]]<br>        <span class="hljs-keyword">for</span> threshold <span class="hljs-keyword">in</span> thresholds:<br>            y_hat = [<span class="hljs-built_in">int</span>(yi_hat &gt;= threshold) <span class="hljs-keyword">for</span> yi_hat <span class="hljs-keyword">in</span> y_hat]<br>            ret.append([<span class="hljs-variable language_">self</span>.get_recall(y,y_hat),<span class="hljs-number">1</span>-<span class="hljs-variable language_">self</span>.get_tnr(y,y_hat)])<br>        <span class="hljs-keyword">return</span> ret<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_auc</span>(<span class="hljs-params">self,y,y_hat</span>):<br>        roc = <span class="hljs-built_in">iter</span>(<span class="hljs-variable language_">self</span>.get_roc(y,y_hat))<br>        tpr_pre, fpr_pre = <span class="hljs-built_in">next</span>(roc)<br>        auc = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> tpr,fpr <span class="hljs-keyword">in</span> roc:<br>            auc += (tpr+tpr_pre)*(fpr-fpr_pre)/<span class="hljs-number">2</span><br>            tpr_pre = tpr<br>            fpr_pre = fpr<br>        <span class="hljs-keyword">return</span> auc<br><br>lr = Logisticregression()<br>lr.fit(x_train,y_train)<br>acc,precision,recall,auc = lr.score(x_test,y_test)<br><br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">"debug_begin"</span>);<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">test</span>(<span class="hljs-params">acc,auc</span>):<br>    <span class="hljs-keyword">if</span> acc&gt;<span class="hljs-number">0.8</span> <span class="hljs-keyword">or</span> auc&gt;<span class="hljs-number">0.8</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-literal">True</span>)<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-literal">False</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">"debug_end"</span>);<br>test(acc,auc)<br><br></code></pre></td></tr></table></figure>
<h2 id="svm-手写数字识别"><a href="#svm-手写数字识别" class="headerlink" title="svm-手写数字识别"></a>svm-手写数字识别</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span>  warnings<br><span class="hljs-keyword">import</span> random<br>warnings.filterwarnings(<span class="hljs-string">"ignore"</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_digits</span>():<br>    X = []<br>    y = []<br>    line = <span class="hljs-built_in">input</span>()<br>    <span class="hljs-keyword">while</span> line:<br>        dx = []<br>        data = [l <span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> line.strip().split(<span class="hljs-string">','</span>)]<br>        X.append(np.array([np.<span class="hljs-built_in">float</span>(d) <span class="hljs-keyword">for</span> d <span class="hljs-keyword">in</span> data[:-<span class="hljs-number">1</span>]]))<br>        y.append(np.<span class="hljs-built_in">int</span>(data[-<span class="hljs-number">1</span>]))<br>        line = <span class="hljs-built_in">input</span>()<br>        <span class="hljs-keyword">if</span> <span class="hljs-string">'#'</span> <span class="hljs-keyword">in</span> line:<br>            <span class="hljs-keyword">break</span><br>    <span class="hljs-keyword">return</span> np.array(X),np.array(y)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_test_split</span>(<span class="hljs-params">X,Y,test_size=<span class="hljs-number">0.2</span>,random_state=<span class="hljs-number">5</span></span>):<br>    n_samples = <span class="hljs-built_in">len</span>(X)<br>    <span class="hljs-keyword">assert</span> <span class="hljs-built_in">len</span>(X)==<span class="hljs-built_in">len</span>(Y)<br><br>    indices = np.arange(n_samples)<br>    random.seed(random_state)<br><br>    train_indexs = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">set</span>(random.sample(indices.tolist(),<span class="hljs-built_in">int</span>(n_samples*(<span class="hljs-number">1</span>-test_size)))))<br>    test_indexs = [k <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> indices <span class="hljs-keyword">if</span> k <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> train_indexs]<br>    <span class="hljs-keyword">return</span> X[train_indexs,:],X[test_indexs,:],Y[train_indexs],Y[test_indexs]<br><br>X,y = load_digits()<br>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="hljs-number">0.5</span>)<br><span class="hljs-keyword">class</span> <span class="hljs-title class_">SVC</span>():<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,X,Y,alpha,steps,reg</span>):<br>        <span class="hljs-variable language_">self</span>.X = X<br>        <span class="hljs-variable language_">self</span>.y = Y<br>        <span class="hljs-variable language_">self</span>.alpha = alpha<br>        <span class="hljs-variable language_">self</span>.steps = steps<br>        <span class="hljs-variable language_">self</span>.reg = reg<br>        <span class="hljs-variable language_">self</span>.model(<span class="hljs-variable language_">self</span>.X,<span class="hljs-variable language_">self</span>.y,<span class="hljs-variable language_">self</span>.alpha,<span class="hljs-variable language_">self</span>.steps,<span class="hljs-variable language_">self</span>.reg)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">lossAndGradNaive</span>(<span class="hljs-params">self,X,Y,W,reg</span>):<br>        dW=np.zeros(W.shape)<br>        loss = <span class="hljs-number">0.0</span><br>        num_class=W.shape[<span class="hljs-number">0</span>]<br>        num_X=X.shape[<span class="hljs-number">0</span>]<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_X):<br>            scores=np.dot(W,X[i])<br>            cur_scores=scores[<span class="hljs-built_in">int</span>(Y[i])]<br>            <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_class):<br>                <span class="hljs-keyword">if</span> j==Y[i]:<br>                    <span class="hljs-keyword">continue</span><br>                margin=scores[j]-cur_scores+<span class="hljs-number">1</span><br>                <span class="hljs-keyword">if</span> margin&gt;<span class="hljs-number">0</span>:<br>                    loss+=margin<br>                    dW[j,:]+=X[i]<br>                    dW[<span class="hljs-built_in">int</span>(Y[i]),:]-=X[i]<br>        loss/=num_X<br>        dW/=num_X<br>        loss+=reg*np.<span class="hljs-built_in">sum</span>(W*W)<br>        dW+=<span class="hljs-number">2</span>*reg*W<br>        <span class="hljs-keyword">return</span> loss,dW<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">lossAndGradVector</span>(<span class="hljs-params">self,X,Y,W,reg</span>):<br>        dW=np.zeros(W.shape)<br>        N=X.shape[<span class="hljs-number">0</span>]<br>        Y_=X.dot(W.T)<br>        margin=Y_-Y_[<span class="hljs-built_in">range</span>(N),Y.astype(<span class="hljs-built_in">int</span>)].reshape([-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>])+<span class="hljs-number">1.0</span><br>        margin[<span class="hljs-built_in">range</span>(N),Y.astype(<span class="hljs-built_in">int</span>)]=<span class="hljs-number">0.0</span><br>        margin=(margin&gt;<span class="hljs-number">0</span>)*margin<br>        loss=<span class="hljs-number">0.0</span><br>        loss+=np.<span class="hljs-built_in">sum</span>(margin)/N<br>        loss+=reg*np.<span class="hljs-built_in">sum</span>(W*W)<br><br>        countsX=(margin&gt;<span class="hljs-number">0</span>).astype(<span class="hljs-built_in">int</span>)<br>        countsX[<span class="hljs-built_in">range</span>(N),Y.astype(<span class="hljs-built_in">int</span>)]=-np.<span class="hljs-built_in">sum</span>(countsX,axis=<span class="hljs-number">1</span>)<br>        dW+=np.dot(countsX.T,X)/N+<span class="hljs-number">2</span>*reg*W<br>        <span class="hljs-keyword">return</span> loss,dW<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>(<span class="hljs-params">self,X,W</span>):<br>        X=np.hstack([X, np.ones((X.shape[<span class="hljs-number">0</span>], <span class="hljs-number">1</span>))])<br>        Y_=np.dot(X,W.T)<br>        Y_pre=np.argmax(Y_,axis=<span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">return</span> Y_pre<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">accuracy</span>(<span class="hljs-params">self,X,Y</span>):<br>        Y_pre=<span class="hljs-variable language_">self</span>.predict(X,<span class="hljs-variable language_">self</span>.W)<br>        acc=(Y_pre==Y).mean()<br>        <span class="hljs-keyword">return</span> acc<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">model</span>(<span class="hljs-params">self,X,Y,alpha,steps,reg</span>):<br>        X=np.hstack([X, np.ones((X.shape[<span class="hljs-number">0</span>], <span class="hljs-number">1</span>))])<br>        W = np.random.randn(<span class="hljs-number">10</span>,X.shape[<span class="hljs-number">1</span>]) * <span class="hljs-number">0.0001</span><br>        <span class="hljs-keyword">for</span> step <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(steps):<br>            loss,grad=<span class="hljs-variable language_">self</span>.lossAndGradNaive(X,Y,W,reg)<br>            W-=alpha*grad<br>        <span class="hljs-variable language_">self</span>.W = W<br><br>svc=SVC(X_train,y_train,<span class="hljs-number">0.01</span>,<span class="hljs-number">25</span>,<span class="hljs-number">0.5</span>)<br>acc = svc.accuracy(X_test,y_test)<br><br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">"debug_begin"</span>);<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">test_acc</span>(<span class="hljs-params">acc</span>):<br>    res = <span class="hljs-literal">True</span> <span class="hljs-keyword">if</span> acc&gt;<span class="hljs-number">0.85</span> <span class="hljs-keyword">else</span> <span class="hljs-literal">False</span><br>    <span class="hljs-built_in">print</span>(res)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">"debug_end"</span>);<br><br>test_acc(acc)<br></code></pre></td></tr></table></figure>
<h2 id="svm-梯度下降实现-SVM-多分类问题"><a href="#svm-梯度下降实现-SVM-多分类问题" class="headerlink" title="svm-梯度下降实现 SVM 多分类问题"></a>svm-梯度下降实现 SVM 多分类问题</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> warnings<br><br><span class="hljs-keyword">def</span>  <span class="hljs-title function_">load_iris</span>():<br>        X  =  []<br>        y  =  []<br>        line  =  <span class="hljs-built_in">input</span>()<br>        <span class="hljs-keyword">while</span>  line:<br>            dx  =  []<br>            data  =  [l  <span class="hljs-keyword">for</span>  l  <span class="hljs-keyword">in</span>  line.strip().split(<span class="hljs-string">','</span>)]<br>            X.append(np.array([np.<span class="hljs-built_in">float</span>(d)  <span class="hljs-keyword">for</span>  d  <span class="hljs-keyword">in</span>  data[:-<span class="hljs-number">1</span>]]))<br>            y.append(np.<span class="hljs-built_in">int</span>(data[-<span class="hljs-number">1</span>]))<br>            line  =  <span class="hljs-built_in">input</span>()<br>            <span class="hljs-keyword">if</span> <span class="hljs-string">'#'</span> <span class="hljs-keyword">in</span> line:<br>                <span class="hljs-keyword">break</span><br>        <span class="hljs-keyword">return</span>  np.array(X),np.array(y)<br><br>x,y = load_iris()<br><span class="hljs-built_in">print</span>(<span class="hljs-string">"debug_begin"</span>);<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">test_acc</span>(<span class="hljs-params">acc</span>):<br>        res = <span class="hljs-literal">True</span> <span class="hljs-keyword">if</span> acc&gt;=<span class="hljs-number">0.9</span> <span class="hljs-keyword">else</span> <span class="hljs-literal">False</span><br>        <span class="hljs-built_in">print</span>(res)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">"debug_end"</span>);<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">normalize_data</span>(<span class="hljs-params">data</span>):<br>    mean = np.mean(data, axis=<span class="hljs-number">0</span>)<br>    std = np.std(data, axis=<span class="hljs-number">0</span>)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(data.shape[<span class="hljs-number">0</span>]):<br>        data[i, :] = (data[i, :] - mean) / std<br>    <span class="hljs-keyword">return</span>  data<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">convert_to_one_hot</span>(<span class="hljs-params">y, C</span>):<br>    <span class="hljs-keyword">return</span> np.eye(C)[y.reshape(-<span class="hljs-number">1</span>)]<br><br>batchsz = <span class="hljs-number">150</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">obtain_w_via_gradient_descent</span>(<span class="hljs-params">x, c, y, penalty_c, threshold = <span class="hljs-number">1e-19</span>, learn_rate = <span class="hljs-number">1e-4</span></span>):<br>    <span class="hljs-string">""" 利用梯度下降法求解如下的SVM问题：min 1/2 * w^T * w + C * Σ_i=1:n（max(0, 1 - y_i * (w^T * x_i + b))）</span><br><span class="hljs-string">    :param x: 训练样本 x = [x_1, x_2, ..., x_i]</span><br><span class="hljs-string">    :param c: 类别数</span><br><span class="hljs-string">    :param y: 样本标签 y = [y_1, y_2, ..., y_c]</span><br><span class="hljs-string">    :param threshold: 梯度下降停止阈值</span><br><span class="hljs-string">    """</span><br>    data_num = np.shape(x)[<span class="hljs-number">1</span>]<br>    feature_dim = np.shape(x)[<span class="hljs-number">0</span>]<br>    w = np.ones([feature_dim, c], dtype=np.float32)<br>    b = np.ones([c, <span class="hljs-number">1</span>], dtype=np.float32)<br>    dl_dw = np.zeros([feature_dim, c], dtype=np.<span class="hljs-built_in">float</span>)<br>    dl_db = np.zeros([c, <span class="hljs-number">1</span>], dtype=np.<span class="hljs-built_in">float</span>)<br>    it = <span class="hljs-number">1</span><br>    th = <span class="hljs-number">0.1</span><br>    <span class="hljs-keyword">while</span> it &lt; <span class="hljs-number">50000</span> <span class="hljs-keyword">and</span> th &gt; threshold:<br>        a = np.tile(b, [<span class="hljs-number">1</span>, data_num])<br>        ksi = (np.transpose(w) @ x + np.tile(b, [<span class="hljs-number">1</span>, data_num])) * y<br>        index_martix = ksi &lt; <span class="hljs-number">1</span><br><br>        <span class="hljs-keyword">for</span> class_num <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(c):<br>            index_vector = index_martix[class_num, :]<br><br>            <span class="hljs-keyword">if</span> <span class="hljs-literal">True</span> <span class="hljs-keyword">in</span> index_vector:<br>                x_c = x[:, index_vector]<br><br>                data_num_c = np.shape(x_c)[<span class="hljs-number">1</span>]<br>                e = np.ones([data_num_c, <span class="hljs-number">1</span>], dtype=np.<span class="hljs-built_in">float</span>)<br>                y_c = np.reshape(y[class_num, index_vector], [data_num_c, <span class="hljs-number">1</span>])<br>                w_c = np.reshape(w[:, class_num], [feature_dim, <span class="hljs-number">1</span>])<br>                b_c = b[class_num]<br><br>                dl_dw[:, class_num] = (w_c + <span class="hljs-number">2</span> * penalty_c * (x_c @ np.transpose(x_c) @ w_c +<br>                                                              x_c @ e * b_c -<br>                                                              x_c @ y_c))[:, <span class="hljs-number">0</span>]<br>                dl_db[class_num, <span class="hljs-number">0</span>] = <span class="hljs-number">2</span> * penalty_c * (b_c * data_num_c +<br>                                                       np.transpose(w_c) @ x_c @ e -<br>                                                       np.transpose(y_c) @ e)<br>            <span class="hljs-keyword">else</span>:<br>                w_c = np.reshape(w[:, class_num], [feature_dim, <span class="hljs-number">1</span>])<br>                dl_dw[:, class_num] = w_c[:, <span class="hljs-number">0</span>]<br>                dl_db[class_num, <span class="hljs-number">0</span>] = <span class="hljs-number">0</span><br><br>        w_ = w - learn_rate * (dl_dw / np.linalg.norm(dl_dw, <span class="hljs-built_in">ord</span>=<span class="hljs-number">2</span>))<br>        b_ = b - learn_rate * dl_db<br><br>        th = np.<span class="hljs-built_in">sum</span>(np.square(w_ - w)) + np.<span class="hljs-built_in">sum</span>(np.square(b_ - b))<br>        it = it + <span class="hljs-number">1</span><br><br>        w = w_<br>        b = b_<br><br>        y_predict = np.transpose(w) @ x + np.tile(b, [<span class="hljs-number">1</span>, data_num])<br>        correct_prediction = np.equal(np.argmax(y_predict, <span class="hljs-number">0</span>), np.argmax(y, <span class="hljs-number">0</span>))<br>        accuracy = np.mean(correct_prediction.astype(np.<span class="hljs-built_in">float</span>))<br><br>    <span class="hljs-keyword">return</span> accuracy<br><br>warnings.filterwarnings(<span class="hljs-string">"ignore"</span>)<br><br>x = normalize_data(x)<br>y = y.astype(np.<span class="hljs-built_in">int</span>)<br>y_onehot = convert_to_one_hot(y,<span class="hljs-number">3</span>)<br>y_onehot[y_onehot==<span class="hljs-number">0</span>]=-<span class="hljs-number">1</span><br><br>x = np.transpose(x)<br>y_onehot = np.transpose(y_onehot)<br>w = np.array([[<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>],[<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>]])<br>b = np.array([[<span class="hljs-number">1</span>],[<span class="hljs-number">1</span>],[<span class="hljs-number">1</span>]])<br>acc = obtain_w_via_gradient_descent(x,<span class="hljs-number">3</span>,y_onehot,<span class="hljs-number">0.5</span>)<br><br>test_acc(acc)<br></code></pre></td></tr></table></figure>
<p>八道代码补全题主要涉及以下机器学习算法和核心组件：</p>
<ul>
<li>题 1：数据划分（留出法，Hold-out Method）</li>
<li>题 2：数据划分（K 折交叉验证，K-Fold Cross Validation）</li>
<li>题 3–题 4：优化算法（一维与二维梯度下降，Gradient Descent）</li>
<li>题 5–题 6：监督学习回归算法（线性回归，Linear Regression，使用正规方程求解）</li>
<li>题 7–题 8：监督学习分类算法（逻辑回归，Logistic Regression，使用梯度下降优化）</li>
</ul>
<p>以下对这些算法的执行流程和关键实现进行系统讲解，重点突出代码补全题中常考的核心步骤。</p>
<h3 id="1-留出法（题-1：train-test-split）"><a href="#1-留出法（题-1：train-test-split）" class="headerlink" title="1. 留出法（题 1：train_test_split）"></a>1. 留出法（题 1：train_test_split）</h3><p><strong>流程</strong>：</p>
<ol>
<li>固定随机种子确保可复现。</li>
<li>计算训练样本数量。</li>
<li>随机抽取训练集索引。</li>
<li>测试集索引取剩余部分。</li>
<li>根据索引切分特征 X 和标签 y。</li>
</ol>
<p><strong>关键实现</strong>：</p>
<ul>
<li>random.sample(range(n_samples), train_num)：无放回随机抽样。</li>
<li>列表推导或 set 差集得到测试索引。</li>
<li>同时切分 X 和 y，保证对应关系不变。</li>
</ul>
<h3 id="2-K-折交叉验证（题-2：simple-kfold）"><a href="#2-K-折交叉验证（题-2：simple-kfold）" class="headerlink" title="2. K 折交叉验证（题 2：simple_kfold）"></a>2. K 折交叉验证（题 2：simple_kfold）</h3><p><strong>流程</strong>：</p>
<ol>
<li>将数据集等分为 n_splits 份（前几份可能多 1 个样本）。</li>
<li>依次将每一份作为测试折，其余折合并为训练集。</li>
<li>返回所有折的训练/测试索引对。</li>
</ol>
<p><strong>关键实现</strong>：</p>
<ul>
<li>fold_sizes 计算每折大小，处理余数。</li>
<li>使用切片 indices[current:current + fold_size]得到测试索引。</li>
<li>np.concatenate 合并前后部分得到训练索引。</li>
</ul>
<h3 id="3–4-梯度下降（题-3-一维，题-4-二维）"><a href="#3–4-梯度下降（题-3-一维，题-4-二维）" class="headerlink" title="3–4. 梯度下降（题 3 一维，题 4 二维）"></a>3–4. 梯度下降（题 3 一维，题 4 二维）</h3><p><strong>流程</strong>：</p>
<ol>
<li>从初始点开始。</li>
<li>计算当前点的梯度。</li>
<li>判断梯度是否足够小（收敛）。</li>
<li>若未收敛，沿负梯度方向更新参数。</li>
<li>重复直到收敛或达到最大迭代次数。</li>
</ol>
<p><strong>关键实现</strong>：</p>
<ul>
<li>一维：abs(grad_cur) &lt; precision</li>
<li>二维：np.linalg.norm(grad_cur) &lt; precision（2-范数）</li>
<li>更新公式：cur_x = cur_x - learning_rate * grad_cur（负梯度方向）</li>
</ul>
<h3 id="5–6-线性回归（正规方程法）"><a href="#5–6-线性回归（正规方程法）" class="headerlink" title="5–6. 线性回归（正规方程法）"></a>5–6. 线性回归（正规方程法）</h3><p><strong>流程</strong>：</p>
<ol>
<li>在特征矩阵左侧添加全 1 列（偏置项）。</li>
<li>使用正规方程直接求解最优参数 θ。</li>
<li>分离截距和系数。</li>
<li>预测时同样添加偏置列，再与 θ 相乘。</li>
<li>评估常用 MSE 或 R²。</li>
</ol>
<p><strong>关键实现</strong>：</p>
<ul>
<li>添加偏置：np.hstack([np.ones((n_samples, 1)), X])</li>
<li>正规方程：np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)</li>
<li>预测：X_b.dot(self._theta)</li>
<li>MSE：np.mean((y_true - y_pred) ** 2)</li>
</ul>
<h3 id="7–8-逻辑回归（梯度下降优化）"><a href="#7–8-逻辑回归（梯度下降优化）" class="headerlink" title="7–8. 逻辑回归（梯度下降优化）"></a>7–8. 逻辑回归（梯度下降优化）</h3><p><strong>流程</strong>：</p>
<ol>
<li>在特征矩阵左侧添加全 1 列（偏置项）。</li>
<li>初始化权重为零。</li>
<li>迭代多次：<ul>
<li>计算线性输出 z = X_b @ w</li>
<li>通过 sigmoid 函数得到预测概率 h</li>
<li>计算梯度（平均交叉熵梯度）</li>
<li>更新权重</li>
</ul>
</li>
<li>预测时计算概率，大于等于 0.5 判为 1 类。</li>
</ol>
<p><strong>关键实现</strong>：</p>
<ul>
<li>添加偏置：np.hstack([np.ones((m, 1)), X_train])</li>
<li>Sigmoid：1 / (1 + np.exp(-z))</li>
<li>梯度：X_b.T.dot(h - y) / m（有时不除 m，效果类似）</li>
<li>更新：self.w -= learning_rate * gradient</li>
<li>预测阈值：(prob &gt;= 0.5).astype(int)</li>
</ul>
<p>监督学习的基础管道：数据划分 → 模型训练（优化求解参数） → 预测与评估。</p>
<div id="paginator"></div></div><div id="post-footer"><div id="pages"><div class="footer-link" style="width: 50%;text-align:right;border-right:1px #fe2 solid"><a href="/Arknight-notes/posts/2418.html">← 下一篇 2026-01-08-机器学习复习</a></div><div class="footer-link" style="width: 50%;right:1px;border-left:1px #fe2 solid"><a href="/Arknight-notes/posts/64338.html">2026-01-06-人工智能导论复习 上一篇 →</a></div></div></div><div id="comments"><div id="gitalk"></div></div></div><div class="bottom-btn"><div><a class="i-top" id="to-top" onClick="scrolls.scrolltop();" title="回到顶部" style="opacity: 0; display: none;">∧ </a><a class="i-index" id="to-index" href="#toc-div" title="文章目录">≡</a><a class="i-color" id="color-mode" onClick="colorMode.change()" title="切换主题"></a></div></div></article><aside><div id="about"><a href="/Arknight-notes/" id="logo"><img src="https://pic4.zhimg.com/80/v2-d9884f32711e19e80979eac58e943897_720w.webp" alt="Logo" style="margin:20;border-radius:0;"></a><h1 id="Dr"><a href="zhongye">柊野</a></h1><div id="description"><p></p></div></div><div id="aside-block"><div id="toc-div"><h1>目录</h1><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AF%84%E4%BC%B0%E6%96%B9%E6%B3%95%EF%BC%88%E7%95%99%E5%87%BA%E6%B3%95%EF%BC%89"><span class="toc-number">1.</span> <span class="toc-text">评估方法（留出法）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AF%84%E4%BC%B0%E6%96%B9%E6%B3%95%EF%BC%88%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81%E6%B3%95%EF%BC%89"><span class="toc-number">1.1.</span> <span class="toc-text">评估方法（交叉验证法）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95-1"><span class="toc-number">1.2.</span> <span class="toc-text">优化算法-梯度下降法 1</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95-2"><span class="toc-number">2.</span> <span class="toc-text">优化算法-梯度下降法 2</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92-%E7%B3%96%E5%B0%BF%E7%97%85%E9%A2%84%E6%B5%8B"><span class="toc-number">3.</span> <span class="toc-text">线性回归-糖尿病预测</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92-%E4%B9%B3%E8%85%BA%E7%99%8C%E9%A2%84%E6%B5%8B"><span class="toc-number">4.</span> <span class="toc-text">逻辑回归-乳腺癌预测</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#svm-%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB"><span class="toc-number">5.</span> <span class="toc-text">svm-手写数字识别</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#svm-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E5%AE%9E%E7%8E%B0-SVM-%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98"><span class="toc-number">6.</span> <span class="toc-text">svm-梯度下降实现 SVM 多分类问题</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E7%95%99%E5%87%BA%E6%B3%95%EF%BC%88%E9%A2%98-1%EF%BC%9Atrain-test-split%EF%BC%89"><span class="toc-number">6.1.</span> <span class="toc-text">1. 留出法（题 1：train_test_split）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-K-%E6%8A%98%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81%EF%BC%88%E9%A2%98-2%EF%BC%9Asimple-kfold%EF%BC%89"><span class="toc-number">6.2.</span> <span class="toc-text">2. K 折交叉验证（题 2：simple_kfold）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3%E2%80%934-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%EF%BC%88%E9%A2%98-3-%E4%B8%80%E7%BB%B4%EF%BC%8C%E9%A2%98-4-%E4%BA%8C%E7%BB%B4%EF%BC%89"><span class="toc-number">6.3.</span> <span class="toc-text">3–4. 梯度下降（题 3 一维，题 4 二维）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5%E2%80%936-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%EF%BC%88%E6%AD%A3%E8%A7%84%E6%96%B9%E7%A8%8B%E6%B3%95%EF%BC%89"><span class="toc-number">6.4.</span> <span class="toc-text">5–6. 线性回归（正规方程法）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7%E2%80%938-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%EF%BC%88%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E4%BC%98%E5%8C%96%EF%BC%89"><span class="toc-number">6.5.</span> <span class="toc-text">7–8. 逻辑回归（梯度下降优化）</span></a></li></ol></li></ol></div></div><footer><nobr><span class="icp-title">GZHU</span><span class="icp-content">193001-0001</span></nobr><br><nobr><span class="icp-title">OUTPOST</span><span class="icp-content">169-2025-0331</span></nobr><br><nobr>构建自 <a target="_blank" rel="noopener" href="http://hexo.io">Hexo</a></nobr><wbr><nobr> 使用主题 <a target="_blank" rel="noopener" href="https://github.com/Yue-plus/hexo-theme-arknights">Arknights</a></nobr><wbr><nobr> 主题作者 <a target="_blank" rel="noopener" href="https://github.com/Yue-plus">Yue_plus</a></nobr></footer></aside></main><canvas id="canvas-dust"></canvas></body></html>