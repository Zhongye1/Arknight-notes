<!DOCTYPE html><html lang="en" theme-mode="dark"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>2026-01-08-机器学习复习其二 | Notes|笔记站</title><link rel="icon" type="image/x-icon" href="/Arknight-notes/favicon.ico"><link rel="preload" as="font" crossorigin="anonymous" href="/Arknight-notes/font/Bender.ttf"><link rel="preload" as="font" crossorigin="anonymous" href="/Arknight-notes/font/BenderLight.ttf"><link rel="preload" as="font" crossorigin="anonymous" href="/Arknight-notes/font/JetBrainsMono-Regular.woff2"><link rel="stylesheet" href="/Arknight-notes/css/arknights.css"><style>@font-face {
  font-family: Bender;
  src: local('Bender'), url("/Arknight-notes/font/Bender.ttf"), url("/Arknight-notes/font/Bender.otf");
}
@font-face {
  font-family: BenderLight;
  src: local('BenderLight'), url("/Arknight-notes/font/BenderLight.ttf");
}
@font-face {
  font-family: 'JetBrains Mono';
  src: local('JetBrains Mono'), url('/Arknight-notes/font/JetBrainsMono-Regular.woff2') format('woff2');
}
</style><script>var config = {"root":"/Arknight-notes/","code_fold":90,"search":{"preload":false,"activeHolder":"Enter here","blurHolder":"Search","noResult":"Data \"$0\" not found"},"code":{"codeInfo":"$0 - $1 lines","copy":"copy"}}</script><link type="text/css" rel="stylesheet" href="/Arknight-notes/lib/encrypt/hbe.style.css"><script src="/Arknight-notes/js/gitalk.js"></script><script src="//unpkg.com/mermaid@10.5.0/dist/mermaid.min.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.6.1/MathJax.js"></script><script>MathJax.Hub.Config({
 menuSettings: {
   zoom: "None"
 },
 showMathMenu: false,
 jax: ["input/TeX","output/CommonHTML"],
 extensions: ["tex2jax.js"],
 TeX: {
   extensions: ["AMSmath.js","AMSsymbols.js"],
   equationNumbers: {
     autoNumber: "AMS"
   }
 },
 tex2jax: {
   inlineMath: [["\\(", "\\)"]],
   displayMath: [["\\[", "\\]"]]
 }
});</script><link type="text/css" rel="stylesheet" href="//unpkg.com/lightgallery@2.7.1/css/lightgallery.css"><link type="text/css" rel="stylesheet" href="//unpkg.com/lightgallery@2.7.1/css/lg-zoom.css"><link type="text/css" rel="stylesheet" href="//unpkg.com/lightgallery@2.7.1/css/lg-thumbnail.css"><link type="text/css" rel="stylesheet" href="/Arknight-notes/lib/fontawesome/css/all.min.css"><script>if (window.localStorage.getItem('theme-mode') === 'light')
 document.documentElement.setAttribute('theme-mode', 'light')
if (window.localStorage.getItem('theme-mode') === 'dark')
 document.documentElement.setAttribute('theme-mode', 'dark')</script><style>@font-face {
 font-family: BenderLight;
 src: local('Bender'), url("/Arknight-notes/font/BenderLight.woff2") format('woff2');
}
@font-face {
 font-family: 'JetBrains Mono';
 src: local('JetBrains Mono'), url('/Arknight-notes/font/JetBrainsMono-Regular.woff2') format('woff2');
}</style><style>:root {
 --dark-background: url('https://pica.zhimg.com/v2-1d14a5f80bbe62302dce99b273e3a948_r.jpg');
 --light-background: url('https://pic2.zhimg.com/v2-6269d74b4dafe14781d03790e5a86b21_r.jpg');
 --theme-encrypt-confirm: 'confirm'
}</style><script defer src="/Arknight-notes/js/arknights.js"></script><script defer src="/Arknight-notes/js/search.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script async src="/Arknight-notes/js/gitalk.js"></script><script defer type="module">import mermaid from '//unpkg.com/mermaid@10.5.0/dist/mermaid.esm.mjs';
window.mermaid = mermaid;
code.paintMermaid();
</script><script src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.6.1/MathJax.js"></script><script>MathJax.Hub.Config({
  menuSettings: {
    zoom: "None"
  },
  showMathMenu: false,
  jax: ["input/TeX","output/CommonHTML"],
  extensions: ["tex2jax.js"],
  TeX: {
    extensions: ["AMSmath.js","AMSsymbols.js"],
    equationNumbers: {
      autoNumber: "AMS"
    }
  },
  tex2jax: {
    inlineMath: [["\\(", "\\)"]],
    displayMath: [["\\[", "\\]"]]
  }
});
</script><script async src="//unpkg.com/lightgallery@2.7.1/lightgallery.min.js"></script><script async src="//unpkg.com/lightgallery@2.7.1/plugins/zoom/lg-zoom.min.js"></script><script async src="//unpkg.com/lightgallery@2.7.1/plugins/thumbnail/lg-thumbnail.min.js"></script><script async src="/Arknight-notes/lib/encrypt/hbe.js"></script><script async src="/Arknight-notes/js/pjax.js"></script><script class="pjax-js">reset= () => {gitalk = new Gitalk({
 clientID: 'Ov23ct13Fb0b67x23wnT',
 clientSecret: 'f18ce69dd545e3c0f5e2456afde9c756fe8a254a',
 repo: 'Arknight-notes',
 owner: 'Zhongye1',
 admin: ['Zhongye1'],
 distractionFreeMode: false,
 id: location.pathname
});
if (document.querySelector("#gitalk")) gitalk.render("gitalk");document.querySelector('.lg-container')?.remove()
lightGallery(document.getElementById('post-bg'), {
  plugins: [lgZoom,lgThumbnail],
  selector: '.item-img'})}</script><script>window.addEventListener("load",() => {pjax = new Pjax({
 cacheBust: false,
 selectors: ['title','article','#aside-block','.pjax-js','data-pjax','.busuanzi'],
 switches: {'article': Pjax.switches.sideBySide},
 switchesOptions: {
   'article': {
     classNames: {
       remove: "pjax-out",
       add: "pjax-in"
     }
   }
 }
});
document.addEventListener("pjax:complete", reset);document.addEventListener('pjax:success', _ => bszCaller.fetch(
 "//busuanzi.ibruce.info/busuanzi?jsonpCallback=BusuanziCallback", a => {
  bszTag.texts(a),
  bszTag.shows()
}));reset()})</script><script class="pjax-js">reset= () => {gitalk = new Gitalk({
 clientID: 'Ov23ct13Fb0b67x23wnT',
 clientSecret: 'f18ce69dd545e3c0f5e2456afde9c756fe8a254a',
 repo: 'Arknight-notes',
 owner: 'Zhongye1',
 admin: ['Zhongye1'],
 distractionFreeMode: false,
 id: location.pathname
});
if (document.querySelector("#gitalk")) gitalk.render("gitalk");document.querySelector('.lg-container')?.remove()
lightGallery(document.getElementById('post-bg'), {
  plugins: [lgZoom,lgThumbnail],
  selector: '.item-img'})}</script><script>window.addEventListener("load",() => {pjax = new Pjax({
 cacheBust: false,
 selectors: ['title','article','#aside-block','.pjax-js'],
 switches: {'article': Pjax.switches.sideBySide},
 switchesOptions: {
   'article': {
     classNames: {
       remove: "pjax-out",
       add: "pjax-in"
     }
   }
 }
});
document.addEventListener("pjax:complete", reset);reset()})</script><meta name="generator" content="Hexo 7.3.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style><link rel="alternate" href="/Arknight-notes/rss.xml" title="Notes|笔记站" type="application/atom+xml">
</head><body><div class="loading" style="opacity: 0;"><div class="loadingBar left"></div><div class="loadingBar right"></div></div><main><header class="closed"><div class="navBtn"><i class="navBtnIcon"><span class="navBtnIconBar"></span><span class="navBtnIconBar"></span><span class="navBtnIconBar"></span></i></div><nav><div class="navItem" id="search-header"><span class="navItemTitle"><input autocomplete="off" autocorrect="off" autocapitalize="none" placeholder="Search" spellcheck="false" maxlength="50" type="text" id="search-input"></span></div><div class="navItem" id="search-holder"></div><div class="search-popup" tabindex="0"><div id="search-result"></div></div><ol class="navContent"><li class="navItem"><a class="navBlock" href="/Arknight-notes/"><span class="navItemTitle">Home</span></a></li><li class="navItem" matchdata="categories,tags"><a class="navBlock" href="/Arknight-notes/archives/"><span class="navItemTitle">Archives</span></a></li><li class="navItem"><a class="navBlock" href="/Arknight-notes/about/"><span class="navItemTitle">About</span></a></li></ol></nav></header><article><div id="post-bg"><div id="post-title"><h1>2026-01-08-机器学习复习其二</h1><div id="post-info"><span>First Post: <div class="control"><time datetime="2026-01-08T18:55:07.000Z" id="date"> 2026-01-09</time></div></span><br><span>Last Update: <div class="control"><time datetime="2026-01-08T20:15:54.640Z" id="updated"> 2026-01-09</time></div></span><br><span id="busuanzi_container_page_pv">Page View: <span class="control" id="busuanzi_value_page_pv">loading...</span></span></div></div><hr><div id="post-content"><ul>
<li>以下哪些是机器学习中的数据预处理步骤？</li>
<li>监督学习包括以下哪些类型？</li>
<li>以下哪些算法属于无监督学习？</li>
<li>神经网络中的激活函数有哪些作用？</li>
<li>影响机器学习模型性能的因素有？</li>
<li>在构建决策树时，以下哪些可以作为分裂节点的选择标准？</li>
<li>以下哪些技术可以用于处理过拟合问题？</li>
<li>以下关于交叉验证的说法正确的是？</li>
<li>以下哪些是深度学习中的优化算法？</li>
<li>对于一个二分类问题，以下哪些指标可以全面评估模型性能？</li>
<li>以下属于机器学习中常用的特征工程方法的有？</li>
<li>下列关于支持向量机（SVM）的说法正确的是？</li>
<li>以下哪些是无监督学习的应用场景？</li>
<li>机器学习中常用的损失函数有？</li>
<li>以下属于深度学习框架的有？</li>
<li>以下属于监督学习任务的有？</li>
<li>常用的数据预处理操作包括？</li>
<li>以下哪些是决策树的优点？</li>
<li>属于集成学习算法的有？</li>
<li>神经网络中常用的激活函数有？</li>
<li>评估分类模型的指标有？</li>
<li>以下哪些方法可以防止模型过拟合？</li>
<li>线性回归模型的假设包括？</li>
<li>支持向量机的核函数类型有？</li>
<li>以下关于 K-Means 算法的描述正确的有？</li>
<li>下列哪些是机器学习的常见应用领域？</li>
<li>下列哪些是数据预处理的方法？</li>
<li>下列哪些是监督学习算法？</li>
<li>下列哪些是评估模型性能的指标？</li>
<li>下列哪些是特征工程的常用方法？</li>
<li>下列哪些是集成学习算法？</li>
<li>下列哪些是过拟合的解决方法？</li>
<li>下列哪些是降维方法？</li>
<li>下列哪些是数据挖掘的步骤？</li>
<li>下列哪些是特征选择的方法？</li>
<li>下列哪些是常用的特征工程方法？</li>
<li>下列哪些是评估分类模型性能的指标？</li>
<li>下列哪些是集成学习算法？</li>
<li>下列哪些是过拟合的解决方法？</li>
<li>下列哪些是降维方法？</li>
<li>下列哪些是监督学习算法？</li>
<li>下列哪些是数据预处理的方法？</li>
<li>下列哪些是特征选择的方法？</li>
<li>下列哪些是数据挖掘的步骤？</li>
<li>下列哪些是常用的交叉验证方法？</li>
<li>以下属于监督学习任务的有？</li>
<li>以下哪些方法可以用于降低过拟合风险？</li>
<li>以下关于支持向量机（SVM）的说法，正确的有？</li>
<li>以下属于无监督学习算法的有？</li>
<li>以下哪些是评估分类模型性能的指标？</li>
<li>以下关于随机森林的说法，正确的有？</li>
<li>以下哪些方法可以用于数据降维？</li>
<li>以下关于 K 近邻算法的说法，正确的有？</li>
<li>以下关于集成学习的方法，正确的有？</li>
<li>以下关于深度学习的说法，正确的有？</li>
<li>以下哪些是逻辑回归的特点？</li>
<li>以下关于聚类算法的说法，正确的有？</li>
<li>以下哪些方法可以用于处理类别不平衡问题？</li>
<li>以下关于梯度下降法的说法，正确的有？</li>
<li>下列哪些是机器学习的常见应用领域？</li>
<li>下列哪些是数据预处理的方法？</li>
<li>下列哪些是监督学习算法？</li>
<li>下列哪些是评估模型性能的指标？</li>
<li>下列哪些是特征工程的常用方法？</li>
<li>下列哪些是集成学习算法？</li>
<li>下列哪些是过拟合的解决方法？</li>
<li>下列哪些是降维方法？</li>
<li>下列哪些是数据挖掘的步骤？</li>
<li>下列哪些是特征选择的方法？</li>
<li>下列哪些是常用的特征工程方法？</li>
<li>下列哪些是评估分类模型性能的指标？</li>
<li>下列哪些是集成学习算法？</li>
<li>下列哪些是过拟合的解决方法？</li>
<li>下列哪些是降维方法？</li>
<li>下列哪些是监督学习算法？</li>
<li>下列哪些是数据预处理的方法？</li>
<li>下列哪些是特征选择的方法？</li>
<li>下列哪些是数据挖掘的步骤？</li>
<li>下列哪些是常用的交叉验证方法？</li>
<li>以下属于监督学习任务的有？</li>
<li>以下哪些方法可以用于降低过拟合风险？</li>
<li>以下关于支持向量机（SVM）的说法，正确的有？</li>
<li>以下属于无监督学习算法的有？</li>
<li>以下哪些是评估分类模型性能的指标？</li>
<li>以下关于随机森林的说法，正确的有？</li>
<li>以下哪些方法可以用于数据降维？</li>
<li>以下关于 K 近邻算法的说法，正确的有？</li>
<li>以下关于集成学习的方法，正确的有？</li>
<li>以下关于深度学习的说法，正确的有？</li>
<li>以下哪些是逻辑回归的特点？</li>
<li>以下关于聚类算法的说法，正确的有？</li>
<li>以下哪些方法可以用于处理类别不平衡问题？</li>
</ul>
<hr>
<h3 id="多选题完整列表-共-92-题"><a href="#多选题完整列表-共-92-题" class="headerlink" title="多选题完整列表 (共 92 题)"></a><strong>多选题完整列表 (共 92 题)</strong></h3><h4 id="1-以下哪些是机器学习中的数据预处理步骤-（）"><a href="#1-以下哪些是机器学习中的数据预处理步骤-（）" class="headerlink" title="1. 以下哪些是机器学习中的数据预处理步骤?（）"></a>1. 以下哪些是机器学习中的数据预处理步骤?（）</h4><p>A. 数据清洗</p>
<p>B. 数据归一化</p>
<p>C. 特征选择</p>
<p>D. 数据可视化</p>
<p><strong>答案: ABC</strong></p>
<h4 id="2-监督学习包括以下哪些类型-（）"><a href="#2-监督学习包括以下哪些类型-（）" class="headerlink" title="2. 监督学习包括以下哪些类型?（）"></a>2. 监督学习包括以下哪些类型?（）</h4><p>A. 分类</p>
<p>B. 回归</p>
<p>C. 聚类</p>
<p>D. 降维</p>
<p><strong>答案: AB</strong></p>
<h4 id="3-以下哪些算法属于无监督学习-（）"><a href="#3-以下哪些算法属于无监督学习-（）" class="headerlink" title="3. 以下哪些算法属于无监督学习?（）"></a>3. 以下哪些算法属于无监督学习?（）</h4><p>A. K-均值聚类</p>
<p>B. 主成分分析(PCA)</p>
<p>C. 关联规则挖掘</p>
<p>D. 线性判别分析(LDA)</p>
<p><strong>答案: ABC</strong></p>
<h4 id="4-神经网络中的激活函数有哪些作用-（）"><a href="#4-神经网络中的激活函数有哪些作用-（）" class="headerlink" title="4. 神经网络中的激活函数有哪些作用?（）"></a>4. 神经网络中的激活函数有哪些作用?（）</h4><p>A. 增加模型的非线性</p>
<p>B. 防止梯度消失</p>
<p>C. 对输入进行归一化</p>
<p>D. 加快模型收敛速度</p>
<p><strong>答案: AB</strong></p>
<h4 id="5-影响机器学习模型性能的因素有（）"><a href="#5-影响机器学习模型性能的因素有（）" class="headerlink" title="5. 影响机器学习模型性能的因素有（）"></a>5. 影响机器学习模型性能的因素有（）</h4><p>A. 数据质量</p>
<p>B. 算法选择</p>
<p>C. 超参数设置</p>
<p>D. 硬件性能</p>
<p><strong>答案: ABC</strong></p>
<h4 id="6-在构建决策树时，以下哪些可以作为分裂节点的选择标准-（）"><a href="#6-在构建决策树时，以下哪些可以作为分裂节点的选择标准-（）" class="headerlink" title="6. 在构建决策树时，以下哪些可以作为分裂节点的选择标准?（）"></a>6. 在构建决策树时，以下哪些可以作为分裂节点的选择标准?（）</h4><p>A. 信息增益</p>
<p>B. 基尼指数</p>
<p>C. 均方误差</p>
<p>D. 准确率</p>
<p><strong>答案: AB</strong></p>
<h4 id="7-以下哪些技术可以用于处理过拟合问题-（）"><a href="#7-以下哪些技术可以用于处理过拟合问题-（）" class="headerlink" title="7. 以下哪些技术可以用于处理过拟合问题?（）"></a>7. 以下哪些技术可以用于处理过拟合问题?（）</h4><p>A. 增加数据量</p>
<p>B. 正则化</p>
<p>C. 早停法</p>
<p>D. 降低模型复杂度</p>
<p><strong>答案: ABCD</strong></p>
<h4 id="8-以下关于交叉验证的说法正确的是（）"><a href="#8-以下关于交叉验证的说法正确的是（）" class="headerlink" title="8. 以下关于交叉验证的说法正确的是（）"></a>8. 以下关于交叉验证的说法正确的是（）</h4><p>A. 可以有效评估模型的泛化能力</p>
<p>B. 常见的有 K-折交叉验证</p>
<p>C. 能避免数据划分的随机性影响</p>
<p>D. 只适用于小数据集</p>
<p><strong>答案: AB</strong></p>
<h4 id="9-以下哪些是深度学习中的优化算法-（）"><a href="#9-以下哪些是深度学习中的优化算法-（）" class="headerlink" title="9. 以下哪些是深度学习中的优化算法?（）"></a>9. 以下哪些是深度学习中的优化算法?（）</h4><p>A. 随机梯度下降(SGD)</p>
<p>B. Adagrad</p>
<p>C. Adam</p>
<p>D. 梯度提升(Gradient Boosting)</p>
<p><strong>答案: ABC</strong></p>
<h4 id="10-对于一个二分类问题，以下哪些指标可以全面评估模型性能-（）"><a href="#10-对于一个二分类问题，以下哪些指标可以全面评估模型性能-（）" class="headerlink" title="10. 对于一个二分类问题，以下哪些指标可以全面评估模型性能?（）"></a>10. 对于一个二分类问题，以下哪些指标可以全面评估模型性能?（）</h4><p>A. 准确率</p>
<p>B. 召回率</p>
<p>C. F1-分数</p>
<p>D. 特异度</p>
<p><strong>答案: ABCD</strong></p>
<h4 id="11-以下属于机器学习中常用的特征工程方法的有（）"><a href="#11-以下属于机器学习中常用的特征工程方法的有（）" class="headerlink" title="11. 以下属于机器学习中常用的特征工程方法的有（）"></a>11. 以下属于机器学习中常用的特征工程方法的有（）</h4><p>A. 数据标准化</p>
<p>B. 独热编码</p>
<p>C. 特征缩放</p>
<p>D. 交叉验证</p>
<p><strong>答案: ABC</strong></p>
<h4 id="12-下列关于支持向量机-SVM-的说法正确的是（）"><a href="#12-下列关于支持向量机-SVM-的说法正确的是（）" class="headerlink" title="12. 下列关于支持向量机(SVM)的说法正确的是（）"></a>12. 下列关于支持向量机(SVM)的说法正确的是（）</h4><p>A. SVM 可以用于线性可分的数据分类</p>
<p>B. SVM 可以通过核函数处理非线性分类问题</p>
<p>C. SVM 的目标是找到一个最大间隔的超平面</p>
<p>D. SVM 对异常值不敏感</p>
<p><strong>答案: ABC</strong></p>
<h4 id="13-以下哪些是无监督学习的应用场景-（）"><a href="#13-以下哪些是无监督学习的应用场景-（）" class="headerlink" title="13. 以下哪些是无监督学习的应用场景?（）"></a>13. 以下哪些是无监督学习的应用场景?（）</h4><p>A. 客户细分</p>
<p>B. 图像识别</p>
<p>C. 异常检测</p>
<p>D. 语音识别</p>
<p><strong>答案: AC</strong></p>
<h4 id="14-机器学习中常用的损失函数有（）"><a href="#14-机器学习中常用的损失函数有（）" class="headerlink" title="14. 机器学习中常用的损失函数有（）"></a>14. 机器学习中常用的损失函数有（）</h4><p>A. 交叉熵损失函数</p>
<p>B. 铰链损失函数</p>
<p>C. 指数损失函数</p>
<p>D. 对数损失函数</p>
<p><strong>答案: ABCD</strong></p>
<h4 id="15-以下属于深度学习框架的有（）"><a href="#15-以下属于深度学习框架的有（）" class="headerlink" title="15. 以下属于深度学习框架的有（）"></a>15. 以下属于深度学习框架的有（）</h4><p>A. TensorFlow</p>
<p>B. PyTorch</p>
<p>C. Scikit-learn</p>
<p>D. Keras</p>
<p><strong>答案: ABD</strong></p>
<h4 id="16-以下属于监督学习任务的有（）"><a href="#16-以下属于监督学习任务的有（）" class="headerlink" title="16. 以下属于监督学习任务的有（）"></a>16. 以下属于监督学习任务的有（）</h4><p>A. 分类</p>
<p>B. 聚类</p>
<p>C. 回归</p>
<p>D. 降维</p>
<p><strong>答案: AC</strong></p>
<h4 id="17-常用的数据预处理操作包括（）"><a href="#17-常用的数据预处理操作包括（）" class="headerlink" title="17. 常用的数据预处理操作包括（）"></a>17. 常用的数据预处理操作包括（）</h4><p>A. 数据清洗</p>
<p>B. 特征工程</p>
<p>C. 数据采样</p>
<p>D. 模型评估</p>
<p><strong>答案: ABC</strong></p>
<h4 id="18-以下哪些是决策树的优点（）"><a href="#18-以下哪些是决策树的优点（）" class="headerlink" title="18. 以下哪些是决策树的优点（）"></a>18. 以下哪些是决策树的优点（）</h4><p>A. 易于理解和解释</p>
<p>B. 对数据的准备要求低</p>
<p>C. 抗过拟合能力强</p>
<p>D. 能处理多分类问题</p>
<p><strong>答案: ABD</strong></p>
<h4 id="19-属于集成学习算法的有（）"><a href="#19-属于集成学习算法的有（）" class="headerlink" title="19. 属于集成学习算法的有（）"></a>19. 属于集成学习算法的有（）</h4><p>A. 决策树集成</p>
<p>B. 随机森林</p>
<p>C. AdaBoost</p>
<p>D. K-Means</p>
<p><strong>答案: ABC</strong></p>
<h4 id="20-神经网络中常用的激活函数有（）"><a href="#20-神经网络中常用的激活函数有（）" class="headerlink" title="20. 神经网络中常用的激活函数有（）"></a>20. 神经网络中常用的激活函数有（）</h4><p>A. sigmoid</p>
<p>B. ReLU</p>
<p>C. tanh</p>
<p>D. Softmax</p>
<p><strong>答案: ABCD</strong></p>
<h4 id="21-评估分类模型的指标有（）"><a href="#21-评估分类模型的指标有（）" class="headerlink" title="21. 评估分类模型的指标有（）"></a>21. 评估分类模型的指标有（）</h4><p>A. 准确率</p>
<p>B. 精确率</p>
<p>C. 召回率</p>
<p>D. F1 值</p>
<p><strong>答案: ABCD</strong></p>
<h4 id="22-以下哪些方法可以防止模型过拟合（）"><a href="#22-以下哪些方法可以防止模型过拟合（）" class="headerlink" title="22. 以下哪些方法可以防止模型过拟合（）"></a>22. 以下哪些方法可以防止模型过拟合（）</h4><p>A. 增加数据量</p>
<p>B. 正则化</p>
<p>C. 减少特征数量</p>
<p>D. 早停法</p>
<p><strong>答案: ABCD</strong></p>
<h4 id="23-线性回归模型的假设包括（）"><a href="#23-线性回归模型的假设包括（）" class="headerlink" title="23. 线性回归模型的假设包括（）"></a>23. 线性回归模型的假设包括（）</h4><p>A. 自变量与因变量之间存在线性关系</p>
<p>B. 误差项服从正态分布</p>
<p>C. 误差项方差齐性</p>
<p>D. 自变量之间不存在多重共线性</p>
<p><strong>答案: ABCD</strong></p>
<h4 id="24-支持向量机的核函数类型有（）"><a href="#24-支持向量机的核函数类型有（）" class="headerlink" title="24. 支持向量机的核函数类型有（）"></a>24. 支持向量机的核函数类型有（）</h4><p>A. 线性核</p>
<p>B. 多项式核</p>
<p>C. RBF 核</p>
<p>D. 高斯核</p>
<p><strong>答案: ABCD</strong></p>
<h4 id="25-以下关于-K-Means-算法的描述正确的有（）"><a href="#25-以下关于-K-Means-算法的描述正确的有（）" class="headerlink" title="25. 以下关于 K-Means 算法的描述正确的有（）"></a>25. 以下关于 K-Means 算法的描述正确的有（）</h4><p>A. 是无监督学习算法</p>
<p>B. 需要预先指定聚类数 K</p>
<p>C. 对初始聚类中心敏感</p>
<p>D. 最终聚类结果唯一</p>
<p><strong>答案: ABC</strong></p>
<h4 id="26-下列哪些是机器学习的常见应用领域（）"><a href="#26-下列哪些是机器学习的常见应用领域（）" class="headerlink" title="26. 下列哪些是机器学习的常见应用领域（）"></a>26. 下列哪些是机器学习的常见应用领域（）</h4><p>A. 图像识别</p>
<p>B. 自然语言处理</p>
<p>C. 推荐系统</p>
<p>D. 数据加密</p>
<p>E. 金融预测</p>
<p><strong>答案: ABCE</strong></p>
<h4 id="27-下列哪些是数据预处理的方法（）"><a href="#27-下列哪些是数据预处理的方法（）" class="headerlink" title="27. 下列哪些是数据预处理的方法（）"></a>27. 下列哪些是数据预处理的方法（）</h4><p>A. 缺失值处理</p>
<p>B. 数据标准化</p>
<p>C. 特征选择</p>
<p>D. 数据分类</p>
<p>E. 数据归一化</p>
<p><strong>答案: ABE</strong></p>
<h4 id="28-下列哪些是监督学习算法（）"><a href="#28-下列哪些是监督学习算法（）" class="headerlink" title="28. 下列哪些是监督学习算法（）"></a>28. 下列哪些是监督学习算法（）</h4><p>A. 线性回归</p>
<p>B. 决策树</p>
<p>C. 支持向量机</p>
<p>D. K 均值聚类</p>
<p>E. 逻辑回归</p>
<p><strong>答案: ABCE</strong></p>
<h4 id="29-下列哪些是评估模型性能的指标（）"><a href="#29-下列哪些是评估模型性能的指标（）" class="headerlink" title="29. 下列哪些是评估模型性能的指标（）"></a>29. 下列哪些是评估模型性能的指标（）</h4><p>A. 准确率</p>
<p>B. 精确率</p>
<p>C. 召回率</p>
<p>D. F1 分数</p>
<p>E. 相关系数</p>
<p><strong>答案: ABCD</strong></p>
<h4 id="30-下列哪些是特征工程的常用方法（）"><a href="#30-下列哪些是特征工程的常用方法（）" class="headerlink" title="30. 下列哪些是特征工程的常用方法（）"></a>30. 下列哪些是特征工程的常用方法（）</h4><p>A. 特征缩放</p>
<p>B. 特征编码</p>
<p>C. 特征选择</p>
<p>D. 特征组合</p>
<p>E. 数据标准化</p>
<p><strong>答案: ABCD</strong></p>
<h4 id="31-下列哪些是集成学习算法（）"><a href="#31-下列哪些是集成学习算法（）" class="headerlink" title="31. 下列哪些是集成学习算法（）"></a>31. 下列哪些是集成学习算法（）</h4><p>A. 决策树集成</p>
<p>B. 随机森林</p>
<p>C. AdaBoost</p>
<p>D. bagging</p>
<p>E. 支持向量机</p>
<p><strong>答案: ABCD</strong></p>
<h4 id="32-下列哪些是过拟合的解决方法（）"><a href="#32-下列哪些是过拟合的解决方法（）" class="headerlink" title="32. 下列哪些是过拟合的解决方法（）"></a>32. 下列哪些是过拟合的解决方法（）</h4><p>A. 增加数据量</p>
<p>B. 正则化</p>
<p>C. 减少模型复杂度</p>
<p>D. 增加模型参数</p>
<p>E. 交叉验证</p>
<p><strong>答案: ABCE</strong></p>
<h4 id="33-下列哪些是降维方法（）"><a href="#33-下列哪些是降维方法（）" class="headerlink" title="33. 下列哪些是降维方法（）"></a>33. 下列哪些是降维方法（）</h4><p>A. 主成分分析</p>
<p>B. 因子分析</p>
<p>C. 线性判别分析</p>
<p>D. K 均值聚类</p>
<p>E. 基于矩阵分解的方法</p>
<p><strong>答案: ABCE</strong></p>
<h4 id="34-下列哪些是数据挖掘的步骤（）"><a href="#34-下列哪些是数据挖掘的步骤（）" class="headerlink" title="34. 下列哪些是数据挖掘的步骤（）"></a>34. 下列哪些是数据挖掘的步骤（）</h4><p>A. 数据收集</p>
<p>B. 数据预处理</p>
<p>C. 模型训练</p>
<p>D. 模型评估</p>
<p>E. 数据可视化</p>
<p><strong>答案: ABCDE</strong></p>
<h4 id="35-下列哪些是特征选择的方法（）"><a href="#35-下列哪些是特征选择的方法（）" class="headerlink" title="35. 下列哪些是特征选择的方法（）"></a>35. 下列哪些是特征选择的方法（）</h4><p>A. 单变量特征选择</p>
<p>B. 基于模型的特征选择</p>
<p>C. 递归特征消除</p>
<p>D. 岭回归</p>
<p>E. Lasso 回归</p>
<p><strong>答案: ABCE</strong></p>
<h4 id="36-下列哪些是常用的特征工程方法（）"><a href="#36-下列哪些是常用的特征工程方法（）" class="headerlink" title="36. 下列哪些是常用的特征工程方法（）"></a>36. 下列哪些是常用的特征工程方法（）</h4><p>A. 特征缩放</p>
<p>B. 特征编码</p>
<p>C. 特征选择</p>
<p>D. 特征组合</p>
<p>E. 数据归一化</p>
<p><strong>答案: ABCDE</strong></p>
<h4 id="37-下列哪些是评估分类模型性能的指标（）"><a href="#37-下列哪些是评估分类模型性能的指标（）" class="headerlink" title="37. 下列哪些是评估分类模型性能的指标（）"></a>37. 下列哪些是评估分类模型性能的指标（）</h4><p>A. 准确率</p>
<p>B. 精确率</p>
<p>C. 召回率</p>
<p>D. F1 分数</p>
<p>E. 相关系数</p>
<p><strong>答案: ABCD</strong></p>
<h4 id="38-下列哪些是集成学习算法（）"><a href="#38-下列哪些是集成学习算法（）" class="headerlink" title="38. 下列哪些是集成学习算法（）"></a>38. 下列哪些是集成学习算法（）</h4><p>A. 决策树集成</p>
<p>B. 随机森林</p>
<p>C. AdaBoost</p>
<p>D. bagging</p>
<p>E. 支持向量机</p>
<p><strong>答案: ABCD</strong></p>
<h4 id="39-下列哪些是过拟合的解决方法（）"><a href="#39-下列哪些是过拟合的解决方法（）" class="headerlink" title="39. 下列哪些是过拟合的解决方法（）"></a>39. 下列哪些是过拟合的解决方法（）</h4><p>A. 增加数据量</p>
<p>B. 正则化</p>
<p>C. 减少模型复杂度</p>
<p>D. 增加模型参数</p>
<p>E. 交叉验证</p>
<p><strong>答案: ABCE</strong></p>
<h4 id="40-下列哪些是降维方法（）"><a href="#40-下列哪些是降维方法（）" class="headerlink" title="40. 下列哪些是降维方法（）"></a>40. 下列哪些是降维方法（）</h4><p>A. 主成分分析</p>
<p>B. 因子分析</p>
<p>C. 线性判别分析</p>
<p>D. K 均值聚类</p>
<p>E. 基于矩阵分解的方法</p>
<p><strong>答案: ABCE</strong></p>
<h4 id="41-下列哪些是监督学习算法（）"><a href="#41-下列哪些是监督学习算法（）" class="headerlink" title="41. 下列哪些是监督学习算法（）"></a>41. 下列哪些是监督学习算法（）</h4><p>A. 线性回归</p>
<p>B. 决策树</p>
<p>C. 支持向量机</p>
<p>D. K 均值聚类</p>
<p>E. 逻辑回归</p>
<p><strong>答案: ABCE</strong></p>
<h4 id="42-下列哪些是数据预处理的方法（）"><a href="#42-下列哪些是数据预处理的方法（）" class="headerlink" title="42. 下列哪些是数据预处理的方法（）"></a>42. 下列哪些是数据预处理的方法（）</h4><p>A. 缺失值处理</p>
<p>B. 数据标准化</p>
<p>C. 特征选择</p>
<p>D. 数据分类</p>
<p>E. 数据归一化</p>
<p><strong>答案: ABE</strong></p>
<h4 id="43-下列哪些是特征选择的方法（）"><a href="#43-下列哪些是特征选择的方法（）" class="headerlink" title="43. 下列哪些是特征选择的方法（）"></a>43. 下列哪些是特征选择的方法（）</h4><p>A. 单变量特征选择</p>
<p>B. 基于模型的特征选择</p>
<p>C. 递归特征消除</p>
<p>D. 岭回归</p>
<p>E. Lasso 回归</p>
<p><strong>答案: ABCE</strong></p>
<h4 id="44-下列哪些是数据挖掘的步骤（）"><a href="#44-下列哪些是数据挖掘的步骤（）" class="headerlink" title="44. 下列哪些是数据挖掘的步骤（）"></a>44. 下列哪些是数据挖掘的步骤（）</h4><p>A. 数据收集</p>
<p>B. 数据预处理</p>
<p>C. 模型训练</p>
<p>D. 模型评估</p>
<p>E. 数据可视化</p>
<p><strong>答案: ABCDE</strong></p>
<h4 id="45-下列哪些是常用的交叉验证方法（）"><a href="#45-下列哪些是常用的交叉验证方法（）" class="headerlink" title="45. 下列哪些是常用的交叉验证方法（）"></a>45. 下列哪些是常用的交叉验证方法（）</h4><p>A. 留出法</p>
<p>B. K 折交叉验证</p>
<p>C. 移动窗口交叉验证</p>
<p>D. 留一法</p>
<p>E. 分层交叉验证</p>
<p><strong>答案: ABCDE</strong></p>
<h4 id="46-以下属于监督学习任务的有-（）"><a href="#46-以下属于监督学习任务的有-（）" class="headerlink" title="46. 以下属于监督学习任务的有:（）"></a>46. 以下属于监督学习任务的有:（）</h4><p>A. 图像分类</p>
<p>B. 语音识别</p>
<p>C. 聚类分析</p>
<p>D. 回归分析</p>
<p><strong>答案: ABD</strong></p>
<h4 id="47-以下哪些方法可以用于降低过拟合风险-（）"><a href="#47-以下哪些方法可以用于降低过拟合风险-（）" class="headerlink" title="47. 以下哪些方法可以用于降低过拟合风险?（）"></a>47. 以下哪些方法可以用于降低过拟合风险?（）</h4><p>A. 增加训练数据</p>
<p>B. 正则化</p>
<p>C. 早停法</p>
<p>D. 减少特征数量</p>
<p><strong>答案: ABCD</strong></p>
<h4 id="48-以下关于支持向量机-SVM-的说法，正确的有-（）"><a href="#48-以下关于支持向量机-SVM-的说法，正确的有-（）" class="headerlink" title="48. 以下关于支持向量机(SVM)的说法，正确的有:（）"></a>48. 以下关于支持向量机(SVM)的说法，正确的有:（）</h4><p>A. SVM 可以处理线性可分和线性不可分的数据</p>
<p>B. 核函数是 SVM 处理线性不可分数据的关键</p>
<p>C. SVM 的目标是找到一个最大间隔超平面</p>
<p>D. SVM 对异常值不敏感</p>
<p><strong>答案: ABC</strong></p>
<h4 id="49-以下属于无监督学习算法的有-（）"><a href="#49-以下属于无监督学习算法的有-（）" class="headerlink" title="49. 以下属于无监督学习算法的有:（）"></a>49. 以下属于无监督学习算法的有:（）</h4><p>A. 主成分分析(PCA)</p>
<p>B. 高斯混合模型(GMM)</p>
<p>C. 决策树</p>
<p>D. 自编码器</p>
<p><strong>答案: ABD</strong></p>
<h4 id="50-以下哪些是评估分类模型性能的指标-（）"><a href="#50-以下哪些是评估分类模型性能的指标-（）" class="headerlink" title="50. 以下哪些是评估分类模型性能的指标?（）"></a>50. 以下哪些是评估分类模型性能的指标?（）</h4><p>A. 准确率</p>
<p>B. 召回率</p>
<p>C. F1 值</p>
<p>D. 均方误差</p>
<p><strong>答案: ABC</strong></p>
<h4 id="51-以下关于随机森林的说法，正确的有-（）"><a href="#51-以下关于随机森林的说法，正确的有-（）" class="headerlink" title="51. 以下关于随机森林的说法，正确的有:（）"></a>51. 以下关于随机森林的说法，正确的有:（）</h4><p>A. 随机森林是由多个决策树组成的集成模型</p>
<p>B. 随机森林可以并行训练多个决策树</p>
<p>C. 随机森林对缺失值和异常值不敏感</p>
<p>D. 随机森林只能用于分类问题</p>
<p><strong>答案: ABC</strong></p>
<h4 id="52-以下哪些方法可以用于数据降维-（）"><a href="#52-以下哪些方法可以用于数据降维-（）" class="headerlink" title="52. 以下哪些方法可以用于数据降维?（）"></a>52. 以下哪些方法可以用于数据降维?（）</h4><p>A. 主成分分析(PCA)</p>
<p>B. 线性判别分析(LDA)</p>
<p>C. 特征选择</p>
<p>D. 奇异值分解(SVD)</p>
<p><strong>答案: ABCD</strong></p>
<h4 id="53-以下关于-K-近邻算法的说法，正确的有-（）"><a href="#53-以下关于-K-近邻算法的说法，正确的有-（）" class="headerlink" title="53. 以下关于 K 近邻算法的说法，正确的有:（）"></a>53. 以下关于 K 近邻算法的说法，正确的有:（）</h4><p>A. K 值越小，模型越容易过拟合</p>
<p>B. K 值越大，模型越容易欠拟合</p>
<p>C. 该算法的时间复杂度较高</p>
<p>D. 该算法对数据的尺度比较敏感</p>
<p><strong>答案: ABCD</strong></p>
<h4 id="54-以下关于集成学习的方法，正确的有-（）"><a href="#54-以下关于集成学习的方法，正确的有-（）" class="headerlink" title="54. 以下关于集成学习的方法，正确的有:（）"></a>54. 以下关于集成学习的方法，正确的有:（）</h4><p>A. Bagging 方法通过自助采样得到多个训练集，训练多个弱学习器</p>
<p>B. Boosting 方法通过迭代训练多个弱学习器，每个弱学习器关注前一个弱学习器的错误样本</p>
<p>C. Stacking 方法将多个弱学习器的输出作为新的特征，再训练一个元学习器</p>
<p>D. 集成学习一定能提高模型的性能</p>
<p><strong>答案: ABC</strong></p>
<h4 id="55-以下关于深度学习的说法，正确的有-（）"><a href="#55-以下关于深度学习的说法，正确的有-（）" class="headerlink" title="55. 以下关于深度学习的说法，正确的有:（）"></a>55. 以下关于深度学习的说法，正确的有:（）</h4><p>A. 深度学习通常使用大规模的数据集进行训练</p>
<p>B. 深度学习模型通常具有很多层</p>
<p>C. 深度学习可以自动学习数据中的特征</p>
<p>D. 深度学习只适用于图像和语音领域</p>
<p><strong>答案: ABC</strong></p>
<h4 id="56-以下哪些是逻辑回归的特点-（）"><a href="#56-以下哪些是逻辑回归的特点-（）" class="headerlink" title="56. 以下哪些是逻辑回归的特点?（）"></a>56. 以下哪些是逻辑回归的特点?（）</h4><p>A. 用于分类问题</p>
<p>B. 输出是概率值</p>
<p>C. 可以处理多分类问题</p>
<p>D. 模型具有线性决策边界</p>
<p><strong>答案: ABCD</strong></p>
<h4 id="57-以下关于聚类算法的说法，正确的有-（）"><a href="#57-以下关于聚类算法的说法，正确的有-（）" class="headerlink" title="57. 以下关于聚类算法的说法，正确的有:（）"></a>57. 以下关于聚类算法的说法，正确的有:（）</h4><p>A. K 均值聚类是基于距离的聚类算法</p>
<p>B. DBSCAN 是基于密度的聚类算法</p>
<p>C. 层次聚类可以构建聚类的层次结构</p>
<p>D. 高斯混合模型聚类是基于概率模型的聚类方法</p>
<p><strong>答案: ABCD</strong></p>
<h4 id="58-以下哪些方法可以用于处理类别不平衡问题-（）"><a href="#58-以下哪些方法可以用于处理类别不平衡问题-（）" class="headerlink" title="58. 以下哪些方法可以用于处理类别不平衡问题?（）"></a>58. 以下哪些方法可以用于处理类别不平衡问题?（）</h4><p>A. 过采样</p>
<p>B. 欠采样</p>
<p>C. 调整分类阈值</p>
<p>D. 使用代价敏感学习</p>
<p><strong>答案: ABCD</strong></p>
<h4 id="59-以下关于梯度下降法的说法，正确的有-（）"><a href="#59-以下关于梯度下降法的说法，正确的有-（）" class="headerlink" title="59. 以下关于梯度下降法的说法，正确的有:（）"></a>59. 以下关于梯度下降法的说法，正确的有:（）</h4><p>A. 批量梯度下降(BGD)使用所有训练样本进行参数更新</p>
<p>B. 随机梯度下降(SGD)每次只使用一个训练样本进行参数更新</p>
<p>C. 小批量梯度下降(MBGD)使用一部分训练样本进行参数更新</p>
<p>D. 梯度下降法的目标是最小化损失函数</p>
<p><strong>答案: ABCD</strong></p>
<h4 id="60-下列哪些是机器学习的常见应用领域（）"><a href="#60-下列哪些是机器学习的常见应用领域（）" class="headerlink" title="60. 下列哪些是机器学习的常见应用领域（）"></a>60. 下列哪些是机器学习的常见应用领域（）</h4><p>A. 图像识别</p>
<p>B. 自然语言处理</p>
<p>C. 推荐系统</p>
<p>D. 数据加密</p>
<p>E. 金融预测</p>
<p><strong>答案: ABCE</strong></p>
<h4 id="61-下列哪些是数据预处理的方法（）"><a href="#61-下列哪些是数据预处理的方法（）" class="headerlink" title="61. 下列哪些是数据预处理的方法（）"></a>61. 下列哪些是数据预处理的方法（）</h4><p>A. 缺失值处理</p>
<p>B. 数据标准化</p>
<p>C. 特征选择</p>
<p>D. 数据分类</p>
<p>E. 数据归一化</p>
<p><strong>答案: ABE</strong></p>
<h4 id="62-下列哪些是监督学习算法（）"><a href="#62-下列哪些是监督学习算法（）" class="headerlink" title="62. 下列哪些是监督学习算法（）"></a>62. 下列哪些是监督学习算法（）</h4><p>A. 线性回归</p>
<p>B. 决策树</p>
<p>C. 支持向量机</p>
<p>D. K 均值聚类</p>
<p>E. 逻辑回归</p>
<p><strong>答案: ABCE</strong></p>
<h4 id="63-下列哪些是评估模型性能的指标（）"><a href="#63-下列哪些是评估模型性能的指标（）" class="headerlink" title="63. 下列哪些是评估模型性能的指标（）"></a>63. 下列哪些是评估模型性能的指标（）</h4><p>A. 准确率</p>
<p>B. 精确率</p>
<p>C. 召回率</p>
<p>D. F1 分数</p>
<p>E. 相关系数</p>
<p><strong>答案: ABCD</strong></p>
<h4 id="64-下列哪些是特征工程的常用方法（）"><a href="#64-下列哪些是特征工程的常用方法（）" class="headerlink" title="64. 下列哪些是特征工程的常用方法（）"></a>64. 下列哪些是特征工程的常用方法（）</h4><p>A. 特征缩放</p>
<p>B. 特征编码</p>
<p>C. 特征选择</p>
<p>D. 特征组合</p>
<p>E. 数据标准化</p>
<p><strong>答案: ABCD</strong></p>
<h4 id="65-下列哪些是集成学习算法（）"><a href="#65-下列哪些是集成学习算法（）" class="headerlink" title="65. 下列哪些是集成学习算法（）"></a>65. 下列哪些是集成学习算法（）</h4><p>A. 决策树集成</p>
<p>B. 随机森林</p>
<p>C. AdaBoost</p>
<p>D. bagging</p>
<p>E. 支持向量机</p>
<p><strong>答案: ABCD</strong></p>
<h4 id="66-下列哪些是过拟合的解决方法（）"><a href="#66-下列哪些是过拟合的解决方法（）" class="headerlink" title="66. 下列哪些是过拟合的解决方法（）"></a>66. 下列哪些是过拟合的解决方法（）</h4><p>A. 增加数据量</p>
<p>B. 正则化</p>
<p>C. 减少模型复杂度</p>
<p>D. 增加模型参数</p>
<p>E. 交叉验证</p>
<p><strong>答案: ABCE</strong></p>
<h4 id="67-下列哪些是降维方法（）"><a href="#67-下列哪些是降维方法（）" class="headerlink" title="67. 下列哪些是降维方法（）"></a>67. 下列哪些是降维方法（）</h4><p>A. 主成分分析</p>
<p>B. 因子分析</p>
<p>C. 线性判别分析</p>
<p>D. K 均值聚类</p>
<p>E. 基于矩阵分解的方法</p>
<p><strong>答案: ABCE</strong></p>
<h4 id="68-下列哪些是数据挖掘的步骤（）"><a href="#68-下列哪些是数据挖掘的步骤（）" class="headerlink" title="68. 下列哪些是数据挖掘的步骤（）"></a>68. 下列哪些是数据挖掘的步骤（）</h4><p>A. 数据收集</p>
<p>B. 数据预处理</p>
<p>C. 模型训练</p>
<p>D. 模型评估</p>
<p>E. 数据可视化</p>
<p><strong>答案: ABCDE</strong></p>
<h4 id="69-下列哪些是特征选择的方法（）"><a href="#69-下列哪些是特征选择的方法（）" class="headerlink" title="69. 下列哪些是特征选择的方法（）"></a>69. 下列哪些是特征选择的方法（）</h4><p>A. 单变量特征选择</p>
<p>B. 基于模型的特征选择</p>
<p>C. 递归特征消除</p>
<p>D. 岭回归</p>
<p>E. Lasso 回归</p>
<p><strong>答案: ABCE</strong></p>
<h4 id="70-下列哪些是常用的特征工程方法（）"><a href="#70-下列哪些是常用的特征工程方法（）" class="headerlink" title="70. 下列哪些是常用的特征工程方法（）"></a>70. 下列哪些是常用的特征工程方法（）</h4><p>A. 特征缩放</p>
<p>B. 特征编码</p>
<p>C. 特征选择</p>
<p>D. 特征组合</p>
<p>E. 数据归一化</p>
<p><strong>答案: ABCDE</strong></p>
<h4 id="71-下列哪些是评估分类模型性能的指标（）"><a href="#71-下列哪些是评估分类模型性能的指标（）" class="headerlink" title="71. 下列哪些是评估分类模型性能的指标（）"></a>71. 下列哪些是评估分类模型性能的指标（）</h4><p>A. 准确率</p>
<p>B. 精确率</p>
<p>C. 召回率</p>
<p>D. F1 分数</p>
<p>E. 相关系数</p>
<p><strong>答案: ABCD</strong></p>
<h4 id="72-下列哪些是集成学习算法（）"><a href="#72-下列哪些是集成学习算法（）" class="headerlink" title="72. 下列哪些是集成学习算法（）"></a>72. 下列哪些是集成学习算法（）</h4><p>A. 决策树集成</p>
<p>B. 随机森林</p>
<p>C. AdaBoost</p>
<p>D. bagging</p>
<p>E. 支持向量机</p>
<p><strong>答案: ABCD</strong></p>
<h4 id="73-下列哪些是过拟合的解决方法（）"><a href="#73-下列哪些是过拟合的解决方法（）" class="headerlink" title="73. 下列哪些是过拟合的解决方法（）"></a>73. 下列哪些是过拟合的解决方法（）</h4><p>A. 增加数据量</p>
<p>B. 正则化</p>
<p>C. 减少模型复杂度</p>
<p>D. 增加模型参数</p>
<p>E. 交叉验证</p>
<p><strong>答案: ABCE</strong></p>
<h4 id="74-下列哪些是降维方法（）"><a href="#74-下列哪些是降维方法（）" class="headerlink" title="74. 下列哪些是降维方法（）"></a>74. 下列哪些是降维方法（）</h4><p>A. 主成分分析</p>
<p>B. 因子分析</p>
<p>C. 线性判别分析</p>
<p>D. K 均值聚类</p>
<p>E. 基于矩阵分解的方法</p>
<p><strong>答案: ABCE</strong></p>
<h4 id="75-下列哪些是监督学习算法（）"><a href="#75-下列哪些是监督学习算法（）" class="headerlink" title="75. 下列哪些是监督学习算法（）"></a>75. 下列哪些是监督学习算法（）</h4><p>A. 线性回归</p>
<p>B. 决策树</p>
<p>C. 支持向量机</p>
<p>D. K 均值聚类</p>
<p>E. 逻辑回归</p>
<p><strong>答案: ABCE</strong></p>
<h4 id="76-下列哪些是数据预处理的方法（）"><a href="#76-下列哪些是数据预处理的方法（）" class="headerlink" title="76. 下列哪些是数据预处理的方法（）"></a>76. 下列哪些是数据预处理的方法（）</h4><p>A. 缺失值处理</p>
<p>B. 数据标准化</p>
<p>C. 特征选择</p>
<p>D. 数据分类</p>
<p>E. 数据归一化</p>
<p><strong>答案: ABE</strong></p>
<h4 id="77-下列哪些是特征选择的方法（）"><a href="#77-下列哪些是特征选择的方法（）" class="headerlink" title="77. 下列哪些是特征选择的方法（）"></a>77. 下列哪些是特征选择的方法（）</h4><p>A. 单变量特征选择</p>
<p>B. 基于模型的特征选择</p>
<p>C. 递归特征消除</p>
<p>D. 岭回归</p>
<p>E. Lasso 回归</p>
<p><strong>答案: ABCE</strong></p>
<h4 id="78-下列哪些是数据挖掘的步骤（）"><a href="#78-下列哪些是数据挖掘的步骤（）" class="headerlink" title="78. 下列哪些是数据挖掘的步骤（）"></a>78. 下列哪些是数据挖掘的步骤（）</h4><p>A. 数据收集</p>
<p>B. 数据预处理</p>
<p>C. 模型训练</p>
<p>D. 模型评估</p>
<p>E. 数据可视化</p>
<p><strong>答案: ABCDE</strong></p>
<h4 id="79-下列哪些是常用的交叉验证方法（）"><a href="#79-下列哪些是常用的交叉验证方法（）" class="headerlink" title="79. 下列哪些是常用的交叉验证方法（）"></a>79. 下列哪些是常用的交叉验证方法（）</h4><p>A. 留出法</p>
<p>B. K 折交叉验证</p>
<p>C. 移动窗口交叉验证</p>
<p>D. 留一法</p>
<p>E. 分层交叉验证</p>
<p><strong>答案: ABCDE</strong></p>
<h4 id="80-以下属于监督学习任务的有-（）"><a href="#80-以下属于监督学习任务的有-（）" class="headerlink" title="80. 以下属于监督学习任务的有:（）"></a>80. 以下属于监督学习任务的有:（）</h4><p>A. 图像分类</p>
<p>B. 语音识别</p>
<p>C. 聚类分析</p>
<p>D. 回归分析</p>
<p><strong>答案: ABD</strong></p>
<h4 id="81-以下哪些方法可以用于降低过拟合风险-（）"><a href="#81-以下哪些方法可以用于降低过拟合风险-（）" class="headerlink" title="81. 以下哪些方法可以用于降低过拟合风险?（）"></a>81. 以下哪些方法可以用于降低过拟合风险?（）</h4><p>A. 增加训练数据</p>
<p>B. 正则化</p>
<p>C. 早停法</p>
<p>D. 减少特征数量</p>
<p><strong>答案: ABCD</strong></p>
<h4 id="82-以下关于支持向量机-SVM-的说法，正确的有-（）"><a href="#82-以下关于支持向量机-SVM-的说法，正确的有-（）" class="headerlink" title="82. 以下关于支持向量机(SVM)的说法，正确的有:（）"></a>82. 以下关于支持向量机(SVM)的说法，正确的有:（）</h4><p>A. SVM 可以处理线性可分和线性不可分的数据</p>
<p>B. 核函数是 SVM 处理线性不可分数据的关键</p>
<p>C. SVM 的目标是找到一个最大间隔超平面</p>
<p>D. SVM 对异常值不敏感</p>
<p><strong>答案: ABC</strong></p>
<h4 id="83-以下属于无监督学习算法的有-（）"><a href="#83-以下属于无监督学习算法的有-（）" class="headerlink" title="83. 以下属于无监督学习算法的有:（）"></a>83. 以下属于无监督学习算法的有:（）</h4><p>A. 主成分分析(PCA)</p>
<p>B. 高斯混合模型(GMM)</p>
<p>C. 决策树</p>
<p>D. 自编码器</p>
<p><strong>答案: ABD</strong></p>
<h4 id="84-以下哪些是评估分类模型性能的指标-（）"><a href="#84-以下哪些是评估分类模型性能的指标-（）" class="headerlink" title="84. 以下哪些是评估分类模型性能的指标?（）"></a>84. 以下哪些是评估分类模型性能的指标?（）</h4><p>A. 准确率</p>
<p>B. 召回率</p>
<p>C. F1 值</p>
<p>D. 均方误差</p>
<p><strong>答案: ABC</strong></p>
<h4 id="85-以下关于随机森林的说法，正确的有-（）"><a href="#85-以下关于随机森林的说法，正确的有-（）" class="headerlink" title="85. 以下关于随机森林的说法，正确的有:（）"></a>85. 以下关于随机森林的说法，正确的有:（）</h4><p>A. 随机森林是由多个决策树组成的集成模型</p>
<p>B. 随机森林可以并行训练多个决策树</p>
<p>C. 随机森林对缺失值和异常值不敏感</p>
<p>D. 随机森林只能用于分类问题</p>
<p><strong>答案: ABC</strong></p>
<h4 id="86-以下哪些方法可以用于数据降维-（）"><a href="#86-以下哪些方法可以用于数据降维-（）" class="headerlink" title="86. 以下哪些方法可以用于数据降维?（）"></a>86. 以下哪些方法可以用于数据降维?（）</h4><p>A. 主成分分析(PCA)</p>
<p>B. 线性判别分析(LDA)</p>
<p>C. 特征选择</p>
<p>D. 奇异值分解(SVD)</p>
<p><strong>答案: ABCD</strong></p>
<h4 id="87-以下关于-K-近邻算法的说法，正确的有-（）"><a href="#87-以下关于-K-近邻算法的说法，正确的有-（）" class="headerlink" title="87. 以下关于 K 近邻算法的说法，正确的有:（）"></a>87. 以下关于 K 近邻算法的说法，正确的有:（）</h4><p>A. K 值越小，模型越容易过拟合</p>
<p>B. K 值越大，模型越容易欠拟合</p>
<p>C. 该算法的时间复杂度较高</p>
<p>D. 该算法对数据的尺度比较敏感</p>
<p><strong>答案: ABCD</strong></p>
<h4 id="88-以下关于集成学习的方法，正确的有-（）"><a href="#88-以下关于集成学习的方法，正确的有-（）" class="headerlink" title="88. 以下关于集成学习的方法，正确的有:（）"></a>88. 以下关于集成学习的方法，正确的有:（）</h4><p>A. Bagging 方法通过自助采样得到多个训练集，训练多个弱学习器</p>
<p>B. Boosting 方法通过迭代训练多个弱学习器，每个弱学习器关注前一个弱学习器的错误样本</p>
<p>C. Stacking 方法将多个弱学习器的输出作为新的特征，再训练一个元学习器</p>
<p>D. 集成学习一定能提高模型的性能</p>
<p><strong>答案: ABC</strong></p>
<h4 id="89-以下关于深度学习的说法，正确的有-（）"><a href="#89-以下关于深度学习的说法，正确的有-（）" class="headerlink" title="89. 以下关于深度学习的说法，正确的有:（）"></a>89. 以下关于深度学习的说法，正确的有:（）</h4><p>A. 深度学习通常使用大规模的数据集进行训练</p>
<p>B. 深度学习模型通常具有很多层</p>
<p>C. 深度学习可以自动学习数据中的特征</p>
<p>D. 深度学习只适用于图像和语音领域</p>
<p><strong>答案: ABC</strong></p>
<h4 id="90-以下哪些是逻辑回归的特点-（）"><a href="#90-以下哪些是逻辑回归的特点-（）" class="headerlink" title="90. 以下哪些是逻辑回归的特点?（）"></a>90. 以下哪些是逻辑回归的特点?（）</h4><p>A. 用于分类问题</p>
<p>B. 输出是概率值</p>
<p>C. 可以处理多分类问题</p>
<p>D. 模型具有线性决策边界</p>
<p><strong>答案: ABCD</strong></p>
<h4 id="91-以下关于聚类算法的说法，正确的有-（）"><a href="#91-以下关于聚类算法的说法，正确的有-（）" class="headerlink" title="91. 以下关于聚类算法的说法，正确的有:（）"></a>91. 以下关于聚类算法的说法，正确的有:（）</h4><p>A. K 均值聚类是基于距离的聚类算法</p>
<p>B. DBSCAN 是基于密度的聚类算法</p>
<p>C. 层次聚类可以构建聚类的层次结构</p>
<p>D. 高斯混合模型聚类是基于概率模型的聚类方法</p>
<p><strong>答案: ABCD</strong></p>
<h4 id="92-以下哪些方法可以用于处理类别不平衡问题-（）"><a href="#92-以下哪些方法可以用于处理类别不平衡问题-（）" class="headerlink" title="92. 以下哪些方法可以用于处理类别不平衡问题?（）"></a>92. 以下哪些方法可以用于处理类别不平衡问题?（）</h4><p>A. 过采样</p>
<p>B. 欠采样</p>
<p>C. 调整分类阈值</p>
<p>D. 使用代价敏感学习</p>
<p><strong>答案: ABCD</strong></p>
<div id="paginator"></div></div><div id="post-footer"><div id="pages" style="justify-content: flex-end"><div class="footer-link" style="width: 50%;right:1px;border-left:1px #fe2 solid"><a href="/Arknight-notes/posts/2418.html">2026-01-08-机器学习复习 Prev →</a></div></div></div><div id="comments"><div id="gitalk"></div></div></div><div class="bottom-btn"><div><a class="i-top" id="to-top" onClick="scrolls.scrolltop();" title="To Top" style="opacity: 0; display: none;">∧ </a><a class="i-index" id="to-index" href="#toc-div" title="To Catalog">≡</a><a class="i-color" id="color-mode" onClick="colorMode.change()" title="Change Theme"></a></div></div></article><aside><div id="about"><a href="/Arknight-notes/" id="logo"><img src="https://pic4.zhimg.com/80/v2-d9884f32711e19e80979eac58e943897_720w.webp" alt="Logo" style="margin:20;border-radius:0;"></a><h1 id="Dr"><a href="zhongye">柊野</a></h1><div id="description"><p></p></div></div><div id="aside-block"><div id="toc-div"><h1>Catalog</h1><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%9A%E9%80%89%E9%A2%98%E5%AE%8C%E6%95%B4%E5%88%97%E8%A1%A8-%E5%85%B1-92-%E9%A2%98"><span class="toc-number">1.</span> <span class="toc-text">多选题完整列表 (共 92 题)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-%E4%BB%A5%E4%B8%8B%E5%93%AA%E4%BA%9B%E6%98%AF%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E6%AD%A5%E9%AA%A4-%EF%BC%88%EF%BC%89"><span class="toc-number">1.1.</span> <span class="toc-text">1. 以下哪些是机器学习中的数据预处理步骤?（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E5%8C%85%E6%8B%AC%E4%BB%A5%E4%B8%8B%E5%93%AA%E4%BA%9B%E7%B1%BB%E5%9E%8B-%EF%BC%88%EF%BC%89"><span class="toc-number">1.2.</span> <span class="toc-text">2. 监督学习包括以下哪些类型?（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-%E4%BB%A5%E4%B8%8B%E5%93%AA%E4%BA%9B%E7%AE%97%E6%B3%95%E5%B1%9E%E4%BA%8E%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%EF%BC%88%EF%BC%89"><span class="toc-number">1.3.</span> <span class="toc-text">3. 以下哪些算法属于无监督学习?（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E6%9C%89%E5%93%AA%E4%BA%9B%E4%BD%9C%E7%94%A8-%EF%BC%88%EF%BC%89"><span class="toc-number">1.4.</span> <span class="toc-text">4. 神经网络中的激活函数有哪些作用?（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-%E5%BD%B1%E5%93%8D%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E6%80%A7%E8%83%BD%E7%9A%84%E5%9B%A0%E7%B4%A0%E6%9C%89%EF%BC%88%EF%BC%89"><span class="toc-number">1.5.</span> <span class="toc-text">5. 影响机器学习模型性能的因素有（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6-%E5%9C%A8%E6%9E%84%E5%BB%BA%E5%86%B3%E7%AD%96%E6%A0%91%E6%97%B6%EF%BC%8C%E4%BB%A5%E4%B8%8B%E5%93%AA%E4%BA%9B%E5%8F%AF%E4%BB%A5%E4%BD%9C%E4%B8%BA%E5%88%86%E8%A3%82%E8%8A%82%E7%82%B9%E7%9A%84%E9%80%89%E6%8B%A9%E6%A0%87%E5%87%86-%EF%BC%88%EF%BC%89"><span class="toc-number">1.6.</span> <span class="toc-text">6. 在构建决策树时，以下哪些可以作为分裂节点的选择标准?（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#7-%E4%BB%A5%E4%B8%8B%E5%93%AA%E4%BA%9B%E6%8A%80%E6%9C%AF%E5%8F%AF%E4%BB%A5%E7%94%A8%E4%BA%8E%E5%A4%84%E7%90%86%E8%BF%87%E6%8B%9F%E5%90%88%E9%97%AE%E9%A2%98-%EF%BC%88%EF%BC%89"><span class="toc-number">1.7.</span> <span class="toc-text">7. 以下哪些技术可以用于处理过拟合问题?（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#8-%E4%BB%A5%E4%B8%8B%E5%85%B3%E4%BA%8E%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81%E7%9A%84%E8%AF%B4%E6%B3%95%E6%AD%A3%E7%A1%AE%E7%9A%84%E6%98%AF%EF%BC%88%EF%BC%89"><span class="toc-number">1.8.</span> <span class="toc-text">8. 以下关于交叉验证的说法正确的是（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#9-%E4%BB%A5%E4%B8%8B%E5%93%AA%E4%BA%9B%E6%98%AF%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95-%EF%BC%88%EF%BC%89"><span class="toc-number">1.9.</span> <span class="toc-text">9. 以下哪些是深度学习中的优化算法?（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#10-%E5%AF%B9%E4%BA%8E%E4%B8%80%E4%B8%AA%E4%BA%8C%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98%EF%BC%8C%E4%BB%A5%E4%B8%8B%E5%93%AA%E4%BA%9B%E6%8C%87%E6%A0%87%E5%8F%AF%E4%BB%A5%E5%85%A8%E9%9D%A2%E8%AF%84%E4%BC%B0%E6%A8%A1%E5%9E%8B%E6%80%A7%E8%83%BD-%EF%BC%88%EF%BC%89"><span class="toc-number">1.10.</span> <span class="toc-text">10. 对于一个二分类问题，以下哪些指标可以全面评估模型性能?（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#11-%E4%BB%A5%E4%B8%8B%E5%B1%9E%E4%BA%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E5%B8%B8%E7%94%A8%E7%9A%84%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B%E6%96%B9%E6%B3%95%E7%9A%84%E6%9C%89%EF%BC%88%EF%BC%89"><span class="toc-number">1.11.</span> <span class="toc-text">11. 以下属于机器学习中常用的特征工程方法的有（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#12-%E4%B8%8B%E5%88%97%E5%85%B3%E4%BA%8E%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA-SVM-%E7%9A%84%E8%AF%B4%E6%B3%95%E6%AD%A3%E7%A1%AE%E7%9A%84%E6%98%AF%EF%BC%88%EF%BC%89"><span class="toc-number">1.12.</span> <span class="toc-text">12. 下列关于支持向量机(SVM)的说法正确的是（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#13-%E4%BB%A5%E4%B8%8B%E5%93%AA%E4%BA%9B%E6%98%AF%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF-%EF%BC%88%EF%BC%89"><span class="toc-number">1.13.</span> <span class="toc-text">13. 以下哪些是无监督学习的应用场景?（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#14-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E5%B8%B8%E7%94%A8%E7%9A%84%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E6%9C%89%EF%BC%88%EF%BC%89"><span class="toc-number">1.14.</span> <span class="toc-text">14. 机器学习中常用的损失函数有（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#15-%E4%BB%A5%E4%B8%8B%E5%B1%9E%E4%BA%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6%E7%9A%84%E6%9C%89%EF%BC%88%EF%BC%89"><span class="toc-number">1.15.</span> <span class="toc-text">15. 以下属于深度学习框架的有（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#16-%E4%BB%A5%E4%B8%8B%E5%B1%9E%E4%BA%8E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E4%BB%BB%E5%8A%A1%E7%9A%84%E6%9C%89%EF%BC%88%EF%BC%89"><span class="toc-number">1.16.</span> <span class="toc-text">16. 以下属于监督学习任务的有（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#17-%E5%B8%B8%E7%94%A8%E7%9A%84%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E6%93%8D%E4%BD%9C%E5%8C%85%E6%8B%AC%EF%BC%88%EF%BC%89"><span class="toc-number">1.17.</span> <span class="toc-text">17. 常用的数据预处理操作包括（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#18-%E4%BB%A5%E4%B8%8B%E5%93%AA%E4%BA%9B%E6%98%AF%E5%86%B3%E7%AD%96%E6%A0%91%E7%9A%84%E4%BC%98%E7%82%B9%EF%BC%88%EF%BC%89"><span class="toc-number">1.18.</span> <span class="toc-text">18. 以下哪些是决策树的优点（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#19-%E5%B1%9E%E4%BA%8E%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9A%84%E6%9C%89%EF%BC%88%EF%BC%89"><span class="toc-number">1.19.</span> <span class="toc-text">19. 属于集成学习算法的有（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#20-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%AD%E5%B8%B8%E7%94%A8%E7%9A%84%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E6%9C%89%EF%BC%88%EF%BC%89"><span class="toc-number">1.20.</span> <span class="toc-text">20. 神经网络中常用的激活函数有（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#21-%E8%AF%84%E4%BC%B0%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%8C%87%E6%A0%87%E6%9C%89%EF%BC%88%EF%BC%89"><span class="toc-number">1.21.</span> <span class="toc-text">21. 评估分类模型的指标有（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#22-%E4%BB%A5%E4%B8%8B%E5%93%AA%E4%BA%9B%E6%96%B9%E6%B3%95%E5%8F%AF%E4%BB%A5%E9%98%B2%E6%AD%A2%E6%A8%A1%E5%9E%8B%E8%BF%87%E6%8B%9F%E5%90%88%EF%BC%88%EF%BC%89"><span class="toc-number">1.22.</span> <span class="toc-text">22. 以下哪些方法可以防止模型过拟合（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#23-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%81%87%E8%AE%BE%E5%8C%85%E6%8B%AC%EF%BC%88%EF%BC%89"><span class="toc-number">1.23.</span> <span class="toc-text">23. 线性回归模型的假设包括（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#24-%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%E7%9A%84%E6%A0%B8%E5%87%BD%E6%95%B0%E7%B1%BB%E5%9E%8B%E6%9C%89%EF%BC%88%EF%BC%89"><span class="toc-number">1.24.</span> <span class="toc-text">24. 支持向量机的核函数类型有（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#25-%E4%BB%A5%E4%B8%8B%E5%85%B3%E4%BA%8E-K-Means-%E7%AE%97%E6%B3%95%E7%9A%84%E6%8F%8F%E8%BF%B0%E6%AD%A3%E7%A1%AE%E7%9A%84%E6%9C%89%EF%BC%88%EF%BC%89"><span class="toc-number">1.25.</span> <span class="toc-text">25. 以下关于 K-Means 算法的描述正确的有（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#26-%E4%B8%8B%E5%88%97%E5%93%AA%E4%BA%9B%E6%98%AF%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%B8%B8%E8%A7%81%E5%BA%94%E7%94%A8%E9%A2%86%E5%9F%9F%EF%BC%88%EF%BC%89"><span class="toc-number">1.26.</span> <span class="toc-text">26. 下列哪些是机器学习的常见应用领域（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#27-%E4%B8%8B%E5%88%97%E5%93%AA%E4%BA%9B%E6%98%AF%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E7%9A%84%E6%96%B9%E6%B3%95%EF%BC%88%EF%BC%89"><span class="toc-number">1.27.</span> <span class="toc-text">27. 下列哪些是数据预处理的方法（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#28-%E4%B8%8B%E5%88%97%E5%93%AA%E4%BA%9B%E6%98%AF%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%88%EF%BC%89"><span class="toc-number">1.28.</span> <span class="toc-text">28. 下列哪些是监督学习算法（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#29-%E4%B8%8B%E5%88%97%E5%93%AA%E4%BA%9B%E6%98%AF%E8%AF%84%E4%BC%B0%E6%A8%A1%E5%9E%8B%E6%80%A7%E8%83%BD%E7%9A%84%E6%8C%87%E6%A0%87%EF%BC%88%EF%BC%89"><span class="toc-number">1.29.</span> <span class="toc-text">29. 下列哪些是评估模型性能的指标（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#30-%E4%B8%8B%E5%88%97%E5%93%AA%E4%BA%9B%E6%98%AF%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B%E7%9A%84%E5%B8%B8%E7%94%A8%E6%96%B9%E6%B3%95%EF%BC%88%EF%BC%89"><span class="toc-number">1.30.</span> <span class="toc-text">30. 下列哪些是特征工程的常用方法（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#31-%E4%B8%8B%E5%88%97%E5%93%AA%E4%BA%9B%E6%98%AF%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%88%EF%BC%89"><span class="toc-number">1.31.</span> <span class="toc-text">31. 下列哪些是集成学习算法（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#32-%E4%B8%8B%E5%88%97%E5%93%AA%E4%BA%9B%E6%98%AF%E8%BF%87%E6%8B%9F%E5%90%88%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%EF%BC%88%EF%BC%89"><span class="toc-number">1.32.</span> <span class="toc-text">32. 下列哪些是过拟合的解决方法（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#33-%E4%B8%8B%E5%88%97%E5%93%AA%E4%BA%9B%E6%98%AF%E9%99%8D%E7%BB%B4%E6%96%B9%E6%B3%95%EF%BC%88%EF%BC%89"><span class="toc-number">1.33.</span> <span class="toc-text">33. 下列哪些是降维方法（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#34-%E4%B8%8B%E5%88%97%E5%93%AA%E4%BA%9B%E6%98%AF%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E7%9A%84%E6%AD%A5%E9%AA%A4%EF%BC%88%EF%BC%89"><span class="toc-number">1.34.</span> <span class="toc-text">34. 下列哪些是数据挖掘的步骤（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#35-%E4%B8%8B%E5%88%97%E5%93%AA%E4%BA%9B%E6%98%AF%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9%E7%9A%84%E6%96%B9%E6%B3%95%EF%BC%88%EF%BC%89"><span class="toc-number">1.35.</span> <span class="toc-text">35. 下列哪些是特征选择的方法（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#36-%E4%B8%8B%E5%88%97%E5%93%AA%E4%BA%9B%E6%98%AF%E5%B8%B8%E7%94%A8%E7%9A%84%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B%E6%96%B9%E6%B3%95%EF%BC%88%EF%BC%89"><span class="toc-number">1.36.</span> <span class="toc-text">36. 下列哪些是常用的特征工程方法（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#37-%E4%B8%8B%E5%88%97%E5%93%AA%E4%BA%9B%E6%98%AF%E8%AF%84%E4%BC%B0%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B%E6%80%A7%E8%83%BD%E7%9A%84%E6%8C%87%E6%A0%87%EF%BC%88%EF%BC%89"><span class="toc-number">1.37.</span> <span class="toc-text">37. 下列哪些是评估分类模型性能的指标（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#38-%E4%B8%8B%E5%88%97%E5%93%AA%E4%BA%9B%E6%98%AF%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%88%EF%BC%89"><span class="toc-number">1.38.</span> <span class="toc-text">38. 下列哪些是集成学习算法（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#39-%E4%B8%8B%E5%88%97%E5%93%AA%E4%BA%9B%E6%98%AF%E8%BF%87%E6%8B%9F%E5%90%88%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%EF%BC%88%EF%BC%89"><span class="toc-number">1.39.</span> <span class="toc-text">39. 下列哪些是过拟合的解决方法（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#40-%E4%B8%8B%E5%88%97%E5%93%AA%E4%BA%9B%E6%98%AF%E9%99%8D%E7%BB%B4%E6%96%B9%E6%B3%95%EF%BC%88%EF%BC%89"><span class="toc-number">1.40.</span> <span class="toc-text">40. 下列哪些是降维方法（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#41-%E4%B8%8B%E5%88%97%E5%93%AA%E4%BA%9B%E6%98%AF%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%88%EF%BC%89"><span class="toc-number">1.41.</span> <span class="toc-text">41. 下列哪些是监督学习算法（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#42-%E4%B8%8B%E5%88%97%E5%93%AA%E4%BA%9B%E6%98%AF%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E7%9A%84%E6%96%B9%E6%B3%95%EF%BC%88%EF%BC%89"><span class="toc-number">1.42.</span> <span class="toc-text">42. 下列哪些是数据预处理的方法（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#43-%E4%B8%8B%E5%88%97%E5%93%AA%E4%BA%9B%E6%98%AF%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9%E7%9A%84%E6%96%B9%E6%B3%95%EF%BC%88%EF%BC%89"><span class="toc-number">1.43.</span> <span class="toc-text">43. 下列哪些是特征选择的方法（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#44-%E4%B8%8B%E5%88%97%E5%93%AA%E4%BA%9B%E6%98%AF%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E7%9A%84%E6%AD%A5%E9%AA%A4%EF%BC%88%EF%BC%89"><span class="toc-number">1.44.</span> <span class="toc-text">44. 下列哪些是数据挖掘的步骤（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#45-%E4%B8%8B%E5%88%97%E5%93%AA%E4%BA%9B%E6%98%AF%E5%B8%B8%E7%94%A8%E7%9A%84%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81%E6%96%B9%E6%B3%95%EF%BC%88%EF%BC%89"><span class="toc-number">1.45.</span> <span class="toc-text">45. 下列哪些是常用的交叉验证方法（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#46-%E4%BB%A5%E4%B8%8B%E5%B1%9E%E4%BA%8E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E4%BB%BB%E5%8A%A1%E7%9A%84%E6%9C%89-%EF%BC%88%EF%BC%89"><span class="toc-number">1.46.</span> <span class="toc-text">46. 以下属于监督学习任务的有:（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#47-%E4%BB%A5%E4%B8%8B%E5%93%AA%E4%BA%9B%E6%96%B9%E6%B3%95%E5%8F%AF%E4%BB%A5%E7%94%A8%E4%BA%8E%E9%99%8D%E4%BD%8E%E8%BF%87%E6%8B%9F%E5%90%88%E9%A3%8E%E9%99%A9-%EF%BC%88%EF%BC%89"><span class="toc-number">1.47.</span> <span class="toc-text">47. 以下哪些方法可以用于降低过拟合风险?（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#48-%E4%BB%A5%E4%B8%8B%E5%85%B3%E4%BA%8E%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA-SVM-%E7%9A%84%E8%AF%B4%E6%B3%95%EF%BC%8C%E6%AD%A3%E7%A1%AE%E7%9A%84%E6%9C%89-%EF%BC%88%EF%BC%89"><span class="toc-number">1.48.</span> <span class="toc-text">48. 以下关于支持向量机(SVM)的说法，正确的有:（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#49-%E4%BB%A5%E4%B8%8B%E5%B1%9E%E4%BA%8E%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9A%84%E6%9C%89-%EF%BC%88%EF%BC%89"><span class="toc-number">1.49.</span> <span class="toc-text">49. 以下属于无监督学习算法的有:（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#50-%E4%BB%A5%E4%B8%8B%E5%93%AA%E4%BA%9B%E6%98%AF%E8%AF%84%E4%BC%B0%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B%E6%80%A7%E8%83%BD%E7%9A%84%E6%8C%87%E6%A0%87-%EF%BC%88%EF%BC%89"><span class="toc-number">1.50.</span> <span class="toc-text">50. 以下哪些是评估分类模型性能的指标?（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#51-%E4%BB%A5%E4%B8%8B%E5%85%B3%E4%BA%8E%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E7%9A%84%E8%AF%B4%E6%B3%95%EF%BC%8C%E6%AD%A3%E7%A1%AE%E7%9A%84%E6%9C%89-%EF%BC%88%EF%BC%89"><span class="toc-number">1.51.</span> <span class="toc-text">51. 以下关于随机森林的说法，正确的有:（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#52-%E4%BB%A5%E4%B8%8B%E5%93%AA%E4%BA%9B%E6%96%B9%E6%B3%95%E5%8F%AF%E4%BB%A5%E7%94%A8%E4%BA%8E%E6%95%B0%E6%8D%AE%E9%99%8D%E7%BB%B4-%EF%BC%88%EF%BC%89"><span class="toc-number">1.52.</span> <span class="toc-text">52. 以下哪些方法可以用于数据降维?（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#53-%E4%BB%A5%E4%B8%8B%E5%85%B3%E4%BA%8E-K-%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95%E7%9A%84%E8%AF%B4%E6%B3%95%EF%BC%8C%E6%AD%A3%E7%A1%AE%E7%9A%84%E6%9C%89-%EF%BC%88%EF%BC%89"><span class="toc-number">1.53.</span> <span class="toc-text">53. 以下关于 K 近邻算法的说法，正确的有:（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#54-%E4%BB%A5%E4%B8%8B%E5%85%B3%E4%BA%8E%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%96%B9%E6%B3%95%EF%BC%8C%E6%AD%A3%E7%A1%AE%E7%9A%84%E6%9C%89-%EF%BC%88%EF%BC%89"><span class="toc-number">1.54.</span> <span class="toc-text">54. 以下关于集成学习的方法，正确的有:（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#55-%E4%BB%A5%E4%B8%8B%E5%85%B3%E4%BA%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%AF%B4%E6%B3%95%EF%BC%8C%E6%AD%A3%E7%A1%AE%E7%9A%84%E6%9C%89-%EF%BC%88%EF%BC%89"><span class="toc-number">1.55.</span> <span class="toc-text">55. 以下关于深度学习的说法，正确的有:（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#56-%E4%BB%A5%E4%B8%8B%E5%93%AA%E4%BA%9B%E6%98%AF%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E7%9A%84%E7%89%B9%E7%82%B9-%EF%BC%88%EF%BC%89"><span class="toc-number">1.56.</span> <span class="toc-text">56. 以下哪些是逻辑回归的特点?（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#57-%E4%BB%A5%E4%B8%8B%E5%85%B3%E4%BA%8E%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95%E7%9A%84%E8%AF%B4%E6%B3%95%EF%BC%8C%E6%AD%A3%E7%A1%AE%E7%9A%84%E6%9C%89-%EF%BC%88%EF%BC%89"><span class="toc-number">1.57.</span> <span class="toc-text">57. 以下关于聚类算法的说法，正确的有:（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#58-%E4%BB%A5%E4%B8%8B%E5%93%AA%E4%BA%9B%E6%96%B9%E6%B3%95%E5%8F%AF%E4%BB%A5%E7%94%A8%E4%BA%8E%E5%A4%84%E7%90%86%E7%B1%BB%E5%88%AB%E4%B8%8D%E5%B9%B3%E8%A1%A1%E9%97%AE%E9%A2%98-%EF%BC%88%EF%BC%89"><span class="toc-number">1.58.</span> <span class="toc-text">58. 以下哪些方法可以用于处理类别不平衡问题?（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#59-%E4%BB%A5%E4%B8%8B%E5%85%B3%E4%BA%8E%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95%E7%9A%84%E8%AF%B4%E6%B3%95%EF%BC%8C%E6%AD%A3%E7%A1%AE%E7%9A%84%E6%9C%89-%EF%BC%88%EF%BC%89"><span class="toc-number">1.59.</span> <span class="toc-text">59. 以下关于梯度下降法的说法，正确的有:（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#60-%E4%B8%8B%E5%88%97%E5%93%AA%E4%BA%9B%E6%98%AF%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%B8%B8%E8%A7%81%E5%BA%94%E7%94%A8%E9%A2%86%E5%9F%9F%EF%BC%88%EF%BC%89"><span class="toc-number">1.60.</span> <span class="toc-text">60. 下列哪些是机器学习的常见应用领域（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#61-%E4%B8%8B%E5%88%97%E5%93%AA%E4%BA%9B%E6%98%AF%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E7%9A%84%E6%96%B9%E6%B3%95%EF%BC%88%EF%BC%89"><span class="toc-number">1.61.</span> <span class="toc-text">61. 下列哪些是数据预处理的方法（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#62-%E4%B8%8B%E5%88%97%E5%93%AA%E4%BA%9B%E6%98%AF%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%88%EF%BC%89"><span class="toc-number">1.62.</span> <span class="toc-text">62. 下列哪些是监督学习算法（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#63-%E4%B8%8B%E5%88%97%E5%93%AA%E4%BA%9B%E6%98%AF%E8%AF%84%E4%BC%B0%E6%A8%A1%E5%9E%8B%E6%80%A7%E8%83%BD%E7%9A%84%E6%8C%87%E6%A0%87%EF%BC%88%EF%BC%89"><span class="toc-number">1.63.</span> <span class="toc-text">63. 下列哪些是评估模型性能的指标（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#64-%E4%B8%8B%E5%88%97%E5%93%AA%E4%BA%9B%E6%98%AF%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B%E7%9A%84%E5%B8%B8%E7%94%A8%E6%96%B9%E6%B3%95%EF%BC%88%EF%BC%89"><span class="toc-number">1.64.</span> <span class="toc-text">64. 下列哪些是特征工程的常用方法（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#65-%E4%B8%8B%E5%88%97%E5%93%AA%E4%BA%9B%E6%98%AF%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%88%EF%BC%89"><span class="toc-number">1.65.</span> <span class="toc-text">65. 下列哪些是集成学习算法（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#66-%E4%B8%8B%E5%88%97%E5%93%AA%E4%BA%9B%E6%98%AF%E8%BF%87%E6%8B%9F%E5%90%88%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%EF%BC%88%EF%BC%89"><span class="toc-number">1.66.</span> <span class="toc-text">66. 下列哪些是过拟合的解决方法（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#67-%E4%B8%8B%E5%88%97%E5%93%AA%E4%BA%9B%E6%98%AF%E9%99%8D%E7%BB%B4%E6%96%B9%E6%B3%95%EF%BC%88%EF%BC%89"><span class="toc-number">1.67.</span> <span class="toc-text">67. 下列哪些是降维方法（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#68-%E4%B8%8B%E5%88%97%E5%93%AA%E4%BA%9B%E6%98%AF%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E7%9A%84%E6%AD%A5%E9%AA%A4%EF%BC%88%EF%BC%89"><span class="toc-number">1.68.</span> <span class="toc-text">68. 下列哪些是数据挖掘的步骤（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#69-%E4%B8%8B%E5%88%97%E5%93%AA%E4%BA%9B%E6%98%AF%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9%E7%9A%84%E6%96%B9%E6%B3%95%EF%BC%88%EF%BC%89"><span class="toc-number">1.69.</span> <span class="toc-text">69. 下列哪些是特征选择的方法（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#70-%E4%B8%8B%E5%88%97%E5%93%AA%E4%BA%9B%E6%98%AF%E5%B8%B8%E7%94%A8%E7%9A%84%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B%E6%96%B9%E6%B3%95%EF%BC%88%EF%BC%89"><span class="toc-number">1.70.</span> <span class="toc-text">70. 下列哪些是常用的特征工程方法（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#71-%E4%B8%8B%E5%88%97%E5%93%AA%E4%BA%9B%E6%98%AF%E8%AF%84%E4%BC%B0%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B%E6%80%A7%E8%83%BD%E7%9A%84%E6%8C%87%E6%A0%87%EF%BC%88%EF%BC%89"><span class="toc-number">1.71.</span> <span class="toc-text">71. 下列哪些是评估分类模型性能的指标（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#72-%E4%B8%8B%E5%88%97%E5%93%AA%E4%BA%9B%E6%98%AF%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%88%EF%BC%89"><span class="toc-number">1.72.</span> <span class="toc-text">72. 下列哪些是集成学习算法（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#73-%E4%B8%8B%E5%88%97%E5%93%AA%E4%BA%9B%E6%98%AF%E8%BF%87%E6%8B%9F%E5%90%88%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%EF%BC%88%EF%BC%89"><span class="toc-number">1.73.</span> <span class="toc-text">73. 下列哪些是过拟合的解决方法（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#74-%E4%B8%8B%E5%88%97%E5%93%AA%E4%BA%9B%E6%98%AF%E9%99%8D%E7%BB%B4%E6%96%B9%E6%B3%95%EF%BC%88%EF%BC%89"><span class="toc-number">1.74.</span> <span class="toc-text">74. 下列哪些是降维方法（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#75-%E4%B8%8B%E5%88%97%E5%93%AA%E4%BA%9B%E6%98%AF%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%88%EF%BC%89"><span class="toc-number">1.75.</span> <span class="toc-text">75. 下列哪些是监督学习算法（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#76-%E4%B8%8B%E5%88%97%E5%93%AA%E4%BA%9B%E6%98%AF%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E7%9A%84%E6%96%B9%E6%B3%95%EF%BC%88%EF%BC%89"><span class="toc-number">1.76.</span> <span class="toc-text">76. 下列哪些是数据预处理的方法（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#77-%E4%B8%8B%E5%88%97%E5%93%AA%E4%BA%9B%E6%98%AF%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9%E7%9A%84%E6%96%B9%E6%B3%95%EF%BC%88%EF%BC%89"><span class="toc-number">1.77.</span> <span class="toc-text">77. 下列哪些是特征选择的方法（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#78-%E4%B8%8B%E5%88%97%E5%93%AA%E4%BA%9B%E6%98%AF%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E7%9A%84%E6%AD%A5%E9%AA%A4%EF%BC%88%EF%BC%89"><span class="toc-number">1.78.</span> <span class="toc-text">78. 下列哪些是数据挖掘的步骤（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#79-%E4%B8%8B%E5%88%97%E5%93%AA%E4%BA%9B%E6%98%AF%E5%B8%B8%E7%94%A8%E7%9A%84%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81%E6%96%B9%E6%B3%95%EF%BC%88%EF%BC%89"><span class="toc-number">1.79.</span> <span class="toc-text">79. 下列哪些是常用的交叉验证方法（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#80-%E4%BB%A5%E4%B8%8B%E5%B1%9E%E4%BA%8E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E4%BB%BB%E5%8A%A1%E7%9A%84%E6%9C%89-%EF%BC%88%EF%BC%89"><span class="toc-number">1.80.</span> <span class="toc-text">80. 以下属于监督学习任务的有:（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#81-%E4%BB%A5%E4%B8%8B%E5%93%AA%E4%BA%9B%E6%96%B9%E6%B3%95%E5%8F%AF%E4%BB%A5%E7%94%A8%E4%BA%8E%E9%99%8D%E4%BD%8E%E8%BF%87%E6%8B%9F%E5%90%88%E9%A3%8E%E9%99%A9-%EF%BC%88%EF%BC%89"><span class="toc-number">1.81.</span> <span class="toc-text">81. 以下哪些方法可以用于降低过拟合风险?（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#82-%E4%BB%A5%E4%B8%8B%E5%85%B3%E4%BA%8E%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA-SVM-%E7%9A%84%E8%AF%B4%E6%B3%95%EF%BC%8C%E6%AD%A3%E7%A1%AE%E7%9A%84%E6%9C%89-%EF%BC%88%EF%BC%89"><span class="toc-number">1.82.</span> <span class="toc-text">82. 以下关于支持向量机(SVM)的说法，正确的有:（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#83-%E4%BB%A5%E4%B8%8B%E5%B1%9E%E4%BA%8E%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9A%84%E6%9C%89-%EF%BC%88%EF%BC%89"><span class="toc-number">1.83.</span> <span class="toc-text">83. 以下属于无监督学习算法的有:（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#84-%E4%BB%A5%E4%B8%8B%E5%93%AA%E4%BA%9B%E6%98%AF%E8%AF%84%E4%BC%B0%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B%E6%80%A7%E8%83%BD%E7%9A%84%E6%8C%87%E6%A0%87-%EF%BC%88%EF%BC%89"><span class="toc-number">1.84.</span> <span class="toc-text">84. 以下哪些是评估分类模型性能的指标?（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#85-%E4%BB%A5%E4%B8%8B%E5%85%B3%E4%BA%8E%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E7%9A%84%E8%AF%B4%E6%B3%95%EF%BC%8C%E6%AD%A3%E7%A1%AE%E7%9A%84%E6%9C%89-%EF%BC%88%EF%BC%89"><span class="toc-number">1.85.</span> <span class="toc-text">85. 以下关于随机森林的说法，正确的有:（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#86-%E4%BB%A5%E4%B8%8B%E5%93%AA%E4%BA%9B%E6%96%B9%E6%B3%95%E5%8F%AF%E4%BB%A5%E7%94%A8%E4%BA%8E%E6%95%B0%E6%8D%AE%E9%99%8D%E7%BB%B4-%EF%BC%88%EF%BC%89"><span class="toc-number">1.86.</span> <span class="toc-text">86. 以下哪些方法可以用于数据降维?（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#87-%E4%BB%A5%E4%B8%8B%E5%85%B3%E4%BA%8E-K-%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95%E7%9A%84%E8%AF%B4%E6%B3%95%EF%BC%8C%E6%AD%A3%E7%A1%AE%E7%9A%84%E6%9C%89-%EF%BC%88%EF%BC%89"><span class="toc-number">1.87.</span> <span class="toc-text">87. 以下关于 K 近邻算法的说法，正确的有:（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#88-%E4%BB%A5%E4%B8%8B%E5%85%B3%E4%BA%8E%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%96%B9%E6%B3%95%EF%BC%8C%E6%AD%A3%E7%A1%AE%E7%9A%84%E6%9C%89-%EF%BC%88%EF%BC%89"><span class="toc-number">1.88.</span> <span class="toc-text">88. 以下关于集成学习的方法，正确的有:（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#89-%E4%BB%A5%E4%B8%8B%E5%85%B3%E4%BA%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%AF%B4%E6%B3%95%EF%BC%8C%E6%AD%A3%E7%A1%AE%E7%9A%84%E6%9C%89-%EF%BC%88%EF%BC%89"><span class="toc-number">1.89.</span> <span class="toc-text">89. 以下关于深度学习的说法，正确的有:（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#90-%E4%BB%A5%E4%B8%8B%E5%93%AA%E4%BA%9B%E6%98%AF%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E7%9A%84%E7%89%B9%E7%82%B9-%EF%BC%88%EF%BC%89"><span class="toc-number">1.90.</span> <span class="toc-text">90. 以下哪些是逻辑回归的特点?（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#91-%E4%BB%A5%E4%B8%8B%E5%85%B3%E4%BA%8E%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95%E7%9A%84%E8%AF%B4%E6%B3%95%EF%BC%8C%E6%AD%A3%E7%A1%AE%E7%9A%84%E6%9C%89-%EF%BC%88%EF%BC%89"><span class="toc-number">1.91.</span> <span class="toc-text">91. 以下关于聚类算法的说法，正确的有:（）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#92-%E4%BB%A5%E4%B8%8B%E5%93%AA%E4%BA%9B%E6%96%B9%E6%B3%95%E5%8F%AF%E4%BB%A5%E7%94%A8%E4%BA%8E%E5%A4%84%E7%90%86%E7%B1%BB%E5%88%AB%E4%B8%8D%E5%B9%B3%E8%A1%A1%E9%97%AE%E9%A2%98-%EF%BC%88%EF%BC%89"><span class="toc-number">1.92.</span> <span class="toc-text">92. 以下哪些方法可以用于处理类别不平衡问题?（）</span></a></li></ol></li></ol></div></div><footer><nobr><span class="icp-title">GZHU</span><span class="icp-content">193001-0001</span></nobr><br><nobr><span class="icp-title">OUTPOST</span><span class="icp-content">169-2025-0331</span></nobr><br><nobr>Published with <a target="_blank" rel="noopener" href="http://hexo.io">Hexo</a></nobr><wbr><nobr> Theme <a target="_blank" rel="noopener" href="https://github.com/Yue-plus/hexo-theme-arknights">Arknights</a></nobr><wbr><nobr> by <a target="_blank" rel="noopener" href="https://github.com/Yue-plus">Yue_plus</a></nobr></footer></aside></main><canvas id="canvas-dust"></canvas></body></html>